fn (%model.query_embed.weight: Tensor[(100, 256), float32], %model.transformer.decoder.layers.0.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.0.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.0.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.0.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.0.norm1.weight: Tensor[(256), float32], %model.transformer.decoder.layers.0.norm1.bias: Tensor[(256), float32], %input: Tensor[(1, 3, 750, 800), float32], %model.backbone.0.body.conv1.weight: Tensor[(64, 3, 7, 7), float32], %model.backbone.0.body.bn1.weight: Tensor[(64), float32], %model.backbone.0.body.bn1.running_var: Tensor[(64), float32], %model.backbone.0.body.bn1.bias: Tensor[(64), float32], %model.backbone.0.body.bn1.running_mean: Tensor[(64), float32], %model.backbone.0.body.layer1.0.conv1.weight: Tensor[(64, 64, 1, 1), float32], %model.backbone.0.body.layer1.0.bn1.weight: Tensor[(64), float32], %model.backbone.0.body.layer1.0.bn1.running_var: Tensor[(64), float32], %model.backbone.0.body.layer1.0.bn1.bias: Tensor[(64), float32], %model.backbone.0.body.layer1.0.bn1.running_mean: Tensor[(64), float32], %model.backbone.0.body.layer1.0.conv2.weight: Tensor[(64, 64, 3, 3), float32], %model.backbone.0.body.layer1.0.bn2.weight: Tensor[(64), float32], %model.backbone.0.body.layer1.0.bn2.running_var: Tensor[(64), float32], %model.backbone.0.body.layer1.0.bn2.bias: Tensor[(64), float32], %model.backbone.0.body.layer1.0.bn2.running_mean: Tensor[(64), float32], %model.backbone.0.body.layer1.0.conv3.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.0.body.layer1.0.bn3.weight: Tensor[(256), float32], %model.backbone.0.body.layer1.0.bn3.running_var: Tensor[(256), float32], %model.backbone.0.body.layer1.0.bn3.bias: Tensor[(256), float32], %model.backbone.0.body.layer1.0.bn3.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer1.0.downsample.0.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.0.body.layer1.0.downsample.1.weight: Tensor[(256), float32], %model.backbone.0.body.layer1.0.downsample.1.running_var: Tensor[(256), float32], %model.backbone.0.body.layer1.0.downsample.1.bias: Tensor[(256), float32], %model.backbone.0.body.layer1.0.downsample.1.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer1.1.conv1.weight: Tensor[(64, 256, 1, 1), float32], %model.backbone.0.body.layer1.1.bn1.weight: Tensor[(64), float32], %model.backbone.0.body.layer1.1.bn1.running_var: Tensor[(64), float32], %model.backbone.0.body.layer1.1.bn1.bias: Tensor[(64), float32], %model.backbone.0.body.layer1.1.bn1.running_mean: Tensor[(64), float32], %model.backbone.0.body.layer1.1.conv2.weight: Tensor[(64, 64, 3, 3), float32], %model.backbone.0.body.layer1.1.bn2.weight: Tensor[(64), float32], %model.backbone.0.body.layer1.1.bn2.running_var: Tensor[(64), float32], %model.backbone.0.body.layer1.1.bn2.bias: Tensor[(64), float32], %model.backbone.0.body.layer1.1.bn2.running_mean: Tensor[(64), float32], %model.backbone.0.body.layer1.1.conv3.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.0.body.layer1.1.bn3.weight: Tensor[(256), float32], %model.backbone.0.body.layer1.1.bn3.running_var: Tensor[(256), float32], %model.backbone.0.body.layer1.1.bn3.bias: Tensor[(256), float32], %model.backbone.0.body.layer1.1.bn3.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer1.2.conv1.weight: Tensor[(64, 256, 1, 1), float32], %model.backbone.0.body.layer1.2.bn1.weight: Tensor[(64), float32], %model.backbone.0.body.layer1.2.bn1.running_var: Tensor[(64), float32], %model.backbone.0.body.layer1.2.bn1.bias: Tensor[(64), float32], %model.backbone.0.body.layer1.2.bn1.running_mean: Tensor[(64), float32], %model.backbone.0.body.layer1.2.conv2.weight: Tensor[(64, 64, 3, 3), float32], %model.backbone.0.body.layer1.2.bn2.weight: Tensor[(64), float32], %model.backbone.0.body.layer1.2.bn2.running_var: Tensor[(64), float32], %model.backbone.0.body.layer1.2.bn2.bias: Tensor[(64), float32], %model.backbone.0.body.layer1.2.bn2.running_mean: Tensor[(64), float32], %model.backbone.0.body.layer1.2.conv3.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.0.body.layer1.2.bn3.weight: Tensor[(256), float32], %model.backbone.0.body.layer1.2.bn3.running_var: Tensor[(256), float32], %model.backbone.0.body.layer1.2.bn3.bias: Tensor[(256), float32], %model.backbone.0.body.layer1.2.bn3.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer2.0.conv1.weight: Tensor[(128, 256, 1, 1), float32], %model.backbone.0.body.layer2.0.bn1.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.0.bn1.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.0.bn1.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.0.bn1.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.0.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.0.body.layer2.0.bn2.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.0.bn2.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.0.bn2.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.0.bn2.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.0.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.0.body.layer2.0.bn3.weight: Tensor[(512), float32], %model.backbone.0.body.layer2.0.bn3.running_var: Tensor[(512), float32], %model.backbone.0.body.layer2.0.bn3.bias: Tensor[(512), float32], %model.backbone.0.body.layer2.0.bn3.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer2.0.downsample.0.weight: Tensor[(512, 256, 1, 1), float32], %model.backbone.0.body.layer2.0.downsample.1.weight: Tensor[(512), float32], %model.backbone.0.body.layer2.0.downsample.1.running_var: Tensor[(512), float32], %model.backbone.0.body.layer2.0.downsample.1.bias: Tensor[(512), float32], %model.backbone.0.body.layer2.0.downsample.1.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer2.1.conv1.weight: Tensor[(128, 512, 1, 1), float32], %model.backbone.0.body.layer2.1.bn1.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.1.bn1.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.1.bn1.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.1.bn1.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.1.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.0.body.layer2.1.bn2.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.1.bn2.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.1.bn2.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.1.bn2.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.1.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.0.body.layer2.1.bn3.weight: Tensor[(512), float32], %model.backbone.0.body.layer2.1.bn3.running_var: Tensor[(512), float32], %model.backbone.0.body.layer2.1.bn3.bias: Tensor[(512), float32], %model.backbone.0.body.layer2.1.bn3.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer2.2.conv1.weight: Tensor[(128, 512, 1, 1), float32], %model.backbone.0.body.layer2.2.bn1.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.2.bn1.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.2.bn1.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.2.bn1.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.2.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.0.body.layer2.2.bn2.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.2.bn2.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.2.bn2.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.2.bn2.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.2.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.0.body.layer2.2.bn3.weight: Tensor[(512), float32], %model.backbone.0.body.layer2.2.bn3.running_var: Tensor[(512), float32], %model.backbone.0.body.layer2.2.bn3.bias: Tensor[(512), float32], %model.backbone.0.body.layer2.2.bn3.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer2.3.conv1.weight: Tensor[(128, 512, 1, 1), float32], %model.backbone.0.body.layer2.3.bn1.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.3.bn1.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.3.bn1.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.3.bn1.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.3.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.0.body.layer2.3.bn2.weight: Tensor[(128), float32], %model.backbone.0.body.layer2.3.bn2.running_var: Tensor[(128), float32], %model.backbone.0.body.layer2.3.bn2.bias: Tensor[(128), float32], %model.backbone.0.body.layer2.3.bn2.running_mean: Tensor[(128), float32], %model.backbone.0.body.layer2.3.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.0.body.layer2.3.bn3.weight: Tensor[(512), float32], %model.backbone.0.body.layer2.3.bn3.running_var: Tensor[(512), float32], %model.backbone.0.body.layer2.3.bn3.bias: Tensor[(512), float32], %model.backbone.0.body.layer2.3.bn3.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer3.0.conv1.weight: Tensor[(256, 512, 1, 1), float32], %model.backbone.0.body.layer3.0.bn1.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.0.bn1.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.0.bn1.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.0.bn1.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.0.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.0.body.layer3.0.bn2.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.0.bn2.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.0.bn2.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.0.bn2.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.0.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.0.body.layer3.0.bn3.weight: Tensor[(1024), float32], %model.backbone.0.body.layer3.0.bn3.running_var: Tensor[(1024), float32], %model.backbone.0.body.layer3.0.bn3.bias: Tensor[(1024), float32], %model.backbone.0.body.layer3.0.bn3.running_mean: Tensor[(1024), float32], %model.backbone.0.body.layer3.0.downsample.0.weight: Tensor[(1024, 512, 1, 1), float32], %model.backbone.0.body.layer3.0.downsample.1.weight: Tensor[(1024), float32], %model.backbone.0.body.layer3.0.downsample.1.running_var: Tensor[(1024), float32], %model.backbone.0.body.layer3.0.downsample.1.bias: Tensor[(1024), float32], %model.backbone.0.body.layer3.0.downsample.1.running_mean: Tensor[(1024), float32], %model.backbone.0.body.layer3.1.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.0.body.layer3.1.bn1.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.1.bn1.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.1.bn1.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.1.bn1.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.1.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.0.body.layer3.1.bn2.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.1.bn2.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.1.bn2.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.1.bn2.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.1.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.0.body.layer3.1.bn3.weight: Tensor[(1024), float32], %model.backbone.0.body.layer3.1.bn3.running_var: Tensor[(1024), float32], %model.backbone.0.body.layer3.1.bn3.bias: Tensor[(1024), float32], %model.backbone.0.body.layer3.1.bn3.running_mean: Tensor[(1024), float32], %model.backbone.0.body.layer3.2.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.0.body.layer3.2.bn1.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.2.bn1.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.2.bn1.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.2.bn1.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.2.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.0.body.layer3.2.bn2.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.2.bn2.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.2.bn2.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.2.bn2.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.2.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.0.body.layer3.2.bn3.weight: Tensor[(1024), float32], %model.backbone.0.body.layer3.2.bn3.running_var: Tensor[(1024), float32], %model.backbone.0.body.layer3.2.bn3.bias: Tensor[(1024), float32], %model.backbone.0.body.layer3.2.bn3.running_mean: Tensor[(1024), float32], %model.backbone.0.body.layer3.3.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.0.body.layer3.3.bn1.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.3.bn1.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.3.bn1.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.3.bn1.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.3.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.0.body.layer3.3.bn2.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.3.bn2.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.3.bn2.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.3.bn2.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.3.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.0.body.layer3.3.bn3.weight: Tensor[(1024), float32], %model.backbone.0.body.layer3.3.bn3.running_var: Tensor[(1024), float32], %model.backbone.0.body.layer3.3.bn3.bias: Tensor[(1024), float32], %model.backbone.0.body.layer3.3.bn3.running_mean: Tensor[(1024), float32], %model.backbone.0.body.layer3.4.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.0.body.layer3.4.bn1.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.4.bn1.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.4.bn1.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.4.bn1.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.4.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.0.body.layer3.4.bn2.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.4.bn2.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.4.bn2.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.4.bn2.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.4.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.0.body.layer3.4.bn3.weight: Tensor[(1024), float32], %model.backbone.0.body.layer3.4.bn3.running_var: Tensor[(1024), float32], %model.backbone.0.body.layer3.4.bn3.bias: Tensor[(1024), float32], %model.backbone.0.body.layer3.4.bn3.running_mean: Tensor[(1024), float32], %model.backbone.0.body.layer3.5.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.0.body.layer3.5.bn1.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.5.bn1.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.5.bn1.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.5.bn1.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.5.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.0.body.layer3.5.bn2.weight: Tensor[(256), float32], %model.backbone.0.body.layer3.5.bn2.running_var: Tensor[(256), float32], %model.backbone.0.body.layer3.5.bn2.bias: Tensor[(256), float32], %model.backbone.0.body.layer3.5.bn2.running_mean: Tensor[(256), float32], %model.backbone.0.body.layer3.5.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.0.body.layer3.5.bn3.weight: Tensor[(1024), float32], %model.backbone.0.body.layer3.5.bn3.running_var: Tensor[(1024), float32], %model.backbone.0.body.layer3.5.bn3.bias: Tensor[(1024), float32], %model.backbone.0.body.layer3.5.bn3.running_mean: Tensor[(1024), float32], %model.backbone.0.body.layer4.0.conv1.weight: Tensor[(512, 1024, 1, 1), float32], %model.backbone.0.body.layer4.0.bn1.weight: Tensor[(512), float32], %model.backbone.0.body.layer4.0.bn1.running_var: Tensor[(512), float32], %model.backbone.0.body.layer4.0.bn1.bias: Tensor[(512), float32], %model.backbone.0.body.layer4.0.bn1.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer4.0.conv2.weight: Tensor[(512, 512, 3, 3), float32], %model.backbone.0.body.layer4.0.bn2.weight: Tensor[(512), float32], %model.backbone.0.body.layer4.0.bn2.running_var: Tensor[(512), float32], %model.backbone.0.body.layer4.0.bn2.bias: Tensor[(512), float32], %model.backbone.0.body.layer4.0.bn2.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer4.0.conv3.weight: Tensor[(2048, 512, 1, 1), float32], %model.backbone.0.body.layer4.0.bn3.weight: Tensor[(2048), float32], %model.backbone.0.body.layer4.0.bn3.running_var: Tensor[(2048), float32], %model.backbone.0.body.layer4.0.bn3.bias: Tensor[(2048), float32], %model.backbone.0.body.layer4.0.bn3.running_mean: Tensor[(2048), float32], %model.backbone.0.body.layer4.0.downsample.0.weight: Tensor[(2048, 1024, 1, 1), float32], %model.backbone.0.body.layer4.0.downsample.1.weight: Tensor[(2048), float32], %model.backbone.0.body.layer4.0.downsample.1.running_var: Tensor[(2048), float32], %model.backbone.0.body.layer4.0.downsample.1.bias: Tensor[(2048), float32], %model.backbone.0.body.layer4.0.downsample.1.running_mean: Tensor[(2048), float32], %model.backbone.0.body.layer4.1.conv1.weight: Tensor[(512, 2048, 1, 1), float32], %model.backbone.0.body.layer4.1.bn1.weight: Tensor[(512), float32], %model.backbone.0.body.layer4.1.bn1.running_var: Tensor[(512), float32], %model.backbone.0.body.layer4.1.bn1.bias: Tensor[(512), float32], %model.backbone.0.body.layer4.1.bn1.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer4.1.conv2.weight: Tensor[(512, 512, 3, 3), float32], %model.backbone.0.body.layer4.1.bn2.weight: Tensor[(512), float32], %model.backbone.0.body.layer4.1.bn2.running_var: Tensor[(512), float32], %model.backbone.0.body.layer4.1.bn2.bias: Tensor[(512), float32], %model.backbone.0.body.layer4.1.bn2.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer4.1.conv3.weight: Tensor[(2048, 512, 1, 1), float32], %model.backbone.0.body.layer4.1.bn3.weight: Tensor[(2048), float32], %model.backbone.0.body.layer4.1.bn3.running_var: Tensor[(2048), float32], %model.backbone.0.body.layer4.1.bn3.bias: Tensor[(2048), float32], %model.backbone.0.body.layer4.1.bn3.running_mean: Tensor[(2048), float32], %model.backbone.0.body.layer4.2.conv1.weight: Tensor[(512, 2048, 1, 1), float32], %model.backbone.0.body.layer4.2.bn1.weight: Tensor[(512), float32], %model.backbone.0.body.layer4.2.bn1.running_var: Tensor[(512), float32], %model.backbone.0.body.layer4.2.bn1.bias: Tensor[(512), float32], %model.backbone.0.body.layer4.2.bn1.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer4.2.conv2.weight: Tensor[(512, 512, 3, 3), float32], %model.backbone.0.body.layer4.2.bn2.weight: Tensor[(512), float32], %model.backbone.0.body.layer4.2.bn2.running_var: Tensor[(512), float32], %model.backbone.0.body.layer4.2.bn2.bias: Tensor[(512), float32], %model.backbone.0.body.layer4.2.bn2.running_mean: Tensor[(512), float32], %model.backbone.0.body.layer4.2.conv3.weight: Tensor[(2048, 512, 1, 1), float32], %model.backbone.0.body.layer4.2.bn3.weight: Tensor[(2048), float32], %model.backbone.0.body.layer4.2.bn3.running_var: Tensor[(2048), float32], %model.backbone.0.body.layer4.2.bn3.bias: Tensor[(2048), float32], %model.backbone.0.body.layer4.2.bn3.running_mean: Tensor[(2048), float32], %model.transformer.decoder.layers.0.multihead_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.0.multihead_attn.in_proj_bias: Tensor[(768), float32], %model.input_proj.weight: Tensor[(256, 2048, 1, 1), float32], %model.input_proj.bias: Tensor[(256), float32], %model.transformer.encoder.layers.0.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.encoder.layers.0.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.encoder.layers.0.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.encoder.layers.0.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.encoder.layers.0.norm1.weight: Tensor[(256), float32], %model.transformer.encoder.layers.0.norm1.bias: Tensor[(256), float32], %model.transformer.encoder.layers.0.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.encoder.layers.0.linear1.bias: Tensor[(2048), float32], %model.transformer.encoder.layers.0.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.encoder.layers.0.linear2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.0.norm2.weight: Tensor[(256), float32], %model.transformer.encoder.layers.0.norm2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.1.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.encoder.layers.1.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.encoder.layers.1.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.encoder.layers.1.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.encoder.layers.1.norm1.weight: Tensor[(256), float32], %model.transformer.encoder.layers.1.norm1.bias: Tensor[(256), float32], %model.transformer.encoder.layers.1.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.encoder.layers.1.linear1.bias: Tensor[(2048), float32], %model.transformer.encoder.layers.1.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.encoder.layers.1.linear2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.1.norm2.weight: Tensor[(256), float32], %model.transformer.encoder.layers.1.norm2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.2.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.encoder.layers.2.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.encoder.layers.2.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.encoder.layers.2.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.encoder.layers.2.norm1.weight: Tensor[(256), float32], %model.transformer.encoder.layers.2.norm1.bias: Tensor[(256), float32], %model.transformer.encoder.layers.2.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.encoder.layers.2.linear1.bias: Tensor[(2048), float32], %model.transformer.encoder.layers.2.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.encoder.layers.2.linear2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.2.norm2.weight: Tensor[(256), float32], %model.transformer.encoder.layers.2.norm2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.3.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.encoder.layers.3.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.encoder.layers.3.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.encoder.layers.3.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.encoder.layers.3.norm1.weight: Tensor[(256), float32], %model.transformer.encoder.layers.3.norm1.bias: Tensor[(256), float32], %model.transformer.encoder.layers.3.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.encoder.layers.3.linear1.bias: Tensor[(2048), float32], %model.transformer.encoder.layers.3.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.encoder.layers.3.linear2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.3.norm2.weight: Tensor[(256), float32], %model.transformer.encoder.layers.3.norm2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.4.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.encoder.layers.4.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.encoder.layers.4.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.encoder.layers.4.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.encoder.layers.4.norm1.weight: Tensor[(256), float32], %model.transformer.encoder.layers.4.norm1.bias: Tensor[(256), float32], %model.transformer.encoder.layers.4.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.encoder.layers.4.linear1.bias: Tensor[(2048), float32], %model.transformer.encoder.layers.4.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.encoder.layers.4.linear2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.4.norm2.weight: Tensor[(256), float32], %model.transformer.encoder.layers.4.norm2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.5.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.encoder.layers.5.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.encoder.layers.5.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.encoder.layers.5.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.encoder.layers.5.norm1.weight: Tensor[(256), float32], %model.transformer.encoder.layers.5.norm1.bias: Tensor[(256), float32], %model.transformer.encoder.layers.5.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.encoder.layers.5.linear1.bias: Tensor[(2048), float32], %model.transformer.encoder.layers.5.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.encoder.layers.5.linear2.bias: Tensor[(256), float32], %model.transformer.encoder.layers.5.norm2.weight: Tensor[(256), float32], %model.transformer.encoder.layers.5.norm2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.0.multihead_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.0.multihead_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.0.norm2.weight: Tensor[(256), float32], %model.transformer.decoder.layers.0.norm2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.0.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.decoder.layers.0.linear1.bias: Tensor[(2048), float32], %model.transformer.decoder.layers.0.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.decoder.layers.0.linear2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.0.norm3.weight: Tensor[(256), float32], %model.transformer.decoder.layers.0.norm3.bias: Tensor[(256), float32], %model.transformer.decoder.norm.weight: Tensor[(256), float32], %model.transformer.decoder.norm.bias: Tensor[(256), float32], %model.transformer.decoder.layers.1.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.1.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.1.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.1.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.1.norm1.weight: Tensor[(256), float32], %model.transformer.decoder.layers.1.norm1.bias: Tensor[(256), float32], %model.transformer.decoder.layers.1.multihead_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.1.multihead_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.1.multihead_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.1.multihead_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.1.norm2.weight: Tensor[(256), float32], %model.transformer.decoder.layers.1.norm2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.1.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.decoder.layers.1.linear1.bias: Tensor[(2048), float32], %model.transformer.decoder.layers.1.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.decoder.layers.1.linear2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.1.norm3.weight: Tensor[(256), float32], %model.transformer.decoder.layers.1.norm3.bias: Tensor[(256), float32], %model.transformer.decoder.layers.2.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.2.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.2.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.2.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.2.norm1.weight: Tensor[(256), float32], %model.transformer.decoder.layers.2.norm1.bias: Tensor[(256), float32], %model.transformer.decoder.layers.2.multihead_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.2.multihead_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.2.multihead_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.2.multihead_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.2.norm2.weight: Tensor[(256), float32], %model.transformer.decoder.layers.2.norm2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.2.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.decoder.layers.2.linear1.bias: Tensor[(2048), float32], %model.transformer.decoder.layers.2.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.decoder.layers.2.linear2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.2.norm3.weight: Tensor[(256), float32], %model.transformer.decoder.layers.2.norm3.bias: Tensor[(256), float32], %model.transformer.decoder.layers.3.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.3.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.3.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.3.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.3.norm1.weight: Tensor[(256), float32], %model.transformer.decoder.layers.3.norm1.bias: Tensor[(256), float32], %model.transformer.decoder.layers.3.multihead_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.3.multihead_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.3.multihead_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.3.multihead_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.3.norm2.weight: Tensor[(256), float32], %model.transformer.decoder.layers.3.norm2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.3.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.decoder.layers.3.linear1.bias: Tensor[(2048), float32], %model.transformer.decoder.layers.3.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.decoder.layers.3.linear2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.3.norm3.weight: Tensor[(256), float32], %model.transformer.decoder.layers.3.norm3.bias: Tensor[(256), float32], %model.transformer.decoder.layers.4.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.4.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.4.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.4.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.4.norm1.weight: Tensor[(256), float32], %model.transformer.decoder.layers.4.norm1.bias: Tensor[(256), float32], %model.transformer.decoder.layers.4.multihead_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.4.multihead_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.4.multihead_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.4.multihead_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.4.norm2.weight: Tensor[(256), float32], %model.transformer.decoder.layers.4.norm2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.4.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.decoder.layers.4.linear1.bias: Tensor[(2048), float32], %model.transformer.decoder.layers.4.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.decoder.layers.4.linear2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.4.norm3.weight: Tensor[(256), float32], %model.transformer.decoder.layers.4.norm3.bias: Tensor[(256), float32], %model.transformer.decoder.layers.5.self_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.5.self_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.5.self_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.5.self_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.5.norm1.weight: Tensor[(256), float32], %model.transformer.decoder.layers.5.norm1.bias: Tensor[(256), float32], %model.transformer.decoder.layers.5.multihead_attn.in_proj_weight: Tensor[(768, 256), float32], %model.transformer.decoder.layers.5.multihead_attn.in_proj_bias: Tensor[(768), float32], %model.transformer.decoder.layers.5.multihead_attn.out_proj.weight: Tensor[(256, 256), float32], %model.transformer.decoder.layers.5.multihead_attn.out_proj.bias: Tensor[(256), float32], %model.transformer.decoder.layers.5.norm2.weight: Tensor[(256), float32], %model.transformer.decoder.layers.5.norm2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.5.linear1.weight: Tensor[(2048, 256), float32], %model.transformer.decoder.layers.5.linear1.bias: Tensor[(2048), float32], %model.transformer.decoder.layers.5.linear2.weight: Tensor[(256, 2048), float32], %model.transformer.decoder.layers.5.linear2.bias: Tensor[(256), float32], %model.transformer.decoder.layers.5.norm3.weight: Tensor[(256), float32], %model.transformer.decoder.layers.5.norm3.bias: Tensor[(256), float32], %model.class_embed.weight: Tensor[(92, 256), float32], %model.class_embed.bias: Tensor[(92), float32], %model.bbox_embed.layers.0.weight: Tensor[(256, 256), float32], %model.bbox_embed.layers.0.bias: Tensor[(256), float32], %model.bbox_embed.layers.1.weight: Tensor[(256, 256), float32], %model.bbox_embed.layers.1.bias: Tensor[(256), float32], %model.bbox_embed.layers.2.weight: Tensor[(4, 256), float32], %model.bbox_embed.layers.2.bias: Tensor[(4), float32]) {
  %0 = expand_dims(%model.query_embed.weight, axis=1);
  %1 = tile(%0, reps=[1, 1, 1]);
  %2 = zeros_like(%1);
  %3 = add(%2, %1);
  %4 = reshape(%3, newshape=[-1, 1, 256]);
  %5 = strided_slice(%model.transformer.decoder.layers.0.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %6 = strided_slice(%5, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %7 = transpose(%6, axes=[1, 0]);
  %8 = reshape(%7, newshape=[-1, 256, 256]);
  %9 = broadcast_to(%8, meta[relay.attrs.InitOpAttrs][0]);
  %10 = transpose(%9, axes=[0, 2, 1]);
  %11 = nn.batch_matmul(%4, %10);
  %12 = reshape(%11, newshape=[100, 1, 256]);
  %13 = strided_slice(%model.transformer.decoder.layers.0.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %14 = add(%12, %13);
  %15 = multiply(%14, 0.176777f);
  %16 = copy(%15);
  %17 = reshape(%16, newshape=[100, 8, 32]);
  %18 = transpose(%17, axes=[1, 0, 2]);
  %19 = reshape(%18, newshape=[-1, 100, 32]);
  %20 = reshape(%3, newshape=[-1, 1, 256]);
  %21 = strided_slice(%model.transformer.decoder.layers.0.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %22 = strided_slice(%21, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %23 = transpose(%22, axes=[1, 0]);
  %24 = reshape(%23, newshape=[-1, 256, 256]);
  %25 = broadcast_to(%24, meta[relay.attrs.InitOpAttrs][1]);
  %26 = transpose(%25, axes=[0, 2, 1]);
  %27 = nn.batch_matmul(%20, %26);
  %28 = reshape(%27, newshape=[100, 1, 256]);
  %29 = strided_slice(%model.transformer.decoder.layers.0.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %30 = add(%28, %29);
  %31 = copy(%30);
  %32 = reshape(%31, newshape=[-1, 8, 32]);
  %33 = transpose(%32, axes=[1, 0, 2]);
  %34 = transpose(%33, axes=[0, 2, 1]);
  %35 = reshape(%34, newshape=[-1, 32, 100]);
  %36 = transpose(%35, axes=[0, 2, 1]);
  %37 = nn.batch_matmul(%19, %36);
  %38 = reshape(%37, newshape=[8, 100, 100]);
  %39 = nn.softmax(%38);
  %40 = nn.dropout(%39, rate=0.1f);
  %41 = %40.0;
  %42 = reshape(%41, newshape=[-1, 100, 100]);
  %43 = reshape(%2, newshape=[-1, 1, 256]);
  %44 = strided_slice(%model.transformer.decoder.layers.0.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %45 = strided_slice(%44, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %46 = transpose(%45, axes=[1, 0]);
  %47 = reshape(%46, newshape=[-1, 256, 256]);
  %48 = broadcast_to(%47, meta[relay.attrs.InitOpAttrs][2]);
  %49 = transpose(%48, axes=[0, 2, 1]);
  %50 = nn.batch_matmul(%43, %49);
  %51 = reshape(%50, newshape=[100, 1, 256]);
  %52 = strided_slice(%model.transformer.decoder.layers.0.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %53 = add(%51, %52);
  %54 = copy(%53);
  %55 = reshape(%54, newshape=[-1, 8, 32]);
  %56 = transpose(%55, axes=[1, 0, 2]);
  %57 = reshape(%56, newshape=[-1, 100, 32]);
  %58 = transpose(%57, axes=[0, 2, 1]);
  %59 = nn.batch_matmul(%42, %58);
  %60 = reshape(%59, newshape=[8, 100, 32]);
  %61 = transpose(%60, axes=[1, 0, 2]);
  %62 = copy(%61);
  %63 = reshape(%62, newshape=[100, 1, 256]);
  %64 = reshape(%63, newshape=[-1, 1, 256]);
  %65 = transpose(%model.transformer.decoder.layers.0.self_attn.out_proj.weight, axes=[1, 0]);
  %66 = reshape(%65, newshape=[-1, 256, 256]);
  %67 = broadcast_to(%66, meta[relay.attrs.InitOpAttrs][3]);
  %68 = transpose(%67, axes=[0, 2, 1]);
  %69 = nn.batch_matmul(%64, %68);
  %70 = reshape(%69, newshape=[100, 1, 256]);
  %71 = add(%70, %model.transformer.decoder.layers.0.self_attn.out_proj.bias);
  %72 = nn.dropout(%71, rate=0.1f);
  %73 = %72.0;
  %74 = add(%2, %73);
  %75 = nn.layer_norm(%74, %model.transformer.decoder.layers.0.norm1.weight, %model.transformer.decoder.layers.0.norm1.bias);
  %76 = split(%input, indices_or_sections=1);
  %77 = %76.0;
  %78 = squeeze(%77, axis=[0]);
  %79 = (%78,);
  %80 = %79.0;
  %81 = take(%80, 0, axis=0);
  %82 = zeros_like(%81);
  %83 = cast(%82, dtype="int32");
  %84 = nn.pad(%83, pad_value=1f, pad_width=[[0, 0], [0, 0]]);
  %85 = (%84,);
  %86 = stack(%85);
  %87 = expand_dims(%86, axis=0);
  %88 = cast(%87, dtype="float32");
  %89 = image.resize(%88, size=[24, 25], method="nearest_neighbor", coordinate_transformation_mode="asymmetric");
  %90 = take(%89, 0, axis=0);
  %91 = nn.pad(%80, pad_width=[[0, 0], [0, 0], [0, 0]]);
  %92 = (%91,);
  %93 = stack(%92);
  %94 = nn.conv2d(%93, %model.backbone.0.body.conv1.weight, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]);
  %95 = reshape(%model.backbone.0.body.bn1.weight, newshape=[1, -1, 1, 1]);
  %96 = reshape(%model.backbone.0.body.bn1.running_var, newshape=[1, -1, 1, 1]);
  %97 = add(%96, 1e-05f);
  %98 = rsqrt(%97);
  %99 = multiply(%95, %98);
  %100 = multiply(%94, %99);
  %101 = reshape(%model.backbone.0.body.bn1.bias, newshape=[1, -1, 1, 1]);
  %102 = reshape(%model.backbone.0.body.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %103 = multiply(%102, %99);
  %104 = subtract(%101, %103);
  %105 = add(%100, %104);
  %106 = nn.relu(%105);
  %107 = nn.max_pool2d(%106, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]);
  %108 = nn.conv2d(%107, %model.backbone.0.body.layer1.0.conv1.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);
  %109 = reshape(%model.backbone.0.body.layer1.0.bn1.weight, newshape=[1, -1, 1, 1]);
  %110 = reshape(%model.backbone.0.body.layer1.0.bn1.running_var, newshape=[1, -1, 1, 1]);
  %111 = add(%110, 1e-05f);
  %112 = rsqrt(%111);
  %113 = multiply(%109, %112);
  %114 = multiply(%108, %113);
  %115 = reshape(%model.backbone.0.body.layer1.0.bn1.bias, newshape=[1, -1, 1, 1]);
  %116 = reshape(%model.backbone.0.body.layer1.0.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %117 = multiply(%116, %113);
  %118 = subtract(%115, %117);
  %119 = add(%114, %118);
  %120 = nn.relu(%119);
  %121 = nn.conv2d(%120, %model.backbone.0.body.layer1.0.conv2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %122 = reshape(%model.backbone.0.body.layer1.0.bn2.weight, newshape=[1, -1, 1, 1]);
  %123 = reshape(%model.backbone.0.body.layer1.0.bn2.running_var, newshape=[1, -1, 1, 1]);
  %124 = add(%123, 1e-05f);
  %125 = rsqrt(%124);
  %126 = multiply(%122, %125);
  %127 = multiply(%121, %126);
  %128 = reshape(%model.backbone.0.body.layer1.0.bn2.bias, newshape=[1, -1, 1, 1]);
  %129 = reshape(%model.backbone.0.body.layer1.0.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %130 = multiply(%129, %126);
  %131 = subtract(%128, %130);
  %132 = add(%127, %131);
  %133 = nn.relu(%132);
  %134 = nn.conv2d(%133, %model.backbone.0.body.layer1.0.conv3.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %135 = reshape(%model.backbone.0.body.layer1.0.bn3.weight, newshape=[1, -1, 1, 1]);
  %136 = reshape(%model.backbone.0.body.layer1.0.bn3.running_var, newshape=[1, -1, 1, 1]);
  %137 = add(%136, 1e-05f);
  %138 = rsqrt(%137);
  %139 = multiply(%135, %138);
  %140 = multiply(%134, %139);
  %141 = reshape(%model.backbone.0.body.layer1.0.bn3.bias, newshape=[1, -1, 1, 1]);
  %142 = reshape(%model.backbone.0.body.layer1.0.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %143 = multiply(%142, %139);
  %144 = subtract(%141, %143);
  %145 = add(%140, %144);
  %146 = nn.conv2d(%107, %model.backbone.0.body.layer1.0.downsample.0.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %147 = reshape(%model.backbone.0.body.layer1.0.downsample.1.weight, newshape=[1, -1, 1, 1]);
  %148 = reshape(%model.backbone.0.body.layer1.0.downsample.1.running_var, newshape=[1, -1, 1, 1]);
  %149 = add(%148, 1e-05f);
  %150 = rsqrt(%149);
  %151 = multiply(%147, %150);
  %152 = multiply(%146, %151);
  %153 = reshape(%model.backbone.0.body.layer1.0.downsample.1.bias, newshape=[1, -1, 1, 1]);
  %154 = reshape(%model.backbone.0.body.layer1.0.downsample.1.running_mean, newshape=[1, -1, 1, 1]);
  %155 = multiply(%154, %151);
  %156 = subtract(%153, %155);
  %157 = add(%152, %156);
  %158 = add(%145, %157);
  %159 = nn.relu(%158);
  %160 = nn.conv2d(%159, %model.backbone.0.body.layer1.1.conv1.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);
  %161 = reshape(%model.backbone.0.body.layer1.1.bn1.weight, newshape=[1, -1, 1, 1]);
  %162 = reshape(%model.backbone.0.body.layer1.1.bn1.running_var, newshape=[1, -1, 1, 1]);
  %163 = add(%162, 1e-05f);
  %164 = rsqrt(%163);
  %165 = multiply(%161, %164);
  %166 = multiply(%160, %165);
  %167 = reshape(%model.backbone.0.body.layer1.1.bn1.bias, newshape=[1, -1, 1, 1]);
  %168 = reshape(%model.backbone.0.body.layer1.1.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %169 = multiply(%168, %165);
  %170 = subtract(%167, %169);
  %171 = add(%166, %170);
  %172 = nn.relu(%171);
  %173 = nn.conv2d(%172, %model.backbone.0.body.layer1.1.conv2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %174 = reshape(%model.backbone.0.body.layer1.1.bn2.weight, newshape=[1, -1, 1, 1]);
  %175 = reshape(%model.backbone.0.body.layer1.1.bn2.running_var, newshape=[1, -1, 1, 1]);
  %176 = add(%175, 1e-05f);
  %177 = rsqrt(%176);
  %178 = multiply(%174, %177);
  %179 = multiply(%173, %178);
  %180 = reshape(%model.backbone.0.body.layer1.1.bn2.bias, newshape=[1, -1, 1, 1]);
  %181 = reshape(%model.backbone.0.body.layer1.1.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %182 = multiply(%181, %178);
  %183 = subtract(%180, %182);
  %184 = add(%179, %183);
  %185 = nn.relu(%184);
  %186 = nn.conv2d(%185, %model.backbone.0.body.layer1.1.conv3.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %187 = reshape(%model.backbone.0.body.layer1.1.bn3.weight, newshape=[1, -1, 1, 1]);
  %188 = reshape(%model.backbone.0.body.layer1.1.bn3.running_var, newshape=[1, -1, 1, 1]);
  %189 = add(%188, 1e-05f);
  %190 = rsqrt(%189);
  %191 = multiply(%187, %190);
  %192 = multiply(%186, %191);
  %193 = reshape(%model.backbone.0.body.layer1.1.bn3.bias, newshape=[1, -1, 1, 1]);
  %194 = reshape(%model.backbone.0.body.layer1.1.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %195 = multiply(%194, %191);
  %196 = subtract(%193, %195);
  %197 = add(%192, %196);
  %198 = add(%197, %159);
  %199 = nn.relu(%198);
  %200 = nn.conv2d(%199, %model.backbone.0.body.layer1.2.conv1.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]);
  %201 = reshape(%model.backbone.0.body.layer1.2.bn1.weight, newshape=[1, -1, 1, 1]);
  %202 = reshape(%model.backbone.0.body.layer1.2.bn1.running_var, newshape=[1, -1, 1, 1]);
  %203 = add(%202, 1e-05f);
  %204 = rsqrt(%203);
  %205 = multiply(%201, %204);
  %206 = multiply(%200, %205);
  %207 = reshape(%model.backbone.0.body.layer1.2.bn1.bias, newshape=[1, -1, 1, 1]);
  %208 = reshape(%model.backbone.0.body.layer1.2.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %209 = multiply(%208, %205);
  %210 = subtract(%207, %209);
  %211 = add(%206, %210);
  %212 = nn.relu(%211);
  %213 = nn.conv2d(%212, %model.backbone.0.body.layer1.2.conv2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]);
  %214 = reshape(%model.backbone.0.body.layer1.2.bn2.weight, newshape=[1, -1, 1, 1]);
  %215 = reshape(%model.backbone.0.body.layer1.2.bn2.running_var, newshape=[1, -1, 1, 1]);
  %216 = add(%215, 1e-05f);
  %217 = rsqrt(%216);
  %218 = multiply(%214, %217);
  %219 = multiply(%213, %218);
  %220 = reshape(%model.backbone.0.body.layer1.2.bn2.bias, newshape=[1, -1, 1, 1]);
  %221 = reshape(%model.backbone.0.body.layer1.2.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %222 = multiply(%221, %218);
  %223 = subtract(%220, %222);
  %224 = add(%219, %223);
  %225 = nn.relu(%224);
  %226 = nn.conv2d(%225, %model.backbone.0.body.layer1.2.conv3.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %227 = reshape(%model.backbone.0.body.layer1.2.bn3.weight, newshape=[1, -1, 1, 1]);
  %228 = reshape(%model.backbone.0.body.layer1.2.bn3.running_var, newshape=[1, -1, 1, 1]);
  %229 = add(%228, 1e-05f);
  %230 = rsqrt(%229);
  %231 = multiply(%227, %230);
  %232 = multiply(%226, %231);
  %233 = reshape(%model.backbone.0.body.layer1.2.bn3.bias, newshape=[1, -1, 1, 1]);
  %234 = reshape(%model.backbone.0.body.layer1.2.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %235 = multiply(%234, %231);
  %236 = subtract(%233, %235);
  %237 = add(%232, %236);
  %238 = add(%237, %199);
  %239 = nn.relu(%238);
  %240 = nn.conv2d(%239, %model.backbone.0.body.layer2.0.conv1.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);
  %241 = reshape(%model.backbone.0.body.layer2.0.bn1.weight, newshape=[1, -1, 1, 1]);
  %242 = reshape(%model.backbone.0.body.layer2.0.bn1.running_var, newshape=[1, -1, 1, 1]);
  %243 = add(%242, 1e-05f);
  %244 = rsqrt(%243);
  %245 = multiply(%241, %244);
  %246 = multiply(%240, %245);
  %247 = reshape(%model.backbone.0.body.layer2.0.bn1.bias, newshape=[1, -1, 1, 1]);
  %248 = reshape(%model.backbone.0.body.layer2.0.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %249 = multiply(%248, %245);
  %250 = subtract(%247, %249);
  %251 = add(%246, %250);
  %252 = nn.relu(%251);
  %253 = nn.conv2d(%252, %model.backbone.0.body.layer2.0.conv2.weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %254 = reshape(%model.backbone.0.body.layer2.0.bn2.weight, newshape=[1, -1, 1, 1]);
  %255 = reshape(%model.backbone.0.body.layer2.0.bn2.running_var, newshape=[1, -1, 1, 1]);
  %256 = add(%255, 1e-05f);
  %257 = rsqrt(%256);
  %258 = multiply(%254, %257);
  %259 = multiply(%253, %258);
  %260 = reshape(%model.backbone.0.body.layer2.0.bn2.bias, newshape=[1, -1, 1, 1]);
  %261 = reshape(%model.backbone.0.body.layer2.0.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %262 = multiply(%261, %258);
  %263 = subtract(%260, %262);
  %264 = add(%259, %263);
  %265 = nn.relu(%264);
  %266 = nn.conv2d(%265, %model.backbone.0.body.layer2.0.conv3.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %267 = reshape(%model.backbone.0.body.layer2.0.bn3.weight, newshape=[1, -1, 1, 1]);
  %268 = reshape(%model.backbone.0.body.layer2.0.bn3.running_var, newshape=[1, -1, 1, 1]);
  %269 = add(%268, 1e-05f);
  %270 = rsqrt(%269);
  %271 = multiply(%267, %270);
  %272 = multiply(%266, %271);
  %273 = reshape(%model.backbone.0.body.layer2.0.bn3.bias, newshape=[1, -1, 1, 1]);
  %274 = reshape(%model.backbone.0.body.layer2.0.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %275 = multiply(%274, %271);
  %276 = subtract(%273, %275);
  %277 = add(%272, %276);
  %278 = nn.conv2d(%239, %model.backbone.0.body.layer2.0.downsample.0.weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %279 = reshape(%model.backbone.0.body.layer2.0.downsample.1.weight, newshape=[1, -1, 1, 1]);
  %280 = reshape(%model.backbone.0.body.layer2.0.downsample.1.running_var, newshape=[1, -1, 1, 1]);
  %281 = add(%280, 1e-05f);
  %282 = rsqrt(%281);
  %283 = multiply(%279, %282);
  %284 = multiply(%278, %283);
  %285 = reshape(%model.backbone.0.body.layer2.0.downsample.1.bias, newshape=[1, -1, 1, 1]);
  %286 = reshape(%model.backbone.0.body.layer2.0.downsample.1.running_mean, newshape=[1, -1, 1, 1]);
  %287 = multiply(%286, %283);
  %288 = subtract(%285, %287);
  %289 = add(%284, %288);
  %290 = add(%277, %289);
  %291 = nn.relu(%290);
  %292 = nn.conv2d(%291, %model.backbone.0.body.layer2.1.conv1.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);
  %293 = reshape(%model.backbone.0.body.layer2.1.bn1.weight, newshape=[1, -1, 1, 1]);
  %294 = reshape(%model.backbone.0.body.layer2.1.bn1.running_var, newshape=[1, -1, 1, 1]);
  %295 = add(%294, 1e-05f);
  %296 = rsqrt(%295);
  %297 = multiply(%293, %296);
  %298 = multiply(%292, %297);
  %299 = reshape(%model.backbone.0.body.layer2.1.bn1.bias, newshape=[1, -1, 1, 1]);
  %300 = reshape(%model.backbone.0.body.layer2.1.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %301 = multiply(%300, %297);
  %302 = subtract(%299, %301);
  %303 = add(%298, %302);
  %304 = nn.relu(%303);
  %305 = nn.conv2d(%304, %model.backbone.0.body.layer2.1.conv2.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %306 = reshape(%model.backbone.0.body.layer2.1.bn2.weight, newshape=[1, -1, 1, 1]);
  %307 = reshape(%model.backbone.0.body.layer2.1.bn2.running_var, newshape=[1, -1, 1, 1]);
  %308 = add(%307, 1e-05f);
  %309 = rsqrt(%308);
  %310 = multiply(%306, %309);
  %311 = multiply(%305, %310);
  %312 = reshape(%model.backbone.0.body.layer2.1.bn2.bias, newshape=[1, -1, 1, 1]);
  %313 = reshape(%model.backbone.0.body.layer2.1.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %314 = multiply(%313, %310);
  %315 = subtract(%312, %314);
  %316 = add(%311, %315);
  %317 = nn.relu(%316);
  %318 = nn.conv2d(%317, %model.backbone.0.body.layer2.1.conv3.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %319 = reshape(%model.backbone.0.body.layer2.1.bn3.weight, newshape=[1, -1, 1, 1]);
  %320 = reshape(%model.backbone.0.body.layer2.1.bn3.running_var, newshape=[1, -1, 1, 1]);
  %321 = add(%320, 1e-05f);
  %322 = rsqrt(%321);
  %323 = multiply(%319, %322);
  %324 = multiply(%318, %323);
  %325 = reshape(%model.backbone.0.body.layer2.1.bn3.bias, newshape=[1, -1, 1, 1]);
  %326 = reshape(%model.backbone.0.body.layer2.1.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %327 = multiply(%326, %323);
  %328 = subtract(%325, %327);
  %329 = add(%324, %328);
  %330 = add(%329, %291);
  %331 = nn.relu(%330);
  %332 = nn.conv2d(%331, %model.backbone.0.body.layer2.2.conv1.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);
  %333 = reshape(%model.backbone.0.body.layer2.2.bn1.weight, newshape=[1, -1, 1, 1]);
  %334 = reshape(%model.backbone.0.body.layer2.2.bn1.running_var, newshape=[1, -1, 1, 1]);
  %335 = add(%334, 1e-05f);
  %336 = rsqrt(%335);
  %337 = multiply(%333, %336);
  %338 = multiply(%332, %337);
  %339 = reshape(%model.backbone.0.body.layer2.2.bn1.bias, newshape=[1, -1, 1, 1]);
  %340 = reshape(%model.backbone.0.body.layer2.2.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %341 = multiply(%340, %337);
  %342 = subtract(%339, %341);
  %343 = add(%338, %342);
  %344 = nn.relu(%343);
  %345 = nn.conv2d(%344, %model.backbone.0.body.layer2.2.conv2.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %346 = reshape(%model.backbone.0.body.layer2.2.bn2.weight, newshape=[1, -1, 1, 1]);
  %347 = reshape(%model.backbone.0.body.layer2.2.bn2.running_var, newshape=[1, -1, 1, 1]);
  %348 = add(%347, 1e-05f);
  %349 = rsqrt(%348);
  %350 = multiply(%346, %349);
  %351 = multiply(%345, %350);
  %352 = reshape(%model.backbone.0.body.layer2.2.bn2.bias, newshape=[1, -1, 1, 1]);
  %353 = reshape(%model.backbone.0.body.layer2.2.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %354 = multiply(%353, %350);
  %355 = subtract(%352, %354);
  %356 = add(%351, %355);
  %357 = nn.relu(%356);
  %358 = nn.conv2d(%357, %model.backbone.0.body.layer2.2.conv3.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %359 = reshape(%model.backbone.0.body.layer2.2.bn3.weight, newshape=[1, -1, 1, 1]);
  %360 = reshape(%model.backbone.0.body.layer2.2.bn3.running_var, newshape=[1, -1, 1, 1]);
  %361 = add(%360, 1e-05f);
  %362 = rsqrt(%361);
  %363 = multiply(%359, %362);
  %364 = multiply(%358, %363);
  %365 = reshape(%model.backbone.0.body.layer2.2.bn3.bias, newshape=[1, -1, 1, 1]);
  %366 = reshape(%model.backbone.0.body.layer2.2.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %367 = multiply(%366, %363);
  %368 = subtract(%365, %367);
  %369 = add(%364, %368);
  %370 = add(%369, %331);
  %371 = nn.relu(%370);
  %372 = nn.conv2d(%371, %model.backbone.0.body.layer2.3.conv1.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]);
  %373 = reshape(%model.backbone.0.body.layer2.3.bn1.weight, newshape=[1, -1, 1, 1]);
  %374 = reshape(%model.backbone.0.body.layer2.3.bn1.running_var, newshape=[1, -1, 1, 1]);
  %375 = add(%374, 1e-05f);
  %376 = rsqrt(%375);
  %377 = multiply(%373, %376);
  %378 = multiply(%372, %377);
  %379 = reshape(%model.backbone.0.body.layer2.3.bn1.bias, newshape=[1, -1, 1, 1]);
  %380 = reshape(%model.backbone.0.body.layer2.3.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %381 = multiply(%380, %377);
  %382 = subtract(%379, %381);
  %383 = add(%378, %382);
  %384 = nn.relu(%383);
  %385 = nn.conv2d(%384, %model.backbone.0.body.layer2.3.conv2.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]);
  %386 = reshape(%model.backbone.0.body.layer2.3.bn2.weight, newshape=[1, -1, 1, 1]);
  %387 = reshape(%model.backbone.0.body.layer2.3.bn2.running_var, newshape=[1, -1, 1, 1]);
  %388 = add(%387, 1e-05f);
  %389 = rsqrt(%388);
  %390 = multiply(%386, %389);
  %391 = multiply(%385, %390);
  %392 = reshape(%model.backbone.0.body.layer2.3.bn2.bias, newshape=[1, -1, 1, 1]);
  %393 = reshape(%model.backbone.0.body.layer2.3.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %394 = multiply(%393, %390);
  %395 = subtract(%392, %394);
  %396 = add(%391, %395);
  %397 = nn.relu(%396);
  %398 = nn.conv2d(%397, %model.backbone.0.body.layer2.3.conv3.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %399 = reshape(%model.backbone.0.body.layer2.3.bn3.weight, newshape=[1, -1, 1, 1]);
  %400 = reshape(%model.backbone.0.body.layer2.3.bn3.running_var, newshape=[1, -1, 1, 1]);
  %401 = add(%400, 1e-05f);
  %402 = rsqrt(%401);
  %403 = multiply(%399, %402);
  %404 = multiply(%398, %403);
  %405 = reshape(%model.backbone.0.body.layer2.3.bn3.bias, newshape=[1, -1, 1, 1]);
  %406 = reshape(%model.backbone.0.body.layer2.3.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %407 = multiply(%406, %403);
  %408 = subtract(%405, %407);
  %409 = add(%404, %408);
  %410 = add(%409, %371);
  %411 = nn.relu(%410);
  %412 = nn.conv2d(%411, %model.backbone.0.body.layer3.0.conv1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %413 = reshape(%model.backbone.0.body.layer3.0.bn1.weight, newshape=[1, -1, 1, 1]);
  %414 = reshape(%model.backbone.0.body.layer3.0.bn1.running_var, newshape=[1, -1, 1, 1]);
  %415 = add(%414, 1e-05f);
  %416 = rsqrt(%415);
  %417 = multiply(%413, %416);
  %418 = multiply(%412, %417);
  %419 = reshape(%model.backbone.0.body.layer3.0.bn1.bias, newshape=[1, -1, 1, 1]);
  %420 = reshape(%model.backbone.0.body.layer3.0.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %421 = multiply(%420, %417);
  %422 = subtract(%419, %421);
  %423 = add(%418, %422);
  %424 = nn.relu(%423);
  %425 = nn.conv2d(%424, %model.backbone.0.body.layer3.0.conv2.weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %426 = reshape(%model.backbone.0.body.layer3.0.bn2.weight, newshape=[1, -1, 1, 1]);
  %427 = reshape(%model.backbone.0.body.layer3.0.bn2.running_var, newshape=[1, -1, 1, 1]);
  %428 = add(%427, 1e-05f);
  %429 = rsqrt(%428);
  %430 = multiply(%426, %429);
  %431 = multiply(%425, %430);
  %432 = reshape(%model.backbone.0.body.layer3.0.bn2.bias, newshape=[1, -1, 1, 1]);
  %433 = reshape(%model.backbone.0.body.layer3.0.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %434 = multiply(%433, %430);
  %435 = subtract(%432, %434);
  %436 = add(%431, %435);
  %437 = nn.relu(%436);
  %438 = nn.conv2d(%437, %model.backbone.0.body.layer3.0.conv3.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);
  %439 = reshape(%model.backbone.0.body.layer3.0.bn3.weight, newshape=[1, -1, 1, 1]);
  %440 = reshape(%model.backbone.0.body.layer3.0.bn3.running_var, newshape=[1, -1, 1, 1]);
  %441 = add(%440, 1e-05f);
  %442 = rsqrt(%441);
  %443 = multiply(%439, %442);
  %444 = multiply(%438, %443);
  %445 = reshape(%model.backbone.0.body.layer3.0.bn3.bias, newshape=[1, -1, 1, 1]);
  %446 = reshape(%model.backbone.0.body.layer3.0.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %447 = multiply(%446, %443);
  %448 = subtract(%445, %447);
  %449 = add(%444, %448);
  %450 = nn.conv2d(%411, %model.backbone.0.body.layer3.0.downsample.0.weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);
  %451 = reshape(%model.backbone.0.body.layer3.0.downsample.1.weight, newshape=[1, -1, 1, 1]);
  %452 = reshape(%model.backbone.0.body.layer3.0.downsample.1.running_var, newshape=[1, -1, 1, 1]);
  %453 = add(%452, 1e-05f);
  %454 = rsqrt(%453);
  %455 = multiply(%451, %454);
  %456 = multiply(%450, %455);
  %457 = reshape(%model.backbone.0.body.layer3.0.downsample.1.bias, newshape=[1, -1, 1, 1]);
  %458 = reshape(%model.backbone.0.body.layer3.0.downsample.1.running_mean, newshape=[1, -1, 1, 1]);
  %459 = multiply(%458, %455);
  %460 = subtract(%457, %459);
  %461 = add(%456, %460);
  %462 = add(%449, %461);
  %463 = nn.relu(%462);
  %464 = nn.conv2d(%463, %model.backbone.0.body.layer3.1.conv1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %465 = reshape(%model.backbone.0.body.layer3.1.bn1.weight, newshape=[1, -1, 1, 1]);
  %466 = reshape(%model.backbone.0.body.layer3.1.bn1.running_var, newshape=[1, -1, 1, 1]);
  %467 = add(%466, 1e-05f);
  %468 = rsqrt(%467);
  %469 = multiply(%465, %468);
  %470 = multiply(%464, %469);
  %471 = reshape(%model.backbone.0.body.layer3.1.bn1.bias, newshape=[1, -1, 1, 1]);
  %472 = reshape(%model.backbone.0.body.layer3.1.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %473 = multiply(%472, %469);
  %474 = subtract(%471, %473);
  %475 = add(%470, %474);
  %476 = nn.relu(%475);
  %477 = nn.conv2d(%476, %model.backbone.0.body.layer3.1.conv2.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %478 = reshape(%model.backbone.0.body.layer3.1.bn2.weight, newshape=[1, -1, 1, 1]);
  %479 = reshape(%model.backbone.0.body.layer3.1.bn2.running_var, newshape=[1, -1, 1, 1]);
  %480 = add(%479, 1e-05f);
  %481 = rsqrt(%480);
  %482 = multiply(%478, %481);
  %483 = multiply(%477, %482);
  %484 = reshape(%model.backbone.0.body.layer3.1.bn2.bias, newshape=[1, -1, 1, 1]);
  %485 = reshape(%model.backbone.0.body.layer3.1.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %486 = multiply(%485, %482);
  %487 = subtract(%484, %486);
  %488 = add(%483, %487);
  %489 = nn.relu(%488);
  %490 = nn.conv2d(%489, %model.backbone.0.body.layer3.1.conv3.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);
  %491 = reshape(%model.backbone.0.body.layer3.1.bn3.weight, newshape=[1, -1, 1, 1]);
  %492 = reshape(%model.backbone.0.body.layer3.1.bn3.running_var, newshape=[1, -1, 1, 1]);
  %493 = add(%492, 1e-05f);
  %494 = rsqrt(%493);
  %495 = multiply(%491, %494);
  %496 = multiply(%490, %495);
  %497 = reshape(%model.backbone.0.body.layer3.1.bn3.bias, newshape=[1, -1, 1, 1]);
  %498 = reshape(%model.backbone.0.body.layer3.1.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %499 = multiply(%498, %495);
  %500 = subtract(%497, %499);
  %501 = add(%496, %500);
  %502 = add(%501, %463);
  %503 = nn.relu(%502);
  %504 = nn.conv2d(%503, %model.backbone.0.body.layer3.2.conv1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %505 = reshape(%model.backbone.0.body.layer3.2.bn1.weight, newshape=[1, -1, 1, 1]);
  %506 = reshape(%model.backbone.0.body.layer3.2.bn1.running_var, newshape=[1, -1, 1, 1]);
  %507 = add(%506, 1e-05f);
  %508 = rsqrt(%507);
  %509 = multiply(%505, %508);
  %510 = multiply(%504, %509);
  %511 = reshape(%model.backbone.0.body.layer3.2.bn1.bias, newshape=[1, -1, 1, 1]);
  %512 = reshape(%model.backbone.0.body.layer3.2.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %513 = multiply(%512, %509);
  %514 = subtract(%511, %513);
  %515 = add(%510, %514);
  %516 = nn.relu(%515);
  %517 = nn.conv2d(%516, %model.backbone.0.body.layer3.2.conv2.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %518 = reshape(%model.backbone.0.body.layer3.2.bn2.weight, newshape=[1, -1, 1, 1]);
  %519 = reshape(%model.backbone.0.body.layer3.2.bn2.running_var, newshape=[1, -1, 1, 1]);
  %520 = add(%519, 1e-05f);
  %521 = rsqrt(%520);
  %522 = multiply(%518, %521);
  %523 = multiply(%517, %522);
  %524 = reshape(%model.backbone.0.body.layer3.2.bn2.bias, newshape=[1, -1, 1, 1]);
  %525 = reshape(%model.backbone.0.body.layer3.2.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %526 = multiply(%525, %522);
  %527 = subtract(%524, %526);
  %528 = add(%523, %527);
  %529 = nn.relu(%528);
  %530 = nn.conv2d(%529, %model.backbone.0.body.layer3.2.conv3.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);
  %531 = reshape(%model.backbone.0.body.layer3.2.bn3.weight, newshape=[1, -1, 1, 1]);
  %532 = reshape(%model.backbone.0.body.layer3.2.bn3.running_var, newshape=[1, -1, 1, 1]);
  %533 = add(%532, 1e-05f);
  %534 = rsqrt(%533);
  %535 = multiply(%531, %534);
  %536 = multiply(%530, %535);
  %537 = reshape(%model.backbone.0.body.layer3.2.bn3.bias, newshape=[1, -1, 1, 1]);
  %538 = reshape(%model.backbone.0.body.layer3.2.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %539 = multiply(%538, %535);
  %540 = subtract(%537, %539);
  %541 = add(%536, %540);
  %542 = add(%541, %503);
  %543 = nn.relu(%542);
  %544 = nn.conv2d(%543, %model.backbone.0.body.layer3.3.conv1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %545 = reshape(%model.backbone.0.body.layer3.3.bn1.weight, newshape=[1, -1, 1, 1]);
  %546 = reshape(%model.backbone.0.body.layer3.3.bn1.running_var, newshape=[1, -1, 1, 1]);
  %547 = add(%546, 1e-05f);
  %548 = rsqrt(%547);
  %549 = multiply(%545, %548);
  %550 = multiply(%544, %549);
  %551 = reshape(%model.backbone.0.body.layer3.3.bn1.bias, newshape=[1, -1, 1, 1]);
  %552 = reshape(%model.backbone.0.body.layer3.3.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %553 = multiply(%552, %549);
  %554 = subtract(%551, %553);
  %555 = add(%550, %554);
  %556 = nn.relu(%555);
  %557 = nn.conv2d(%556, %model.backbone.0.body.layer3.3.conv2.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %558 = reshape(%model.backbone.0.body.layer3.3.bn2.weight, newshape=[1, -1, 1, 1]);
  %559 = reshape(%model.backbone.0.body.layer3.3.bn2.running_var, newshape=[1, -1, 1, 1]);
  %560 = add(%559, 1e-05f);
  %561 = rsqrt(%560);
  %562 = multiply(%558, %561);
  %563 = multiply(%557, %562);
  %564 = reshape(%model.backbone.0.body.layer3.3.bn2.bias, newshape=[1, -1, 1, 1]);
  %565 = reshape(%model.backbone.0.body.layer3.3.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %566 = multiply(%565, %562);
  %567 = subtract(%564, %566);
  %568 = add(%563, %567);
  %569 = nn.relu(%568);
  %570 = nn.conv2d(%569, %model.backbone.0.body.layer3.3.conv3.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);
  %571 = reshape(%model.backbone.0.body.layer3.3.bn3.weight, newshape=[1, -1, 1, 1]);
  %572 = reshape(%model.backbone.0.body.layer3.3.bn3.running_var, newshape=[1, -1, 1, 1]);
  %573 = add(%572, 1e-05f);
  %574 = rsqrt(%573);
  %575 = multiply(%571, %574);
  %576 = multiply(%570, %575);
  %577 = reshape(%model.backbone.0.body.layer3.3.bn3.bias, newshape=[1, -1, 1, 1]);
  %578 = reshape(%model.backbone.0.body.layer3.3.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %579 = multiply(%578, %575);
  %580 = subtract(%577, %579);
  %581 = add(%576, %580);
  %582 = add(%581, %543);
  %583 = nn.relu(%582);
  %584 = nn.conv2d(%583, %model.backbone.0.body.layer3.4.conv1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %585 = reshape(%model.backbone.0.body.layer3.4.bn1.weight, newshape=[1, -1, 1, 1]);
  %586 = reshape(%model.backbone.0.body.layer3.4.bn1.running_var, newshape=[1, -1, 1, 1]);
  %587 = add(%586, 1e-05f);
  %588 = rsqrt(%587);
  %589 = multiply(%585, %588);
  %590 = multiply(%584, %589);
  %591 = reshape(%model.backbone.0.body.layer3.4.bn1.bias, newshape=[1, -1, 1, 1]);
  %592 = reshape(%model.backbone.0.body.layer3.4.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %593 = multiply(%592, %589);
  %594 = subtract(%591, %593);
  %595 = add(%590, %594);
  %596 = nn.relu(%595);
  %597 = nn.conv2d(%596, %model.backbone.0.body.layer3.4.conv2.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %598 = reshape(%model.backbone.0.body.layer3.4.bn2.weight, newshape=[1, -1, 1, 1]);
  %599 = reshape(%model.backbone.0.body.layer3.4.bn2.running_var, newshape=[1, -1, 1, 1]);
  %600 = add(%599, 1e-05f);
  %601 = rsqrt(%600);
  %602 = multiply(%598, %601);
  %603 = multiply(%597, %602);
  %604 = reshape(%model.backbone.0.body.layer3.4.bn2.bias, newshape=[1, -1, 1, 1]);
  %605 = reshape(%model.backbone.0.body.layer3.4.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %606 = multiply(%605, %602);
  %607 = subtract(%604, %606);
  %608 = add(%603, %607);
  %609 = nn.relu(%608);
  %610 = nn.conv2d(%609, %model.backbone.0.body.layer3.4.conv3.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);
  %611 = reshape(%model.backbone.0.body.layer3.4.bn3.weight, newshape=[1, -1, 1, 1]);
  %612 = reshape(%model.backbone.0.body.layer3.4.bn3.running_var, newshape=[1, -1, 1, 1]);
  %613 = add(%612, 1e-05f);
  %614 = rsqrt(%613);
  %615 = multiply(%611, %614);
  %616 = multiply(%610, %615);
  %617 = reshape(%model.backbone.0.body.layer3.4.bn3.bias, newshape=[1, -1, 1, 1]);
  %618 = reshape(%model.backbone.0.body.layer3.4.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %619 = multiply(%618, %615);
  %620 = subtract(%617, %619);
  %621 = add(%616, %620);
  %622 = add(%621, %583);
  %623 = nn.relu(%622);
  %624 = nn.conv2d(%623, %model.backbone.0.body.layer3.5.conv1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %625 = reshape(%model.backbone.0.body.layer3.5.bn1.weight, newshape=[1, -1, 1, 1]);
  %626 = reshape(%model.backbone.0.body.layer3.5.bn1.running_var, newshape=[1, -1, 1, 1]);
  %627 = add(%626, 1e-05f);
  %628 = rsqrt(%627);
  %629 = multiply(%625, %628);
  %630 = multiply(%624, %629);
  %631 = reshape(%model.backbone.0.body.layer3.5.bn1.bias, newshape=[1, -1, 1, 1]);
  %632 = reshape(%model.backbone.0.body.layer3.5.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %633 = multiply(%632, %629);
  %634 = subtract(%631, %633);
  %635 = add(%630, %634);
  %636 = nn.relu(%635);
  %637 = nn.conv2d(%636, %model.backbone.0.body.layer3.5.conv2.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]);
  %638 = reshape(%model.backbone.0.body.layer3.5.bn2.weight, newshape=[1, -1, 1, 1]);
  %639 = reshape(%model.backbone.0.body.layer3.5.bn2.running_var, newshape=[1, -1, 1, 1]);
  %640 = add(%639, 1e-05f);
  %641 = rsqrt(%640);
  %642 = multiply(%638, %641);
  %643 = multiply(%637, %642);
  %644 = reshape(%model.backbone.0.body.layer3.5.bn2.bias, newshape=[1, -1, 1, 1]);
  %645 = reshape(%model.backbone.0.body.layer3.5.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %646 = multiply(%645, %642);
  %647 = subtract(%644, %646);
  %648 = add(%643, %647);
  %649 = nn.relu(%648);
  %650 = nn.conv2d(%649, %model.backbone.0.body.layer3.5.conv3.weight, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]);
  %651 = reshape(%model.backbone.0.body.layer3.5.bn3.weight, newshape=[1, -1, 1, 1]);
  %652 = reshape(%model.backbone.0.body.layer3.5.bn3.running_var, newshape=[1, -1, 1, 1]);
  %653 = add(%652, 1e-05f);
  %654 = rsqrt(%653);
  %655 = multiply(%651, %654);
  %656 = multiply(%650, %655);
  %657 = reshape(%model.backbone.0.body.layer3.5.bn3.bias, newshape=[1, -1, 1, 1]);
  %658 = reshape(%model.backbone.0.body.layer3.5.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %659 = multiply(%658, %655);
  %660 = subtract(%657, %659);
  %661 = add(%656, %660);
  %662 = add(%661, %623);
  %663 = nn.relu(%662);
  %664 = nn.conv2d(%663, %model.backbone.0.body.layer4.0.conv1.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %665 = reshape(%model.backbone.0.body.layer4.0.bn1.weight, newshape=[1, -1, 1, 1]);
  %666 = reshape(%model.backbone.0.body.layer4.0.bn1.running_var, newshape=[1, -1, 1, 1]);
  %667 = add(%666, 1e-05f);
  %668 = rsqrt(%667);
  %669 = multiply(%665, %668);
  %670 = multiply(%664, %669);
  %671 = reshape(%model.backbone.0.body.layer4.0.bn1.bias, newshape=[1, -1, 1, 1]);
  %672 = reshape(%model.backbone.0.body.layer4.0.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %673 = multiply(%672, %669);
  %674 = subtract(%671, %673);
  %675 = add(%670, %674);
  %676 = nn.relu(%675);
  %677 = nn.conv2d(%676, %model.backbone.0.body.layer4.0.conv2.weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);
  %678 = reshape(%model.backbone.0.body.layer4.0.bn2.weight, newshape=[1, -1, 1, 1]);
  %679 = reshape(%model.backbone.0.body.layer4.0.bn2.running_var, newshape=[1, -1, 1, 1]);
  %680 = add(%679, 1e-05f);
  %681 = rsqrt(%680);
  %682 = multiply(%678, %681);
  %683 = multiply(%677, %682);
  %684 = reshape(%model.backbone.0.body.layer4.0.bn2.bias, newshape=[1, -1, 1, 1]);
  %685 = reshape(%model.backbone.0.body.layer4.0.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %686 = multiply(%685, %682);
  %687 = subtract(%684, %686);
  %688 = add(%683, %687);
  %689 = nn.relu(%688);
  %690 = nn.conv2d(%689, %model.backbone.0.body.layer4.0.conv3.weight, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);
  %691 = reshape(%model.backbone.0.body.layer4.0.bn3.weight, newshape=[1, -1, 1, 1]);
  %692 = reshape(%model.backbone.0.body.layer4.0.bn3.running_var, newshape=[1, -1, 1, 1]);
  %693 = add(%692, 1e-05f);
  %694 = rsqrt(%693);
  %695 = multiply(%691, %694);
  %696 = multiply(%690, %695);
  %697 = reshape(%model.backbone.0.body.layer4.0.bn3.bias, newshape=[1, -1, 1, 1]);
  %698 = reshape(%model.backbone.0.body.layer4.0.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %699 = multiply(%698, %695);
  %700 = subtract(%697, %699);
  %701 = add(%696, %700);
  %702 = nn.conv2d(%663, %model.backbone.0.body.layer4.0.downsample.0.weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);
  %703 = reshape(%model.backbone.0.body.layer4.0.downsample.1.weight, newshape=[1, -1, 1, 1]);
  %704 = reshape(%model.backbone.0.body.layer4.0.downsample.1.running_var, newshape=[1, -1, 1, 1]);
  %705 = add(%704, 1e-05f);
  %706 = rsqrt(%705);
  %707 = multiply(%703, %706);
  %708 = multiply(%702, %707);
  %709 = reshape(%model.backbone.0.body.layer4.0.downsample.1.bias, newshape=[1, -1, 1, 1]);
  %710 = reshape(%model.backbone.0.body.layer4.0.downsample.1.running_mean, newshape=[1, -1, 1, 1]);
  %711 = multiply(%710, %707);
  %712 = subtract(%709, %711);
  %713 = add(%708, %712);
  %714 = add(%701, %713);
  %715 = nn.relu(%714);
  %716 = nn.conv2d(%715, %model.backbone.0.body.layer4.1.conv1.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %717 = reshape(%model.backbone.0.body.layer4.1.bn1.weight, newshape=[1, -1, 1, 1]);
  %718 = reshape(%model.backbone.0.body.layer4.1.bn1.running_var, newshape=[1, -1, 1, 1]);
  %719 = add(%718, 1e-05f);
  %720 = rsqrt(%719);
  %721 = multiply(%717, %720);
  %722 = multiply(%716, %721);
  %723 = reshape(%model.backbone.0.body.layer4.1.bn1.bias, newshape=[1, -1, 1, 1]);
  %724 = reshape(%model.backbone.0.body.layer4.1.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %725 = multiply(%724, %721);
  %726 = subtract(%723, %725);
  %727 = add(%722, %726);
  %728 = nn.relu(%727);
  %729 = nn.conv2d(%728, %model.backbone.0.body.layer4.1.conv2.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);
  %730 = reshape(%model.backbone.0.body.layer4.1.bn2.weight, newshape=[1, -1, 1, 1]);
  %731 = reshape(%model.backbone.0.body.layer4.1.bn2.running_var, newshape=[1, -1, 1, 1]);
  %732 = add(%731, 1e-05f);
  %733 = rsqrt(%732);
  %734 = multiply(%730, %733);
  %735 = multiply(%729, %734);
  %736 = reshape(%model.backbone.0.body.layer4.1.bn2.bias, newshape=[1, -1, 1, 1]);
  %737 = reshape(%model.backbone.0.body.layer4.1.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %738 = multiply(%737, %734);
  %739 = subtract(%736, %738);
  %740 = add(%735, %739);
  %741 = nn.relu(%740);
  %742 = nn.conv2d(%741, %model.backbone.0.body.layer4.1.conv3.weight, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);
  %743 = reshape(%model.backbone.0.body.layer4.1.bn3.weight, newshape=[1, -1, 1, 1]);
  %744 = reshape(%model.backbone.0.body.layer4.1.bn3.running_var, newshape=[1, -1, 1, 1]);
  %745 = add(%744, 1e-05f);
  %746 = rsqrt(%745);
  %747 = multiply(%743, %746);
  %748 = multiply(%742, %747);
  %749 = reshape(%model.backbone.0.body.layer4.1.bn3.bias, newshape=[1, -1, 1, 1]);
  %750 = reshape(%model.backbone.0.body.layer4.1.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %751 = multiply(%750, %747);
  %752 = subtract(%749, %751);
  %753 = add(%748, %752);
  %754 = add(%753, %715);
  %755 = nn.relu(%754);
  %756 = nn.conv2d(%755, %model.backbone.0.body.layer4.2.conv1.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]);
  %757 = reshape(%model.backbone.0.body.layer4.2.bn1.weight, newshape=[1, -1, 1, 1]);
  %758 = reshape(%model.backbone.0.body.layer4.2.bn1.running_var, newshape=[1, -1, 1, 1]);
  %759 = add(%758, 1e-05f);
  %760 = rsqrt(%759);
  %761 = multiply(%757, %760);
  %762 = multiply(%756, %761);
  %763 = reshape(%model.backbone.0.body.layer4.2.bn1.bias, newshape=[1, -1, 1, 1]);
  %764 = reshape(%model.backbone.0.body.layer4.2.bn1.running_mean, newshape=[1, -1, 1, 1]);
  %765 = multiply(%764, %761);
  %766 = subtract(%763, %765);
  %767 = add(%762, %766);
  %768 = nn.relu(%767);
  %769 = nn.conv2d(%768, %model.backbone.0.body.layer4.2.conv2.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]);
  %770 = reshape(%model.backbone.0.body.layer4.2.bn2.weight, newshape=[1, -1, 1, 1]);
  %771 = reshape(%model.backbone.0.body.layer4.2.bn2.running_var, newshape=[1, -1, 1, 1]);
  %772 = add(%771, 1e-05f);
  %773 = rsqrt(%772);
  %774 = multiply(%770, %773);
  %775 = multiply(%769, %774);
  %776 = reshape(%model.backbone.0.body.layer4.2.bn2.bias, newshape=[1, -1, 1, 1]);
  %777 = reshape(%model.backbone.0.body.layer4.2.bn2.running_mean, newshape=[1, -1, 1, 1]);
  %778 = multiply(%777, %774);
  %779 = subtract(%776, %778);
  %780 = add(%775, %779);
  %781 = nn.relu(%780);
  %782 = nn.conv2d(%781, %model.backbone.0.body.layer4.2.conv3.weight, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]);
  %783 = reshape(%model.backbone.0.body.layer4.2.bn3.weight, newshape=[1, -1, 1, 1]);
  %784 = reshape(%model.backbone.0.body.layer4.2.bn3.running_var, newshape=[1, -1, 1, 1]);
  %785 = add(%784, 1e-05f);
  %786 = rsqrt(%785);
  %787 = multiply(%783, %786);
  %788 = multiply(%782, %787);
  %789 = reshape(%model.backbone.0.body.layer4.2.bn3.bias, newshape=[1, -1, 1, 1]);
  %790 = reshape(%model.backbone.0.body.layer4.2.bn3.running_mean, newshape=[1, -1, 1, 1]);
  %791 = multiply(%790, %787);
  %792 = subtract(%789, %791);
  %793 = add(%788, %792);
  %794 = add(%793, %755);
  %795 = nn.relu(%794);
  %796 = (%90, %795);
  %797 = %796.1;
  %798 = %796.0;
  %799 = cast(%798, dtype="bool");
  %800 = logical_not(%799);
  %801 = cumsum(%800, meta[relay.attrs.CumsumAttrs][0]);
  %802 = strided_slice(%801, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %803 = strided_slice(%802, begin=[0, -1, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %804 = strided_slice(%803, begin=[0, 0, 0], end=[1, 1, 25], strides=[1, 1, 1]);
  %805 = add(%804, 1e-06f);
  %806 = divide(%801, %805);
  %807 = multiply(%806, 6.28319f);
  %808 = strided_slice(%807, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %809 = strided_slice(%808, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %810 = strided_slice(%809, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %811 = expand_dims(%810, axis=3);
  %812 = arange(0f, 128f, 1f, start=meta[relay.Constant][0], stop=meta[relay.Constant][1], step=meta[relay.Constant][2], dtype="float32");
  %813 = floor_divide(%812, 2f);
  %814 = multiply(%813, 2f);
  %815 = divide(%814, 128f);
  %816 = power(10000f, %815);
  %817 = divide(%811, %816);
  %818 = strided_slice(%817, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %819 = strided_slice(%818, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %820 = strided_slice(%819, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %821 = strided_slice(%820, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 2]);
  %822 = sin(%821);
  %823 = strided_slice(%817, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %824 = strided_slice(%823, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %825 = strided_slice(%824, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %826 = strided_slice(%825, begin=[0, 0, 0, 1], end=[1, 24, 25, 128], strides=[1, 1, 1, 2]);
  %827 = cos(%826);
  %828 = (%822, %827);
  %829 = stack(%828, axis=4);
  %830 = reshape(%829, newshape=[0, 0, 0, -1, 1]);
  %831 = squeeze(%830, axis=[4]);
  %832 = cumsum(%800, meta[relay.attrs.CumsumAttrs][1]);
  %833 = strided_slice(%832, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %834 = strided_slice(%833, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %835 = strided_slice(%834, begin=[0, 0, -1], end=[1, 24, 25], strides=[1, 1, 1]);
  %836 = add(%835, 1e-06f);
  %837 = divide(%832, %836);
  %838 = multiply(%837, 6.28319f);
  %839 = strided_slice(%838, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %840 = strided_slice(%839, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %841 = strided_slice(%840, begin=[0, 0, 0], end=[1, 24, 25], strides=[1, 1, 1]);
  %842 = expand_dims(%841, axis=3);
  %843 = divide(%842, %816);
  %844 = strided_slice(%843, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %845 = strided_slice(%844, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %846 = strided_slice(%845, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %847 = strided_slice(%846, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 2]);
  %848 = sin(%847);
  %849 = strided_slice(%843, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %850 = strided_slice(%849, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %851 = strided_slice(%850, begin=[0, 0, 0, 0], end=[1, 24, 25, 128], strides=[1, 1, 1, 1]);
  %852 = strided_slice(%851, begin=[0, 0, 0, 1], end=[1, 24, 25, 128], strides=[1, 1, 1, 2]);
  %853 = cos(%852);
  %854 = (%848, %853);
  %855 = stack(%854, axis=4);
  %856 = reshape(%855, newshape=[0, 0, 0, -1, 1]);
  %857 = squeeze(%856, axis=[4]);
  %858 = (%831, %857);
  %859 = concatenate(%858, axis=3);
  %860 = transpose(%859, axes=[0, 3, 1, 2]);
  %861 = (%797, %860, %798);
  %862 = %861.2;
  %863 = reshape(%862, newshape=[0, -1, 1]);
  %864 = squeeze(%863, axis=[2]);
  %865 = expand_dims(%864, axis=1);
  %866 = expand_dims(%865, axis=2);
  %867 = cast(-inff, dtype="float32");
  %868 = add(%75, %1);
  %869 = reshape(%868, newshape=[-1, 1, 256]);
  %870 = strided_slice(%model.transformer.decoder.layers.0.multihead_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %871 = strided_slice(%870, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %872 = transpose(%871, axes=[1, 0]);
  %873 = reshape(%872, newshape=[-1, 256, 256]);
  %874 = broadcast_to(%873, meta[relay.attrs.InitOpAttrs][4]);
  %875 = transpose(%874, axes=[0, 2, 1]);
  %876 = nn.batch_matmul(%869, %875);
  %877 = reshape(%876, newshape=[100, 1, 256]);
  %878 = strided_slice(%model.transformer.decoder.layers.0.multihead_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %879 = add(%877, %878);
  %880 = multiply(%879, 0.176777f);
  %881 = copy(%880);
  %882 = reshape(%881, newshape=[100, 8, 32]);
  %883 = transpose(%882, axes=[1, 0, 2]);
  %884 = reshape(%883, newshape=[-1, 100, 32]);
  %885 = %861.0;
  %886 = nn.conv2d(%885, %model.input_proj.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]);
  %887 = nn.bias_add(%886, %model.input_proj.bias);
  %888 = reshape(%887, newshape=[0, 0, -1, 1]);
  %889 = squeeze(%888, axis=[3]);
  %890 = transpose(%889, axes=[2, 0, 1]);
  %891 = expand_dims(%864, axis=1);
  %892 = expand_dims(%891, axis=2);
  %893 = cast(-inff, dtype="float32");
  %894 = %861.1;
  %895 = reshape(%894, newshape=[0, 0, -1, 1]);
  %896 = squeeze(%895, axis=[3]);
  %897 = transpose(%896, axes=[2, 0, 1]);
  %898 = add(%890, %897);
  %899 = reshape(%898, newshape=[-1, 1, 256]);
  %900 = strided_slice(%model.transformer.encoder.layers.0.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %901 = strided_slice(%900, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %902 = transpose(%901, axes=[1, 0]);
  %903 = reshape(%902, newshape=[-1, 256, 256]);
  %904 = broadcast_to(%903, meta[relay.attrs.InitOpAttrs][5]);
  %905 = transpose(%904, axes=[0, 2, 1]);
  %906 = nn.batch_matmul(%899, %905);
  %907 = reshape(%906, newshape=[600, 1, 256]);
  %908 = strided_slice(%model.transformer.encoder.layers.0.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %909 = add(%907, %908);
  %910 = multiply(%909, 0.176777f);
  %911 = copy(%910);
  %912 = reshape(%911, newshape=[600, 8, 32]);
  %913 = transpose(%912, axes=[1, 0, 2]);
  %914 = reshape(%913, newshape=[-1, 600, 32]);
  %915 = reshape(%898, newshape=[-1, 1, 256]);
  %916 = strided_slice(%model.transformer.encoder.layers.0.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %917 = strided_slice(%916, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %918 = transpose(%917, axes=[1, 0]);
  %919 = reshape(%918, newshape=[-1, 256, 256]);
  %920 = broadcast_to(%919, meta[relay.attrs.InitOpAttrs][6]);
  %921 = transpose(%920, axes=[0, 2, 1]);
  %922 = nn.batch_matmul(%915, %921);
  %923 = reshape(%922, newshape=[600, 1, 256]);
  %924 = strided_slice(%model.transformer.encoder.layers.0.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %925 = add(%923, %924);
  %926 = copy(%925);
  %927 = reshape(%926, newshape=[-1, 8, 32]);
  %928 = transpose(%927, axes=[1, 0, 2]);
  %929 = transpose(%928, axes=[0, 2, 1]);
  %930 = reshape(%929, newshape=[-1, 32, 600]);
  %931 = transpose(%930, axes=[0, 2, 1]);
  %932 = nn.batch_matmul(%914, %931);
  %933 = reshape(%932, newshape=[8, 600, 600]);
  %934 = reshape(%933, newshape=[1, 8, 600, 600]);
  %935 = where(%892, %893, %934);
  %936 = reshape(%935, newshape=[8, 600, 600]);
  %937 = nn.softmax(%936);
  %938 = nn.dropout(%937, rate=0.1f);
  %939 = %938.0;
  %940 = reshape(%939, newshape=[-1, 600, 600]);
  %941 = reshape(%890, newshape=[-1, 1, 256]);
  %942 = strided_slice(%model.transformer.encoder.layers.0.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %943 = strided_slice(%942, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %944 = transpose(%943, axes=[1, 0]);
  %945 = reshape(%944, newshape=[-1, 256, 256]);
  %946 = broadcast_to(%945, meta[relay.attrs.InitOpAttrs][7]);
  %947 = transpose(%946, axes=[0, 2, 1]);
  %948 = nn.batch_matmul(%941, %947);
  %949 = reshape(%948, newshape=[600, 1, 256]);
  %950 = strided_slice(%model.transformer.encoder.layers.0.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %951 = add(%949, %950);
  %952 = copy(%951);
  %953 = reshape(%952, newshape=[-1, 8, 32]);
  %954 = transpose(%953, axes=[1, 0, 2]);
  %955 = reshape(%954, newshape=[-1, 600, 32]);
  %956 = transpose(%955, axes=[0, 2, 1]);
  %957 = nn.batch_matmul(%940, %956);
  %958 = reshape(%957, newshape=[8, 600, 32]);
  %959 = transpose(%958, axes=[1, 0, 2]);
  %960 = copy(%959);
  %961 = reshape(%960, newshape=[600, 1, 256]);
  %962 = reshape(%961, newshape=[-1, 1, 256]);
  %963 = transpose(%model.transformer.encoder.layers.0.self_attn.out_proj.weight, axes=[1, 0]);
  %964 = reshape(%963, newshape=[-1, 256, 256]);
  %965 = broadcast_to(%964, meta[relay.attrs.InitOpAttrs][8]);
  %966 = transpose(%965, axes=[0, 2, 1]);
  %967 = nn.batch_matmul(%962, %966);
  %968 = reshape(%967, newshape=[600, 1, 256]);
  %969 = add(%968, %model.transformer.encoder.layers.0.self_attn.out_proj.bias);
  %970 = nn.dropout(%969, rate=0.1f);
  %971 = %970.0;
  %972 = add(%890, %971);
  %973 = nn.layer_norm(%972, %model.transformer.encoder.layers.0.norm1.weight, %model.transformer.encoder.layers.0.norm1.bias);
  %974 = reshape(%973, newshape=[-1, 1, 256]);
  %975 = transpose(%model.transformer.encoder.layers.0.linear1.weight, axes=[1, 0]);
  %976 = reshape(%975, newshape=[-1, 256, 2048]);
  %977 = broadcast_to(%976, meta[relay.attrs.InitOpAttrs][9]);
  %978 = transpose(%977, axes=[0, 2, 1]);
  %979 = nn.batch_matmul(%974, %978);
  %980 = reshape(%979, newshape=[600, 1, 2048]);
  %981 = add(%980, %model.transformer.encoder.layers.0.linear1.bias);
  %982 = nn.relu(%981);
  %983 = nn.dropout(%982, rate=0.1f);
  %984 = %983.0;
  %985 = reshape(%984, newshape=[-1, 1, 2048]);
  %986 = transpose(%model.transformer.encoder.layers.0.linear2.weight, axes=[1, 0]);
  %987 = reshape(%986, newshape=[-1, 2048, 256]);
  %988 = broadcast_to(%987, meta[relay.attrs.InitOpAttrs][10]);
  %989 = transpose(%988, axes=[0, 2, 1]);
  %990 = nn.batch_matmul(%985, %989);
  %991 = reshape(%990, newshape=[600, 1, 256]);
  %992 = add(%991, %model.transformer.encoder.layers.0.linear2.bias);
  %993 = nn.dropout(%992, rate=0.1f);
  %994 = %993.0;
  %995 = add(%973, %994);
  %996 = nn.layer_norm(%995, %model.transformer.encoder.layers.0.norm2.weight, %model.transformer.encoder.layers.0.norm2.bias);
  %997 = expand_dims(%864, axis=1);
  %998 = expand_dims(%997, axis=2);
  %999 = cast(-inff, dtype="float32");
  %1000 = add(%996, %897);
  %1001 = reshape(%1000, newshape=[-1, 1, 256]);
  %1002 = strided_slice(%model.transformer.encoder.layers.1.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1003 = strided_slice(%1002, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1004 = transpose(%1003, axes=[1, 0]);
  %1005 = reshape(%1004, newshape=[-1, 256, 256]);
  %1006 = broadcast_to(%1005, meta[relay.attrs.InitOpAttrs][11]);
  %1007 = transpose(%1006, axes=[0, 2, 1]);
  %1008 = nn.batch_matmul(%1001, %1007);
  %1009 = reshape(%1008, newshape=[600, 1, 256]);
  %1010 = strided_slice(%model.transformer.encoder.layers.1.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1011 = add(%1009, %1010);
  %1012 = multiply(%1011, 0.176777f);
  %1013 = copy(%1012);
  %1014 = reshape(%1013, newshape=[600, 8, 32]);
  %1015 = transpose(%1014, axes=[1, 0, 2]);
  %1016 = reshape(%1015, newshape=[-1, 600, 32]);
  %1017 = reshape(%1000, newshape=[-1, 1, 256]);
  %1018 = strided_slice(%model.transformer.encoder.layers.1.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1019 = strided_slice(%1018, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1020 = transpose(%1019, axes=[1, 0]);
  %1021 = reshape(%1020, newshape=[-1, 256, 256]);
  %1022 = broadcast_to(%1021, meta[relay.attrs.InitOpAttrs][12]);
  %1023 = transpose(%1022, axes=[0, 2, 1]);
  %1024 = nn.batch_matmul(%1017, %1023);
  %1025 = reshape(%1024, newshape=[600, 1, 256]);
  %1026 = strided_slice(%model.transformer.encoder.layers.1.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1027 = add(%1025, %1026);
  %1028 = copy(%1027);
  %1029 = reshape(%1028, newshape=[-1, 8, 32]);
  %1030 = transpose(%1029, axes=[1, 0, 2]);
  %1031 = transpose(%1030, axes=[0, 2, 1]);
  %1032 = reshape(%1031, newshape=[-1, 32, 600]);
  %1033 = transpose(%1032, axes=[0, 2, 1]);
  %1034 = nn.batch_matmul(%1016, %1033);
  %1035 = reshape(%1034, newshape=[8, 600, 600]);
  %1036 = reshape(%1035, newshape=[1, 8, 600, 600]);
  %1037 = where(%998, %999, %1036);
  %1038 = reshape(%1037, newshape=[8, 600, 600]);
  %1039 = nn.softmax(%1038);
  %1040 = nn.dropout(%1039, rate=0.1f);
  %1041 = %1040.0;
  %1042 = reshape(%1041, newshape=[-1, 600, 600]);
  %1043 = reshape(%996, newshape=[-1, 1, 256]);
  %1044 = strided_slice(%model.transformer.encoder.layers.1.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1045 = strided_slice(%1044, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1046 = transpose(%1045, axes=[1, 0]);
  %1047 = reshape(%1046, newshape=[-1, 256, 256]);
  %1048 = broadcast_to(%1047, meta[relay.attrs.InitOpAttrs][13]);
  %1049 = transpose(%1048, axes=[0, 2, 1]);
  %1050 = nn.batch_matmul(%1043, %1049);
  %1051 = reshape(%1050, newshape=[600, 1, 256]);
  %1052 = strided_slice(%model.transformer.encoder.layers.1.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1053 = add(%1051, %1052);
  %1054 = copy(%1053);
  %1055 = reshape(%1054, newshape=[-1, 8, 32]);
  %1056 = transpose(%1055, axes=[1, 0, 2]);
  %1057 = reshape(%1056, newshape=[-1, 600, 32]);
  %1058 = transpose(%1057, axes=[0, 2, 1]);
  %1059 = nn.batch_matmul(%1042, %1058);
  %1060 = reshape(%1059, newshape=[8, 600, 32]);
  %1061 = transpose(%1060, axes=[1, 0, 2]);
  %1062 = copy(%1061);
  %1063 = reshape(%1062, newshape=[600, 1, 256]);
  %1064 = reshape(%1063, newshape=[-1, 1, 256]);
  %1065 = transpose(%model.transformer.encoder.layers.1.self_attn.out_proj.weight, axes=[1, 0]);
  %1066 = reshape(%1065, newshape=[-1, 256, 256]);
  %1067 = broadcast_to(%1066, meta[relay.attrs.InitOpAttrs][14]);
  %1068 = transpose(%1067, axes=[0, 2, 1]);
  %1069 = nn.batch_matmul(%1064, %1068);
  %1070 = reshape(%1069, newshape=[600, 1, 256]);
  %1071 = add(%1070, %model.transformer.encoder.layers.1.self_attn.out_proj.bias);
  %1072 = nn.dropout(%1071, rate=0.1f);
  %1073 = %1072.0;
  %1074 = add(%996, %1073);
  %1075 = nn.layer_norm(%1074, %model.transformer.encoder.layers.1.norm1.weight, %model.transformer.encoder.layers.1.norm1.bias);
  %1076 = reshape(%1075, newshape=[-1, 1, 256]);
  %1077 = transpose(%model.transformer.encoder.layers.1.linear1.weight, axes=[1, 0]);
  %1078 = reshape(%1077, newshape=[-1, 256, 2048]);
  %1079 = broadcast_to(%1078, meta[relay.attrs.InitOpAttrs][15]);
  %1080 = transpose(%1079, axes=[0, 2, 1]);
  %1081 = nn.batch_matmul(%1076, %1080);
  %1082 = reshape(%1081, newshape=[600, 1, 2048]);
  %1083 = add(%1082, %model.transformer.encoder.layers.1.linear1.bias);
  %1084 = nn.relu(%1083);
  %1085 = nn.dropout(%1084, rate=0.1f);
  %1086 = %1085.0;
  %1087 = reshape(%1086, newshape=[-1, 1, 2048]);
  %1088 = transpose(%model.transformer.encoder.layers.1.linear2.weight, axes=[1, 0]);
  %1089 = reshape(%1088, newshape=[-1, 2048, 256]);
  %1090 = broadcast_to(%1089, meta[relay.attrs.InitOpAttrs][16]);
  %1091 = transpose(%1090, axes=[0, 2, 1]);
  %1092 = nn.batch_matmul(%1087, %1091);
  %1093 = reshape(%1092, newshape=[600, 1, 256]);
  %1094 = add(%1093, %model.transformer.encoder.layers.1.linear2.bias);
  %1095 = nn.dropout(%1094, rate=0.1f);
  %1096 = %1095.0;
  %1097 = add(%1075, %1096);
  %1098 = nn.layer_norm(%1097, %model.transformer.encoder.layers.1.norm2.weight, %model.transformer.encoder.layers.1.norm2.bias);
  %1099 = expand_dims(%864, axis=1);
  %1100 = expand_dims(%1099, axis=2);
  %1101 = cast(-inff, dtype="float32");
  %1102 = add(%1098, %897);
  %1103 = reshape(%1102, newshape=[-1, 1, 256]);
  %1104 = strided_slice(%model.transformer.encoder.layers.2.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1105 = strided_slice(%1104, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1106 = transpose(%1105, axes=[1, 0]);
  %1107 = reshape(%1106, newshape=[-1, 256, 256]);
  %1108 = broadcast_to(%1107, meta[relay.attrs.InitOpAttrs][17]);
  %1109 = transpose(%1108, axes=[0, 2, 1]);
  %1110 = nn.batch_matmul(%1103, %1109);
  %1111 = reshape(%1110, newshape=[600, 1, 256]);
  %1112 = strided_slice(%model.transformer.encoder.layers.2.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1113 = add(%1111, %1112);
  %1114 = multiply(%1113, 0.176777f);
  %1115 = copy(%1114);
  %1116 = reshape(%1115, newshape=[600, 8, 32]);
  %1117 = transpose(%1116, axes=[1, 0, 2]);
  %1118 = reshape(%1117, newshape=[-1, 600, 32]);
  %1119 = reshape(%1102, newshape=[-1, 1, 256]);
  %1120 = strided_slice(%model.transformer.encoder.layers.2.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1121 = strided_slice(%1120, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1122 = transpose(%1121, axes=[1, 0]);
  %1123 = reshape(%1122, newshape=[-1, 256, 256]);
  %1124 = broadcast_to(%1123, meta[relay.attrs.InitOpAttrs][18]);
  %1125 = transpose(%1124, axes=[0, 2, 1]);
  %1126 = nn.batch_matmul(%1119, %1125);
  %1127 = reshape(%1126, newshape=[600, 1, 256]);
  %1128 = strided_slice(%model.transformer.encoder.layers.2.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1129 = add(%1127, %1128);
  %1130 = copy(%1129);
  %1131 = reshape(%1130, newshape=[-1, 8, 32]);
  %1132 = transpose(%1131, axes=[1, 0, 2]);
  %1133 = transpose(%1132, axes=[0, 2, 1]);
  %1134 = reshape(%1133, newshape=[-1, 32, 600]);
  %1135 = transpose(%1134, axes=[0, 2, 1]);
  %1136 = nn.batch_matmul(%1118, %1135);
  %1137 = reshape(%1136, newshape=[8, 600, 600]);
  %1138 = reshape(%1137, newshape=[1, 8, 600, 600]);
  %1139 = where(%1100, %1101, %1138);
  %1140 = reshape(%1139, newshape=[8, 600, 600]);
  %1141 = nn.softmax(%1140);
  %1142 = nn.dropout(%1141, rate=0.1f);
  %1143 = %1142.0;
  %1144 = reshape(%1143, newshape=[-1, 600, 600]);
  %1145 = reshape(%1098, newshape=[-1, 1, 256]);
  %1146 = strided_slice(%model.transformer.encoder.layers.2.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1147 = strided_slice(%1146, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1148 = transpose(%1147, axes=[1, 0]);
  %1149 = reshape(%1148, newshape=[-1, 256, 256]);
  %1150 = broadcast_to(%1149, meta[relay.attrs.InitOpAttrs][19]);
  %1151 = transpose(%1150, axes=[0, 2, 1]);
  %1152 = nn.batch_matmul(%1145, %1151);
  %1153 = reshape(%1152, newshape=[600, 1, 256]);
  %1154 = strided_slice(%model.transformer.encoder.layers.2.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1155 = add(%1153, %1154);
  %1156 = copy(%1155);
  %1157 = reshape(%1156, newshape=[-1, 8, 32]);
  %1158 = transpose(%1157, axes=[1, 0, 2]);
  %1159 = reshape(%1158, newshape=[-1, 600, 32]);
  %1160 = transpose(%1159, axes=[0, 2, 1]);
  %1161 = nn.batch_matmul(%1144, %1160);
  %1162 = reshape(%1161, newshape=[8, 600, 32]);
  %1163 = transpose(%1162, axes=[1, 0, 2]);
  %1164 = copy(%1163);
  %1165 = reshape(%1164, newshape=[600, 1, 256]);
  %1166 = reshape(%1165, newshape=[-1, 1, 256]);
  %1167 = transpose(%model.transformer.encoder.layers.2.self_attn.out_proj.weight, axes=[1, 0]);
  %1168 = reshape(%1167, newshape=[-1, 256, 256]);
  %1169 = broadcast_to(%1168, meta[relay.attrs.InitOpAttrs][20]);
  %1170 = transpose(%1169, axes=[0, 2, 1]);
  %1171 = nn.batch_matmul(%1166, %1170);
  %1172 = reshape(%1171, newshape=[600, 1, 256]);
  %1173 = add(%1172, %model.transformer.encoder.layers.2.self_attn.out_proj.bias);
  %1174 = nn.dropout(%1173, rate=0.1f);
  %1175 = %1174.0;
  %1176 = add(%1098, %1175);
  %1177 = nn.layer_norm(%1176, %model.transformer.encoder.layers.2.norm1.weight, %model.transformer.encoder.layers.2.norm1.bias);
  %1178 = reshape(%1177, newshape=[-1, 1, 256]);
  %1179 = transpose(%model.transformer.encoder.layers.2.linear1.weight, axes=[1, 0]);
  %1180 = reshape(%1179, newshape=[-1, 256, 2048]);
  %1181 = broadcast_to(%1180, meta[relay.attrs.InitOpAttrs][21]);
  %1182 = transpose(%1181, axes=[0, 2, 1]);
  %1183 = nn.batch_matmul(%1178, %1182);
  %1184 = reshape(%1183, newshape=[600, 1, 2048]);
  %1185 = add(%1184, %model.transformer.encoder.layers.2.linear1.bias);
  %1186 = nn.relu(%1185);
  %1187 = nn.dropout(%1186, rate=0.1f);
  %1188 = %1187.0;
  %1189 = reshape(%1188, newshape=[-1, 1, 2048]);
  %1190 = transpose(%model.transformer.encoder.layers.2.linear2.weight, axes=[1, 0]);
  %1191 = reshape(%1190, newshape=[-1, 2048, 256]);
  %1192 = broadcast_to(%1191, meta[relay.attrs.InitOpAttrs][22]);
  %1193 = transpose(%1192, axes=[0, 2, 1]);
  %1194 = nn.batch_matmul(%1189, %1193);
  %1195 = reshape(%1194, newshape=[600, 1, 256]);
  %1196 = add(%1195, %model.transformer.encoder.layers.2.linear2.bias);
  %1197 = nn.dropout(%1196, rate=0.1f);
  %1198 = %1197.0;
  %1199 = add(%1177, %1198);
  %1200 = nn.layer_norm(%1199, %model.transformer.encoder.layers.2.norm2.weight, %model.transformer.encoder.layers.2.norm2.bias);
  %1201 = expand_dims(%864, axis=1);
  %1202 = expand_dims(%1201, axis=2);
  %1203 = cast(-inff, dtype="float32");
  %1204 = add(%1200, %897);
  %1205 = reshape(%1204, newshape=[-1, 1, 256]);
  %1206 = strided_slice(%model.transformer.encoder.layers.3.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1207 = strided_slice(%1206, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1208 = transpose(%1207, axes=[1, 0]);
  %1209 = reshape(%1208, newshape=[-1, 256, 256]);
  %1210 = broadcast_to(%1209, meta[relay.attrs.InitOpAttrs][23]);
  %1211 = transpose(%1210, axes=[0, 2, 1]);
  %1212 = nn.batch_matmul(%1205, %1211);
  %1213 = reshape(%1212, newshape=[600, 1, 256]);
  %1214 = strided_slice(%model.transformer.encoder.layers.3.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1215 = add(%1213, %1214);
  %1216 = multiply(%1215, 0.176777f);
  %1217 = copy(%1216);
  %1218 = reshape(%1217, newshape=[600, 8, 32]);
  %1219 = transpose(%1218, axes=[1, 0, 2]);
  %1220 = reshape(%1219, newshape=[-1, 600, 32]);
  %1221 = reshape(%1204, newshape=[-1, 1, 256]);
  %1222 = strided_slice(%model.transformer.encoder.layers.3.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1223 = strided_slice(%1222, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1224 = transpose(%1223, axes=[1, 0]);
  %1225 = reshape(%1224, newshape=[-1, 256, 256]);
  %1226 = broadcast_to(%1225, meta[relay.attrs.InitOpAttrs][24]);
  %1227 = transpose(%1226, axes=[0, 2, 1]);
  %1228 = nn.batch_matmul(%1221, %1227);
  %1229 = reshape(%1228, newshape=[600, 1, 256]);
  %1230 = strided_slice(%model.transformer.encoder.layers.3.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1231 = add(%1229, %1230);
  %1232 = copy(%1231);
  %1233 = reshape(%1232, newshape=[-1, 8, 32]);
  %1234 = transpose(%1233, axes=[1, 0, 2]);
  %1235 = transpose(%1234, axes=[0, 2, 1]);
  %1236 = reshape(%1235, newshape=[-1, 32, 600]);
  %1237 = transpose(%1236, axes=[0, 2, 1]);
  %1238 = nn.batch_matmul(%1220, %1237);
  %1239 = reshape(%1238, newshape=[8, 600, 600]);
  %1240 = reshape(%1239, newshape=[1, 8, 600, 600]);
  %1241 = where(%1202, %1203, %1240);
  %1242 = reshape(%1241, newshape=[8, 600, 600]);
  %1243 = nn.softmax(%1242);
  %1244 = nn.dropout(%1243, rate=0.1f);
  %1245 = %1244.0;
  %1246 = reshape(%1245, newshape=[-1, 600, 600]);
  %1247 = reshape(%1200, newshape=[-1, 1, 256]);
  %1248 = strided_slice(%model.transformer.encoder.layers.3.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1249 = strided_slice(%1248, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1250 = transpose(%1249, axes=[1, 0]);
  %1251 = reshape(%1250, newshape=[-1, 256, 256]);
  %1252 = broadcast_to(%1251, meta[relay.attrs.InitOpAttrs][25]);
  %1253 = transpose(%1252, axes=[0, 2, 1]);
  %1254 = nn.batch_matmul(%1247, %1253);
  %1255 = reshape(%1254, newshape=[600, 1, 256]);
  %1256 = strided_slice(%model.transformer.encoder.layers.3.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1257 = add(%1255, %1256);
  %1258 = copy(%1257);
  %1259 = reshape(%1258, newshape=[-1, 8, 32]);
  %1260 = transpose(%1259, axes=[1, 0, 2]);
  %1261 = reshape(%1260, newshape=[-1, 600, 32]);
  %1262 = transpose(%1261, axes=[0, 2, 1]);
  %1263 = nn.batch_matmul(%1246, %1262);
  %1264 = reshape(%1263, newshape=[8, 600, 32]);
  %1265 = transpose(%1264, axes=[1, 0, 2]);
  %1266 = copy(%1265);
  %1267 = reshape(%1266, newshape=[600, 1, 256]);
  %1268 = reshape(%1267, newshape=[-1, 1, 256]);
  %1269 = transpose(%model.transformer.encoder.layers.3.self_attn.out_proj.weight, axes=[1, 0]);
  %1270 = reshape(%1269, newshape=[-1, 256, 256]);
  %1271 = broadcast_to(%1270, meta[relay.attrs.InitOpAttrs][26]);
  %1272 = transpose(%1271, axes=[0, 2, 1]);
  %1273 = nn.batch_matmul(%1268, %1272);
  %1274 = reshape(%1273, newshape=[600, 1, 256]);
  %1275 = add(%1274, %model.transformer.encoder.layers.3.self_attn.out_proj.bias);
  %1276 = nn.dropout(%1275, rate=0.1f);
  %1277 = %1276.0;
  %1278 = add(%1200, %1277);
  %1279 = nn.layer_norm(%1278, %model.transformer.encoder.layers.3.norm1.weight, %model.transformer.encoder.layers.3.norm1.bias);
  %1280 = reshape(%1279, newshape=[-1, 1, 256]);
  %1281 = transpose(%model.transformer.encoder.layers.3.linear1.weight, axes=[1, 0]);
  %1282 = reshape(%1281, newshape=[-1, 256, 2048]);
  %1283 = broadcast_to(%1282, meta[relay.attrs.InitOpAttrs][27]);
  %1284 = transpose(%1283, axes=[0, 2, 1]);
  %1285 = nn.batch_matmul(%1280, %1284);
  %1286 = reshape(%1285, newshape=[600, 1, 2048]);
  %1287 = add(%1286, %model.transformer.encoder.layers.3.linear1.bias);
  %1288 = nn.relu(%1287);
  %1289 = nn.dropout(%1288, rate=0.1f);
  %1290 = %1289.0;
  %1291 = reshape(%1290, newshape=[-1, 1, 2048]);
  %1292 = transpose(%model.transformer.encoder.layers.3.linear2.weight, axes=[1, 0]);
  %1293 = reshape(%1292, newshape=[-1, 2048, 256]);
  %1294 = broadcast_to(%1293, meta[relay.attrs.InitOpAttrs][28]);
  %1295 = transpose(%1294, axes=[0, 2, 1]);
  %1296 = nn.batch_matmul(%1291, %1295);
  %1297 = reshape(%1296, newshape=[600, 1, 256]);
  %1298 = add(%1297, %model.transformer.encoder.layers.3.linear2.bias);
  %1299 = nn.dropout(%1298, rate=0.1f);
  %1300 = %1299.0;
  %1301 = add(%1279, %1300);
  %1302 = nn.layer_norm(%1301, %model.transformer.encoder.layers.3.norm2.weight, %model.transformer.encoder.layers.3.norm2.bias);
  %1303 = expand_dims(%864, axis=1);
  %1304 = expand_dims(%1303, axis=2);
  %1305 = cast(-inff, dtype="float32");
  %1306 = add(%1302, %897);
  %1307 = reshape(%1306, newshape=[-1, 1, 256]);
  %1308 = strided_slice(%model.transformer.encoder.layers.4.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1309 = strided_slice(%1308, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1310 = transpose(%1309, axes=[1, 0]);
  %1311 = reshape(%1310, newshape=[-1, 256, 256]);
  %1312 = broadcast_to(%1311, meta[relay.attrs.InitOpAttrs][29]);
  %1313 = transpose(%1312, axes=[0, 2, 1]);
  %1314 = nn.batch_matmul(%1307, %1313);
  %1315 = reshape(%1314, newshape=[600, 1, 256]);
  %1316 = strided_slice(%model.transformer.encoder.layers.4.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1317 = add(%1315, %1316);
  %1318 = multiply(%1317, 0.176777f);
  %1319 = copy(%1318);
  %1320 = reshape(%1319, newshape=[600, 8, 32]);
  %1321 = transpose(%1320, axes=[1, 0, 2]);
  %1322 = reshape(%1321, newshape=[-1, 600, 32]);
  %1323 = reshape(%1306, newshape=[-1, 1, 256]);
  %1324 = strided_slice(%model.transformer.encoder.layers.4.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1325 = strided_slice(%1324, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1326 = transpose(%1325, axes=[1, 0]);
  %1327 = reshape(%1326, newshape=[-1, 256, 256]);
  %1328 = broadcast_to(%1327, meta[relay.attrs.InitOpAttrs][30]);
  %1329 = transpose(%1328, axes=[0, 2, 1]);
  %1330 = nn.batch_matmul(%1323, %1329);
  %1331 = reshape(%1330, newshape=[600, 1, 256]);
  %1332 = strided_slice(%model.transformer.encoder.layers.4.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1333 = add(%1331, %1332);
  %1334 = copy(%1333);
  %1335 = reshape(%1334, newshape=[-1, 8, 32]);
  %1336 = transpose(%1335, axes=[1, 0, 2]);
  %1337 = transpose(%1336, axes=[0, 2, 1]);
  %1338 = reshape(%1337, newshape=[-1, 32, 600]);
  %1339 = transpose(%1338, axes=[0, 2, 1]);
  %1340 = nn.batch_matmul(%1322, %1339);
  %1341 = reshape(%1340, newshape=[8, 600, 600]);
  %1342 = reshape(%1341, newshape=[1, 8, 600, 600]);
  %1343 = where(%1304, %1305, %1342);
  %1344 = reshape(%1343, newshape=[8, 600, 600]);
  %1345 = nn.softmax(%1344);
  %1346 = nn.dropout(%1345, rate=0.1f);
  %1347 = %1346.0;
  %1348 = reshape(%1347, newshape=[-1, 600, 600]);
  %1349 = reshape(%1302, newshape=[-1, 1, 256]);
  %1350 = strided_slice(%model.transformer.encoder.layers.4.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1351 = strided_slice(%1350, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1352 = transpose(%1351, axes=[1, 0]);
  %1353 = reshape(%1352, newshape=[-1, 256, 256]);
  %1354 = broadcast_to(%1353, meta[relay.attrs.InitOpAttrs][31]);
  %1355 = transpose(%1354, axes=[0, 2, 1]);
  %1356 = nn.batch_matmul(%1349, %1355);
  %1357 = reshape(%1356, newshape=[600, 1, 256]);
  %1358 = strided_slice(%model.transformer.encoder.layers.4.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1359 = add(%1357, %1358);
  %1360 = copy(%1359);
  %1361 = reshape(%1360, newshape=[-1, 8, 32]);
  %1362 = transpose(%1361, axes=[1, 0, 2]);
  %1363 = reshape(%1362, newshape=[-1, 600, 32]);
  %1364 = transpose(%1363, axes=[0, 2, 1]);
  %1365 = nn.batch_matmul(%1348, %1364);
  %1366 = reshape(%1365, newshape=[8, 600, 32]);
  %1367 = transpose(%1366, axes=[1, 0, 2]);
  %1368 = copy(%1367);
  %1369 = reshape(%1368, newshape=[600, 1, 256]);
  %1370 = reshape(%1369, newshape=[-1, 1, 256]);
  %1371 = transpose(%model.transformer.encoder.layers.4.self_attn.out_proj.weight, axes=[1, 0]);
  %1372 = reshape(%1371, newshape=[-1, 256, 256]);
  %1373 = broadcast_to(%1372, meta[relay.attrs.InitOpAttrs][32]);
  %1374 = transpose(%1373, axes=[0, 2, 1]);
  %1375 = nn.batch_matmul(%1370, %1374);
  %1376 = reshape(%1375, newshape=[600, 1, 256]);
  %1377 = add(%1376, %model.transformer.encoder.layers.4.self_attn.out_proj.bias);
  %1378 = nn.dropout(%1377, rate=0.1f);
  %1379 = %1378.0;
  %1380 = add(%1302, %1379);
  %1381 = nn.layer_norm(%1380, %model.transformer.encoder.layers.4.norm1.weight, %model.transformer.encoder.layers.4.norm1.bias);
  %1382 = reshape(%1381, newshape=[-1, 1, 256]);
  %1383 = transpose(%model.transformer.encoder.layers.4.linear1.weight, axes=[1, 0]);
  %1384 = reshape(%1383, newshape=[-1, 256, 2048]);
  %1385 = broadcast_to(%1384, meta[relay.attrs.InitOpAttrs][33]);
  %1386 = transpose(%1385, axes=[0, 2, 1]);
  %1387 = nn.batch_matmul(%1382, %1386);
  %1388 = reshape(%1387, newshape=[600, 1, 2048]);
  %1389 = add(%1388, %model.transformer.encoder.layers.4.linear1.bias);
  %1390 = nn.relu(%1389);
  %1391 = nn.dropout(%1390, rate=0.1f);
  %1392 = %1391.0;
  %1393 = reshape(%1392, newshape=[-1, 1, 2048]);
  %1394 = transpose(%model.transformer.encoder.layers.4.linear2.weight, axes=[1, 0]);
  %1395 = reshape(%1394, newshape=[-1, 2048, 256]);
  %1396 = broadcast_to(%1395, meta[relay.attrs.InitOpAttrs][34]);
  %1397 = transpose(%1396, axes=[0, 2, 1]);
  %1398 = nn.batch_matmul(%1393, %1397);
  %1399 = reshape(%1398, newshape=[600, 1, 256]);
  %1400 = add(%1399, %model.transformer.encoder.layers.4.linear2.bias);
  %1401 = nn.dropout(%1400, rate=0.1f);
  %1402 = %1401.0;
  %1403 = add(%1381, %1402);
  %1404 = nn.layer_norm(%1403, %model.transformer.encoder.layers.4.norm2.weight, %model.transformer.encoder.layers.4.norm2.bias);
  %1405 = expand_dims(%864, axis=1);
  %1406 = expand_dims(%1405, axis=2);
  %1407 = cast(-inff, dtype="float32");
  %1408 = add(%1404, %897);
  %1409 = reshape(%1408, newshape=[-1, 1, 256]);
  %1410 = strided_slice(%model.transformer.encoder.layers.5.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1411 = strided_slice(%1410, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1412 = transpose(%1411, axes=[1, 0]);
  %1413 = reshape(%1412, newshape=[-1, 256, 256]);
  %1414 = broadcast_to(%1413, meta[relay.attrs.InitOpAttrs][35]);
  %1415 = transpose(%1414, axes=[0, 2, 1]);
  %1416 = nn.batch_matmul(%1409, %1415);
  %1417 = reshape(%1416, newshape=[600, 1, 256]);
  %1418 = strided_slice(%model.transformer.encoder.layers.5.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1419 = add(%1417, %1418);
  %1420 = multiply(%1419, 0.176777f);
  %1421 = copy(%1420);
  %1422 = reshape(%1421, newshape=[600, 8, 32]);
  %1423 = transpose(%1422, axes=[1, 0, 2]);
  %1424 = reshape(%1423, newshape=[-1, 600, 32]);
  %1425 = reshape(%1408, newshape=[-1, 1, 256]);
  %1426 = strided_slice(%model.transformer.encoder.layers.5.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1427 = strided_slice(%1426, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1428 = transpose(%1427, axes=[1, 0]);
  %1429 = reshape(%1428, newshape=[-1, 256, 256]);
  %1430 = broadcast_to(%1429, meta[relay.attrs.InitOpAttrs][36]);
  %1431 = transpose(%1430, axes=[0, 2, 1]);
  %1432 = nn.batch_matmul(%1425, %1431);
  %1433 = reshape(%1432, newshape=[600, 1, 256]);
  %1434 = strided_slice(%model.transformer.encoder.layers.5.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1435 = add(%1433, %1434);
  %1436 = copy(%1435);
  %1437 = reshape(%1436, newshape=[-1, 8, 32]);
  %1438 = transpose(%1437, axes=[1, 0, 2]);
  %1439 = transpose(%1438, axes=[0, 2, 1]);
  %1440 = reshape(%1439, newshape=[-1, 32, 600]);
  %1441 = transpose(%1440, axes=[0, 2, 1]);
  %1442 = nn.batch_matmul(%1424, %1441);
  %1443 = reshape(%1442, newshape=[8, 600, 600]);
  %1444 = reshape(%1443, newshape=[1, 8, 600, 600]);
  %1445 = where(%1406, %1407, %1444);
  %1446 = reshape(%1445, newshape=[8, 600, 600]);
  %1447 = nn.softmax(%1446);
  %1448 = nn.dropout(%1447, rate=0.1f);
  %1449 = %1448.0;
  %1450 = reshape(%1449, newshape=[-1, 600, 600]);
  %1451 = reshape(%1404, newshape=[-1, 1, 256]);
  %1452 = strided_slice(%model.transformer.encoder.layers.5.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1453 = strided_slice(%1452, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1454 = transpose(%1453, axes=[1, 0]);
  %1455 = reshape(%1454, newshape=[-1, 256, 256]);
  %1456 = broadcast_to(%1455, meta[relay.attrs.InitOpAttrs][37]);
  %1457 = transpose(%1456, axes=[0, 2, 1]);
  %1458 = nn.batch_matmul(%1451, %1457);
  %1459 = reshape(%1458, newshape=[600, 1, 256]);
  %1460 = strided_slice(%model.transformer.encoder.layers.5.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1461 = add(%1459, %1460);
  %1462 = copy(%1461);
  %1463 = reshape(%1462, newshape=[-1, 8, 32]);
  %1464 = transpose(%1463, axes=[1, 0, 2]);
  %1465 = reshape(%1464, newshape=[-1, 600, 32]);
  %1466 = transpose(%1465, axes=[0, 2, 1]);
  %1467 = nn.batch_matmul(%1450, %1466);
  %1468 = reshape(%1467, newshape=[8, 600, 32]);
  %1469 = transpose(%1468, axes=[1, 0, 2]);
  %1470 = copy(%1469);
  %1471 = reshape(%1470, newshape=[600, 1, 256]);
  %1472 = reshape(%1471, newshape=[-1, 1, 256]);
  %1473 = transpose(%model.transformer.encoder.layers.5.self_attn.out_proj.weight, axes=[1, 0]);
  %1474 = reshape(%1473, newshape=[-1, 256, 256]);
  %1475 = broadcast_to(%1474, meta[relay.attrs.InitOpAttrs][38]);
  %1476 = transpose(%1475, axes=[0, 2, 1]);
  %1477 = nn.batch_matmul(%1472, %1476);
  %1478 = reshape(%1477, newshape=[600, 1, 256]);
  %1479 = add(%1478, %model.transformer.encoder.layers.5.self_attn.out_proj.bias);
  %1480 = nn.dropout(%1479, rate=0.1f);
  %1481 = %1480.0;
  %1482 = add(%1404, %1481);
  %1483 = nn.layer_norm(%1482, %model.transformer.encoder.layers.5.norm1.weight, %model.transformer.encoder.layers.5.norm1.bias);
  %1484 = reshape(%1483, newshape=[-1, 1, 256]);
  %1485 = transpose(%model.transformer.encoder.layers.5.linear1.weight, axes=[1, 0]);
  %1486 = reshape(%1485, newshape=[-1, 256, 2048]);
  %1487 = broadcast_to(%1486, meta[relay.attrs.InitOpAttrs][39]);
  %1488 = transpose(%1487, axes=[0, 2, 1]);
  %1489 = nn.batch_matmul(%1484, %1488);
  %1490 = reshape(%1489, newshape=[600, 1, 2048]);
  %1491 = add(%1490, %model.transformer.encoder.layers.5.linear1.bias);
  %1492 = nn.relu(%1491);
  %1493 = nn.dropout(%1492, rate=0.1f);
  %1494 = %1493.0;
  %1495 = reshape(%1494, newshape=[-1, 1, 2048]);
  %1496 = transpose(%model.transformer.encoder.layers.5.linear2.weight, axes=[1, 0]);
  %1497 = reshape(%1496, newshape=[-1, 2048, 256]);
  %1498 = broadcast_to(%1497, meta[relay.attrs.InitOpAttrs][40]);
  %1499 = transpose(%1498, axes=[0, 2, 1]);
  %1500 = nn.batch_matmul(%1495, %1499);
  %1501 = reshape(%1500, newshape=[600, 1, 256]);
  %1502 = add(%1501, %model.transformer.encoder.layers.5.linear2.bias);
  %1503 = nn.dropout(%1502, rate=0.1f);
  %1504 = %1503.0;
  %1505 = add(%1483, %1504);
  %1506 = nn.layer_norm(%1505, %model.transformer.encoder.layers.5.norm2.weight, %model.transformer.encoder.layers.5.norm2.bias);
  %1507 = add(%1506, %897);
  %1508 = reshape(%1507, newshape=[-1, 1, 256]);
  %1509 = strided_slice(%model.transformer.decoder.layers.0.multihead_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1510 = strided_slice(%1509, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1511 = transpose(%1510, axes=[1, 0]);
  %1512 = reshape(%1511, newshape=[-1, 256, 256]);
  %1513 = broadcast_to(%1512, meta[relay.attrs.InitOpAttrs][41]);
  %1514 = transpose(%1513, axes=[0, 2, 1]);
  %1515 = nn.batch_matmul(%1508, %1514);
  %1516 = reshape(%1515, newshape=[600, 1, 256]);
  %1517 = strided_slice(%model.transformer.decoder.layers.0.multihead_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1518 = add(%1516, %1517);
  %1519 = copy(%1518);
  %1520 = reshape(%1519, newshape=[-1, 8, 32]);
  %1521 = transpose(%1520, axes=[1, 0, 2]);
  %1522 = transpose(%1521, axes=[0, 2, 1]);
  %1523 = reshape(%1522, newshape=[-1, 32, 600]);
  %1524 = transpose(%1523, axes=[0, 2, 1]);
  %1525 = nn.batch_matmul(%884, %1524);
  %1526 = reshape(%1525, newshape=[8, 100, 600]);
  %1527 = reshape(%1526, newshape=[1, 8, 100, 600]);
  %1528 = where(%866, %867, %1527);
  %1529 = reshape(%1528, newshape=[8, 100, 600]);
  %1530 = nn.softmax(%1529);
  %1531 = nn.dropout(%1530, rate=0.1f);
  %1532 = %1531.0;
  %1533 = reshape(%1532, newshape=[-1, 100, 600]);
  %1534 = reshape(%1506, newshape=[-1, 1, 256]);
  %1535 = strided_slice(%model.transformer.decoder.layers.0.multihead_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1536 = strided_slice(%1535, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1537 = transpose(%1536, axes=[1, 0]);
  %1538 = reshape(%1537, newshape=[-1, 256, 256]);
  %1539 = broadcast_to(%1538, meta[relay.attrs.InitOpAttrs][42]);
  %1540 = transpose(%1539, axes=[0, 2, 1]);
  %1541 = nn.batch_matmul(%1534, %1540);
  %1542 = reshape(%1541, newshape=[600, 1, 256]);
  %1543 = strided_slice(%model.transformer.decoder.layers.0.multihead_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1544 = add(%1542, %1543);
  %1545 = copy(%1544);
  %1546 = reshape(%1545, newshape=[-1, 8, 32]);
  %1547 = transpose(%1546, axes=[1, 0, 2]);
  %1548 = reshape(%1547, newshape=[-1, 600, 32]);
  %1549 = transpose(%1548, axes=[0, 2, 1]);
  %1550 = nn.batch_matmul(%1533, %1549);
  %1551 = reshape(%1550, newshape=[8, 100, 32]);
  %1552 = transpose(%1551, axes=[1, 0, 2]);
  %1553 = copy(%1552);
  %1554 = reshape(%1553, newshape=[100, 1, 256]);
  %1555 = reshape(%1554, newshape=[-1, 1, 256]);
  %1556 = transpose(%model.transformer.decoder.layers.0.multihead_attn.out_proj.weight, axes=[1, 0]);
  %1557 = reshape(%1556, newshape=[-1, 256, 256]);
  %1558 = broadcast_to(%1557, meta[relay.attrs.InitOpAttrs][43]);
  %1559 = transpose(%1558, axes=[0, 2, 1]);
  %1560 = nn.batch_matmul(%1555, %1559);
  %1561 = reshape(%1560, newshape=[100, 1, 256]);
  %1562 = add(%1561, %model.transformer.decoder.layers.0.multihead_attn.out_proj.bias);
  %1563 = nn.dropout(%1562, rate=0.1f);
  %1564 = %1563.0;
  %1565 = add(%75, %1564);
  %1566 = nn.layer_norm(%1565, %model.transformer.decoder.layers.0.norm2.weight, %model.transformer.decoder.layers.0.norm2.bias);
  %1567 = reshape(%1566, newshape=[-1, 1, 256]);
  %1568 = transpose(%model.transformer.decoder.layers.0.linear1.weight, axes=[1, 0]);
  %1569 = reshape(%1568, newshape=[-1, 256, 2048]);
  %1570 = broadcast_to(%1569, meta[relay.attrs.InitOpAttrs][44]);
  %1571 = transpose(%1570, axes=[0, 2, 1]);
  %1572 = nn.batch_matmul(%1567, %1571);
  %1573 = reshape(%1572, newshape=[100, 1, 2048]);
  %1574 = add(%1573, %model.transformer.decoder.layers.0.linear1.bias);
  %1575 = nn.relu(%1574);
  %1576 = nn.dropout(%1575, rate=0.1f);
  %1577 = %1576.0;
  %1578 = reshape(%1577, newshape=[-1, 1, 2048]);
  %1579 = transpose(%model.transformer.decoder.layers.0.linear2.weight, axes=[1, 0]);
  %1580 = reshape(%1579, newshape=[-1, 2048, 256]);
  %1581 = broadcast_to(%1580, meta[relay.attrs.InitOpAttrs][45]);
  %1582 = transpose(%1581, axes=[0, 2, 1]);
  %1583 = nn.batch_matmul(%1578, %1582);
  %1584 = reshape(%1583, newshape=[100, 1, 256]);
  %1585 = add(%1584, %model.transformer.decoder.layers.0.linear2.bias);
  %1586 = nn.dropout(%1585, rate=0.1f);
  %1587 = %1586.0;
  %1588 = add(%1566, %1587);
  %1589 = nn.layer_norm(%1588, %model.transformer.decoder.layers.0.norm3.weight, %model.transformer.decoder.layers.0.norm3.bias);
  %1590 = nn.layer_norm(%1589, %model.transformer.decoder.norm.weight, %model.transformer.decoder.norm.bias);
  %1591 = add(%1589, %1);
  %1592 = reshape(%1591, newshape=[-1, 1, 256]);
  %1593 = strided_slice(%model.transformer.decoder.layers.1.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1594 = strided_slice(%1593, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1595 = transpose(%1594, axes=[1, 0]);
  %1596 = reshape(%1595, newshape=[-1, 256, 256]);
  %1597 = broadcast_to(%1596, meta[relay.attrs.InitOpAttrs][46]);
  %1598 = transpose(%1597, axes=[0, 2, 1]);
  %1599 = nn.batch_matmul(%1592, %1598);
  %1600 = reshape(%1599, newshape=[100, 1, 256]);
  %1601 = strided_slice(%model.transformer.decoder.layers.1.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1602 = add(%1600, %1601);
  %1603 = multiply(%1602, 0.176777f);
  %1604 = copy(%1603);
  %1605 = reshape(%1604, newshape=[100, 8, 32]);
  %1606 = transpose(%1605, axes=[1, 0, 2]);
  %1607 = reshape(%1606, newshape=[-1, 100, 32]);
  %1608 = reshape(%1591, newshape=[-1, 1, 256]);
  %1609 = strided_slice(%model.transformer.decoder.layers.1.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1610 = strided_slice(%1609, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1611 = transpose(%1610, axes=[1, 0]);
  %1612 = reshape(%1611, newshape=[-1, 256, 256]);
  %1613 = broadcast_to(%1612, meta[relay.attrs.InitOpAttrs][47]);
  %1614 = transpose(%1613, axes=[0, 2, 1]);
  %1615 = nn.batch_matmul(%1608, %1614);
  %1616 = reshape(%1615, newshape=[100, 1, 256]);
  %1617 = strided_slice(%model.transformer.decoder.layers.1.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1618 = add(%1616, %1617);
  %1619 = copy(%1618);
  %1620 = reshape(%1619, newshape=[-1, 8, 32]);
  %1621 = transpose(%1620, axes=[1, 0, 2]);
  %1622 = transpose(%1621, axes=[0, 2, 1]);
  %1623 = reshape(%1622, newshape=[-1, 32, 100]);
  %1624 = transpose(%1623, axes=[0, 2, 1]);
  %1625 = nn.batch_matmul(%1607, %1624);
  %1626 = reshape(%1625, newshape=[8, 100, 100]);
  %1627 = nn.softmax(%1626);
  %1628 = nn.dropout(%1627, rate=0.1f);
  %1629 = %1628.0;
  %1630 = reshape(%1629, newshape=[-1, 100, 100]);
  %1631 = reshape(%1589, newshape=[-1, 1, 256]);
  %1632 = strided_slice(%model.transformer.decoder.layers.1.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1633 = strided_slice(%1632, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1634 = transpose(%1633, axes=[1, 0]);
  %1635 = reshape(%1634, newshape=[-1, 256, 256]);
  %1636 = broadcast_to(%1635, meta[relay.attrs.InitOpAttrs][48]);
  %1637 = transpose(%1636, axes=[0, 2, 1]);
  %1638 = nn.batch_matmul(%1631, %1637);
  %1639 = reshape(%1638, newshape=[100, 1, 256]);
  %1640 = strided_slice(%model.transformer.decoder.layers.1.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1641 = add(%1639, %1640);
  %1642 = copy(%1641);
  %1643 = reshape(%1642, newshape=[-1, 8, 32]);
  %1644 = transpose(%1643, axes=[1, 0, 2]);
  %1645 = reshape(%1644, newshape=[-1, 100, 32]);
  %1646 = transpose(%1645, axes=[0, 2, 1]);
  %1647 = nn.batch_matmul(%1630, %1646);
  %1648 = reshape(%1647, newshape=[8, 100, 32]);
  %1649 = transpose(%1648, axes=[1, 0, 2]);
  %1650 = copy(%1649);
  %1651 = reshape(%1650, newshape=[100, 1, 256]);
  %1652 = reshape(%1651, newshape=[-1, 1, 256]);
  %1653 = transpose(%model.transformer.decoder.layers.1.self_attn.out_proj.weight, axes=[1, 0]);
  %1654 = reshape(%1653, newshape=[-1, 256, 256]);
  %1655 = broadcast_to(%1654, meta[relay.attrs.InitOpAttrs][49]);
  %1656 = transpose(%1655, axes=[0, 2, 1]);
  %1657 = nn.batch_matmul(%1652, %1656);
  %1658 = reshape(%1657, newshape=[100, 1, 256]);
  %1659 = add(%1658, %model.transformer.decoder.layers.1.self_attn.out_proj.bias);
  %1660 = nn.dropout(%1659, rate=0.1f);
  %1661 = %1660.0;
  %1662 = add(%1589, %1661);
  %1663 = nn.layer_norm(%1662, %model.transformer.decoder.layers.1.norm1.weight, %model.transformer.decoder.layers.1.norm1.bias);
  %1664 = expand_dims(%864, axis=1);
  %1665 = expand_dims(%1664, axis=2);
  %1666 = cast(-inff, dtype="float32");
  %1667 = add(%1663, %1);
  %1668 = reshape(%1667, newshape=[-1, 1, 256]);
  %1669 = strided_slice(%model.transformer.decoder.layers.1.multihead_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1670 = strided_slice(%1669, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1671 = transpose(%1670, axes=[1, 0]);
  %1672 = reshape(%1671, newshape=[-1, 256, 256]);
  %1673 = broadcast_to(%1672, meta[relay.attrs.InitOpAttrs][50]);
  %1674 = transpose(%1673, axes=[0, 2, 1]);
  %1675 = nn.batch_matmul(%1668, %1674);
  %1676 = reshape(%1675, newshape=[100, 1, 256]);
  %1677 = strided_slice(%model.transformer.decoder.layers.1.multihead_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1678 = add(%1676, %1677);
  %1679 = multiply(%1678, 0.176777f);
  %1680 = copy(%1679);
  %1681 = reshape(%1680, newshape=[100, 8, 32]);
  %1682 = transpose(%1681, axes=[1, 0, 2]);
  %1683 = reshape(%1682, newshape=[-1, 100, 32]);
  %1684 = add(%1506, %897);
  %1685 = reshape(%1684, newshape=[-1, 1, 256]);
  %1686 = strided_slice(%model.transformer.decoder.layers.1.multihead_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1687 = strided_slice(%1686, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1688 = transpose(%1687, axes=[1, 0]);
  %1689 = reshape(%1688, newshape=[-1, 256, 256]);
  %1690 = broadcast_to(%1689, meta[relay.attrs.InitOpAttrs][51]);
  %1691 = transpose(%1690, axes=[0, 2, 1]);
  %1692 = nn.batch_matmul(%1685, %1691);
  %1693 = reshape(%1692, newshape=[600, 1, 256]);
  %1694 = strided_slice(%model.transformer.decoder.layers.1.multihead_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1695 = add(%1693, %1694);
  %1696 = copy(%1695);
  %1697 = reshape(%1696, newshape=[-1, 8, 32]);
  %1698 = transpose(%1697, axes=[1, 0, 2]);
  %1699 = transpose(%1698, axes=[0, 2, 1]);
  %1700 = reshape(%1699, newshape=[-1, 32, 600]);
  %1701 = transpose(%1700, axes=[0, 2, 1]);
  %1702 = nn.batch_matmul(%1683, %1701);
  %1703 = reshape(%1702, newshape=[8, 100, 600]);
  %1704 = reshape(%1703, newshape=[1, 8, 100, 600]);
  %1705 = where(%1665, %1666, %1704);
  %1706 = reshape(%1705, newshape=[8, 100, 600]);
  %1707 = nn.softmax(%1706);
  %1708 = nn.dropout(%1707, rate=0.1f);
  %1709 = %1708.0;
  %1710 = reshape(%1709, newshape=[-1, 100, 600]);
  %1711 = reshape(%1506, newshape=[-1, 1, 256]);
  %1712 = strided_slice(%model.transformer.decoder.layers.1.multihead_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1713 = strided_slice(%1712, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1714 = transpose(%1713, axes=[1, 0]);
  %1715 = reshape(%1714, newshape=[-1, 256, 256]);
  %1716 = broadcast_to(%1715, meta[relay.attrs.InitOpAttrs][52]);
  %1717 = transpose(%1716, axes=[0, 2, 1]);
  %1718 = nn.batch_matmul(%1711, %1717);
  %1719 = reshape(%1718, newshape=[600, 1, 256]);
  %1720 = strided_slice(%model.transformer.decoder.layers.1.multihead_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1721 = add(%1719, %1720);
  %1722 = copy(%1721);
  %1723 = reshape(%1722, newshape=[-1, 8, 32]);
  %1724 = transpose(%1723, axes=[1, 0, 2]);
  %1725 = reshape(%1724, newshape=[-1, 600, 32]);
  %1726 = transpose(%1725, axes=[0, 2, 1]);
  %1727 = nn.batch_matmul(%1710, %1726);
  %1728 = reshape(%1727, newshape=[8, 100, 32]);
  %1729 = transpose(%1728, axes=[1, 0, 2]);
  %1730 = copy(%1729);
  %1731 = reshape(%1730, newshape=[100, 1, 256]);
  %1732 = reshape(%1731, newshape=[-1, 1, 256]);
  %1733 = transpose(%model.transformer.decoder.layers.1.multihead_attn.out_proj.weight, axes=[1, 0]);
  %1734 = reshape(%1733, newshape=[-1, 256, 256]);
  %1735 = broadcast_to(%1734, meta[relay.attrs.InitOpAttrs][53]);
  %1736 = transpose(%1735, axes=[0, 2, 1]);
  %1737 = nn.batch_matmul(%1732, %1736);
  %1738 = reshape(%1737, newshape=[100, 1, 256]);
  %1739 = add(%1738, %model.transformer.decoder.layers.1.multihead_attn.out_proj.bias);
  %1740 = nn.dropout(%1739, rate=0.1f);
  %1741 = %1740.0;
  %1742 = add(%1663, %1741);
  %1743 = nn.layer_norm(%1742, %model.transformer.decoder.layers.1.norm2.weight, %model.transformer.decoder.layers.1.norm2.bias);
  %1744 = reshape(%1743, newshape=[-1, 1, 256]);
  %1745 = transpose(%model.transformer.decoder.layers.1.linear1.weight, axes=[1, 0]);
  %1746 = reshape(%1745, newshape=[-1, 256, 2048]);
  %1747 = broadcast_to(%1746, meta[relay.attrs.InitOpAttrs][54]);
  %1748 = transpose(%1747, axes=[0, 2, 1]);
  %1749 = nn.batch_matmul(%1744, %1748);
  %1750 = reshape(%1749, newshape=[100, 1, 2048]);
  %1751 = add(%1750, %model.transformer.decoder.layers.1.linear1.bias);
  %1752 = nn.relu(%1751);
  %1753 = nn.dropout(%1752, rate=0.1f);
  %1754 = %1753.0;
  %1755 = reshape(%1754, newshape=[-1, 1, 2048]);
  %1756 = transpose(%model.transformer.decoder.layers.1.linear2.weight, axes=[1, 0]);
  %1757 = reshape(%1756, newshape=[-1, 2048, 256]);
  %1758 = broadcast_to(%1757, meta[relay.attrs.InitOpAttrs][55]);
  %1759 = transpose(%1758, axes=[0, 2, 1]);
  %1760 = nn.batch_matmul(%1755, %1759);
  %1761 = reshape(%1760, newshape=[100, 1, 256]);
  %1762 = add(%1761, %model.transformer.decoder.layers.1.linear2.bias);
  %1763 = nn.dropout(%1762, rate=0.1f);
  %1764 = %1763.0;
  %1765 = add(%1743, %1764);
  %1766 = nn.layer_norm(%1765, %model.transformer.decoder.layers.1.norm3.weight, %model.transformer.decoder.layers.1.norm3.bias);
  %1767 = nn.layer_norm(%1766, %model.transformer.decoder.norm.weight, %model.transformer.decoder.norm.bias);
  %1768 = add(%1766, %1);
  %1769 = reshape(%1768, newshape=[-1, 1, 256]);
  %1770 = strided_slice(%model.transformer.decoder.layers.2.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1771 = strided_slice(%1770, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1772 = transpose(%1771, axes=[1, 0]);
  %1773 = reshape(%1772, newshape=[-1, 256, 256]);
  %1774 = broadcast_to(%1773, meta[relay.attrs.InitOpAttrs][56]);
  %1775 = transpose(%1774, axes=[0, 2, 1]);
  %1776 = nn.batch_matmul(%1769, %1775);
  %1777 = reshape(%1776, newshape=[100, 1, 256]);
  %1778 = strided_slice(%model.transformer.decoder.layers.2.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1779 = add(%1777, %1778);
  %1780 = multiply(%1779, 0.176777f);
  %1781 = copy(%1780);
  %1782 = reshape(%1781, newshape=[100, 8, 32]);
  %1783 = transpose(%1782, axes=[1, 0, 2]);
  %1784 = reshape(%1783, newshape=[-1, 100, 32]);
  %1785 = reshape(%1768, newshape=[-1, 1, 256]);
  %1786 = strided_slice(%model.transformer.decoder.layers.2.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1787 = strided_slice(%1786, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1788 = transpose(%1787, axes=[1, 0]);
  %1789 = reshape(%1788, newshape=[-1, 256, 256]);
  %1790 = broadcast_to(%1789, meta[relay.attrs.InitOpAttrs][57]);
  %1791 = transpose(%1790, axes=[0, 2, 1]);
  %1792 = nn.batch_matmul(%1785, %1791);
  %1793 = reshape(%1792, newshape=[100, 1, 256]);
  %1794 = strided_slice(%model.transformer.decoder.layers.2.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1795 = add(%1793, %1794);
  %1796 = copy(%1795);
  %1797 = reshape(%1796, newshape=[-1, 8, 32]);
  %1798 = transpose(%1797, axes=[1, 0, 2]);
  %1799 = transpose(%1798, axes=[0, 2, 1]);
  %1800 = reshape(%1799, newshape=[-1, 32, 100]);
  %1801 = transpose(%1800, axes=[0, 2, 1]);
  %1802 = nn.batch_matmul(%1784, %1801);
  %1803 = reshape(%1802, newshape=[8, 100, 100]);
  %1804 = nn.softmax(%1803);
  %1805 = nn.dropout(%1804, rate=0.1f);
  %1806 = %1805.0;
  %1807 = reshape(%1806, newshape=[-1, 100, 100]);
  %1808 = reshape(%1766, newshape=[-1, 1, 256]);
  %1809 = strided_slice(%model.transformer.decoder.layers.2.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1810 = strided_slice(%1809, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1811 = transpose(%1810, axes=[1, 0]);
  %1812 = reshape(%1811, newshape=[-1, 256, 256]);
  %1813 = broadcast_to(%1812, meta[relay.attrs.InitOpAttrs][58]);
  %1814 = transpose(%1813, axes=[0, 2, 1]);
  %1815 = nn.batch_matmul(%1808, %1814);
  %1816 = reshape(%1815, newshape=[100, 1, 256]);
  %1817 = strided_slice(%model.transformer.decoder.layers.2.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1818 = add(%1816, %1817);
  %1819 = copy(%1818);
  %1820 = reshape(%1819, newshape=[-1, 8, 32]);
  %1821 = transpose(%1820, axes=[1, 0, 2]);
  %1822 = reshape(%1821, newshape=[-1, 100, 32]);
  %1823 = transpose(%1822, axes=[0, 2, 1]);
  %1824 = nn.batch_matmul(%1807, %1823);
  %1825 = reshape(%1824, newshape=[8, 100, 32]);
  %1826 = transpose(%1825, axes=[1, 0, 2]);
  %1827 = copy(%1826);
  %1828 = reshape(%1827, newshape=[100, 1, 256]);
  %1829 = reshape(%1828, newshape=[-1, 1, 256]);
  %1830 = transpose(%model.transformer.decoder.layers.2.self_attn.out_proj.weight, axes=[1, 0]);
  %1831 = reshape(%1830, newshape=[-1, 256, 256]);
  %1832 = broadcast_to(%1831, meta[relay.attrs.InitOpAttrs][59]);
  %1833 = transpose(%1832, axes=[0, 2, 1]);
  %1834 = nn.batch_matmul(%1829, %1833);
  %1835 = reshape(%1834, newshape=[100, 1, 256]);
  %1836 = add(%1835, %model.transformer.decoder.layers.2.self_attn.out_proj.bias);
  %1837 = nn.dropout(%1836, rate=0.1f);
  %1838 = %1837.0;
  %1839 = add(%1766, %1838);
  %1840 = nn.layer_norm(%1839, %model.transformer.decoder.layers.2.norm1.weight, %model.transformer.decoder.layers.2.norm1.bias);
  %1841 = expand_dims(%864, axis=1);
  %1842 = expand_dims(%1841, axis=2);
  %1843 = cast(-inff, dtype="float32");
  %1844 = add(%1840, %1);
  %1845 = reshape(%1844, newshape=[-1, 1, 256]);
  %1846 = strided_slice(%model.transformer.decoder.layers.2.multihead_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1847 = strided_slice(%1846, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1848 = transpose(%1847, axes=[1, 0]);
  %1849 = reshape(%1848, newshape=[-1, 256, 256]);
  %1850 = broadcast_to(%1849, meta[relay.attrs.InitOpAttrs][60]);
  %1851 = transpose(%1850, axes=[0, 2, 1]);
  %1852 = nn.batch_matmul(%1845, %1851);
  %1853 = reshape(%1852, newshape=[100, 1, 256]);
  %1854 = strided_slice(%model.transformer.decoder.layers.2.multihead_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1855 = add(%1853, %1854);
  %1856 = multiply(%1855, 0.176777f);
  %1857 = copy(%1856);
  %1858 = reshape(%1857, newshape=[100, 8, 32]);
  %1859 = transpose(%1858, axes=[1, 0, 2]);
  %1860 = reshape(%1859, newshape=[-1, 100, 32]);
  %1861 = add(%1506, %897);
  %1862 = reshape(%1861, newshape=[-1, 1, 256]);
  %1863 = strided_slice(%model.transformer.decoder.layers.2.multihead_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1864 = strided_slice(%1863, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1865 = transpose(%1864, axes=[1, 0]);
  %1866 = reshape(%1865, newshape=[-1, 256, 256]);
  %1867 = broadcast_to(%1866, meta[relay.attrs.InitOpAttrs][61]);
  %1868 = transpose(%1867, axes=[0, 2, 1]);
  %1869 = nn.batch_matmul(%1862, %1868);
  %1870 = reshape(%1869, newshape=[600, 1, 256]);
  %1871 = strided_slice(%model.transformer.decoder.layers.2.multihead_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1872 = add(%1870, %1871);
  %1873 = copy(%1872);
  %1874 = reshape(%1873, newshape=[-1, 8, 32]);
  %1875 = transpose(%1874, axes=[1, 0, 2]);
  %1876 = transpose(%1875, axes=[0, 2, 1]);
  %1877 = reshape(%1876, newshape=[-1, 32, 600]);
  %1878 = transpose(%1877, axes=[0, 2, 1]);
  %1879 = nn.batch_matmul(%1860, %1878);
  %1880 = reshape(%1879, newshape=[8, 100, 600]);
  %1881 = reshape(%1880, newshape=[1, 8, 100, 600]);
  %1882 = where(%1842, %1843, %1881);
  %1883 = reshape(%1882, newshape=[8, 100, 600]);
  %1884 = nn.softmax(%1883);
  %1885 = nn.dropout(%1884, rate=0.1f);
  %1886 = %1885.0;
  %1887 = reshape(%1886, newshape=[-1, 100, 600]);
  %1888 = reshape(%1506, newshape=[-1, 1, 256]);
  %1889 = strided_slice(%model.transformer.decoder.layers.2.multihead_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1890 = strided_slice(%1889, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1891 = transpose(%1890, axes=[1, 0]);
  %1892 = reshape(%1891, newshape=[-1, 256, 256]);
  %1893 = broadcast_to(%1892, meta[relay.attrs.InitOpAttrs][62]);
  %1894 = transpose(%1893, axes=[0, 2, 1]);
  %1895 = nn.batch_matmul(%1888, %1894);
  %1896 = reshape(%1895, newshape=[600, 1, 256]);
  %1897 = strided_slice(%model.transformer.decoder.layers.2.multihead_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1898 = add(%1896, %1897);
  %1899 = copy(%1898);
  %1900 = reshape(%1899, newshape=[-1, 8, 32]);
  %1901 = transpose(%1900, axes=[1, 0, 2]);
  %1902 = reshape(%1901, newshape=[-1, 600, 32]);
  %1903 = transpose(%1902, axes=[0, 2, 1]);
  %1904 = nn.batch_matmul(%1887, %1903);
  %1905 = reshape(%1904, newshape=[8, 100, 32]);
  %1906 = transpose(%1905, axes=[1, 0, 2]);
  %1907 = copy(%1906);
  %1908 = reshape(%1907, newshape=[100, 1, 256]);
  %1909 = reshape(%1908, newshape=[-1, 1, 256]);
  %1910 = transpose(%model.transformer.decoder.layers.2.multihead_attn.out_proj.weight, axes=[1, 0]);
  %1911 = reshape(%1910, newshape=[-1, 256, 256]);
  %1912 = broadcast_to(%1911, meta[relay.attrs.InitOpAttrs][63]);
  %1913 = transpose(%1912, axes=[0, 2, 1]);
  %1914 = nn.batch_matmul(%1909, %1913);
  %1915 = reshape(%1914, newshape=[100, 1, 256]);
  %1916 = add(%1915, %model.transformer.decoder.layers.2.multihead_attn.out_proj.bias);
  %1917 = nn.dropout(%1916, rate=0.1f);
  %1918 = %1917.0;
  %1919 = add(%1840, %1918);
  %1920 = nn.layer_norm(%1919, %model.transformer.decoder.layers.2.norm2.weight, %model.transformer.decoder.layers.2.norm2.bias);
  %1921 = reshape(%1920, newshape=[-1, 1, 256]);
  %1922 = transpose(%model.transformer.decoder.layers.2.linear1.weight, axes=[1, 0]);
  %1923 = reshape(%1922, newshape=[-1, 256, 2048]);
  %1924 = broadcast_to(%1923, meta[relay.attrs.InitOpAttrs][64]);
  %1925 = transpose(%1924, axes=[0, 2, 1]);
  %1926 = nn.batch_matmul(%1921, %1925);
  %1927 = reshape(%1926, newshape=[100, 1, 2048]);
  %1928 = add(%1927, %model.transformer.decoder.layers.2.linear1.bias);
  %1929 = nn.relu(%1928);
  %1930 = nn.dropout(%1929, rate=0.1f);
  %1931 = %1930.0;
  %1932 = reshape(%1931, newshape=[-1, 1, 2048]);
  %1933 = transpose(%model.transformer.decoder.layers.2.linear2.weight, axes=[1, 0]);
  %1934 = reshape(%1933, newshape=[-1, 2048, 256]);
  %1935 = broadcast_to(%1934, meta[relay.attrs.InitOpAttrs][65]);
  %1936 = transpose(%1935, axes=[0, 2, 1]);
  %1937 = nn.batch_matmul(%1932, %1936);
  %1938 = reshape(%1937, newshape=[100, 1, 256]);
  %1939 = add(%1938, %model.transformer.decoder.layers.2.linear2.bias);
  %1940 = nn.dropout(%1939, rate=0.1f);
  %1941 = %1940.0;
  %1942 = add(%1920, %1941);
  %1943 = nn.layer_norm(%1942, %model.transformer.decoder.layers.2.norm3.weight, %model.transformer.decoder.layers.2.norm3.bias);
  %1944 = nn.layer_norm(%1943, %model.transformer.decoder.norm.weight, %model.transformer.decoder.norm.bias);
  %1945 = add(%1943, %1);
  %1946 = reshape(%1945, newshape=[-1, 1, 256]);
  %1947 = strided_slice(%model.transformer.decoder.layers.3.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1948 = strided_slice(%1947, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1949 = transpose(%1948, axes=[1, 0]);
  %1950 = reshape(%1949, newshape=[-1, 256, 256]);
  %1951 = broadcast_to(%1950, meta[relay.attrs.InitOpAttrs][66]);
  %1952 = transpose(%1951, axes=[0, 2, 1]);
  %1953 = nn.batch_matmul(%1946, %1952);
  %1954 = reshape(%1953, newshape=[100, 1, 256]);
  %1955 = strided_slice(%model.transformer.decoder.layers.3.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %1956 = add(%1954, %1955);
  %1957 = multiply(%1956, 0.176777f);
  %1958 = copy(%1957);
  %1959 = reshape(%1958, newshape=[100, 8, 32]);
  %1960 = transpose(%1959, axes=[1, 0, 2]);
  %1961 = reshape(%1960, newshape=[-1, 100, 32]);
  %1962 = reshape(%1945, newshape=[-1, 1, 256]);
  %1963 = strided_slice(%model.transformer.decoder.layers.3.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %1964 = strided_slice(%1963, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1965 = transpose(%1964, axes=[1, 0]);
  %1966 = reshape(%1965, newshape=[-1, 256, 256]);
  %1967 = broadcast_to(%1966, meta[relay.attrs.InitOpAttrs][67]);
  %1968 = transpose(%1967, axes=[0, 2, 1]);
  %1969 = nn.batch_matmul(%1962, %1968);
  %1970 = reshape(%1969, newshape=[100, 1, 256]);
  %1971 = strided_slice(%model.transformer.decoder.layers.3.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %1972 = add(%1970, %1971);
  %1973 = copy(%1972);
  %1974 = reshape(%1973, newshape=[-1, 8, 32]);
  %1975 = transpose(%1974, axes=[1, 0, 2]);
  %1976 = transpose(%1975, axes=[0, 2, 1]);
  %1977 = reshape(%1976, newshape=[-1, 32, 100]);
  %1978 = transpose(%1977, axes=[0, 2, 1]);
  %1979 = nn.batch_matmul(%1961, %1978);
  %1980 = reshape(%1979, newshape=[8, 100, 100]);
  %1981 = nn.softmax(%1980);
  %1982 = nn.dropout(%1981, rate=0.1f);
  %1983 = %1982.0;
  %1984 = reshape(%1983, newshape=[-1, 100, 100]);
  %1985 = reshape(%1943, newshape=[-1, 1, 256]);
  %1986 = strided_slice(%model.transformer.decoder.layers.3.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %1987 = strided_slice(%1986, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %1988 = transpose(%1987, axes=[1, 0]);
  %1989 = reshape(%1988, newshape=[-1, 256, 256]);
  %1990 = broadcast_to(%1989, meta[relay.attrs.InitOpAttrs][68]);
  %1991 = transpose(%1990, axes=[0, 2, 1]);
  %1992 = nn.batch_matmul(%1985, %1991);
  %1993 = reshape(%1992, newshape=[100, 1, 256]);
  %1994 = strided_slice(%model.transformer.decoder.layers.3.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %1995 = add(%1993, %1994);
  %1996 = copy(%1995);
  %1997 = reshape(%1996, newshape=[-1, 8, 32]);
  %1998 = transpose(%1997, axes=[1, 0, 2]);
  %1999 = reshape(%1998, newshape=[-1, 100, 32]);
  %2000 = transpose(%1999, axes=[0, 2, 1]);
  %2001 = nn.batch_matmul(%1984, %2000);
  %2002 = reshape(%2001, newshape=[8, 100, 32]);
  %2003 = transpose(%2002, axes=[1, 0, 2]);
  %2004 = copy(%2003);
  %2005 = reshape(%2004, newshape=[100, 1, 256]);
  %2006 = reshape(%2005, newshape=[-1, 1, 256]);
  %2007 = transpose(%model.transformer.decoder.layers.3.self_attn.out_proj.weight, axes=[1, 0]);
  %2008 = reshape(%2007, newshape=[-1, 256, 256]);
  %2009 = broadcast_to(%2008, meta[relay.attrs.InitOpAttrs][69]);
  %2010 = transpose(%2009, axes=[0, 2, 1]);
  %2011 = nn.batch_matmul(%2006, %2010);
  %2012 = reshape(%2011, newshape=[100, 1, 256]);
  %2013 = add(%2012, %model.transformer.decoder.layers.3.self_attn.out_proj.bias);
  %2014 = nn.dropout(%2013, rate=0.1f);
  %2015 = %2014.0;
  %2016 = add(%1943, %2015);
  %2017 = nn.layer_norm(%2016, %model.transformer.decoder.layers.3.norm1.weight, %model.transformer.decoder.layers.3.norm1.bias);
  %2018 = expand_dims(%864, axis=1);
  %2019 = expand_dims(%2018, axis=2);
  %2020 = cast(-inff, dtype="float32");
  %2021 = add(%2017, %1);
  %2022 = reshape(%2021, newshape=[-1, 1, 256]);
  %2023 = strided_slice(%model.transformer.decoder.layers.3.multihead_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2024 = strided_slice(%2023, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2025 = transpose(%2024, axes=[1, 0]);
  %2026 = reshape(%2025, newshape=[-1, 256, 256]);
  %2027 = broadcast_to(%2026, meta[relay.attrs.InitOpAttrs][70]);
  %2028 = transpose(%2027, axes=[0, 2, 1]);
  %2029 = nn.batch_matmul(%2022, %2028);
  %2030 = reshape(%2029, newshape=[100, 1, 256]);
  %2031 = strided_slice(%model.transformer.decoder.layers.3.multihead_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %2032 = add(%2030, %2031);
  %2033 = multiply(%2032, 0.176777f);
  %2034 = copy(%2033);
  %2035 = reshape(%2034, newshape=[100, 8, 32]);
  %2036 = transpose(%2035, axes=[1, 0, 2]);
  %2037 = reshape(%2036, newshape=[-1, 100, 32]);
  %2038 = add(%1506, %897);
  %2039 = reshape(%2038, newshape=[-1, 1, 256]);
  %2040 = strided_slice(%model.transformer.decoder.layers.3.multihead_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %2041 = strided_slice(%2040, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2042 = transpose(%2041, axes=[1, 0]);
  %2043 = reshape(%2042, newshape=[-1, 256, 256]);
  %2044 = broadcast_to(%2043, meta[relay.attrs.InitOpAttrs][71]);
  %2045 = transpose(%2044, axes=[0, 2, 1]);
  %2046 = nn.batch_matmul(%2039, %2045);
  %2047 = reshape(%2046, newshape=[600, 1, 256]);
  %2048 = strided_slice(%model.transformer.decoder.layers.3.multihead_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %2049 = add(%2047, %2048);
  %2050 = copy(%2049);
  %2051 = reshape(%2050, newshape=[-1, 8, 32]);
  %2052 = transpose(%2051, axes=[1, 0, 2]);
  %2053 = transpose(%2052, axes=[0, 2, 1]);
  %2054 = reshape(%2053, newshape=[-1, 32, 600]);
  %2055 = transpose(%2054, axes=[0, 2, 1]);
  %2056 = nn.batch_matmul(%2037, %2055);
  %2057 = reshape(%2056, newshape=[8, 100, 600]);
  %2058 = reshape(%2057, newshape=[1, 8, 100, 600]);
  %2059 = where(%2019, %2020, %2058);
  %2060 = reshape(%2059, newshape=[8, 100, 600]);
  %2061 = nn.softmax(%2060);
  %2062 = nn.dropout(%2061, rate=0.1f);
  %2063 = %2062.0;
  %2064 = reshape(%2063, newshape=[-1, 100, 600]);
  %2065 = reshape(%1506, newshape=[-1, 1, 256]);
  %2066 = strided_slice(%model.transformer.decoder.layers.3.multihead_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %2067 = strided_slice(%2066, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2068 = transpose(%2067, axes=[1, 0]);
  %2069 = reshape(%2068, newshape=[-1, 256, 256]);
  %2070 = broadcast_to(%2069, meta[relay.attrs.InitOpAttrs][72]);
  %2071 = transpose(%2070, axes=[0, 2, 1]);
  %2072 = nn.batch_matmul(%2065, %2071);
  %2073 = reshape(%2072, newshape=[600, 1, 256]);
  %2074 = strided_slice(%model.transformer.decoder.layers.3.multihead_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %2075 = add(%2073, %2074);
  %2076 = copy(%2075);
  %2077 = reshape(%2076, newshape=[-1, 8, 32]);
  %2078 = transpose(%2077, axes=[1, 0, 2]);
  %2079 = reshape(%2078, newshape=[-1, 600, 32]);
  %2080 = transpose(%2079, axes=[0, 2, 1]);
  %2081 = nn.batch_matmul(%2064, %2080);
  %2082 = reshape(%2081, newshape=[8, 100, 32]);
  %2083 = transpose(%2082, axes=[1, 0, 2]);
  %2084 = copy(%2083);
  %2085 = reshape(%2084, newshape=[100, 1, 256]);
  %2086 = reshape(%2085, newshape=[-1, 1, 256]);
  %2087 = transpose(%model.transformer.decoder.layers.3.multihead_attn.out_proj.weight, axes=[1, 0]);
  %2088 = reshape(%2087, newshape=[-1, 256, 256]);
  %2089 = broadcast_to(%2088, meta[relay.attrs.InitOpAttrs][73]);
  %2090 = transpose(%2089, axes=[0, 2, 1]);
  %2091 = nn.batch_matmul(%2086, %2090);
  %2092 = reshape(%2091, newshape=[100, 1, 256]);
  %2093 = add(%2092, %model.transformer.decoder.layers.3.multihead_attn.out_proj.bias);
  %2094 = nn.dropout(%2093, rate=0.1f);
  %2095 = %2094.0;
  %2096 = add(%2017, %2095);
  %2097 = nn.layer_norm(%2096, %model.transformer.decoder.layers.3.norm2.weight, %model.transformer.decoder.layers.3.norm2.bias);
  %2098 = reshape(%2097, newshape=[-1, 1, 256]);
  %2099 = transpose(%model.transformer.decoder.layers.3.linear1.weight, axes=[1, 0]);
  %2100 = reshape(%2099, newshape=[-1, 256, 2048]);
  %2101 = broadcast_to(%2100, meta[relay.attrs.InitOpAttrs][74]);
  %2102 = transpose(%2101, axes=[0, 2, 1]);
  %2103 = nn.batch_matmul(%2098, %2102);
  %2104 = reshape(%2103, newshape=[100, 1, 2048]);
  %2105 = add(%2104, %model.transformer.decoder.layers.3.linear1.bias);
  %2106 = nn.relu(%2105);
  %2107 = nn.dropout(%2106, rate=0.1f);
  %2108 = %2107.0;
  %2109 = reshape(%2108, newshape=[-1, 1, 2048]);
  %2110 = transpose(%model.transformer.decoder.layers.3.linear2.weight, axes=[1, 0]);
  %2111 = reshape(%2110, newshape=[-1, 2048, 256]);
  %2112 = broadcast_to(%2111, meta[relay.attrs.InitOpAttrs][75]);
  %2113 = transpose(%2112, axes=[0, 2, 1]);
  %2114 = nn.batch_matmul(%2109, %2113);
  %2115 = reshape(%2114, newshape=[100, 1, 256]);
  %2116 = add(%2115, %model.transformer.decoder.layers.3.linear2.bias);
  %2117 = nn.dropout(%2116, rate=0.1f);
  %2118 = %2117.0;
  %2119 = add(%2097, %2118);
  %2120 = nn.layer_norm(%2119, %model.transformer.decoder.layers.3.norm3.weight, %model.transformer.decoder.layers.3.norm3.bias);
  %2121 = nn.layer_norm(%2120, %model.transformer.decoder.norm.weight, %model.transformer.decoder.norm.bias);
  %2122 = add(%2120, %1);
  %2123 = reshape(%2122, newshape=[-1, 1, 256]);
  %2124 = strided_slice(%model.transformer.decoder.layers.4.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2125 = strided_slice(%2124, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2126 = transpose(%2125, axes=[1, 0]);
  %2127 = reshape(%2126, newshape=[-1, 256, 256]);
  %2128 = broadcast_to(%2127, meta[relay.attrs.InitOpAttrs][76]);
  %2129 = transpose(%2128, axes=[0, 2, 1]);
  %2130 = nn.batch_matmul(%2123, %2129);
  %2131 = reshape(%2130, newshape=[100, 1, 256]);
  %2132 = strided_slice(%model.transformer.decoder.layers.4.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %2133 = add(%2131, %2132);
  %2134 = multiply(%2133, 0.176777f);
  %2135 = copy(%2134);
  %2136 = reshape(%2135, newshape=[100, 8, 32]);
  %2137 = transpose(%2136, axes=[1, 0, 2]);
  %2138 = reshape(%2137, newshape=[-1, 100, 32]);
  %2139 = reshape(%2122, newshape=[-1, 1, 256]);
  %2140 = strided_slice(%model.transformer.decoder.layers.4.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %2141 = strided_slice(%2140, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2142 = transpose(%2141, axes=[1, 0]);
  %2143 = reshape(%2142, newshape=[-1, 256, 256]);
  %2144 = broadcast_to(%2143, meta[relay.attrs.InitOpAttrs][77]);
  %2145 = transpose(%2144, axes=[0, 2, 1]);
  %2146 = nn.batch_matmul(%2139, %2145);
  %2147 = reshape(%2146, newshape=[100, 1, 256]);
  %2148 = strided_slice(%model.transformer.decoder.layers.4.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %2149 = add(%2147, %2148);
  %2150 = copy(%2149);
  %2151 = reshape(%2150, newshape=[-1, 8, 32]);
  %2152 = transpose(%2151, axes=[1, 0, 2]);
  %2153 = transpose(%2152, axes=[0, 2, 1]);
  %2154 = reshape(%2153, newshape=[-1, 32, 100]);
  %2155 = transpose(%2154, axes=[0, 2, 1]);
  %2156 = nn.batch_matmul(%2138, %2155);
  %2157 = reshape(%2156, newshape=[8, 100, 100]);
  %2158 = nn.softmax(%2157);
  %2159 = nn.dropout(%2158, rate=0.1f);
  %2160 = %2159.0;
  %2161 = reshape(%2160, newshape=[-1, 100, 100]);
  %2162 = reshape(%2120, newshape=[-1, 1, 256]);
  %2163 = strided_slice(%model.transformer.decoder.layers.4.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %2164 = strided_slice(%2163, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2165 = transpose(%2164, axes=[1, 0]);
  %2166 = reshape(%2165, newshape=[-1, 256, 256]);
  %2167 = broadcast_to(%2166, meta[relay.attrs.InitOpAttrs][78]);
  %2168 = transpose(%2167, axes=[0, 2, 1]);
  %2169 = nn.batch_matmul(%2162, %2168);
  %2170 = reshape(%2169, newshape=[100, 1, 256]);
  %2171 = strided_slice(%model.transformer.decoder.layers.4.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %2172 = add(%2170, %2171);
  %2173 = copy(%2172);
  %2174 = reshape(%2173, newshape=[-1, 8, 32]);
  %2175 = transpose(%2174, axes=[1, 0, 2]);
  %2176 = reshape(%2175, newshape=[-1, 100, 32]);
  %2177 = transpose(%2176, axes=[0, 2, 1]);
  %2178 = nn.batch_matmul(%2161, %2177);
  %2179 = reshape(%2178, newshape=[8, 100, 32]);
  %2180 = transpose(%2179, axes=[1, 0, 2]);
  %2181 = copy(%2180);
  %2182 = reshape(%2181, newshape=[100, 1, 256]);
  %2183 = reshape(%2182, newshape=[-1, 1, 256]);
  %2184 = transpose(%model.transformer.decoder.layers.4.self_attn.out_proj.weight, axes=[1, 0]);
  %2185 = reshape(%2184, newshape=[-1, 256, 256]);
  %2186 = broadcast_to(%2185, meta[relay.attrs.InitOpAttrs][79]);
  %2187 = transpose(%2186, axes=[0, 2, 1]);
  %2188 = nn.batch_matmul(%2183, %2187);
  %2189 = reshape(%2188, newshape=[100, 1, 256]);
  %2190 = add(%2189, %model.transformer.decoder.layers.4.self_attn.out_proj.bias);
  %2191 = nn.dropout(%2190, rate=0.1f);
  %2192 = %2191.0;
  %2193 = add(%2120, %2192);
  %2194 = nn.layer_norm(%2193, %model.transformer.decoder.layers.4.norm1.weight, %model.transformer.decoder.layers.4.norm1.bias);
  %2195 = expand_dims(%864, axis=1);
  %2196 = expand_dims(%2195, axis=2);
  %2197 = cast(-inff, dtype="float32");
  %2198 = add(%2194, %1);
  %2199 = reshape(%2198, newshape=[-1, 1, 256]);
  %2200 = strided_slice(%model.transformer.decoder.layers.4.multihead_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2201 = strided_slice(%2200, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2202 = transpose(%2201, axes=[1, 0]);
  %2203 = reshape(%2202, newshape=[-1, 256, 256]);
  %2204 = broadcast_to(%2203, meta[relay.attrs.InitOpAttrs][80]);
  %2205 = transpose(%2204, axes=[0, 2, 1]);
  %2206 = nn.batch_matmul(%2199, %2205);
  %2207 = reshape(%2206, newshape=[100, 1, 256]);
  %2208 = strided_slice(%model.transformer.decoder.layers.4.multihead_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %2209 = add(%2207, %2208);
  %2210 = multiply(%2209, 0.176777f);
  %2211 = copy(%2210);
  %2212 = reshape(%2211, newshape=[100, 8, 32]);
  %2213 = transpose(%2212, axes=[1, 0, 2]);
  %2214 = reshape(%2213, newshape=[-1, 100, 32]);
  %2215 = add(%1506, %897);
  %2216 = reshape(%2215, newshape=[-1, 1, 256]);
  %2217 = strided_slice(%model.transformer.decoder.layers.4.multihead_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %2218 = strided_slice(%2217, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2219 = transpose(%2218, axes=[1, 0]);
  %2220 = reshape(%2219, newshape=[-1, 256, 256]);
  %2221 = broadcast_to(%2220, meta[relay.attrs.InitOpAttrs][81]);
  %2222 = transpose(%2221, axes=[0, 2, 1]);
  %2223 = nn.batch_matmul(%2216, %2222);
  %2224 = reshape(%2223, newshape=[600, 1, 256]);
  %2225 = strided_slice(%model.transformer.decoder.layers.4.multihead_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %2226 = add(%2224, %2225);
  %2227 = copy(%2226);
  %2228 = reshape(%2227, newshape=[-1, 8, 32]);
  %2229 = transpose(%2228, axes=[1, 0, 2]);
  %2230 = transpose(%2229, axes=[0, 2, 1]);
  %2231 = reshape(%2230, newshape=[-1, 32, 600]);
  %2232 = transpose(%2231, axes=[0, 2, 1]);
  %2233 = nn.batch_matmul(%2214, %2232);
  %2234 = reshape(%2233, newshape=[8, 100, 600]);
  %2235 = reshape(%2234, newshape=[1, 8, 100, 600]);
  %2236 = where(%2196, %2197, %2235);
  %2237 = reshape(%2236, newshape=[8, 100, 600]);
  %2238 = nn.softmax(%2237);
  %2239 = nn.dropout(%2238, rate=0.1f);
  %2240 = %2239.0;
  %2241 = reshape(%2240, newshape=[-1, 100, 600]);
  %2242 = reshape(%1506, newshape=[-1, 1, 256]);
  %2243 = strided_slice(%model.transformer.decoder.layers.4.multihead_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %2244 = strided_slice(%2243, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2245 = transpose(%2244, axes=[1, 0]);
  %2246 = reshape(%2245, newshape=[-1, 256, 256]);
  %2247 = broadcast_to(%2246, meta[relay.attrs.InitOpAttrs][82]);
  %2248 = transpose(%2247, axes=[0, 2, 1]);
  %2249 = nn.batch_matmul(%2242, %2248);
  %2250 = reshape(%2249, newshape=[600, 1, 256]);
  %2251 = strided_slice(%model.transformer.decoder.layers.4.multihead_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %2252 = add(%2250, %2251);
  %2253 = copy(%2252);
  %2254 = reshape(%2253, newshape=[-1, 8, 32]);
  %2255 = transpose(%2254, axes=[1, 0, 2]);
  %2256 = reshape(%2255, newshape=[-1, 600, 32]);
  %2257 = transpose(%2256, axes=[0, 2, 1]);
  %2258 = nn.batch_matmul(%2241, %2257);
  %2259 = reshape(%2258, newshape=[8, 100, 32]);
  %2260 = transpose(%2259, axes=[1, 0, 2]);
  %2261 = copy(%2260);
  %2262 = reshape(%2261, newshape=[100, 1, 256]);
  %2263 = reshape(%2262, newshape=[-1, 1, 256]);
  %2264 = transpose(%model.transformer.decoder.layers.4.multihead_attn.out_proj.weight, axes=[1, 0]);
  %2265 = reshape(%2264, newshape=[-1, 256, 256]);
  %2266 = broadcast_to(%2265, meta[relay.attrs.InitOpAttrs][83]);
  %2267 = transpose(%2266, axes=[0, 2, 1]);
  %2268 = nn.batch_matmul(%2263, %2267);
  %2269 = reshape(%2268, newshape=[100, 1, 256]);
  %2270 = add(%2269, %model.transformer.decoder.layers.4.multihead_attn.out_proj.bias);
  %2271 = nn.dropout(%2270, rate=0.1f);
  %2272 = %2271.0;
  %2273 = add(%2194, %2272);
  %2274 = nn.layer_norm(%2273, %model.transformer.decoder.layers.4.norm2.weight, %model.transformer.decoder.layers.4.norm2.bias);
  %2275 = reshape(%2274, newshape=[-1, 1, 256]);
  %2276 = transpose(%model.transformer.decoder.layers.4.linear1.weight, axes=[1, 0]);
  %2277 = reshape(%2276, newshape=[-1, 256, 2048]);
  %2278 = broadcast_to(%2277, meta[relay.attrs.InitOpAttrs][84]);
  %2279 = transpose(%2278, axes=[0, 2, 1]);
  %2280 = nn.batch_matmul(%2275, %2279);
  %2281 = reshape(%2280, newshape=[100, 1, 2048]);
  %2282 = add(%2281, %model.transformer.decoder.layers.4.linear1.bias);
  %2283 = nn.relu(%2282);
  %2284 = nn.dropout(%2283, rate=0.1f);
  %2285 = %2284.0;
  %2286 = reshape(%2285, newshape=[-1, 1, 2048]);
  %2287 = transpose(%model.transformer.decoder.layers.4.linear2.weight, axes=[1, 0]);
  %2288 = reshape(%2287, newshape=[-1, 2048, 256]);
  %2289 = broadcast_to(%2288, meta[relay.attrs.InitOpAttrs][85]);
  %2290 = transpose(%2289, axes=[0, 2, 1]);
  %2291 = nn.batch_matmul(%2286, %2290);
  %2292 = reshape(%2291, newshape=[100, 1, 256]);
  %2293 = add(%2292, %model.transformer.decoder.layers.4.linear2.bias);
  %2294 = nn.dropout(%2293, rate=0.1f);
  %2295 = %2294.0;
  %2296 = add(%2274, %2295);
  %2297 = nn.layer_norm(%2296, %model.transformer.decoder.layers.4.norm3.weight, %model.transformer.decoder.layers.4.norm3.bias);
  %2298 = nn.layer_norm(%2297, %model.transformer.decoder.norm.weight, %model.transformer.decoder.norm.bias);
  %2299 = add(%2297, %1);
  %2300 = reshape(%2299, newshape=[-1, 1, 256]);
  %2301 = strided_slice(%model.transformer.decoder.layers.5.self_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2302 = strided_slice(%2301, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2303 = transpose(%2302, axes=[1, 0]);
  %2304 = reshape(%2303, newshape=[-1, 256, 256]);
  %2305 = broadcast_to(%2304, meta[relay.attrs.InitOpAttrs][86]);
  %2306 = transpose(%2305, axes=[0, 2, 1]);
  %2307 = nn.batch_matmul(%2300, %2306);
  %2308 = reshape(%2307, newshape=[100, 1, 256]);
  %2309 = strided_slice(%model.transformer.decoder.layers.5.self_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %2310 = add(%2308, %2309);
  %2311 = multiply(%2310, 0.176777f);
  %2312 = copy(%2311);
  %2313 = reshape(%2312, newshape=[100, 8, 32]);
  %2314 = transpose(%2313, axes=[1, 0, 2]);
  %2315 = reshape(%2314, newshape=[-1, 100, 32]);
  %2316 = reshape(%2299, newshape=[-1, 1, 256]);
  %2317 = strided_slice(%model.transformer.decoder.layers.5.self_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %2318 = strided_slice(%2317, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2319 = transpose(%2318, axes=[1, 0]);
  %2320 = reshape(%2319, newshape=[-1, 256, 256]);
  %2321 = broadcast_to(%2320, meta[relay.attrs.InitOpAttrs][87]);
  %2322 = transpose(%2321, axes=[0, 2, 1]);
  %2323 = nn.batch_matmul(%2316, %2322);
  %2324 = reshape(%2323, newshape=[100, 1, 256]);
  %2325 = strided_slice(%model.transformer.decoder.layers.5.self_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %2326 = add(%2324, %2325);
  %2327 = copy(%2326);
  %2328 = reshape(%2327, newshape=[-1, 8, 32]);
  %2329 = transpose(%2328, axes=[1, 0, 2]);
  %2330 = transpose(%2329, axes=[0, 2, 1]);
  %2331 = reshape(%2330, newshape=[-1, 32, 100]);
  %2332 = transpose(%2331, axes=[0, 2, 1]);
  %2333 = nn.batch_matmul(%2315, %2332);
  %2334 = reshape(%2333, newshape=[8, 100, 100]);
  %2335 = nn.softmax(%2334);
  %2336 = nn.dropout(%2335, rate=0.1f);
  %2337 = %2336.0;
  %2338 = reshape(%2337, newshape=[-1, 100, 100]);
  %2339 = reshape(%2297, newshape=[-1, 1, 256]);
  %2340 = strided_slice(%model.transformer.decoder.layers.5.self_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %2341 = strided_slice(%2340, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2342 = transpose(%2341, axes=[1, 0]);
  %2343 = reshape(%2342, newshape=[-1, 256, 256]);
  %2344 = broadcast_to(%2343, meta[relay.attrs.InitOpAttrs][88]);
  %2345 = transpose(%2344, axes=[0, 2, 1]);
  %2346 = nn.batch_matmul(%2339, %2345);
  %2347 = reshape(%2346, newshape=[100, 1, 256]);
  %2348 = strided_slice(%model.transformer.decoder.layers.5.self_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %2349 = add(%2347, %2348);
  %2350 = copy(%2349);
  %2351 = reshape(%2350, newshape=[-1, 8, 32]);
  %2352 = transpose(%2351, axes=[1, 0, 2]);
  %2353 = reshape(%2352, newshape=[-1, 100, 32]);
  %2354 = transpose(%2353, axes=[0, 2, 1]);
  %2355 = nn.batch_matmul(%2338, %2354);
  %2356 = reshape(%2355, newshape=[8, 100, 32]);
  %2357 = transpose(%2356, axes=[1, 0, 2]);
  %2358 = copy(%2357);
  %2359 = reshape(%2358, newshape=[100, 1, 256]);
  %2360 = reshape(%2359, newshape=[-1, 1, 256]);
  %2361 = transpose(%model.transformer.decoder.layers.5.self_attn.out_proj.weight, axes=[1, 0]);
  %2362 = reshape(%2361, newshape=[-1, 256, 256]);
  %2363 = broadcast_to(%2362, meta[relay.attrs.InitOpAttrs][89]);
  %2364 = transpose(%2363, axes=[0, 2, 1]);
  %2365 = nn.batch_matmul(%2360, %2364);
  %2366 = reshape(%2365, newshape=[100, 1, 256]);
  %2367 = add(%2366, %model.transformer.decoder.layers.5.self_attn.out_proj.bias);
  %2368 = nn.dropout(%2367, rate=0.1f);
  %2369 = %2368.0;
  %2370 = add(%2297, %2369);
  %2371 = nn.layer_norm(%2370, %model.transformer.decoder.layers.5.norm1.weight, %model.transformer.decoder.layers.5.norm1.bias);
  %2372 = expand_dims(%864, axis=1);
  %2373 = expand_dims(%2372, axis=2);
  %2374 = cast(-inff, dtype="float32");
  %2375 = add(%2371, %1);
  %2376 = reshape(%2375, newshape=[-1, 1, 256]);
  %2377 = strided_slice(%model.transformer.decoder.layers.5.multihead_attn.in_proj_weight, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2378 = strided_slice(%2377, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2379 = transpose(%2378, axes=[1, 0]);
  %2380 = reshape(%2379, newshape=[-1, 256, 256]);
  %2381 = broadcast_to(%2380, meta[relay.attrs.InitOpAttrs][90]);
  %2382 = transpose(%2381, axes=[0, 2, 1]);
  %2383 = nn.batch_matmul(%2376, %2382);
  %2384 = reshape(%2383, newshape=[100, 1, 256]);
  %2385 = strided_slice(%model.transformer.decoder.layers.5.multihead_attn.in_proj_bias, begin=[0], end=[256], strides=[1]);
  %2386 = add(%2384, %2385);
  %2387 = multiply(%2386, 0.176777f);
  %2388 = copy(%2387);
  %2389 = reshape(%2388, newshape=[100, 8, 32]);
  %2390 = transpose(%2389, axes=[1, 0, 2]);
  %2391 = reshape(%2390, newshape=[-1, 100, 32]);
  %2392 = add(%1506, %897);
  %2393 = reshape(%2392, newshape=[-1, 1, 256]);
  %2394 = strided_slice(%model.transformer.decoder.layers.5.multihead_attn.in_proj_weight, begin=[256, 0], end=[512, 256], strides=[1, 1]);
  %2395 = strided_slice(%2394, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2396 = transpose(%2395, axes=[1, 0]);
  %2397 = reshape(%2396, newshape=[-1, 256, 256]);
  %2398 = broadcast_to(%2397, meta[relay.attrs.InitOpAttrs][91]);
  %2399 = transpose(%2398, axes=[0, 2, 1]);
  %2400 = nn.batch_matmul(%2393, %2399);
  %2401 = reshape(%2400, newshape=[600, 1, 256]);
  %2402 = strided_slice(%model.transformer.decoder.layers.5.multihead_attn.in_proj_bias, begin=[256], end=[512], strides=[1]);
  %2403 = add(%2401, %2402);
  %2404 = copy(%2403);
  %2405 = reshape(%2404, newshape=[-1, 8, 32]);
  %2406 = transpose(%2405, axes=[1, 0, 2]);
  %2407 = transpose(%2406, axes=[0, 2, 1]);
  %2408 = reshape(%2407, newshape=[-1, 32, 600]);
  %2409 = transpose(%2408, axes=[0, 2, 1]);
  %2410 = nn.batch_matmul(%2391, %2409);
  %2411 = reshape(%2410, newshape=[8, 100, 600]);
  %2412 = reshape(%2411, newshape=[1, 8, 100, 600]);
  %2413 = where(%2373, %2374, %2412);
  %2414 = reshape(%2413, newshape=[8, 100, 600]);
  %2415 = nn.softmax(%2414);
  %2416 = nn.dropout(%2415, rate=0.1f);
  %2417 = %2416.0;
  %2418 = reshape(%2417, newshape=[-1, 100, 600]);
  %2419 = reshape(%1506, newshape=[-1, 1, 256]);
  %2420 = strided_slice(%model.transformer.decoder.layers.5.multihead_attn.in_proj_weight, begin=[512, 0], end=[768, 256], strides=[1, 1]);
  %2421 = strided_slice(%2420, begin=[0, 0], end=[256, 256], strides=[1, 1]);
  %2422 = transpose(%2421, axes=[1, 0]);
  %2423 = reshape(%2422, newshape=[-1, 256, 256]);
  %2424 = broadcast_to(%2423, meta[relay.attrs.InitOpAttrs][92]);
  %2425 = transpose(%2424, axes=[0, 2, 1]);
  %2426 = nn.batch_matmul(%2419, %2425);
  %2427 = reshape(%2426, newshape=[600, 1, 256]);
  %2428 = strided_slice(%model.transformer.decoder.layers.5.multihead_attn.in_proj_bias, begin=[512], end=[768], strides=[1]);
  %2429 = add(%2427, %2428);
  %2430 = copy(%2429);
  %2431 = reshape(%2430, newshape=[-1, 8, 32]);
  %2432 = transpose(%2431, axes=[1, 0, 2]);
  %2433 = reshape(%2432, newshape=[-1, 600, 32]);
  %2434 = transpose(%2433, axes=[0, 2, 1]);
  %2435 = nn.batch_matmul(%2418, %2434);
  %2436 = reshape(%2435, newshape=[8, 100, 32]);
  %2437 = transpose(%2436, axes=[1, 0, 2]);
  %2438 = copy(%2437);
  %2439 = reshape(%2438, newshape=[100, 1, 256]);
  %2440 = reshape(%2439, newshape=[-1, 1, 256]);
  %2441 = transpose(%model.transformer.decoder.layers.5.multihead_attn.out_proj.weight, axes=[1, 0]);
  %2442 = reshape(%2441, newshape=[-1, 256, 256]);
  %2443 = broadcast_to(%2442, meta[relay.attrs.InitOpAttrs][93]);
  %2444 = transpose(%2443, axes=[0, 2, 1]);
  %2445 = nn.batch_matmul(%2440, %2444);
  %2446 = reshape(%2445, newshape=[100, 1, 256]);
  %2447 = add(%2446, %model.transformer.decoder.layers.5.multihead_attn.out_proj.bias);
  %2448 = nn.dropout(%2447, rate=0.1f);
  %2449 = %2448.0;
  %2450 = add(%2371, %2449);
  %2451 = nn.layer_norm(%2450, %model.transformer.decoder.layers.5.norm2.weight, %model.transformer.decoder.layers.5.norm2.bias);
  %2452 = reshape(%2451, newshape=[-1, 1, 256]);
  %2453 = transpose(%model.transformer.decoder.layers.5.linear1.weight, axes=[1, 0]);
  %2454 = reshape(%2453, newshape=[-1, 256, 2048]);
  %2455 = broadcast_to(%2454, meta[relay.attrs.InitOpAttrs][94]);
  %2456 = transpose(%2455, axes=[0, 2, 1]);
  %2457 = nn.batch_matmul(%2452, %2456);
  %2458 = reshape(%2457, newshape=[100, 1, 2048]);
  %2459 = add(%2458, %model.transformer.decoder.layers.5.linear1.bias);
  %2460 = nn.relu(%2459);
  %2461 = nn.dropout(%2460, rate=0.1f);
  %2462 = %2461.0;
  %2463 = reshape(%2462, newshape=[-1, 1, 2048]);
  %2464 = transpose(%model.transformer.decoder.layers.5.linear2.weight, axes=[1, 0]);
  %2465 = reshape(%2464, newshape=[-1, 2048, 256]);
  %2466 = broadcast_to(%2465, meta[relay.attrs.InitOpAttrs][95]);
  %2467 = transpose(%2466, axes=[0, 2, 1]);
  %2468 = nn.batch_matmul(%2463, %2467);
  %2469 = reshape(%2468, newshape=[100, 1, 256]);
  %2470 = add(%2469, %model.transformer.decoder.layers.5.linear2.bias);
  %2471 = nn.dropout(%2470, rate=0.1f);
  %2472 = %2471.0;
  %2473 = add(%2451, %2472);
  %2474 = nn.layer_norm(%2473, %model.transformer.decoder.layers.5.norm3.weight, %model.transformer.decoder.layers.5.norm3.bias);
  %2475 = nn.layer_norm(%2474, %model.transformer.decoder.norm.weight, %model.transformer.decoder.norm.bias);
  %2476 = (%1590, %1767, %1944, %2121, %2298, %2475);
  %2477 = stack(%2476);
  %2478 = transpose(%2477, axes=[0, 2, 1, 3]);
  %2479 = reshape(%2478, newshape=[-1, 100, 256]);
  %2480 = transpose(%model.class_embed.weight, axes=[1, 0]);
  %2481 = reshape(%2480, newshape=[-1, 256, 92]);
  %2482 = broadcast_to(%2481, meta[relay.attrs.InitOpAttrs][96]);
  %2483 = transpose(%2482, axes=[0, 2, 1]);
  %2484 = nn.batch_matmul(%2479, %2483);
  %2485 = reshape(%2484, newshape=[6, 1, 100, 92]);
  %2486 = add(%2485, %model.class_embed.bias);
  %2487 = take(%2486, -1, axis=0);
  %2488 = reshape(%2478, newshape=[-1, 100, 256]);
  %2489 = transpose(%model.bbox_embed.layers.0.weight, axes=[1, 0]);
  %2490 = reshape(%2489, newshape=[-1, 256, 256]);
  %2491 = broadcast_to(%2490, meta[relay.attrs.InitOpAttrs][97]);
  %2492 = transpose(%2491, axes=[0, 2, 1]);
  %2493 = nn.batch_matmul(%2488, %2492);
  %2494 = reshape(%2493, newshape=[6, 1, 100, 256]);
  %2495 = add(%2494, %model.bbox_embed.layers.0.bias);
  %2496 = nn.relu(%2495);
  %2497 = reshape(%2496, newshape=[-1, 100, 256]);
  %2498 = transpose(%model.bbox_embed.layers.1.weight, axes=[1, 0]);
  %2499 = reshape(%2498, newshape=[-1, 256, 256]);
  %2500 = broadcast_to(%2499, meta[relay.attrs.InitOpAttrs][98]);
  %2501 = transpose(%2500, axes=[0, 2, 1]);
  %2502 = nn.batch_matmul(%2497, %2501);
  %2503 = reshape(%2502, newshape=[6, 1, 100, 256]);
  %2504 = add(%2503, %model.bbox_embed.layers.1.bias);
  %2505 = nn.relu(%2504);
  %2506 = reshape(%2505, newshape=[-1, 100, 256]);
  %2507 = transpose(%model.bbox_embed.layers.2.weight, axes=[1, 0]);
  %2508 = reshape(%2507, newshape=[-1, 256, 4]);
  %2509 = broadcast_to(%2508, meta[relay.attrs.InitOpAttrs][99]);
  %2510 = transpose(%2509, axes=[0, 2, 1]);
  %2511 = nn.batch_matmul(%2506, %2510);
  %2512 = reshape(%2511, newshape=[6, 1, 100, 4]);
  %2513 = add(%2512, %model.bbox_embed.layers.2.bias);
  %2514 = sigmoid(%2513);
  %2515 = take(%2514, -1, axis=0);
  %2516 = (%2487, %2515);
  %2517 = %2516.0;
  %2518 = %2516.1;
  (%2517, %2518)
}

