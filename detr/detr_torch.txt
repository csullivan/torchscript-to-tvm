graph(%self.1 : __torch__.TraceWrapper,
      %tensor_list : Float(1:1800000, 3:600000, 750:800, 800:1, requires_grad=0, device=cpu)):
  %2 : __torch__.models.detr.DETR = prim::GetAttr[name="model"](%self.1)
  %7 : __torch__.models.detr.MLP = prim::GetAttr[name="bbox_embed"](%2)
  %8 : __torch__.torch.nn.modules.linear.___torch_mangle_139.Linear = prim::GetAttr[name="class_embed"](%2)
  %9 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name="query_embed"](%2)
  %10 : Tensor = prim::GetAttr[name="weight"](%9)
  %11 : __torch__.models.transformer.Transformer = prim::GetAttr[name="transformer"](%2)
  %12 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="input_proj"](%2)
  %13 : __torch__.models.backbone.Joiner = prim::GetAttr[name="backbone"](%2)
  %14 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %15 : Tensor[] = aten::unbind(%tensor_list, %14), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %img.1 : Float(3:600000, 750:800, 800:1, requires_grad=0, device=cpu) = prim::ListUnpack(%15), scope: __module.model
  %17 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %18 : int = aten::size(%img.1, %17), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %19 : Long(device=cpu) = prim::NumToTensor(%18), scope: __module.model
  %20 : Tensor[] = prim::ListConstruct(%19), scope: __module.model
  %21 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %22 : Long(1:1, requires_grad=0, device=cpu) = aten::stack(%20, %21), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %23 : int = prim::Constant[value=6](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %24 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %25 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %26 : None = prim::Constant(), scope: __module.model
  %27 : Float(1:1, requires_grad=0, device=cpu) = aten::to(%22, %23, %24, %25, %26), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %28 : Float(requires_grad=0, device=cpu) = aten::max(%27), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %29 : int = prim::Constant[value=4](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %30 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %31 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %32 : None = prim::Constant(), scope: __module.model
  %s1.1 : Long(requires_grad=0, device=cpu) = aten::to(%28, %29, %30, %31, %32), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %34 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %35 : Tensor[] = aten::unbind(%tensor_list, %34), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %img.2 : Float(3:600000, 750:800, 800:1, requires_grad=0, device=cpu) = prim::ListUnpack(%35), scope: __module.model
  %37 : int = prim::Constant[value=1](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %38 : int = aten::size(%img.2, %37), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %39 : Long(device=cpu) = prim::NumToTensor(%38), scope: __module.model
  %40 : Tensor[] = prim::ListConstruct(%39), scope: __module.model
  %41 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %42 : Long(1:1, requires_grad=0, device=cpu) = aten::stack(%40, %41), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %43 : int = prim::Constant[value=6](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %44 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %45 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %46 : None = prim::Constant(), scope: __module.model
  %47 : Float(1:1, requires_grad=0, device=cpu) = aten::to(%42, %43, %44, %45, %46), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %48 : Float(requires_grad=0, device=cpu) = aten::max(%47), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %49 : int = prim::Constant[value=4](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %50 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %51 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %52 : None = prim::Constant(), scope: __module.model
  %s1.2 : Long(requires_grad=0, device=cpu) = aten::to(%48, %49, %50, %51, %52), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %54 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %55 : Tensor[] = aten::unbind(%tensor_list, %54), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %img.3 : Float(3:600000, 750:800, 800:1, requires_grad=0, device=cpu) = prim::ListUnpack(%55), scope: __module.model
  %57 : int = prim::Constant[value=2](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %58 : int = aten::size(%img.3, %57), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %59 : Long(device=cpu) = prim::NumToTensor(%58), scope: __module.model
  %60 : Tensor[] = prim::ListConstruct(%59), scope: __module.model
  %61 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %62 : Long(1:1, requires_grad=0, device=cpu) = aten::stack(%60, %61), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %63 : int = prim::Constant[value=6](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %64 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %65 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %66 : None = prim::Constant(), scope: __module.model
  %67 : Float(1:1, requires_grad=0, device=cpu) = aten::to(%62, %63, %64, %65, %66), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %68 : Float(requires_grad=0, device=cpu) = aten::max(%67), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %69 : int = prim::Constant[value=4](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %70 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %71 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %72 : None = prim::Constant(), scope: __module.model
  %s1 : Long(requires_grad=0, device=cpu) = aten::to(%68, %69, %70, %71, %72), scope: __module.model # ../../ml/detr/util/misc.py:337:0
  %74 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %75 : Tensor[] = aten::unbind(%tensor_list, %74), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:594:0
  %img : Float(3:600000, 750:800, 800:1, requires_grad=0, device=cpu) = prim::ListUnpack(%75), scope: __module.model
  %77 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %78 : int = aten::size(%img, %77), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %s2.1 : Long(device=cpu) = prim::NumToTensor(%78), scope: __module.model
  %80 : int = prim::Constant[value=1](), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %81 : int = aten::size(%img, %80), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %s2.2 : Long(device=cpu) = prim::NumToTensor(%81), scope: __module.model
  %83 : int = prim::Constant[value=2](), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %84 : int = aten::size(%img, %83), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %s2 : Long(device=cpu) = prim::NumToTensor(%84), scope: __module.model
  %86 : int = prim::Constant[value=1](), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %87 : Long(requires_grad=0, device=cpu) = aten::sub(%s1.1, %s2.1, %86), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %88 : int = aten::Int(%87), scope: __module.model
  %89 : int = prim::Constant[value=1](), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %90 : Long(requires_grad=0, device=cpu) = aten::sub(%s1.2, %s2.2, %89), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %91 : int = aten::Int(%90), scope: __module.model
  %92 : int = aten::Int(%90), scope: __module.model
  %93 : int = prim::Constant[value=1](), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %94 : Long(requires_grad=0, device=cpu) = aten::sub(%s1, %s2, %93), scope: __module.model # ../../ml/detr/util/misc.py:348:0
  %95 : int = aten::Int(%94), scope: __module.model
  %96 : int = aten::Int(%94), scope: __module.model
  %97 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %98 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %99 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %100 : int[] = prim::ListConstruct(%97, %96, %98, %92, %99, %88), scope: __module.model
  %101 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %padded_img : Float(3:600000, 750:800, 800:1, requires_grad=0, device=cpu) = aten::constant_pad_nd(%img, %100, %101), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %103 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %104 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %105 : Float(750:800, 800:1, requires_grad=0, device=cpu) = aten::select(%img, %103, %104), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %106 : int = prim::Constant[value=3](), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %107 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %108 : Device = prim::Constant[value="cpu"](), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %109 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %110 : None = prim::Constant(), scope: __module.model
  %input.1 : Int(750:800, 800:1, requires_grad=0, device=cpu) = aten::zeros_like(%105, %106, %107, %108, %109, %110), scope: __module.model # ../../ml/detr/util/misc.py:352:0
  %112 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %113 : int = prim::Constant[value=0](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %114 : int[] = prim::ListConstruct(%112, %95, %113, %91), scope: __module.model
  %115 : int = prim::Constant[value=1](), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %padded_mask : Int(750:800, 800:1, requires_grad=0, device=cpu) = aten::constant_pad_nd(%input.1, %114, %115), scope: __module.model # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3553:0
  %117 : int = prim::Constant[value=11](), scope: __module.model # ../../ml/detr/util/misc.py:354:0
  %118 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:354:0
  %119 : bool = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:354:0
  %120 : None = prim::Constant(), scope: __module.model
  %121 : Bool(750:800, 800:1, requires_grad=0, device=cpu) = aten::to(%padded_mask, %117, %118, %119, %120), scope: __module.model # ../../ml/detr/util/misc.py:354:0
  %122 : Tensor[] = prim::ListConstruct(%padded_img), scope: __module.model
  %123 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:356:0
  %input.2 : Float(1:1800000, 3:600000, 750:800, 800:1, requires_grad=0, device=cpu) = aten::stack(%122, %123), scope: __module.model # ../../ml/detr/util/misc.py:356:0
  %125 : Tensor[] = prim::ListConstruct(%121), scope: __module.model
  %126 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/util/misc.py:357:0
  %m : Bool(1:600000, 750:800, 800:1, requires_grad=0, device=cpu) = aten::stack(%125, %126), scope: __module.model # ../../ml/detr/util/misc.py:357:0
  %128 : __torch__.models.position_encoding.PositionEmbeddingSine = prim::GetAttr[name="1"](%13)
  %129 : __torch__.models.backbone.Backbone = prim::GetAttr[name="0"](%13)
  %130 : __torch__.torchvision.models._utils.IntermediateLayerGetter = prim::GetAttr[name="body"](%129)
  %131 : __torch__.torch.nn.modules.container.___torch_mangle_286.Sequential = prim::GetAttr[name="layer4"](%130)
  %132 : __torch__.torch.nn.modules.container.___torch_mangle_258.Sequential = prim::GetAttr[name="layer3"](%130)
  %133 : __torch__.torch.nn.modules.container.___torch_mangle_206.Sequential = prim::GetAttr[name="layer2"](%130)
  %134 : __torch__.torch.nn.modules.container.___torch_mangle_170.Sequential = prim::GetAttr[name="layer1"](%130)
  %135 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name="maxpool"](%130)
  %136 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="relu"](%130)
  %137 : __torch__.models.backbone.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%130)
  %138 : __torch__.torch.nn.modules.conv.___torch_mangle_144.Conv2d = prim::GetAttr[name="conv1"](%130)
  %139 : Tensor = prim::GetAttr[name="weight"](%138)
  %140 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1
  %141 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %142 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %143 : int[] = prim::ListConstruct(%141, %142), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1
  %144 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %145 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %146 : int[] = prim::ListConstruct(%144, %145), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1
  %147 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %148 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %149 : int[] = prim::ListConstruct(%147, %148), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1
  %150 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %151 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %152 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %153 : int[] = prim::ListConstruct(%151, %152), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1
  %154 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %155 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %156 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %157 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %158 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.1 : Float(1:9600000, 64:150000, 375:400, 400:1, requires_grad=0, device=cpu) = aten::_convolution(%input.2, %139, %140, %143, %146, %149, %150, %153, %154, %155, %156, %157, %158), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %160 : Tensor = prim::GetAttr[name="running_mean"](%137)
  %161 : Tensor = prim::GetAttr[name="running_var"](%137)
  %162 : Tensor = prim::GetAttr[name="bias"](%137)
  %163 : Tensor = prim::GetAttr[name="weight"](%137)
  %164 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:48:0
  %165 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:48:0
  %166 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:48:0
  %167 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:48:0
  %168 : int[] = prim::ListConstruct(%164, %165, %166, %167), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1
  %w.1 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%163, %168), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:48:0
  %170 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:49:0
  %171 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:49:0
  %172 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:49:0
  %173 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:49:0
  %174 : int[] = prim::ListConstruct(%170, %171, %172, %173), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1
  %b.1 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%162, %174), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:49:0
  %176 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:50:0
  %177 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:50:0
  %178 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:50:0
  %179 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:50:0
  %180 : int[] = prim::ListConstruct(%176, %177, %178, %179), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1
  %rv.1 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%161, %180), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:50:0
  %182 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:51:0
  %183 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:51:0
  %184 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:51:0
  %185 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:51:0
  %186 : int[] = prim::ListConstruct(%182, %183, %184, %185), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1
  %rm.1 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%160, %186), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:51:0
  %188 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:53:0
  %189 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:53:0
  %190 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.1, %188, %189), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:53:0
  %191 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%190), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.1 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.1, %191), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:53:0
  %193 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.1, %scale.1), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:54:0
  %194 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.1 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.1, %193, %194), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:54:0
  %196 : Float(1:9600000, 64:150000, 375:400, 400:1, requires_grad=0, device=cpu) = aten::mul(%x.1, %scale.1), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:55:0
  %197 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.3 : Float(1:9600000, 64:150000, 375:400, 400:1, requires_grad=0, device=cpu) = aten::add(%196, %bias.1, %197), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.4 : Float(1:9600000, 64:150000, 375:400, 400:1, requires_grad=0, device=cpu) = aten::relu_(%input.3), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %200 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %201 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %202 : int[] = prim::ListConstruct(%200, %201), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool
  %203 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %204 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %205 : int[] = prim::ListConstruct(%203, %204), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool
  %206 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %207 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %208 : int[] = prim::ListConstruct(%206, %207), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool
  %209 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %210 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %211 : int[] = prim::ListConstruct(%209, %210), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool
  %212 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %input.5 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::max_pool2d(%input.4, %202, %205, %208, %211, %212), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.maxpool # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:585:0
  %214 : __torch__.torchvision.models.resnet.___torch_mangle_169.Bottleneck = prim::GetAttr[name="2"](%134)
  %215 : __torch__.torchvision.models.resnet.___torch_mangle_161.Bottleneck = prim::GetAttr[name="1"](%134)
  %216 : __torch__.torchvision.models.resnet.Bottleneck = prim::GetAttr[name="0"](%134)
  %217 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="downsample"](%216)
  %218 : __torch__.models.backbone.___torch_mangle_150.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%216)
  %219 : __torch__.torch.nn.modules.conv.___torch_mangle_149.Conv2d = prim::GetAttr[name="conv3"](%216)
  %220 : __torch__.models.backbone.___torch_mangle_148.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%216)
  %221 : __torch__.torch.nn.modules.conv.___torch_mangle_147.Conv2d = prim::GetAttr[name="conv2"](%216)
  %222 : __torch__.torch.nn.modules.activation.___torch_mangle_151.ReLU = prim::GetAttr[name="relu"](%216)
  %223 : __torch__.models.backbone.___torch_mangle_146.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%216)
  %224 : __torch__.torch.nn.modules.conv.___torch_mangle_145.Conv2d = prim::GetAttr[name="conv1"](%216)
  %225 : Tensor = prim::GetAttr[name="weight"](%224)
  %226 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1
  %227 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %228 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %229 : int[] = prim::ListConstruct(%227, %228), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1
  %230 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %231 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %232 : int[] = prim::ListConstruct(%230, %231), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1
  %233 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %234 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %235 : int[] = prim::ListConstruct(%233, %234), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1
  %236 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %237 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %238 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %239 : int[] = prim::ListConstruct(%237, %238), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1
  %240 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %241 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %242 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %243 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %244 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.2 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.5, %225, %226, %229, %232, %235, %236, %239, %240, %241, %242, %243, %244), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %246 : Tensor = prim::GetAttr[name="running_mean"](%223)
  %247 : Tensor = prim::GetAttr[name="running_var"](%223)
  %248 : Tensor = prim::GetAttr[name="bias"](%223)
  %249 : Tensor = prim::GetAttr[name="weight"](%223)
  %250 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %251 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %252 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %253 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %254 : int[] = prim::ListConstruct(%250, %251, %252, %253), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1
  %w.2 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%249, %254), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %256 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %257 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %258 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %259 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %260 : int[] = prim::ListConstruct(%256, %257, %258, %259), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1
  %b.2 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%248, %260), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %262 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %263 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %264 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %265 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %266 : int[] = prim::ListConstruct(%262, %263, %264, %265), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1
  %rv.2 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%247, %266), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %268 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %269 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %270 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %271 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %272 : int[] = prim::ListConstruct(%268, %269, %270, %271), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1
  %rm.2 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%246, %272), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %274 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %275 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %276 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.2, %274, %275), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %277 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%276), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.2 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.2, %277), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %279 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.2, %scale.2), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %280 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.2 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.2, %279, %280), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %282 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.2, %scale.2), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.6 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%282, %bias.2, %283), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.7 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.6), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %286 : Tensor = prim::GetAttr[name="weight"](%221)
  %287 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2
  %288 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %289 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %290 : int[] = prim::ListConstruct(%288, %289), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2
  %291 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %292 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %293 : int[] = prim::ListConstruct(%291, %292), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2
  %294 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %295 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %296 : int[] = prim::ListConstruct(%294, %295), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2
  %297 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %298 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %299 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %300 : int[] = prim::ListConstruct(%298, %299), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2
  %301 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %302 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %303 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %304 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %305 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.3 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.7, %286, %287, %290, %293, %296, %297, %300, %301, %302, %303, %304, %305), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %307 : Tensor = prim::GetAttr[name="running_mean"](%220)
  %308 : Tensor = prim::GetAttr[name="running_var"](%220)
  %309 : Tensor = prim::GetAttr[name="bias"](%220)
  %310 : Tensor = prim::GetAttr[name="weight"](%220)
  %311 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %312 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %313 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %314 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %315 : int[] = prim::ListConstruct(%311, %312, %313, %314), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2
  %w.3 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%310, %315), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %317 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %318 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %319 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %320 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %321 : int[] = prim::ListConstruct(%317, %318, %319, %320), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2
  %b.3 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%309, %321), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %323 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %324 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %325 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %326 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %327 : int[] = prim::ListConstruct(%323, %324, %325, %326), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2
  %rv.3 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%308, %327), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %329 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %330 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %331 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %332 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %333 : int[] = prim::ListConstruct(%329, %330, %331, %332), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2
  %rm.3 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%307, %333), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %335 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %336 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %337 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.3, %335, %336), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %338 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%337), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.3 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.3, %338), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %340 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.3, %scale.3), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %341 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.3 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.3, %340, %341), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %343 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.3, %scale.3), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %344 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.8 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%343, %bias.3, %344), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.9 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.8), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %347 : Tensor = prim::GetAttr[name="weight"](%219)
  %348 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3
  %349 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %350 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %351 : int[] = prim::ListConstruct(%349, %350), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3
  %352 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %353 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %354 : int[] = prim::ListConstruct(%352, %353), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3
  %355 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %356 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %357 : int[] = prim::ListConstruct(%355, %356), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3
  %358 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %359 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %360 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %361 : int[] = prim::ListConstruct(%359, %360), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3
  %362 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %363 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %364 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %365 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %366 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.4 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.9, %347, %348, %351, %354, %357, %358, %361, %362, %363, %364, %365, %366), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %368 : Tensor = prim::GetAttr[name="running_mean"](%218)
  %369 : Tensor = prim::GetAttr[name="running_var"](%218)
  %370 : Tensor = prim::GetAttr[name="bias"](%218)
  %371 : Tensor = prim::GetAttr[name="weight"](%218)
  %372 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %373 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %374 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %375 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %376 : int[] = prim::ListConstruct(%372, %373, %374, %375), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3
  %w.4 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%371, %376), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %378 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %379 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %380 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %381 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %382 : int[] = prim::ListConstruct(%378, %379, %380, %381), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3
  %b.4 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%370, %382), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %384 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %385 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %386 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %387 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %388 : int[] = prim::ListConstruct(%384, %385, %386, %387), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3
  %rv.4 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%369, %388), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %390 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %391 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %392 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %393 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %394 : int[] = prim::ListConstruct(%390, %391, %392, %393), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3
  %rm.4 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%368, %394), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %396 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %397 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %398 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.4, %396, %397), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %399 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%398), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.4 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.4, %399), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %401 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.4, %scale.4), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %402 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.4 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.4, %401, %402), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %404 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.4, %scale.4), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %405 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.1 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%404, %bias.4, %405), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %407 : __torch__.models.backbone.___torch_mangle_153.FrozenBatchNorm2d = prim::GetAttr[name="1"](%217)
  %408 : __torch__.torch.nn.modules.conv.___torch_mangle_152.Conv2d = prim::GetAttr[name="0"](%217)
  %409 : Tensor = prim::GetAttr[name="weight"](%408)
  %410 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0
  %411 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %412 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %413 : int[] = prim::ListConstruct(%411, %412), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0
  %414 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %415 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %416 : int[] = prim::ListConstruct(%414, %415), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0
  %417 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %418 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %419 : int[] = prim::ListConstruct(%417, %418), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0
  %420 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %421 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %422 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %423 : int[] = prim::ListConstruct(%421, %422), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0
  %424 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %425 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %426 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %427 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %428 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.5 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.5, %409, %410, %413, %416, %419, %420, %423, %424, %425, %426, %427, %428), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %430 : Tensor = prim::GetAttr[name="running_mean"](%407)
  %431 : Tensor = prim::GetAttr[name="running_var"](%407)
  %432 : Tensor = prim::GetAttr[name="bias"](%407)
  %433 : Tensor = prim::GetAttr[name="weight"](%407)
  %434 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %435 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %436 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %437 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %438 : int[] = prim::ListConstruct(%434, %435, %436, %437), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1
  %w.5 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%433, %438), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %440 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %441 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %442 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %443 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %444 : int[] = prim::ListConstruct(%440, %441, %442, %443), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1
  %b.5 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%432, %444), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %446 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %447 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %448 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %449 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %450 : int[] = prim::ListConstruct(%446, %447, %448, %449), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1
  %rv.5 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%431, %450), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %452 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %453 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %454 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %455 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %456 : int[] = prim::ListConstruct(%452, %453, %454, %455), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1
  %rm.5 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%430, %456), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %458 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %459 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %460 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.5, %458, %459), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %461 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%460), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %scale.5 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.5, %461), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %463 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.5, %scale.5), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %464 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %bias.5 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.5, %463, %464), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %466 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.5, %scale.5), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %467 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %identity.1 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%466, %bias.5, %467), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.downsample/__module.model.backbone.0.body.layer1.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %469 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.10 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add_(%out.1, %identity.1, %469), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.11 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.10), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.0/__module.model.backbone.0.body.layer1.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %472 : __torch__.models.backbone.___torch_mangle_159.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%215)
  %473 : __torch__.torch.nn.modules.conv.___torch_mangle_158.Conv2d = prim::GetAttr[name="conv3"](%215)
  %474 : __torch__.models.backbone.___torch_mangle_157.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%215)
  %475 : __torch__.torch.nn.modules.conv.___torch_mangle_156.Conv2d = prim::GetAttr[name="conv2"](%215)
  %476 : __torch__.torch.nn.modules.activation.___torch_mangle_160.ReLU = prim::GetAttr[name="relu"](%215)
  %477 : __torch__.models.backbone.___torch_mangle_155.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%215)
  %478 : __torch__.torch.nn.modules.conv.___torch_mangle_154.Conv2d = prim::GetAttr[name="conv1"](%215)
  %479 : Tensor = prim::GetAttr[name="weight"](%478)
  %480 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1
  %481 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %482 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %483 : int[] = prim::ListConstruct(%481, %482), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1
  %484 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %485 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %486 : int[] = prim::ListConstruct(%484, %485), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1
  %487 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %488 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %489 : int[] = prim::ListConstruct(%487, %488), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1
  %490 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %491 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %492 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %493 : int[] = prim::ListConstruct(%491, %492), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1
  %494 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %495 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %496 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %497 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %498 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.6 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.11, %479, %480, %483, %486, %489, %490, %493, %494, %495, %496, %497, %498), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %500 : Tensor = prim::GetAttr[name="running_mean"](%477)
  %501 : Tensor = prim::GetAttr[name="running_var"](%477)
  %502 : Tensor = prim::GetAttr[name="bias"](%477)
  %503 : Tensor = prim::GetAttr[name="weight"](%477)
  %504 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %505 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %506 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %507 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %508 : int[] = prim::ListConstruct(%504, %505, %506, %507), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1
  %w.6 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%503, %508), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %510 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %511 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %512 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %513 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %514 : int[] = prim::ListConstruct(%510, %511, %512, %513), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1
  %b.6 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%502, %514), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %516 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %517 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %518 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %519 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %520 : int[] = prim::ListConstruct(%516, %517, %518, %519), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1
  %rv.6 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%501, %520), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %522 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %523 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %524 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %525 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %526 : int[] = prim::ListConstruct(%522, %523, %524, %525), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1
  %rm.6 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%500, %526), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %528 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %529 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %530 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.6, %528, %529), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %531 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%530), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.6 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.6, %531), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %533 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.6, %scale.6), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %534 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.6 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.6, %533, %534), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %536 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.6, %scale.6), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %537 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.12 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%536, %bias.6, %537), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.13 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.12), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %540 : Tensor = prim::GetAttr[name="weight"](%475)
  %541 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2
  %542 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %543 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %544 : int[] = prim::ListConstruct(%542, %543), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2
  %545 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %546 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %547 : int[] = prim::ListConstruct(%545, %546), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2
  %548 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %549 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %550 : int[] = prim::ListConstruct(%548, %549), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2
  %551 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %552 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %553 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %554 : int[] = prim::ListConstruct(%552, %553), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2
  %555 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %556 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %557 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %558 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %559 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.7 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.13, %540, %541, %544, %547, %550, %551, %554, %555, %556, %557, %558, %559), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %561 : Tensor = prim::GetAttr[name="running_mean"](%474)
  %562 : Tensor = prim::GetAttr[name="running_var"](%474)
  %563 : Tensor = prim::GetAttr[name="bias"](%474)
  %564 : Tensor = prim::GetAttr[name="weight"](%474)
  %565 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %566 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %567 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %568 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %569 : int[] = prim::ListConstruct(%565, %566, %567, %568), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2
  %w.7 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%564, %569), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %571 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %572 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %573 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %574 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %575 : int[] = prim::ListConstruct(%571, %572, %573, %574), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2
  %b.7 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%563, %575), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %577 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %578 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %579 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %580 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %581 : int[] = prim::ListConstruct(%577, %578, %579, %580), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2
  %rv.7 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%562, %581), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %583 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %584 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %585 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %586 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %587 : int[] = prim::ListConstruct(%583, %584, %585, %586), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2
  %rm.7 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%561, %587), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %589 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %590 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %591 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.7, %589, %590), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %592 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%591), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.7 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.7, %592), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %594 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.7, %scale.7), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %595 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.7 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.7, %594, %595), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %597 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.7, %scale.7), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %598 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.14 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%597, %bias.7, %598), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.15 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.14), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %601 : Tensor = prim::GetAttr[name="weight"](%473)
  %602 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3
  %603 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %604 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %605 : int[] = prim::ListConstruct(%603, %604), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3
  %606 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %607 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %608 : int[] = prim::ListConstruct(%606, %607), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3
  %609 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %610 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %611 : int[] = prim::ListConstruct(%609, %610), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3
  %612 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %613 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %614 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %615 : int[] = prim::ListConstruct(%613, %614), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3
  %616 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %617 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %618 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %619 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %620 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.8 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.15, %601, %602, %605, %608, %611, %612, %615, %616, %617, %618, %619, %620), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %622 : Tensor = prim::GetAttr[name="running_mean"](%472)
  %623 : Tensor = prim::GetAttr[name="running_var"](%472)
  %624 : Tensor = prim::GetAttr[name="bias"](%472)
  %625 : Tensor = prim::GetAttr[name="weight"](%472)
  %626 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %627 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %628 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %629 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %630 : int[] = prim::ListConstruct(%626, %627, %628, %629), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3
  %w.8 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%625, %630), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %632 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %633 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %634 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %635 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %636 : int[] = prim::ListConstruct(%632, %633, %634, %635), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3
  %b.8 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%624, %636), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %638 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %639 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %640 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %641 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %642 : int[] = prim::ListConstruct(%638, %639, %640, %641), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3
  %rv.8 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%623, %642), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %644 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %645 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %646 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %647 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %648 : int[] = prim::ListConstruct(%644, %645, %646, %647), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3
  %rm.8 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%622, %648), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %650 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %651 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %652 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.8, %650, %651), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %653 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%652), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.8 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.8, %653), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %655 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.8, %scale.8), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %656 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.8 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.8, %655, %656), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %658 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.8, %scale.8), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %659 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.2 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%658, %bias.8, %659), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %661 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.16 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add_(%out.2, %input.11, %661), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.17 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.16), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.1/__module.model.backbone.0.body.layer1.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %664 : __torch__.models.backbone.___torch_mangle_167.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%214)
  %665 : __torch__.torch.nn.modules.conv.___torch_mangle_166.Conv2d = prim::GetAttr[name="conv3"](%214)
  %666 : __torch__.models.backbone.___torch_mangle_165.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%214)
  %667 : __torch__.torch.nn.modules.conv.___torch_mangle_164.Conv2d = prim::GetAttr[name="conv2"](%214)
  %668 : __torch__.torch.nn.modules.activation.___torch_mangle_168.ReLU = prim::GetAttr[name="relu"](%214)
  %669 : __torch__.models.backbone.___torch_mangle_163.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%214)
  %670 : __torch__.torch.nn.modules.conv.___torch_mangle_162.Conv2d = prim::GetAttr[name="conv1"](%214)
  %671 : Tensor = prim::GetAttr[name="weight"](%670)
  %672 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1
  %673 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %674 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %675 : int[] = prim::ListConstruct(%673, %674), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1
  %676 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %677 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %678 : int[] = prim::ListConstruct(%676, %677), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1
  %679 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %680 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %681 : int[] = prim::ListConstruct(%679, %680), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1
  %682 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %683 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %684 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %685 : int[] = prim::ListConstruct(%683, %684), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1
  %686 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %687 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %688 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %689 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %690 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.9 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.17, %671, %672, %675, %678, %681, %682, %685, %686, %687, %688, %689, %690), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %692 : Tensor = prim::GetAttr[name="running_mean"](%669)
  %693 : Tensor = prim::GetAttr[name="running_var"](%669)
  %694 : Tensor = prim::GetAttr[name="bias"](%669)
  %695 : Tensor = prim::GetAttr[name="weight"](%669)
  %696 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %697 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %698 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %699 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %700 : int[] = prim::ListConstruct(%696, %697, %698, %699), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1
  %w.9 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%695, %700), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %702 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %703 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %704 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %705 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %706 : int[] = prim::ListConstruct(%702, %703, %704, %705), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1
  %b.9 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%694, %706), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %708 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %709 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %710 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %711 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %712 : int[] = prim::ListConstruct(%708, %709, %710, %711), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1
  %rv.9 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%693, %712), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %714 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %715 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %716 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %717 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %718 : int[] = prim::ListConstruct(%714, %715, %716, %717), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1
  %rm.9 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%692, %718), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %720 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %721 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %722 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.9, %720, %721), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %723 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%722), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.9 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.9, %723), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %725 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.9, %scale.9), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %726 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.9 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.9, %725, %726), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %728 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.9, %scale.9), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %729 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.18 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%728, %bias.9, %729), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.19 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.18), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %732 : Tensor = prim::GetAttr[name="weight"](%667)
  %733 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2
  %734 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %735 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %736 : int[] = prim::ListConstruct(%734, %735), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2
  %737 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %738 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %739 : int[] = prim::ListConstruct(%737, %738), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2
  %740 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %741 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %742 : int[] = prim::ListConstruct(%740, %741), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2
  %743 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %744 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %745 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %746 : int[] = prim::ListConstruct(%744, %745), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2
  %747 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %748 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %749 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %750 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %751 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.10 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.19, %732, %733, %736, %739, %742, %743, %746, %747, %748, %749, %750, %751), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %753 : Tensor = prim::GetAttr[name="running_mean"](%666)
  %754 : Tensor = prim::GetAttr[name="running_var"](%666)
  %755 : Tensor = prim::GetAttr[name="bias"](%666)
  %756 : Tensor = prim::GetAttr[name="weight"](%666)
  %757 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %758 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %759 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %760 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %761 : int[] = prim::ListConstruct(%757, %758, %759, %760), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2
  %w.10 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%756, %761), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %763 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %764 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %765 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %766 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %767 : int[] = prim::ListConstruct(%763, %764, %765, %766), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2
  %b.10 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%755, %767), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %769 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %770 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %771 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %772 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %773 : int[] = prim::ListConstruct(%769, %770, %771, %772), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2
  %rv.10 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%754, %773), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %775 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %776 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %777 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %778 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %779 : int[] = prim::ListConstruct(%775, %776, %777, %778), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2
  %rm.10 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%753, %779), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %781 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %782 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %783 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.10, %781, %782), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %784 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%783), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.10 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.10, %784), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %786 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.10, %scale.10), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %787 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.10 : Float(1:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.10, %786, %787), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %789 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.10, %scale.10), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %790 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.20 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%789, %bias.10, %790), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.21 : Float(1:2406400, 64:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.20), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %793 : Tensor = prim::GetAttr[name="weight"](%665)
  %794 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3
  %795 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %796 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %797 : int[] = prim::ListConstruct(%795, %796), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3
  %798 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %799 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %800 : int[] = prim::ListConstruct(%798, %799), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3
  %801 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %802 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %803 : int[] = prim::ListConstruct(%801, %802), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3
  %804 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %805 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %806 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %807 : int[] = prim::ListConstruct(%805, %806), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3
  %808 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %809 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %810 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %811 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %812 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.11 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.21, %793, %794, %797, %800, %803, %804, %807, %808, %809, %810, %811, %812), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %814 : Tensor = prim::GetAttr[name="running_mean"](%664)
  %815 : Tensor = prim::GetAttr[name="running_var"](%664)
  %816 : Tensor = prim::GetAttr[name="bias"](%664)
  %817 : Tensor = prim::GetAttr[name="weight"](%664)
  %818 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %819 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %820 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %821 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %822 : int[] = prim::ListConstruct(%818, %819, %820, %821), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3
  %w.11 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%817, %822), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %824 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %825 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %826 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %827 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %828 : int[] = prim::ListConstruct(%824, %825, %826, %827), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3
  %b.11 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%816, %828), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %830 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %831 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %832 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %833 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %834 : int[] = prim::ListConstruct(%830, %831, %832, %833), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3
  %rv.11 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%815, %834), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %836 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %837 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %838 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %839 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %840 : int[] = prim::ListConstruct(%836, %837, %838, %839), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3
  %rm.11 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%814, %840), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %842 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %843 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %844 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.11, %842, %843), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %845 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%844), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.11 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.11, %845), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %847 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.11, %scale.11), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %848 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.11 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.11, %847, %848), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %850 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.11, %scale.11), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %851 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.3 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%850, %bias.11, %851), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %853 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.22 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add_(%out.3, %input.17, %853), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.23 : Float(1:9625600, 256:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.22), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer1/__module.model.backbone.0.body.layer1.2/__module.model.backbone.0.body.layer1.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %856 : __torch__.torchvision.models.resnet.___torch_mangle_205.Bottleneck = prim::GetAttr[name="3"](%133)
  %857 : __torch__.torchvision.models.resnet.___torch_mangle_197.Bottleneck = prim::GetAttr[name="2"](%133)
  %858 : __torch__.torchvision.models.resnet.___torch_mangle_189.Bottleneck = prim::GetAttr[name="1"](%133)
  %859 : __torch__.torchvision.models.resnet.___torch_mangle_181.Bottleneck = prim::GetAttr[name="0"](%133)
  %860 : __torch__.torch.nn.modules.container.___torch_mangle_180.Sequential = prim::GetAttr[name="downsample"](%859)
  %861 : __torch__.models.backbone.___torch_mangle_176.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%859)
  %862 : __torch__.torch.nn.modules.conv.___torch_mangle_175.Conv2d = prim::GetAttr[name="conv3"](%859)
  %863 : __torch__.models.backbone.___torch_mangle_174.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%859)
  %864 : __torch__.torch.nn.modules.conv.___torch_mangle_173.Conv2d = prim::GetAttr[name="conv2"](%859)
  %865 : __torch__.torch.nn.modules.activation.___torch_mangle_177.ReLU = prim::GetAttr[name="relu"](%859)
  %866 : __torch__.models.backbone.___torch_mangle_172.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%859)
  %867 : __torch__.torch.nn.modules.conv.___torch_mangle_171.Conv2d = prim::GetAttr[name="conv1"](%859)
  %868 : Tensor = prim::GetAttr[name="weight"](%867)
  %869 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1
  %870 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %871 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %872 : int[] = prim::ListConstruct(%870, %871), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1
  %873 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %874 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %875 : int[] = prim::ListConstruct(%873, %874), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1
  %876 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %877 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %878 : int[] = prim::ListConstruct(%876, %877), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1
  %879 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %880 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %881 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %882 : int[] = prim::ListConstruct(%880, %881), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1
  %883 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %884 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %885 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %886 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %887 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.12 : Float(1:4812800, 128:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::_convolution(%input.23, %868, %869, %872, %875, %878, %879, %882, %883, %884, %885, %886, %887), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %889 : Tensor = prim::GetAttr[name="running_mean"](%866)
  %890 : Tensor = prim::GetAttr[name="running_var"](%866)
  %891 : Tensor = prim::GetAttr[name="bias"](%866)
  %892 : Tensor = prim::GetAttr[name="weight"](%866)
  %893 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %894 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %895 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %896 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %897 : int[] = prim::ListConstruct(%893, %894, %895, %896), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1
  %w.12 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%892, %897), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %899 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %900 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %901 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %902 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %903 : int[] = prim::ListConstruct(%899, %900, %901, %902), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1
  %b.12 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%891, %903), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %905 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %906 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %907 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %908 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %909 : int[] = prim::ListConstruct(%905, %906, %907, %908), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1
  %rv.12 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%890, %909), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %911 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %912 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %913 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %914 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %915 : int[] = prim::ListConstruct(%911, %912, %913, %914), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1
  %rm.12 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%889, %915), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %917 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %918 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %919 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.12, %917, %918), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %920 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%919), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.12 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.12, %920), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %922 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.12, %scale.12), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %923 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.12 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.12, %922, %923), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %925 : Float(1:4812800, 128:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::mul(%x.12, %scale.12), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %926 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.24 : Float(1:4812800, 128:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::add(%925, %bias.12, %926), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.25 : Float(1:4812800, 128:37600, 188:200, 200:1, requires_grad=0, device=cpu) = aten::relu_(%input.24), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %929 : Tensor = prim::GetAttr[name="weight"](%864)
  %930 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2
  %931 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %932 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %933 : int[] = prim::ListConstruct(%931, %932), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2
  %934 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %935 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %936 : int[] = prim::ListConstruct(%934, %935), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2
  %937 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %938 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %939 : int[] = prim::ListConstruct(%937, %938), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2
  %940 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %941 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %942 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %943 : int[] = prim::ListConstruct(%941, %942), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2
  %944 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %945 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %946 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %947 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %948 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.13 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.25, %929, %930, %933, %936, %939, %940, %943, %944, %945, %946, %947, %948), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %950 : Tensor = prim::GetAttr[name="running_mean"](%863)
  %951 : Tensor = prim::GetAttr[name="running_var"](%863)
  %952 : Tensor = prim::GetAttr[name="bias"](%863)
  %953 : Tensor = prim::GetAttr[name="weight"](%863)
  %954 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %955 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %956 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %957 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %958 : int[] = prim::ListConstruct(%954, %955, %956, %957), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2
  %w.13 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%953, %958), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %960 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %961 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %962 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %963 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %964 : int[] = prim::ListConstruct(%960, %961, %962, %963), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2
  %b.13 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%952, %964), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %966 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %967 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %968 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %969 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %970 : int[] = prim::ListConstruct(%966, %967, %968, %969), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2
  %rv.13 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%951, %970), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %972 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %973 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %974 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %975 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %976 : int[] = prim::ListConstruct(%972, %973, %974, %975), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2
  %rm.13 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%950, %976), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %978 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %979 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %980 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.13, %978, %979), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %981 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%980), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.13 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.13, %981), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %983 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.13, %scale.13), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %984 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.13 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.13, %983, %984), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %986 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.13, %scale.13), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %987 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.26 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%986, %bias.13, %987), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.27 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.26), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %990 : Tensor = prim::GetAttr[name="weight"](%862)
  %991 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3
  %992 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %993 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %994 : int[] = prim::ListConstruct(%992, %993), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3
  %995 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %996 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %997 : int[] = prim::ListConstruct(%995, %996), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3
  %998 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %999 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1000 : int[] = prim::ListConstruct(%998, %999), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3
  %1001 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1002 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1003 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1004 : int[] = prim::ListConstruct(%1002, %1003), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3
  %1005 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1006 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1007 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1008 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1009 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.14 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.27, %990, %991, %994, %997, %1000, %1001, %1004, %1005, %1006, %1007, %1008, %1009), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1011 : Tensor = prim::GetAttr[name="running_mean"](%861)
  %1012 : Tensor = prim::GetAttr[name="running_var"](%861)
  %1013 : Tensor = prim::GetAttr[name="bias"](%861)
  %1014 : Tensor = prim::GetAttr[name="weight"](%861)
  %1015 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1016 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1017 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1018 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1019 : int[] = prim::ListConstruct(%1015, %1016, %1017, %1018), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3
  %w.14 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1014, %1019), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1021 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1022 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1023 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1024 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1025 : int[] = prim::ListConstruct(%1021, %1022, %1023, %1024), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3
  %b.14 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1013, %1025), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1027 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1028 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1029 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1030 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1031 : int[] = prim::ListConstruct(%1027, %1028, %1029, %1030), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3
  %rv.14 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1012, %1031), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1033 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1034 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1035 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1036 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1037 : int[] = prim::ListConstruct(%1033, %1034, %1035, %1036), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3
  %rm.14 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1011, %1037), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1039 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1040 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1041 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.14, %1039, %1040), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1042 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1041), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.14 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.14, %1042), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1044 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.14, %scale.14), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1045 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.14 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.14, %1044, %1045), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1047 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.14, %scale.14), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1048 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.4 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1047, %bias.14, %1048), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1050 : __torch__.models.backbone.___torch_mangle_179.FrozenBatchNorm2d = prim::GetAttr[name="1"](%860)
  %1051 : __torch__.torch.nn.modules.conv.___torch_mangle_178.Conv2d = prim::GetAttr[name="0"](%860)
  %1052 : Tensor = prim::GetAttr[name="weight"](%1051)
  %1053 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0
  %1054 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1055 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1056 : int[] = prim::ListConstruct(%1054, %1055), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0
  %1057 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1058 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1059 : int[] = prim::ListConstruct(%1057, %1058), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0
  %1060 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1061 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1062 : int[] = prim::ListConstruct(%1060, %1061), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0
  %1063 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1064 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1065 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1066 : int[] = prim::ListConstruct(%1064, %1065), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0
  %1067 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1068 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1069 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1070 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1071 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.15 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.23, %1052, %1053, %1056, %1059, %1062, %1063, %1066, %1067, %1068, %1069, %1070, %1071), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1073 : Tensor = prim::GetAttr[name="running_mean"](%1050)
  %1074 : Tensor = prim::GetAttr[name="running_var"](%1050)
  %1075 : Tensor = prim::GetAttr[name="bias"](%1050)
  %1076 : Tensor = prim::GetAttr[name="weight"](%1050)
  %1077 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1078 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1079 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1080 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1081 : int[] = prim::ListConstruct(%1077, %1078, %1079, %1080), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1
  %w.15 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1076, %1081), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1083 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1084 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1085 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1086 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1087 : int[] = prim::ListConstruct(%1083, %1084, %1085, %1086), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1
  %b.15 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1075, %1087), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1089 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1090 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1091 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1092 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1093 : int[] = prim::ListConstruct(%1089, %1090, %1091, %1092), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1
  %rv.15 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1074, %1093), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1095 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1096 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1097 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1098 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1099 : int[] = prim::ListConstruct(%1095, %1096, %1097, %1098), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1
  %rm.15 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1073, %1099), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1101 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1102 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1103 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.15, %1101, %1102), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1104 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1103), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %scale.15 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.15, %1104), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1106 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.15, %scale.15), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %1107 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %bias.15 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.15, %1106, %1107), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %1109 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.15, %scale.15), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %1110 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %identity.2 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1109, %bias.15, %1110), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.downsample/__module.model.backbone.0.body.layer2.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %1112 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.28 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add_(%out.4, %identity.2, %1112), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.29 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.28), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.0/__module.model.backbone.0.body.layer2.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1115 : __torch__.models.backbone.___torch_mangle_187.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%858)
  %1116 : __torch__.torch.nn.modules.conv.___torch_mangle_186.Conv2d = prim::GetAttr[name="conv3"](%858)
  %1117 : __torch__.models.backbone.___torch_mangle_185.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%858)
  %1118 : __torch__.torch.nn.modules.conv.___torch_mangle_184.Conv2d = prim::GetAttr[name="conv2"](%858)
  %1119 : __torch__.torch.nn.modules.activation.___torch_mangle_188.ReLU = prim::GetAttr[name="relu"](%858)
  %1120 : __torch__.models.backbone.___torch_mangle_183.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%858)
  %1121 : __torch__.torch.nn.modules.conv.___torch_mangle_182.Conv2d = prim::GetAttr[name="conv1"](%858)
  %1122 : Tensor = prim::GetAttr[name="weight"](%1121)
  %1123 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1
  %1124 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1125 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1126 : int[] = prim::ListConstruct(%1124, %1125), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1
  %1127 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1128 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1129 : int[] = prim::ListConstruct(%1127, %1128), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1
  %1130 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1131 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1132 : int[] = prim::ListConstruct(%1130, %1131), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1
  %1133 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1134 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1135 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1136 : int[] = prim::ListConstruct(%1134, %1135), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1
  %1137 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1138 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1139 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1140 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1141 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.16 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.29, %1122, %1123, %1126, %1129, %1132, %1133, %1136, %1137, %1138, %1139, %1140, %1141), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1143 : Tensor = prim::GetAttr[name="running_mean"](%1120)
  %1144 : Tensor = prim::GetAttr[name="running_var"](%1120)
  %1145 : Tensor = prim::GetAttr[name="bias"](%1120)
  %1146 : Tensor = prim::GetAttr[name="weight"](%1120)
  %1147 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1148 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1149 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1150 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1151 : int[] = prim::ListConstruct(%1147, %1148, %1149, %1150), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1
  %w.16 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1146, %1151), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1153 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1154 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1155 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1156 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1157 : int[] = prim::ListConstruct(%1153, %1154, %1155, %1156), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1
  %b.16 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1145, %1157), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1159 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1160 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1161 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1162 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1163 : int[] = prim::ListConstruct(%1159, %1160, %1161, %1162), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1
  %rv.16 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1144, %1163), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1166 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1167 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1168 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1169 : int[] = prim::ListConstruct(%1165, %1166, %1167, %1168), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1
  %rm.16 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1143, %1169), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1171 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1172 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1173 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.16, %1171, %1172), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1174 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1173), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.16 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.16, %1174), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1176 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.16, %scale.16), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1177 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.16 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.16, %1176, %1177), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1179 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.16, %scale.16), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %1180 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.30 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1179, %bias.16, %1180), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.31 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.30), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1183 : Tensor = prim::GetAttr[name="weight"](%1118)
  %1184 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2
  %1185 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1186 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1187 : int[] = prim::ListConstruct(%1185, %1186), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2
  %1188 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1189 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1190 : int[] = prim::ListConstruct(%1188, %1189), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2
  %1191 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1192 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1193 : int[] = prim::ListConstruct(%1191, %1192), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2
  %1194 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1195 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1196 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1197 : int[] = prim::ListConstruct(%1195, %1196), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2
  %1198 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1199 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1200 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1201 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1202 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.17 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.31, %1183, %1184, %1187, %1190, %1193, %1194, %1197, %1198, %1199, %1200, %1201, %1202), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1204 : Tensor = prim::GetAttr[name="running_mean"](%1117)
  %1205 : Tensor = prim::GetAttr[name="running_var"](%1117)
  %1206 : Tensor = prim::GetAttr[name="bias"](%1117)
  %1207 : Tensor = prim::GetAttr[name="weight"](%1117)
  %1208 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1209 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1210 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1211 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1212 : int[] = prim::ListConstruct(%1208, %1209, %1210, %1211), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2
  %w.17 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1207, %1212), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1214 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1215 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1216 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1217 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1218 : int[] = prim::ListConstruct(%1214, %1215, %1216, %1217), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2
  %b.17 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1206, %1218), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1220 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1221 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1222 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1223 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1224 : int[] = prim::ListConstruct(%1220, %1221, %1222, %1223), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2
  %rv.17 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1205, %1224), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1226 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1227 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1228 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1229 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1230 : int[] = prim::ListConstruct(%1226, %1227, %1228, %1229), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2
  %rm.17 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1204, %1230), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1232 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1233 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1234 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.17, %1232, %1233), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1235 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1234), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.17 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.17, %1235), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1237 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.17, %scale.17), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1238 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.17 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.17, %1237, %1238), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1240 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.17, %scale.17), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %1241 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.32 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1240, %bias.17, %1241), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.33 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.32), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1244 : Tensor = prim::GetAttr[name="weight"](%1116)
  %1245 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3
  %1246 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1248 : int[] = prim::ListConstruct(%1246, %1247), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3
  %1249 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1250 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1251 : int[] = prim::ListConstruct(%1249, %1250), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3
  %1252 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1253 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1254 : int[] = prim::ListConstruct(%1252, %1253), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3
  %1255 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1256 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1257 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1258 : int[] = prim::ListConstruct(%1256, %1257), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3
  %1259 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1260 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1261 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1262 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1263 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.18 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.33, %1244, %1245, %1248, %1251, %1254, %1255, %1258, %1259, %1260, %1261, %1262, %1263), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1265 : Tensor = prim::GetAttr[name="running_mean"](%1115)
  %1266 : Tensor = prim::GetAttr[name="running_var"](%1115)
  %1267 : Tensor = prim::GetAttr[name="bias"](%1115)
  %1268 : Tensor = prim::GetAttr[name="weight"](%1115)
  %1269 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1270 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1271 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1272 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1273 : int[] = prim::ListConstruct(%1269, %1270, %1271, %1272), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3
  %w.18 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1268, %1273), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1275 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1276 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1277 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1278 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1279 : int[] = prim::ListConstruct(%1275, %1276, %1277, %1278), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3
  %b.18 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1267, %1279), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1281 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1282 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1284 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1285 : int[] = prim::ListConstruct(%1281, %1282, %1283, %1284), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3
  %rv.18 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1266, %1285), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1287 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1288 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1289 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1290 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1291 : int[] = prim::ListConstruct(%1287, %1288, %1289, %1290), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3
  %rm.18 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1265, %1291), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1293 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1294 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1295 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.18, %1293, %1294), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1296 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1295), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.18 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.18, %1296), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1298 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.18, %scale.18), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1299 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.18 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.18, %1298, %1299), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1301 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.18, %scale.18), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1302 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.5 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1301, %bias.18, %1302), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1304 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.34 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add_(%out.5, %input.29, %1304), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.35 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.34), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.1/__module.model.backbone.0.body.layer2.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1307 : __torch__.models.backbone.___torch_mangle_195.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%857)
  %1308 : __torch__.torch.nn.modules.conv.___torch_mangle_194.Conv2d = prim::GetAttr[name="conv3"](%857)
  %1309 : __torch__.models.backbone.___torch_mangle_193.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%857)
  %1310 : __torch__.torch.nn.modules.conv.___torch_mangle_192.Conv2d = prim::GetAttr[name="conv2"](%857)
  %1311 : __torch__.torch.nn.modules.activation.___torch_mangle_196.ReLU = prim::GetAttr[name="relu"](%857)
  %1312 : __torch__.models.backbone.___torch_mangle_191.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%857)
  %1313 : __torch__.torch.nn.modules.conv.___torch_mangle_190.Conv2d = prim::GetAttr[name="conv1"](%857)
  %1314 : Tensor = prim::GetAttr[name="weight"](%1313)
  %1315 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1
  %1316 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1317 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1318 : int[] = prim::ListConstruct(%1316, %1317), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1
  %1319 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1320 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1321 : int[] = prim::ListConstruct(%1319, %1320), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1
  %1322 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1323 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1324 : int[] = prim::ListConstruct(%1322, %1323), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1
  %1325 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1326 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1327 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1328 : int[] = prim::ListConstruct(%1326, %1327), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1
  %1329 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1330 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1331 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1332 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1333 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.19 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.35, %1314, %1315, %1318, %1321, %1324, %1325, %1328, %1329, %1330, %1331, %1332, %1333), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1335 : Tensor = prim::GetAttr[name="running_mean"](%1312)
  %1336 : Tensor = prim::GetAttr[name="running_var"](%1312)
  %1337 : Tensor = prim::GetAttr[name="bias"](%1312)
  %1338 : Tensor = prim::GetAttr[name="weight"](%1312)
  %1339 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1340 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1341 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1342 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1343 : int[] = prim::ListConstruct(%1339, %1340, %1341, %1342), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1
  %w.19 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1338, %1343), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1345 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1346 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1347 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1348 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1349 : int[] = prim::ListConstruct(%1345, %1346, %1347, %1348), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1
  %b.19 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1337, %1349), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1351 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1352 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1353 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1354 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1355 : int[] = prim::ListConstruct(%1351, %1352, %1353, %1354), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1
  %rv.19 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1336, %1355), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1357 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1358 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1359 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1360 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1361 : int[] = prim::ListConstruct(%1357, %1358, %1359, %1360), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1
  %rm.19 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1335, %1361), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1363 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1364 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1365 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.19, %1363, %1364), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1366 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1365), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.19 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.19, %1366), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1368 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.19, %scale.19), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1369 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.19 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.19, %1368, %1369), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1371 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.19, %scale.19), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %1372 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.36 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1371, %bias.19, %1372), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.37 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.36), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1375 : Tensor = prim::GetAttr[name="weight"](%1310)
  %1376 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2
  %1377 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1378 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1379 : int[] = prim::ListConstruct(%1377, %1378), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2
  %1380 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1381 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1382 : int[] = prim::ListConstruct(%1380, %1381), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2
  %1383 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1384 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1385 : int[] = prim::ListConstruct(%1383, %1384), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2
  %1386 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1387 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1388 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1389 : int[] = prim::ListConstruct(%1387, %1388), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2
  %1390 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1391 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1392 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1393 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1394 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.20 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.37, %1375, %1376, %1379, %1382, %1385, %1386, %1389, %1390, %1391, %1392, %1393, %1394), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1396 : Tensor = prim::GetAttr[name="running_mean"](%1309)
  %1397 : Tensor = prim::GetAttr[name="running_var"](%1309)
  %1398 : Tensor = prim::GetAttr[name="bias"](%1309)
  %1399 : Tensor = prim::GetAttr[name="weight"](%1309)
  %1400 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1401 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1402 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1403 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1404 : int[] = prim::ListConstruct(%1400, %1401, %1402, %1403), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2
  %w.20 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1399, %1404), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1406 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1407 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1408 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1409 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1410 : int[] = prim::ListConstruct(%1406, %1407, %1408, %1409), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2
  %b.20 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1398, %1410), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1412 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1413 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1414 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1415 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1416 : int[] = prim::ListConstruct(%1412, %1413, %1414, %1415), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2
  %rv.20 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1397, %1416), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1418 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1419 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1420 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1421 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1422 : int[] = prim::ListConstruct(%1418, %1419, %1420, %1421), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2
  %rm.20 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1396, %1422), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1424 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1425 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1426 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.20, %1424, %1425), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1427 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1426), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.20 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.20, %1427), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1429 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.20, %scale.20), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1430 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.20 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.20, %1429, %1430), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1432 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.20, %scale.20), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %1433 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.38 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1432, %bias.20, %1433), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.39 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.38), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1436 : Tensor = prim::GetAttr[name="weight"](%1308)
  %1437 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3
  %1438 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1439 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1440 : int[] = prim::ListConstruct(%1438, %1439), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3
  %1441 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1442 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1443 : int[] = prim::ListConstruct(%1441, %1442), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3
  %1444 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1445 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1446 : int[] = prim::ListConstruct(%1444, %1445), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3
  %1447 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1448 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1449 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1450 : int[] = prim::ListConstruct(%1448, %1449), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3
  %1451 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1452 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1453 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1454 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1455 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.21 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.39, %1436, %1437, %1440, %1443, %1446, %1447, %1450, %1451, %1452, %1453, %1454, %1455), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1457 : Tensor = prim::GetAttr[name="running_mean"](%1307)
  %1458 : Tensor = prim::GetAttr[name="running_var"](%1307)
  %1459 : Tensor = prim::GetAttr[name="bias"](%1307)
  %1460 : Tensor = prim::GetAttr[name="weight"](%1307)
  %1461 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1462 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1463 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1464 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1465 : int[] = prim::ListConstruct(%1461, %1462, %1463, %1464), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3
  %w.21 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1460, %1465), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1467 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1468 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1469 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1470 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1471 : int[] = prim::ListConstruct(%1467, %1468, %1469, %1470), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3
  %b.21 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1459, %1471), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1473 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1474 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1475 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1476 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1477 : int[] = prim::ListConstruct(%1473, %1474, %1475, %1476), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3
  %rv.21 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1458, %1477), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1479 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1480 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1481 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1482 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1483 : int[] = prim::ListConstruct(%1479, %1480, %1481, %1482), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3
  %rm.21 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1457, %1483), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1485 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1486 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1487 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.21, %1485, %1486), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1488 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1487), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.21 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.21, %1488), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1490 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.21, %scale.21), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1491 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.21 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.21, %1490, %1491), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1493 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.21, %scale.21), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1494 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.6 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1493, %bias.21, %1494), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1496 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.40 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add_(%out.6, %input.35, %1496), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.41 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.40), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.2/__module.model.backbone.0.body.layer2.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1499 : __torch__.models.backbone.___torch_mangle_203.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%856)
  %1500 : __torch__.torch.nn.modules.conv.___torch_mangle_202.Conv2d = prim::GetAttr[name="conv3"](%856)
  %1501 : __torch__.models.backbone.___torch_mangle_201.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%856)
  %1502 : __torch__.torch.nn.modules.conv.___torch_mangle_200.Conv2d = prim::GetAttr[name="conv2"](%856)
  %1503 : __torch__.torch.nn.modules.activation.___torch_mangle_204.ReLU = prim::GetAttr[name="relu"](%856)
  %1504 : __torch__.models.backbone.___torch_mangle_199.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%856)
  %1505 : __torch__.torch.nn.modules.conv.___torch_mangle_198.Conv2d = prim::GetAttr[name="conv1"](%856)
  %1506 : Tensor = prim::GetAttr[name="weight"](%1505)
  %1507 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1
  %1508 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1509 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1510 : int[] = prim::ListConstruct(%1508, %1509), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1
  %1511 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1512 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1513 : int[] = prim::ListConstruct(%1511, %1512), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1
  %1514 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1515 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1516 : int[] = prim::ListConstruct(%1514, %1515), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1
  %1517 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1518 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1519 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1520 : int[] = prim::ListConstruct(%1518, %1519), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1
  %1521 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1522 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1523 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1524 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1525 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.22 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.41, %1506, %1507, %1510, %1513, %1516, %1517, %1520, %1521, %1522, %1523, %1524, %1525), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1527 : Tensor = prim::GetAttr[name="running_mean"](%1504)
  %1528 : Tensor = prim::GetAttr[name="running_var"](%1504)
  %1529 : Tensor = prim::GetAttr[name="bias"](%1504)
  %1530 : Tensor = prim::GetAttr[name="weight"](%1504)
  %1531 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1532 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1533 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1534 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1535 : int[] = prim::ListConstruct(%1531, %1532, %1533, %1534), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1
  %w.22 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1530, %1535), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1537 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1538 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1539 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1540 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1541 : int[] = prim::ListConstruct(%1537, %1538, %1539, %1540), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1
  %b.22 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1529, %1541), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1543 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1544 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1545 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1546 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1547 : int[] = prim::ListConstruct(%1543, %1544, %1545, %1546), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1
  %rv.22 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1528, %1547), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1549 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1550 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1551 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1552 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1553 : int[] = prim::ListConstruct(%1549, %1550, %1551, %1552), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1
  %rm.22 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1527, %1553), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1555 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1556 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1557 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.22, %1555, %1556), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1558 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1557), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.22 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.22, %1558), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1560 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.22, %scale.22), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1561 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.22 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.22, %1560, %1561), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1563 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.22, %scale.22), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:55:0
  %1564 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.42 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1563, %bias.22, %1564), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.43 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.42), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1567 : Tensor = prim::GetAttr[name="weight"](%1502)
  %1568 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2
  %1569 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1570 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1571 : int[] = prim::ListConstruct(%1569, %1570), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2
  %1572 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1573 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1574 : int[] = prim::ListConstruct(%1572, %1573), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2
  %1575 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1576 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1577 : int[] = prim::ListConstruct(%1575, %1576), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2
  %1578 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1579 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1580 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1581 : int[] = prim::ListConstruct(%1579, %1580), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2
  %1582 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1583 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1584 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1585 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1586 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.23 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.43, %1567, %1568, %1571, %1574, %1577, %1578, %1581, %1582, %1583, %1584, %1585, %1586), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1588 : Tensor = prim::GetAttr[name="running_mean"](%1501)
  %1589 : Tensor = prim::GetAttr[name="running_var"](%1501)
  %1590 : Tensor = prim::GetAttr[name="bias"](%1501)
  %1591 : Tensor = prim::GetAttr[name="weight"](%1501)
  %1592 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1593 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1594 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1595 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1596 : int[] = prim::ListConstruct(%1592, %1593, %1594, %1595), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2
  %w.23 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1591, %1596), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1598 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1599 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1600 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1601 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1602 : int[] = prim::ListConstruct(%1598, %1599, %1600, %1601), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2
  %b.23 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1590, %1602), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1604 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1605 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1606 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1607 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1608 : int[] = prim::ListConstruct(%1604, %1605, %1606, %1607), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2
  %rv.23 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1589, %1608), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1610 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1611 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1612 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1613 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1614 : int[] = prim::ListConstruct(%1610, %1611, %1612, %1613), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2
  %rm.23 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1588, %1614), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1616 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1617 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1618 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.23, %1616, %1617), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1619 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1618), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.23 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.23, %1619), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1621 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.23, %scale.23), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1622 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.23 : Float(1:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.23, %1621, %1622), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1624 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.23, %scale.23), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:55:0
  %1625 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.44 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1624, %bias.23, %1625), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.45 : Float(1:1203200, 128:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.44), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1628 : Tensor = prim::GetAttr[name="weight"](%1500)
  %1629 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3
  %1630 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1631 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1632 : int[] = prim::ListConstruct(%1630, %1631), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3
  %1633 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1634 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1635 : int[] = prim::ListConstruct(%1633, %1634), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3
  %1636 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1637 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1638 : int[] = prim::ListConstruct(%1636, %1637), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3
  %1639 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1640 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1641 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1642 : int[] = prim::ListConstruct(%1640, %1641), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3
  %1643 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1644 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1645 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1646 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1647 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.24 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.45, %1628, %1629, %1632, %1635, %1638, %1639, %1642, %1643, %1644, %1645, %1646, %1647), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1649 : Tensor = prim::GetAttr[name="running_mean"](%1499)
  %1650 : Tensor = prim::GetAttr[name="running_var"](%1499)
  %1651 : Tensor = prim::GetAttr[name="bias"](%1499)
  %1652 : Tensor = prim::GetAttr[name="weight"](%1499)
  %1653 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1654 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1655 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1656 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1657 : int[] = prim::ListConstruct(%1653, %1654, %1655, %1656), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3
  %w.24 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1652, %1657), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1659 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1660 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1661 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1662 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1663 : int[] = prim::ListConstruct(%1659, %1660, %1661, %1662), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3
  %b.24 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1651, %1663), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1665 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1666 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1667 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1668 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1669 : int[] = prim::ListConstruct(%1665, %1666, %1667, %1668), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3
  %rv.24 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1650, %1669), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1671 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1672 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1673 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1674 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1675 : int[] = prim::ListConstruct(%1671, %1672, %1673, %1674), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3
  %rm.24 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1649, %1675), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1677 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1678 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1679 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.24, %1677, %1678), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1680 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1679), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.24 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.24, %1680), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1682 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.24, %scale.24), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1683 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.24 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.24, %1682, %1683), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1685 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.24, %scale.24), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1686 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.7 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1685, %bias.24, %1686), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1688 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.46 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add_(%out.7, %input.41, %1688), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.47 : Float(1:4812800, 512:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.46), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer2/__module.model.backbone.0.body.layer2.3/__module.model.backbone.0.body.layer2.3.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1691 : __torch__.torchvision.models.resnet.___torch_mangle_257.Bottleneck = prim::GetAttr[name="5"](%132)
  %1692 : __torch__.torchvision.models.resnet.___torch_mangle_249.Bottleneck = prim::GetAttr[name="4"](%132)
  %1693 : __torch__.torchvision.models.resnet.___torch_mangle_241.Bottleneck = prim::GetAttr[name="3"](%132)
  %1694 : __torch__.torchvision.models.resnet.___torch_mangle_233.Bottleneck = prim::GetAttr[name="2"](%132)
  %1695 : __torch__.torchvision.models.resnet.___torch_mangle_225.Bottleneck = prim::GetAttr[name="1"](%132)
  %1696 : __torch__.torchvision.models.resnet.___torch_mangle_217.Bottleneck = prim::GetAttr[name="0"](%132)
  %1697 : __torch__.torch.nn.modules.container.___torch_mangle_216.Sequential = prim::GetAttr[name="downsample"](%1696)
  %1698 : __torch__.models.backbone.___torch_mangle_212.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%1696)
  %1699 : __torch__.torch.nn.modules.conv.___torch_mangle_211.Conv2d = prim::GetAttr[name="conv3"](%1696)
  %1700 : __torch__.models.backbone.___torch_mangle_210.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%1696)
  %1701 : __torch__.torch.nn.modules.conv.___torch_mangle_209.Conv2d = prim::GetAttr[name="conv2"](%1696)
  %1702 : __torch__.torch.nn.modules.activation.___torch_mangle_213.ReLU = prim::GetAttr[name="relu"](%1696)
  %1703 : __torch__.models.backbone.___torch_mangle_208.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%1696)
  %1704 : __torch__.torch.nn.modules.conv.___torch_mangle_207.Conv2d = prim::GetAttr[name="conv1"](%1696)
  %1705 : Tensor = prim::GetAttr[name="weight"](%1704)
  %1706 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1
  %1707 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1708 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1709 : int[] = prim::ListConstruct(%1707, %1708), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1
  %1710 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1711 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1712 : int[] = prim::ListConstruct(%1710, %1711), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1
  %1713 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1714 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1715 : int[] = prim::ListConstruct(%1713, %1714), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1
  %1716 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1717 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1718 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1719 : int[] = prim::ListConstruct(%1717, %1718), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1
  %1720 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1721 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1722 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1723 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1724 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.25 : Float(1:2406400, 256:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::_convolution(%input.47, %1705, %1706, %1709, %1712, %1715, %1716, %1719, %1720, %1721, %1722, %1723, %1724), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1726 : Tensor = prim::GetAttr[name="running_mean"](%1703)
  %1727 : Tensor = prim::GetAttr[name="running_var"](%1703)
  %1728 : Tensor = prim::GetAttr[name="bias"](%1703)
  %1729 : Tensor = prim::GetAttr[name="weight"](%1703)
  %1730 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1731 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1732 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1733 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1734 : int[] = prim::ListConstruct(%1730, %1731, %1732, %1733), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1
  %w.25 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1729, %1734), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1736 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1737 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1738 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1739 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1740 : int[] = prim::ListConstruct(%1736, %1737, %1738, %1739), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1
  %b.25 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1728, %1740), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1742 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1743 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1744 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1745 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1746 : int[] = prim::ListConstruct(%1742, %1743, %1744, %1745), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1
  %rv.25 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1727, %1746), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1748 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1749 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1750 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1751 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1752 : int[] = prim::ListConstruct(%1748, %1749, %1750, %1751), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1
  %rm.25 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1726, %1752), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %1754 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1755 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1756 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.25, %1754, %1755), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1757 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1756), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.25 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.25, %1757), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %1759 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.25, %scale.25), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1760 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.25 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.25, %1759, %1760), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %1762 : Float(1:2406400, 256:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::mul(%x.25, %scale.25), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %1763 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.48 : Float(1:2406400, 256:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::add(%1762, %bias.25, %1763), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.49 : Float(1:2406400, 256:9400, 94:100, 100:1, requires_grad=0, device=cpu) = aten::relu_(%input.48), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1766 : Tensor = prim::GetAttr[name="weight"](%1701)
  %1767 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2
  %1768 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1769 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1770 : int[] = prim::ListConstruct(%1768, %1769), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2
  %1771 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1772 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1773 : int[] = prim::ListConstruct(%1771, %1772), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2
  %1774 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1775 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1776 : int[] = prim::ListConstruct(%1774, %1775), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2
  %1777 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1778 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1779 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1780 : int[] = prim::ListConstruct(%1778, %1779), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2
  %1781 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1782 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1783 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1784 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1785 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.26 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.49, %1766, %1767, %1770, %1773, %1776, %1777, %1780, %1781, %1782, %1783, %1784, %1785), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1787 : Tensor = prim::GetAttr[name="running_mean"](%1700)
  %1788 : Tensor = prim::GetAttr[name="running_var"](%1700)
  %1789 : Tensor = prim::GetAttr[name="bias"](%1700)
  %1790 : Tensor = prim::GetAttr[name="weight"](%1700)
  %1791 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1792 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1793 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1794 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1795 : int[] = prim::ListConstruct(%1791, %1792, %1793, %1794), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2
  %w.26 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1790, %1795), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %1797 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1798 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1799 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1800 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1801 : int[] = prim::ListConstruct(%1797, %1798, %1799, %1800), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2
  %b.26 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1789, %1801), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %1803 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1804 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1805 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1806 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1807 : int[] = prim::ListConstruct(%1803, %1804, %1805, %1806), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2
  %rv.26 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1788, %1807), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %1809 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1810 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1811 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1812 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1813 : int[] = prim::ListConstruct(%1809, %1810, %1811, %1812), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2
  %rm.26 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1787, %1813), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %1815 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1816 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1817 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.26, %1815, %1816), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1818 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1817), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.26 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.26, %1818), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %1820 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.26, %scale.26), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1821 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.26 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.26, %1820, %1821), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %1823 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.26, %scale.26), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %1824 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.50 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%1823, %bias.26, %1824), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.51 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.50), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1827 : Tensor = prim::GetAttr[name="weight"](%1699)
  %1828 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3
  %1829 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1830 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1831 : int[] = prim::ListConstruct(%1829, %1830), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3
  %1832 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1833 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1834 : int[] = prim::ListConstruct(%1832, %1833), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3
  %1835 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1836 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1837 : int[] = prim::ListConstruct(%1835, %1836), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3
  %1838 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1839 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1840 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1841 : int[] = prim::ListConstruct(%1839, %1840), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3
  %1842 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1843 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1844 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1845 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1846 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.27 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.51, %1827, %1828, %1831, %1834, %1837, %1838, %1841, %1842, %1843, %1844, %1845, %1846), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1848 : Tensor = prim::GetAttr[name="running_mean"](%1698)
  %1849 : Tensor = prim::GetAttr[name="running_var"](%1698)
  %1850 : Tensor = prim::GetAttr[name="bias"](%1698)
  %1851 : Tensor = prim::GetAttr[name="weight"](%1698)
  %1852 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1853 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1854 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1855 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1856 : int[] = prim::ListConstruct(%1852, %1853, %1854, %1855), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3
  %w.27 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1851, %1856), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %1858 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1859 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1860 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1861 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1862 : int[] = prim::ListConstruct(%1858, %1859, %1860, %1861), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3
  %b.27 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1850, %1862), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %1864 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1865 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1866 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1867 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1868 : int[] = prim::ListConstruct(%1864, %1865, %1866, %1867), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3
  %rv.27 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1849, %1868), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %1870 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1871 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1872 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1873 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1874 : int[] = prim::ListConstruct(%1870, %1871, %1872, %1873), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3
  %rm.27 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1848, %1874), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %1876 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1877 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1878 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.27, %1876, %1877), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1879 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1878), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.27 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.27, %1879), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %1881 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.27, %scale.27), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1882 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.27 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.27, %1881, %1882), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %1884 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.27, %scale.27), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1885 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.8 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%1884, %bias.27, %1885), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %1887 : __torch__.models.backbone.___torch_mangle_215.FrozenBatchNorm2d = prim::GetAttr[name="1"](%1697)
  %1888 : __torch__.torch.nn.modules.conv.___torch_mangle_214.Conv2d = prim::GetAttr[name="0"](%1697)
  %1889 : Tensor = prim::GetAttr[name="weight"](%1888)
  %1890 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0
  %1891 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1892 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1893 : int[] = prim::ListConstruct(%1891, %1892), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0
  %1894 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1895 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1896 : int[] = prim::ListConstruct(%1894, %1895), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0
  %1897 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1898 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1899 : int[] = prim::ListConstruct(%1897, %1898), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0
  %1900 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1901 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1902 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1903 : int[] = prim::ListConstruct(%1901, %1902), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0
  %1904 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1905 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1906 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1907 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1908 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.28 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.47, %1889, %1890, %1893, %1896, %1899, %1900, %1903, %1904, %1905, %1906, %1907, %1908), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1910 : Tensor = prim::GetAttr[name="running_mean"](%1887)
  %1911 : Tensor = prim::GetAttr[name="running_var"](%1887)
  %1912 : Tensor = prim::GetAttr[name="bias"](%1887)
  %1913 : Tensor = prim::GetAttr[name="weight"](%1887)
  %1914 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1915 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1916 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1917 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1918 : int[] = prim::ListConstruct(%1914, %1915, %1916, %1917), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1
  %w.28 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1913, %1918), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %1920 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1921 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1922 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1923 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1924 : int[] = prim::ListConstruct(%1920, %1921, %1922, %1923), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1
  %b.28 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1912, %1924), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %1926 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1927 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1928 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1929 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1930 : int[] = prim::ListConstruct(%1926, %1927, %1928, %1929), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1
  %rv.28 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1911, %1930), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %1932 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1933 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1934 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1935 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1936 : int[] = prim::ListConstruct(%1932, %1933, %1934, %1935), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1
  %rm.28 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1910, %1936), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %1938 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1939 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1940 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.28, %1938, %1939), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1941 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%1940), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %scale.28 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.28, %1941), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %1943 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.28, %scale.28), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %1944 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %bias.28 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.28, %1943, %1944), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %1946 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.28, %scale.28), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %1947 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %identity.3 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%1946, %bias.28, %1947), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.downsample/__module.model.backbone.0.body.layer3.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %1949 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.52 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add_(%out.8, %identity.3, %1949), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.53 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.52), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.0/__module.model.backbone.0.body.layer3.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %1952 : __torch__.models.backbone.___torch_mangle_223.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%1695)
  %1953 : __torch__.torch.nn.modules.conv.___torch_mangle_222.Conv2d = prim::GetAttr[name="conv3"](%1695)
  %1954 : __torch__.models.backbone.___torch_mangle_221.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%1695)
  %1955 : __torch__.torch.nn.modules.conv.___torch_mangle_220.Conv2d = prim::GetAttr[name="conv2"](%1695)
  %1956 : __torch__.torch.nn.modules.activation.___torch_mangle_224.ReLU = prim::GetAttr[name="relu"](%1695)
  %1957 : __torch__.models.backbone.___torch_mangle_219.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%1695)
  %1958 : __torch__.torch.nn.modules.conv.___torch_mangle_218.Conv2d = prim::GetAttr[name="conv1"](%1695)
  %1959 : Tensor = prim::GetAttr[name="weight"](%1958)
  %1960 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1
  %1961 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1962 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1963 : int[] = prim::ListConstruct(%1961, %1962), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1
  %1964 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1965 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1966 : int[] = prim::ListConstruct(%1964, %1965), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1
  %1967 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1968 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1969 : int[] = prim::ListConstruct(%1967, %1968), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1
  %1970 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1971 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1972 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1973 : int[] = prim::ListConstruct(%1971, %1972), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1
  %1974 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1975 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1976 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1977 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1978 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.29 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.53, %1959, %1960, %1963, %1966, %1969, %1970, %1973, %1974, %1975, %1976, %1977, %1978), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %1980 : Tensor = prim::GetAttr[name="running_mean"](%1957)
  %1981 : Tensor = prim::GetAttr[name="running_var"](%1957)
  %1982 : Tensor = prim::GetAttr[name="bias"](%1957)
  %1983 : Tensor = prim::GetAttr[name="weight"](%1957)
  %1984 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1985 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1986 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1987 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1988 : int[] = prim::ListConstruct(%1984, %1985, %1986, %1987), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1
  %w.29 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1983, %1988), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %1990 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1991 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1992 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1993 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1994 : int[] = prim::ListConstruct(%1990, %1991, %1992, %1993), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1
  %b.29 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1982, %1994), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %1996 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1997 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1998 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %1999 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2000 : int[] = prim::ListConstruct(%1996, %1997, %1998, %1999), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1
  %rv.29 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1981, %2000), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2002 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2003 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2004 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2005 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2006 : int[] = prim::ListConstruct(%2002, %2003, %2004, %2005), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1
  %rm.29 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%1980, %2006), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2008 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2009 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2010 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.29, %2008, %2009), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2011 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2010), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.29 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.29, %2011), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2013 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.29, %scale.29), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2014 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.29 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.29, %2013, %2014), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2016 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.29, %scale.29), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %2017 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.54 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2016, %bias.29, %2017), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.55 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.54), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2020 : Tensor = prim::GetAttr[name="weight"](%1955)
  %2021 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2
  %2022 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2023 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2024 : int[] = prim::ListConstruct(%2022, %2023), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2
  %2025 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2026 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2027 : int[] = prim::ListConstruct(%2025, %2026), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2
  %2028 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2029 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2030 : int[] = prim::ListConstruct(%2028, %2029), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2
  %2031 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2032 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2033 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2034 : int[] = prim::ListConstruct(%2032, %2033), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2
  %2035 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2036 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2037 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2038 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2039 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.30 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.55, %2020, %2021, %2024, %2027, %2030, %2031, %2034, %2035, %2036, %2037, %2038, %2039), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2041 : Tensor = prim::GetAttr[name="running_mean"](%1954)
  %2042 : Tensor = prim::GetAttr[name="running_var"](%1954)
  %2043 : Tensor = prim::GetAttr[name="bias"](%1954)
  %2044 : Tensor = prim::GetAttr[name="weight"](%1954)
  %2045 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2046 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2047 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2048 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2049 : int[] = prim::ListConstruct(%2045, %2046, %2047, %2048), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2
  %w.30 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2044, %2049), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2051 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2052 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2053 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2054 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2055 : int[] = prim::ListConstruct(%2051, %2052, %2053, %2054), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2
  %b.30 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2043, %2055), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2057 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2058 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2059 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2060 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2061 : int[] = prim::ListConstruct(%2057, %2058, %2059, %2060), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2
  %rv.30 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2042, %2061), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2063 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2064 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2065 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2066 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2067 : int[] = prim::ListConstruct(%2063, %2064, %2065, %2066), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2
  %rm.30 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2041, %2067), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2069 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2070 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2071 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.30, %2069, %2070), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2072 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2071), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.30 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.30, %2072), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2074 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.30, %scale.30), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2075 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.30 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.30, %2074, %2075), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2077 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.30, %scale.30), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %2078 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.56 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2077, %bias.30, %2078), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.57 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.56), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2081 : Tensor = prim::GetAttr[name="weight"](%1953)
  %2082 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3
  %2083 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2084 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2085 : int[] = prim::ListConstruct(%2083, %2084), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3
  %2086 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2087 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2088 : int[] = prim::ListConstruct(%2086, %2087), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3
  %2089 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2090 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2091 : int[] = prim::ListConstruct(%2089, %2090), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3
  %2092 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2093 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2094 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2095 : int[] = prim::ListConstruct(%2093, %2094), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3
  %2096 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2097 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2098 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2099 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2100 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.31 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.57, %2081, %2082, %2085, %2088, %2091, %2092, %2095, %2096, %2097, %2098, %2099, %2100), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2102 : Tensor = prim::GetAttr[name="running_mean"](%1952)
  %2103 : Tensor = prim::GetAttr[name="running_var"](%1952)
  %2104 : Tensor = prim::GetAttr[name="bias"](%1952)
  %2105 : Tensor = prim::GetAttr[name="weight"](%1952)
  %2106 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2107 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2108 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2109 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2110 : int[] = prim::ListConstruct(%2106, %2107, %2108, %2109), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3
  %w.31 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2105, %2110), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2112 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2113 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2114 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2115 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2116 : int[] = prim::ListConstruct(%2112, %2113, %2114, %2115), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3
  %b.31 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2104, %2116), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2118 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2119 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2120 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2121 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2122 : int[] = prim::ListConstruct(%2118, %2119, %2120, %2121), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3
  %rv.31 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2103, %2122), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2124 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2125 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2126 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2127 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2128 : int[] = prim::ListConstruct(%2124, %2125, %2126, %2127), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3
  %rm.31 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2102, %2128), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2130 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2131 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2132 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.31, %2130, %2131), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2133 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2132), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.31 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.31, %2133), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2135 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.31, %scale.31), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2136 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.31 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.31, %2135, %2136), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2138 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.31, %scale.31), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2139 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.9 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2138, %bias.31, %2139), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2141 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.58 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add_(%out.9, %input.53, %2141), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.59 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.58), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.1/__module.model.backbone.0.body.layer3.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2144 : __torch__.models.backbone.___torch_mangle_231.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%1694)
  %2145 : __torch__.torch.nn.modules.conv.___torch_mangle_230.Conv2d = prim::GetAttr[name="conv3"](%1694)
  %2146 : __torch__.models.backbone.___torch_mangle_229.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%1694)
  %2147 : __torch__.torch.nn.modules.conv.___torch_mangle_228.Conv2d = prim::GetAttr[name="conv2"](%1694)
  %2148 : __torch__.torch.nn.modules.activation.___torch_mangle_232.ReLU = prim::GetAttr[name="relu"](%1694)
  %2149 : __torch__.models.backbone.___torch_mangle_227.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%1694)
  %2150 : __torch__.torch.nn.modules.conv.___torch_mangle_226.Conv2d = prim::GetAttr[name="conv1"](%1694)
  %2151 : Tensor = prim::GetAttr[name="weight"](%2150)
  %2152 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1
  %2153 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2154 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2155 : int[] = prim::ListConstruct(%2153, %2154), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1
  %2156 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2157 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2158 : int[] = prim::ListConstruct(%2156, %2157), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1
  %2159 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2160 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2161 : int[] = prim::ListConstruct(%2159, %2160), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1
  %2162 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2163 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2164 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2165 : int[] = prim::ListConstruct(%2163, %2164), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1
  %2166 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2167 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2168 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2169 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2170 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.32 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.59, %2151, %2152, %2155, %2158, %2161, %2162, %2165, %2166, %2167, %2168, %2169, %2170), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2172 : Tensor = prim::GetAttr[name="running_mean"](%2149)
  %2173 : Tensor = prim::GetAttr[name="running_var"](%2149)
  %2174 : Tensor = prim::GetAttr[name="bias"](%2149)
  %2175 : Tensor = prim::GetAttr[name="weight"](%2149)
  %2176 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2177 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2178 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2179 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2180 : int[] = prim::ListConstruct(%2176, %2177, %2178, %2179), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1
  %w.32 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2175, %2180), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2182 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2183 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2184 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2185 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2186 : int[] = prim::ListConstruct(%2182, %2183, %2184, %2185), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1
  %b.32 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2174, %2186), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2188 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2189 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2190 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2191 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2192 : int[] = prim::ListConstruct(%2188, %2189, %2190, %2191), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1
  %rv.32 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2173, %2192), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2194 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2195 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2196 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2197 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2198 : int[] = prim::ListConstruct(%2194, %2195, %2196, %2197), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1
  %rm.32 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2172, %2198), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2200 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2201 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2202 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.32, %2200, %2201), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2203 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2202), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.32 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.32, %2203), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2205 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.32, %scale.32), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2206 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.32 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.32, %2205, %2206), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2208 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.32, %scale.32), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %2209 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.60 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2208, %bias.32, %2209), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.61 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.60), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2212 : Tensor = prim::GetAttr[name="weight"](%2147)
  %2213 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2
  %2214 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2215 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2216 : int[] = prim::ListConstruct(%2214, %2215), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2
  %2217 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2218 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2219 : int[] = prim::ListConstruct(%2217, %2218), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2
  %2220 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2221 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2222 : int[] = prim::ListConstruct(%2220, %2221), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2
  %2223 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2224 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2225 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2226 : int[] = prim::ListConstruct(%2224, %2225), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2
  %2227 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2228 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2229 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2230 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2231 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.33 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.61, %2212, %2213, %2216, %2219, %2222, %2223, %2226, %2227, %2228, %2229, %2230, %2231), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2233 : Tensor = prim::GetAttr[name="running_mean"](%2146)
  %2234 : Tensor = prim::GetAttr[name="running_var"](%2146)
  %2235 : Tensor = prim::GetAttr[name="bias"](%2146)
  %2236 : Tensor = prim::GetAttr[name="weight"](%2146)
  %2237 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2238 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2239 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2240 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2241 : int[] = prim::ListConstruct(%2237, %2238, %2239, %2240), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2
  %w.33 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2236, %2241), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2243 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2244 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2245 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2246 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2247 : int[] = prim::ListConstruct(%2243, %2244, %2245, %2246), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2
  %b.33 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2235, %2247), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2249 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2250 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2251 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2252 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2253 : int[] = prim::ListConstruct(%2249, %2250, %2251, %2252), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2
  %rv.33 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2234, %2253), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2255 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2256 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2258 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2259 : int[] = prim::ListConstruct(%2255, %2256, %2257, %2258), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2
  %rm.33 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2233, %2259), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2261 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2262 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2263 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.33, %2261, %2262), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2264 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2263), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.33 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.33, %2264), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2266 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.33, %scale.33), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2267 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.33 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.33, %2266, %2267), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2269 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.33, %scale.33), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %2270 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.62 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2269, %bias.33, %2270), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.63 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.62), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2273 : Tensor = prim::GetAttr[name="weight"](%2145)
  %2274 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3
  %2275 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2276 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2277 : int[] = prim::ListConstruct(%2275, %2276), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3
  %2278 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2279 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2280 : int[] = prim::ListConstruct(%2278, %2279), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3
  %2281 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2282 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2283 : int[] = prim::ListConstruct(%2281, %2282), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3
  %2284 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2285 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2286 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2287 : int[] = prim::ListConstruct(%2285, %2286), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3
  %2288 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2289 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2290 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2291 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2292 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.34 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.63, %2273, %2274, %2277, %2280, %2283, %2284, %2287, %2288, %2289, %2290, %2291, %2292), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2294 : Tensor = prim::GetAttr[name="running_mean"](%2144)
  %2295 : Tensor = prim::GetAttr[name="running_var"](%2144)
  %2296 : Tensor = prim::GetAttr[name="bias"](%2144)
  %2297 : Tensor = prim::GetAttr[name="weight"](%2144)
  %2298 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2299 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2300 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2301 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2302 : int[] = prim::ListConstruct(%2298, %2299, %2300, %2301), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3
  %w.34 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2297, %2302), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2304 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2305 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2306 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2307 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2308 : int[] = prim::ListConstruct(%2304, %2305, %2306, %2307), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3
  %b.34 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2296, %2308), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2310 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2311 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2312 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2313 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2314 : int[] = prim::ListConstruct(%2310, %2311, %2312, %2313), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3
  %rv.34 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2295, %2314), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2316 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2317 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2318 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2319 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2320 : int[] = prim::ListConstruct(%2316, %2317, %2318, %2319), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3
  %rm.34 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2294, %2320), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2322 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2323 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2324 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.34, %2322, %2323), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2325 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2324), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.34 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.34, %2325), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2327 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.34, %scale.34), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2328 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.34 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.34, %2327, %2328), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2330 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.34, %scale.34), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2331 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.10 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2330, %bias.34, %2331), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2333 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.64 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add_(%out.10, %input.59, %2333), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.65 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.64), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.2/__module.model.backbone.0.body.layer3.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2336 : __torch__.models.backbone.___torch_mangle_239.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%1693)
  %2337 : __torch__.torch.nn.modules.conv.___torch_mangle_238.Conv2d = prim::GetAttr[name="conv3"](%1693)
  %2338 : __torch__.models.backbone.___torch_mangle_237.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%1693)
  %2339 : __torch__.torch.nn.modules.conv.___torch_mangle_236.Conv2d = prim::GetAttr[name="conv2"](%1693)
  %2340 : __torch__.torch.nn.modules.activation.___torch_mangle_240.ReLU = prim::GetAttr[name="relu"](%1693)
  %2341 : __torch__.models.backbone.___torch_mangle_235.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%1693)
  %2342 : __torch__.torch.nn.modules.conv.___torch_mangle_234.Conv2d = prim::GetAttr[name="conv1"](%1693)
  %2343 : Tensor = prim::GetAttr[name="weight"](%2342)
  %2344 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1
  %2345 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2346 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2347 : int[] = prim::ListConstruct(%2345, %2346), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1
  %2348 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2349 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2350 : int[] = prim::ListConstruct(%2348, %2349), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1
  %2351 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2352 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2353 : int[] = prim::ListConstruct(%2351, %2352), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1
  %2354 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2355 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2356 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2357 : int[] = prim::ListConstruct(%2355, %2356), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1
  %2358 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2359 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2360 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2361 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2362 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.35 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.65, %2343, %2344, %2347, %2350, %2353, %2354, %2357, %2358, %2359, %2360, %2361, %2362), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2364 : Tensor = prim::GetAttr[name="running_mean"](%2341)
  %2365 : Tensor = prim::GetAttr[name="running_var"](%2341)
  %2366 : Tensor = prim::GetAttr[name="bias"](%2341)
  %2367 : Tensor = prim::GetAttr[name="weight"](%2341)
  %2368 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2369 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2370 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2371 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2372 : int[] = prim::ListConstruct(%2368, %2369, %2370, %2371), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1
  %w.35 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2367, %2372), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2374 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2375 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2376 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2377 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2378 : int[] = prim::ListConstruct(%2374, %2375, %2376, %2377), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1
  %b.35 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2366, %2378), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2380 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2381 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2382 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2383 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2384 : int[] = prim::ListConstruct(%2380, %2381, %2382, %2383), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1
  %rv.35 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2365, %2384), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2386 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2387 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2388 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2389 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2390 : int[] = prim::ListConstruct(%2386, %2387, %2388, %2389), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1
  %rm.35 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2364, %2390), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2392 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2393 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2394 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.35, %2392, %2393), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2395 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2394), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.35 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.35, %2395), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2397 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.35, %scale.35), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2398 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.35 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.35, %2397, %2398), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2400 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.35, %scale.35), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:55:0
  %2401 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.66 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2400, %bias.35, %2401), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.67 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.66), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2404 : Tensor = prim::GetAttr[name="weight"](%2339)
  %2405 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2
  %2406 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2407 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2408 : int[] = prim::ListConstruct(%2406, %2407), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2
  %2409 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2410 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2411 : int[] = prim::ListConstruct(%2409, %2410), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2
  %2412 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2413 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2414 : int[] = prim::ListConstruct(%2412, %2413), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2
  %2415 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2416 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2417 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2418 : int[] = prim::ListConstruct(%2416, %2417), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2
  %2419 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2420 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2421 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2422 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2423 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.36 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.67, %2404, %2405, %2408, %2411, %2414, %2415, %2418, %2419, %2420, %2421, %2422, %2423), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2425 : Tensor = prim::GetAttr[name="running_mean"](%2338)
  %2426 : Tensor = prim::GetAttr[name="running_var"](%2338)
  %2427 : Tensor = prim::GetAttr[name="bias"](%2338)
  %2428 : Tensor = prim::GetAttr[name="weight"](%2338)
  %2429 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2430 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2431 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2432 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2433 : int[] = prim::ListConstruct(%2429, %2430, %2431, %2432), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2
  %w.36 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2428, %2433), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2435 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2436 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2437 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2438 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2439 : int[] = prim::ListConstruct(%2435, %2436, %2437, %2438), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2
  %b.36 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2427, %2439), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2441 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2442 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2443 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2444 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2445 : int[] = prim::ListConstruct(%2441, %2442, %2443, %2444), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2
  %rv.36 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2426, %2445), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2447 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2448 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2449 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2450 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2451 : int[] = prim::ListConstruct(%2447, %2448, %2449, %2450), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2
  %rm.36 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2425, %2451), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2453 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2454 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2455 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.36, %2453, %2454), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2456 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2455), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.36 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.36, %2456), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2458 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.36, %scale.36), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2459 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.36 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.36, %2458, %2459), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2461 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.36, %scale.36), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:55:0
  %2462 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.68 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2461, %bias.36, %2462), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.69 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.68), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2465 : Tensor = prim::GetAttr[name="weight"](%2337)
  %2466 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3
  %2467 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2468 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2469 : int[] = prim::ListConstruct(%2467, %2468), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3
  %2470 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2471 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2472 : int[] = prim::ListConstruct(%2470, %2471), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3
  %2473 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2474 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2475 : int[] = prim::ListConstruct(%2473, %2474), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3
  %2476 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2477 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2478 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2479 : int[] = prim::ListConstruct(%2477, %2478), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3
  %2480 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2481 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2482 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2483 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2484 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.37 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.69, %2465, %2466, %2469, %2472, %2475, %2476, %2479, %2480, %2481, %2482, %2483, %2484), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2486 : Tensor = prim::GetAttr[name="running_mean"](%2336)
  %2487 : Tensor = prim::GetAttr[name="running_var"](%2336)
  %2488 : Tensor = prim::GetAttr[name="bias"](%2336)
  %2489 : Tensor = prim::GetAttr[name="weight"](%2336)
  %2490 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2491 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2492 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2493 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2494 : int[] = prim::ListConstruct(%2490, %2491, %2492, %2493), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3
  %w.37 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2489, %2494), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2496 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2497 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2498 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2499 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2500 : int[] = prim::ListConstruct(%2496, %2497, %2498, %2499), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3
  %b.37 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2488, %2500), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2502 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2503 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2504 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2505 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2506 : int[] = prim::ListConstruct(%2502, %2503, %2504, %2505), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3
  %rv.37 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2487, %2506), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2508 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2509 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2510 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2511 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2512 : int[] = prim::ListConstruct(%2508, %2509, %2510, %2511), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3
  %rm.37 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2486, %2512), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2514 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2515 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2516 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.37, %2514, %2515), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2517 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2516), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.37 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.37, %2517), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2519 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.37, %scale.37), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2520 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.37 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.37, %2519, %2520), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2522 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.37, %scale.37), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2523 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.11 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2522, %bias.37, %2523), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2525 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.70 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add_(%out.11, %input.65, %2525), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.71 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.70), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.3/__module.model.backbone.0.body.layer3.3.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2528 : __torch__.models.backbone.___torch_mangle_247.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%1692)
  %2529 : __torch__.torch.nn.modules.conv.___torch_mangle_246.Conv2d = prim::GetAttr[name="conv3"](%1692)
  %2530 : __torch__.models.backbone.___torch_mangle_245.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%1692)
  %2531 : __torch__.torch.nn.modules.conv.___torch_mangle_244.Conv2d = prim::GetAttr[name="conv2"](%1692)
  %2532 : __torch__.torch.nn.modules.activation.___torch_mangle_248.ReLU = prim::GetAttr[name="relu"](%1692)
  %2533 : __torch__.models.backbone.___torch_mangle_243.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%1692)
  %2534 : __torch__.torch.nn.modules.conv.___torch_mangle_242.Conv2d = prim::GetAttr[name="conv1"](%1692)
  %2535 : Tensor = prim::GetAttr[name="weight"](%2534)
  %2536 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1
  %2537 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2538 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2539 : int[] = prim::ListConstruct(%2537, %2538), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1
  %2540 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2541 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2542 : int[] = prim::ListConstruct(%2540, %2541), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1
  %2543 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2544 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2545 : int[] = prim::ListConstruct(%2543, %2544), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1
  %2546 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2547 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2548 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2549 : int[] = prim::ListConstruct(%2547, %2548), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1
  %2550 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2551 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2552 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2553 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2554 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.38 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.71, %2535, %2536, %2539, %2542, %2545, %2546, %2549, %2550, %2551, %2552, %2553, %2554), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2556 : Tensor = prim::GetAttr[name="running_mean"](%2533)
  %2557 : Tensor = prim::GetAttr[name="running_var"](%2533)
  %2558 : Tensor = prim::GetAttr[name="bias"](%2533)
  %2559 : Tensor = prim::GetAttr[name="weight"](%2533)
  %2560 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2561 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2562 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2563 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2564 : int[] = prim::ListConstruct(%2560, %2561, %2562, %2563), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1
  %w.38 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2559, %2564), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2566 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2567 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2568 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2569 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2570 : int[] = prim::ListConstruct(%2566, %2567, %2568, %2569), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1
  %b.38 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2558, %2570), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2572 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2573 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2574 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2575 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2576 : int[] = prim::ListConstruct(%2572, %2573, %2574, %2575), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1
  %rv.38 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2557, %2576), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2578 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2579 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2580 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2581 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2582 : int[] = prim::ListConstruct(%2578, %2579, %2580, %2581), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1
  %rm.38 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2556, %2582), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2584 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2585 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2586 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.38, %2584, %2585), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2587 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2586), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.38 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.38, %2587), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2589 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.38, %scale.38), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2590 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.38 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.38, %2589, %2590), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2592 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.38, %scale.38), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:55:0
  %2593 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.72 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2592, %bias.38, %2593), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.73 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.72), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2596 : Tensor = prim::GetAttr[name="weight"](%2531)
  %2597 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2
  %2598 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2599 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2600 : int[] = prim::ListConstruct(%2598, %2599), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2
  %2601 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2602 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2603 : int[] = prim::ListConstruct(%2601, %2602), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2
  %2604 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2605 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2606 : int[] = prim::ListConstruct(%2604, %2605), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2
  %2607 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2608 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2609 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2610 : int[] = prim::ListConstruct(%2608, %2609), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2
  %2611 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2612 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2613 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2614 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2615 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.39 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.73, %2596, %2597, %2600, %2603, %2606, %2607, %2610, %2611, %2612, %2613, %2614, %2615), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2617 : Tensor = prim::GetAttr[name="running_mean"](%2530)
  %2618 : Tensor = prim::GetAttr[name="running_var"](%2530)
  %2619 : Tensor = prim::GetAttr[name="bias"](%2530)
  %2620 : Tensor = prim::GetAttr[name="weight"](%2530)
  %2621 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2622 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2623 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2624 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2625 : int[] = prim::ListConstruct(%2621, %2622, %2623, %2624), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2
  %w.39 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2620, %2625), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2627 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2628 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2629 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2630 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2631 : int[] = prim::ListConstruct(%2627, %2628, %2629, %2630), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2
  %b.39 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2619, %2631), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2633 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2634 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2635 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2636 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2637 : int[] = prim::ListConstruct(%2633, %2634, %2635, %2636), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2
  %rv.39 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2618, %2637), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2639 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2640 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2641 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2642 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2643 : int[] = prim::ListConstruct(%2639, %2640, %2641, %2642), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2
  %rm.39 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2617, %2643), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2645 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2646 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2647 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.39, %2645, %2646), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2648 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2647), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.39 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.39, %2648), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2650 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.39, %scale.39), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2651 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.39 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.39, %2650, %2651), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2653 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.39, %scale.39), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:55:0
  %2654 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.74 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2653, %bias.39, %2654), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.75 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.74), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2657 : Tensor = prim::GetAttr[name="weight"](%2529)
  %2658 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3
  %2659 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2660 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2661 : int[] = prim::ListConstruct(%2659, %2660), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3
  %2662 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2663 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2664 : int[] = prim::ListConstruct(%2662, %2663), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3
  %2665 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2666 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2667 : int[] = prim::ListConstruct(%2665, %2666), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3
  %2668 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2669 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2670 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2671 : int[] = prim::ListConstruct(%2669, %2670), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3
  %2672 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2673 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2674 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2675 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2676 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.40 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.75, %2657, %2658, %2661, %2664, %2667, %2668, %2671, %2672, %2673, %2674, %2675, %2676), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2678 : Tensor = prim::GetAttr[name="running_mean"](%2528)
  %2679 : Tensor = prim::GetAttr[name="running_var"](%2528)
  %2680 : Tensor = prim::GetAttr[name="bias"](%2528)
  %2681 : Tensor = prim::GetAttr[name="weight"](%2528)
  %2682 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2683 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2684 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2685 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2686 : int[] = prim::ListConstruct(%2682, %2683, %2684, %2685), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3
  %w.40 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2681, %2686), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2688 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2689 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2690 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2691 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2692 : int[] = prim::ListConstruct(%2688, %2689, %2690, %2691), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3
  %b.40 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2680, %2692), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2694 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2695 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2696 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2697 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2698 : int[] = prim::ListConstruct(%2694, %2695, %2696, %2697), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3
  %rv.40 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2679, %2698), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2700 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2701 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2702 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2703 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2704 : int[] = prim::ListConstruct(%2700, %2701, %2702, %2703), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3
  %rm.40 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2678, %2704), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2706 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2707 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2708 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.40, %2706, %2707), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2709 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2708), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.40 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.40, %2709), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2711 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.40, %scale.40), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2712 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.40 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.40, %2711, %2712), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2714 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.40, %scale.40), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2715 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.12 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2714, %bias.40, %2715), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2717 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.76 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add_(%out.12, %input.71, %2717), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.77 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.76), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.4/__module.model.backbone.0.body.layer3.4.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2720 : __torch__.models.backbone.___torch_mangle_255.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%1691)
  %2721 : __torch__.torch.nn.modules.conv.___torch_mangle_254.Conv2d = prim::GetAttr[name="conv3"](%1691)
  %2722 : __torch__.models.backbone.___torch_mangle_253.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%1691)
  %2723 : __torch__.torch.nn.modules.conv.___torch_mangle_252.Conv2d = prim::GetAttr[name="conv2"](%1691)
  %2724 : __torch__.torch.nn.modules.activation.___torch_mangle_256.ReLU = prim::GetAttr[name="relu"](%1691)
  %2725 : __torch__.models.backbone.___torch_mangle_251.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%1691)
  %2726 : __torch__.torch.nn.modules.conv.___torch_mangle_250.Conv2d = prim::GetAttr[name="conv1"](%1691)
  %2727 : Tensor = prim::GetAttr[name="weight"](%2726)
  %2728 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1
  %2729 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2730 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2731 : int[] = prim::ListConstruct(%2729, %2730), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1
  %2732 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2733 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2734 : int[] = prim::ListConstruct(%2732, %2733), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1
  %2735 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2736 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2737 : int[] = prim::ListConstruct(%2735, %2736), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1
  %2738 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2739 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2740 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2741 : int[] = prim::ListConstruct(%2739, %2740), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1
  %2742 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2743 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2744 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2745 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2746 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.41 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.77, %2727, %2728, %2731, %2734, %2737, %2738, %2741, %2742, %2743, %2744, %2745, %2746), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2748 : Tensor = prim::GetAttr[name="running_mean"](%2725)
  %2749 : Tensor = prim::GetAttr[name="running_var"](%2725)
  %2750 : Tensor = prim::GetAttr[name="bias"](%2725)
  %2751 : Tensor = prim::GetAttr[name="weight"](%2725)
  %2752 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2753 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2754 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2755 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2756 : int[] = prim::ListConstruct(%2752, %2753, %2754, %2755), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1
  %w.41 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2751, %2756), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2758 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2759 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2760 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2761 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2762 : int[] = prim::ListConstruct(%2758, %2759, %2760, %2761), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1
  %b.41 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2750, %2762), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2764 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2765 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2766 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2767 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2768 : int[] = prim::ListConstruct(%2764, %2765, %2766, %2767), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1
  %rv.41 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2749, %2768), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2770 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2771 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2772 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2773 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2774 : int[] = prim::ListConstruct(%2770, %2771, %2772, %2773), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1
  %rm.41 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2748, %2774), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2776 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2777 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2778 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.41, %2776, %2777), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2779 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2778), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.41 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.41, %2779), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2781 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.41, %scale.41), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2782 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.41 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.41, %2781, %2782), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2784 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.41, %scale.41), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:55:0
  %2785 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.78 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2784, %bias.41, %2785), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.79 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.78), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2788 : Tensor = prim::GetAttr[name="weight"](%2723)
  %2789 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2
  %2790 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2791 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2792 : int[] = prim::ListConstruct(%2790, %2791), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2
  %2793 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2794 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2795 : int[] = prim::ListConstruct(%2793, %2794), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2
  %2796 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2797 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2798 : int[] = prim::ListConstruct(%2796, %2797), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2
  %2799 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2800 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2801 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2802 : int[] = prim::ListConstruct(%2800, %2801), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2
  %2803 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2804 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2805 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2806 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2807 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.42 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.79, %2788, %2789, %2792, %2795, %2798, %2799, %2802, %2803, %2804, %2805, %2806, %2807), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2809 : Tensor = prim::GetAttr[name="running_mean"](%2722)
  %2810 : Tensor = prim::GetAttr[name="running_var"](%2722)
  %2811 : Tensor = prim::GetAttr[name="bias"](%2722)
  %2812 : Tensor = prim::GetAttr[name="weight"](%2722)
  %2813 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2814 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2815 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2816 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2817 : int[] = prim::ListConstruct(%2813, %2814, %2815, %2816), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2
  %w.42 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2812, %2817), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:48:0
  %2819 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2820 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2821 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2822 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2823 : int[] = prim::ListConstruct(%2819, %2820, %2821, %2822), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2
  %b.42 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2811, %2823), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:49:0
  %2825 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2826 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2827 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2828 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2829 : int[] = prim::ListConstruct(%2825, %2826, %2827, %2828), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2
  %rv.42 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2810, %2829), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:50:0
  %2831 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2832 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2833 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2834 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2835 : int[] = prim::ListConstruct(%2831, %2832, %2833, %2834), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2
  %rm.42 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2809, %2835), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:51:0
  %2837 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2838 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2839 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.42, %2837, %2838), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2840 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2839), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.42 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.42, %2840), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:53:0
  %2842 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.42, %scale.42), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2843 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.42 : Float(1:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.42, %2842, %2843), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:54:0
  %2845 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.42, %scale.42), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:55:0
  %2846 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.80 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2845, %bias.42, %2846), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.81 : Float(1:601600, 256:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.80), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2849 : Tensor = prim::GetAttr[name="weight"](%2721)
  %2850 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3
  %2851 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2852 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2853 : int[] = prim::ListConstruct(%2851, %2852), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3
  %2854 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2855 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2856 : int[] = prim::ListConstruct(%2854, %2855), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3
  %2857 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2858 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2859 : int[] = prim::ListConstruct(%2857, %2858), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3
  %2860 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2861 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2862 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2863 : int[] = prim::ListConstruct(%2861, %2862), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3
  %2864 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2865 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2866 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2867 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2868 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.43 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.81, %2849, %2850, %2853, %2856, %2859, %2860, %2863, %2864, %2865, %2866, %2867, %2868), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2870 : Tensor = prim::GetAttr[name="running_mean"](%2720)
  %2871 : Tensor = prim::GetAttr[name="running_var"](%2720)
  %2872 : Tensor = prim::GetAttr[name="bias"](%2720)
  %2873 : Tensor = prim::GetAttr[name="weight"](%2720)
  %2874 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2875 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2876 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2877 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2878 : int[] = prim::ListConstruct(%2874, %2875, %2876, %2877), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3
  %w.43 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2873, %2878), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:48:0
  %2880 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2881 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2882 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2883 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2884 : int[] = prim::ListConstruct(%2880, %2881, %2882, %2883), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3
  %b.43 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2872, %2884), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:49:0
  %2886 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2887 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2888 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2889 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2890 : int[] = prim::ListConstruct(%2886, %2887, %2888, %2889), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3
  %rv.43 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2871, %2890), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:50:0
  %2892 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2893 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2894 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2895 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2896 : int[] = prim::ListConstruct(%2892, %2893, %2894, %2895), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3
  %rm.43 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2870, %2896), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:51:0
  %2898 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2899 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2900 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.43, %2898, %2899), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2901 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2900), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.43 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.43, %2901), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:53:0
  %2903 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.43, %scale.43), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2904 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.43 : Float(1:1024, 1024:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.43, %2903, %2904), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:54:0
  %2906 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.43, %scale.43), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2907 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.13 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2906, %bias.43, %2907), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.bn3 # ../../ml/detr/models/backbone.py:55:0
  %2909 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.82 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add_(%out.13, %input.77, %2909), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.83 : Float(1:2406400, 1024:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.82), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer3/__module.model.backbone.0.body.layer3.5/__module.model.backbone.0.body.layer3.5.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2912 : __torch__.torchvision.models.resnet.___torch_mangle_285.Bottleneck = prim::GetAttr[name="2"](%131)
  %2913 : __torch__.torchvision.models.resnet.___torch_mangle_277.Bottleneck = prim::GetAttr[name="1"](%131)
  %2914 : __torch__.torchvision.models.resnet.___torch_mangle_269.Bottleneck = prim::GetAttr[name="0"](%131)
  %2915 : __torch__.torch.nn.modules.container.___torch_mangle_268.Sequential = prim::GetAttr[name="downsample"](%2914)
  %2916 : __torch__.models.backbone.___torch_mangle_264.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%2914)
  %2917 : __torch__.torch.nn.modules.conv.___torch_mangle_263.Conv2d = prim::GetAttr[name="conv3"](%2914)
  %2918 : __torch__.models.backbone.___torch_mangle_262.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%2914)
  %2919 : __torch__.torch.nn.modules.conv.___torch_mangle_261.Conv2d = prim::GetAttr[name="conv2"](%2914)
  %2920 : __torch__.torch.nn.modules.activation.___torch_mangle_265.ReLU = prim::GetAttr[name="relu"](%2914)
  %2921 : __torch__.models.backbone.___torch_mangle_260.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%2914)
  %2922 : __torch__.torch.nn.modules.conv.___torch_mangle_259.Conv2d = prim::GetAttr[name="conv1"](%2914)
  %2923 : Tensor = prim::GetAttr[name="weight"](%2922)
  %2924 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1
  %2925 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2926 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2927 : int[] = prim::ListConstruct(%2925, %2926), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1
  %2928 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2929 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2930 : int[] = prim::ListConstruct(%2928, %2929), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1
  %2931 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2932 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2933 : int[] = prim::ListConstruct(%2931, %2932), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1
  %2934 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2935 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2936 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2937 : int[] = prim::ListConstruct(%2935, %2936), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1
  %2938 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2939 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2940 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2941 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2942 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.44 : Float(1:1203200, 512:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::_convolution(%input.83, %2923, %2924, %2927, %2930, %2933, %2934, %2937, %2938, %2939, %2940, %2941, %2942), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2944 : Tensor = prim::GetAttr[name="running_mean"](%2921)
  %2945 : Tensor = prim::GetAttr[name="running_var"](%2921)
  %2946 : Tensor = prim::GetAttr[name="bias"](%2921)
  %2947 : Tensor = prim::GetAttr[name="weight"](%2921)
  %2948 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2949 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2950 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2951 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2952 : int[] = prim::ListConstruct(%2948, %2949, %2950, %2951), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1
  %w.44 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2947, %2952), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:48:0
  %2954 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2955 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2956 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2957 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2958 : int[] = prim::ListConstruct(%2954, %2955, %2956, %2957), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1
  %b.44 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2946, %2958), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:49:0
  %2960 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2961 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2962 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2963 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2964 : int[] = prim::ListConstruct(%2960, %2961, %2962, %2963), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1
  %rv.44 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2945, %2964), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:50:0
  %2966 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2967 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2968 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2969 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2970 : int[] = prim::ListConstruct(%2966, %2967, %2968, %2969), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1
  %rm.44 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%2944, %2970), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:51:0
  %2972 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2973 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2974 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.44, %2972, %2973), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2975 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%2974), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.44 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.44, %2975), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:53:0
  %2977 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.44, %scale.44), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2978 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.44 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.44, %2977, %2978), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:54:0
  %2980 : Float(1:1203200, 512:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::mul(%x.44, %scale.44), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %2981 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.84 : Float(1:1203200, 512:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::add(%2980, %bias.44, %2981), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.85 : Float(1:1203200, 512:2350, 47:50, 50:1, requires_grad=0, device=cpu) = aten::relu_(%input.84), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %2984 : Tensor = prim::GetAttr[name="weight"](%2919)
  %2985 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2
  %2986 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2987 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2988 : int[] = prim::ListConstruct(%2986, %2987), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2
  %2989 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2990 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2991 : int[] = prim::ListConstruct(%2989, %2990), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2
  %2992 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2993 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2994 : int[] = prim::ListConstruct(%2992, %2993), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2
  %2995 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2996 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2997 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %2998 : int[] = prim::ListConstruct(%2996, %2997), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2
  %2999 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3000 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3001 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3002 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3003 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.45 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.85, %2984, %2985, %2988, %2991, %2994, %2995, %2998, %2999, %3000, %3001, %3002, %3003), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3005 : Tensor = prim::GetAttr[name="running_mean"](%2918)
  %3006 : Tensor = prim::GetAttr[name="running_var"](%2918)
  %3007 : Tensor = prim::GetAttr[name="bias"](%2918)
  %3008 : Tensor = prim::GetAttr[name="weight"](%2918)
  %3009 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3010 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3011 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3012 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3013 : int[] = prim::ListConstruct(%3009, %3010, %3011, %3012), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2
  %w.45 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3008, %3013), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3015 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3016 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3017 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3018 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3019 : int[] = prim::ListConstruct(%3015, %3016, %3017, %3018), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2
  %b.45 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3007, %3019), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3021 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3022 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3023 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3024 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3025 : int[] = prim::ListConstruct(%3021, %3022, %3023, %3024), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2
  %rv.45 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3006, %3025), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3027 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3028 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3029 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3030 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3031 : int[] = prim::ListConstruct(%3027, %3028, %3029, %3030), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2
  %rm.45 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3005, %3031), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3033 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3034 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3035 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.45, %3033, %3034), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3036 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3035), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.45 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.45, %3036), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3038 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.45, %scale.45), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %3039 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.45 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.45, %3038, %3039), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:54:0
  %3041 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.45, %scale.45), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %3042 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.86 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3041, %bias.45, %3042), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.87 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.86), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3045 : Tensor = prim::GetAttr[name="weight"](%2917)
  %3046 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3
  %3047 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3048 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3049 : int[] = prim::ListConstruct(%3047, %3048), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3
  %3050 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3051 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3052 : int[] = prim::ListConstruct(%3050, %3051), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3
  %3053 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3054 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3055 : int[] = prim::ListConstruct(%3053, %3054), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3
  %3056 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3057 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3058 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3059 : int[] = prim::ListConstruct(%3057, %3058), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3
  %3060 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3061 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3062 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3063 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3064 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.46 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.87, %3045, %3046, %3049, %3052, %3055, %3056, %3059, %3060, %3061, %3062, %3063, %3064), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3066 : Tensor = prim::GetAttr[name="running_mean"](%2916)
  %3067 : Tensor = prim::GetAttr[name="running_var"](%2916)
  %3068 : Tensor = prim::GetAttr[name="bias"](%2916)
  %3069 : Tensor = prim::GetAttr[name="weight"](%2916)
  %3070 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3071 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3072 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3073 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3074 : int[] = prim::ListConstruct(%3070, %3071, %3072, %3073), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3
  %w.46 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3069, %3074), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3076 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3077 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3078 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3079 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3080 : int[] = prim::ListConstruct(%3076, %3077, %3078, %3079), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3
  %b.46 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3068, %3080), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3082 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3083 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3084 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3085 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3086 : int[] = prim::ListConstruct(%3082, %3083, %3084, %3085), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3
  %rv.46 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3067, %3086), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3088 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3089 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3090 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3091 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3092 : int[] = prim::ListConstruct(%3088, %3089, %3090, %3091), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3
  %rm.46 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3066, %3092), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3094 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3095 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3096 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.46, %3094, %3095), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3097 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3096), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.46 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.46, %3097), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3099 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.46, %scale.46), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %3100 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.46 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.46, %3099, %3100), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:54:0
  %3102 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.46, %scale.46), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %3103 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.14 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3102, %bias.46, %3103), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.bn3 # ../../ml/detr/models/backbone.py:55:0
  %3105 : __torch__.models.backbone.___torch_mangle_267.FrozenBatchNorm2d = prim::GetAttr[name="1"](%2915)
  %3106 : __torch__.torch.nn.modules.conv.___torch_mangle_266.Conv2d = prim::GetAttr[name="0"](%2915)
  %3107 : Tensor = prim::GetAttr[name="weight"](%3106)
  %3108 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0
  %3109 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3110 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3111 : int[] = prim::ListConstruct(%3109, %3110), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0
  %3112 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3113 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3114 : int[] = prim::ListConstruct(%3112, %3113), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0
  %3115 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3116 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3117 : int[] = prim::ListConstruct(%3115, %3116), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0
  %3118 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3119 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3120 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3121 : int[] = prim::ListConstruct(%3119, %3120), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0
  %3122 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3123 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3124 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3125 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3126 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.47 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.83, %3107, %3108, %3111, %3114, %3117, %3118, %3121, %3122, %3123, %3124, %3125, %3126), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3128 : Tensor = prim::GetAttr[name="running_mean"](%3105)
  %3129 : Tensor = prim::GetAttr[name="running_var"](%3105)
  %3130 : Tensor = prim::GetAttr[name="bias"](%3105)
  %3131 : Tensor = prim::GetAttr[name="weight"](%3105)
  %3132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %3133 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %3134 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %3135 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %3136 : int[] = prim::ListConstruct(%3132, %3133, %3134, %3135), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1
  %w.47 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3131, %3136), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:48:0
  %3138 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %3139 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %3140 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %3141 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %3142 : int[] = prim::ListConstruct(%3138, %3139, %3140, %3141), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1
  %b.47 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3130, %3142), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:49:0
  %3144 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %3145 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %3146 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %3147 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %3148 : int[] = prim::ListConstruct(%3144, %3145, %3146, %3147), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1
  %rv.47 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3129, %3148), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:50:0
  %3150 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %3151 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %3152 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %3153 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %3154 : int[] = prim::ListConstruct(%3150, %3151, %3152, %3153), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1
  %rm.47 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3128, %3154), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:51:0
  %3156 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %3157 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %3158 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.47, %3156, %3157), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %3159 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3158), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %scale.47 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.47, %3159), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:53:0
  %3161 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.47, %scale.47), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %3162 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %bias.47 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.47, %3161, %3162), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:54:0
  %3164 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.47, %scale.47), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %3165 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %identity : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3164, %bias.47, %3165), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.downsample/__module.model.backbone.0.body.layer4.0.downsample.1 # ../../ml/detr/models/backbone.py:55:0
  %3167 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.88 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add_(%out.14, %identity, %3167), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.89 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.88), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.0/__module.model.backbone.0.body.layer4.0.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3170 : __torch__.models.backbone.___torch_mangle_275.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%2913)
  %3171 : __torch__.torch.nn.modules.conv.___torch_mangle_274.Conv2d = prim::GetAttr[name="conv3"](%2913)
  %3172 : __torch__.models.backbone.___torch_mangle_273.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%2913)
  %3173 : __torch__.torch.nn.modules.conv.___torch_mangle_272.Conv2d = prim::GetAttr[name="conv2"](%2913)
  %3174 : __torch__.torch.nn.modules.activation.___torch_mangle_276.ReLU = prim::GetAttr[name="relu"](%2913)
  %3175 : __torch__.models.backbone.___torch_mangle_271.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%2913)
  %3176 : __torch__.torch.nn.modules.conv.___torch_mangle_270.Conv2d = prim::GetAttr[name="conv1"](%2913)
  %3177 : Tensor = prim::GetAttr[name="weight"](%3176)
  %3178 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1
  %3179 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3180 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3181 : int[] = prim::ListConstruct(%3179, %3180), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1
  %3182 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3183 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3184 : int[] = prim::ListConstruct(%3182, %3183), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1
  %3185 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3186 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3187 : int[] = prim::ListConstruct(%3185, %3186), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1
  %3188 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3189 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3190 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3191 : int[] = prim::ListConstruct(%3189, %3190), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1
  %3192 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3193 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3194 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3195 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3196 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.48 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.89, %3177, %3178, %3181, %3184, %3187, %3188, %3191, %3192, %3193, %3194, %3195, %3196), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3198 : Tensor = prim::GetAttr[name="running_mean"](%3175)
  %3199 : Tensor = prim::GetAttr[name="running_var"](%3175)
  %3200 : Tensor = prim::GetAttr[name="bias"](%3175)
  %3201 : Tensor = prim::GetAttr[name="weight"](%3175)
  %3202 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3203 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3204 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3205 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3206 : int[] = prim::ListConstruct(%3202, %3203, %3204, %3205), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1
  %w.48 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3201, %3206), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3208 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3209 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3210 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3211 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3212 : int[] = prim::ListConstruct(%3208, %3209, %3210, %3211), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1
  %b.48 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3200, %3212), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3214 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3215 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3216 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3217 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3218 : int[] = prim::ListConstruct(%3214, %3215, %3216, %3217), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1
  %rv.48 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3199, %3218), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3220 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3221 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3222 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3223 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3224 : int[] = prim::ListConstruct(%3220, %3221, %3222, %3223), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1
  %rm.48 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3198, %3224), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3226 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3227 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3228 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.48, %3226, %3227), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3229 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3228), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.48 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.48, %3229), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3231 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.48, %scale.48), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %3232 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.48 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.48, %3231, %3232), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:54:0
  %3234 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.48, %scale.48), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %3235 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.90 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3234, %bias.48, %3235), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.91 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.90), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3238 : Tensor = prim::GetAttr[name="weight"](%3173)
  %3239 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2
  %3240 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3241 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3242 : int[] = prim::ListConstruct(%3240, %3241), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2
  %3243 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3244 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3245 : int[] = prim::ListConstruct(%3243, %3244), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2
  %3246 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3248 : int[] = prim::ListConstruct(%3246, %3247), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2
  %3249 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3250 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3251 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3252 : int[] = prim::ListConstruct(%3250, %3251), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2
  %3253 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3254 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3255 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3256 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3257 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.49 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.91, %3238, %3239, %3242, %3245, %3248, %3249, %3252, %3253, %3254, %3255, %3256, %3257), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3259 : Tensor = prim::GetAttr[name="running_mean"](%3172)
  %3260 : Tensor = prim::GetAttr[name="running_var"](%3172)
  %3261 : Tensor = prim::GetAttr[name="bias"](%3172)
  %3262 : Tensor = prim::GetAttr[name="weight"](%3172)
  %3263 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3264 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3265 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3266 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3267 : int[] = prim::ListConstruct(%3263, %3264, %3265, %3266), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2
  %w.49 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3262, %3267), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3269 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3270 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3271 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3272 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3273 : int[] = prim::ListConstruct(%3269, %3270, %3271, %3272), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2
  %b.49 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3261, %3273), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3275 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3276 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3277 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3278 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3279 : int[] = prim::ListConstruct(%3275, %3276, %3277, %3278), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2
  %rv.49 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3260, %3279), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3281 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3282 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3284 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3285 : int[] = prim::ListConstruct(%3281, %3282, %3283, %3284), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2
  %rm.49 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3259, %3285), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3287 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3288 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3289 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.49, %3287, %3288), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3290 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3289), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.49 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.49, %3290), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3292 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.49, %scale.49), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %3293 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.49 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.49, %3292, %3293), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:54:0
  %3295 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.49, %scale.49), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %3296 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.92 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3295, %bias.49, %3296), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.93 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.92), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3299 : Tensor = prim::GetAttr[name="weight"](%3171)
  %3300 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3
  %3301 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3302 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3303 : int[] = prim::ListConstruct(%3301, %3302), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3
  %3304 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3305 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3306 : int[] = prim::ListConstruct(%3304, %3305), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3
  %3307 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3308 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3309 : int[] = prim::ListConstruct(%3307, %3308), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3
  %3310 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3311 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3312 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3313 : int[] = prim::ListConstruct(%3311, %3312), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3
  %3314 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3315 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3316 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3317 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3318 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.50 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.93, %3299, %3300, %3303, %3306, %3309, %3310, %3313, %3314, %3315, %3316, %3317, %3318), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3320 : Tensor = prim::GetAttr[name="running_mean"](%3170)
  %3321 : Tensor = prim::GetAttr[name="running_var"](%3170)
  %3322 : Tensor = prim::GetAttr[name="bias"](%3170)
  %3323 : Tensor = prim::GetAttr[name="weight"](%3170)
  %3324 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3325 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3326 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3327 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3328 : int[] = prim::ListConstruct(%3324, %3325, %3326, %3327), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3
  %w.50 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3323, %3328), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3330 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3331 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3332 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3333 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3334 : int[] = prim::ListConstruct(%3330, %3331, %3332, %3333), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3
  %b.50 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3322, %3334), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3336 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3337 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3338 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3339 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3340 : int[] = prim::ListConstruct(%3336, %3337, %3338, %3339), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3
  %rv.50 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3321, %3340), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3342 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3343 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3344 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3345 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3346 : int[] = prim::ListConstruct(%3342, %3343, %3344, %3345), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3
  %rm.50 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3320, %3346), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3348 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3349 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3350 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.50, %3348, %3349), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3351 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3350), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale.50 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.50, %3351), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3353 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.50, %scale.50), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %3354 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.50 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.50, %3353, %3354), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:54:0
  %3356 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.50, %scale.50), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %3357 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out.15 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3356, %bias.50, %3357), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.bn3 # ../../ml/detr/models/backbone.py:55:0
  %3359 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.94 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add_(%out.15, %input.89, %3359), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.95 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.94), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.1/__module.model.backbone.0.body.layer4.1.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3362 : __torch__.models.backbone.___torch_mangle_283.FrozenBatchNorm2d = prim::GetAttr[name="bn3"](%2912)
  %3363 : __torch__.torch.nn.modules.conv.___torch_mangle_282.Conv2d = prim::GetAttr[name="conv3"](%2912)
  %3364 : __torch__.models.backbone.___torch_mangle_281.FrozenBatchNorm2d = prim::GetAttr[name="bn2"](%2912)
  %3365 : __torch__.torch.nn.modules.conv.___torch_mangle_280.Conv2d = prim::GetAttr[name="conv2"](%2912)
  %3366 : __torch__.torch.nn.modules.activation.___torch_mangle_284.ReLU = prim::GetAttr[name="relu"](%2912)
  %3367 : __torch__.models.backbone.___torch_mangle_279.FrozenBatchNorm2d = prim::GetAttr[name="bn1"](%2912)
  %3368 : __torch__.torch.nn.modules.conv.___torch_mangle_278.Conv2d = prim::GetAttr[name="conv1"](%2912)
  %3369 : Tensor = prim::GetAttr[name="weight"](%3368)
  %3370 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1
  %3371 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3372 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3373 : int[] = prim::ListConstruct(%3371, %3372), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1
  %3374 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3375 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3376 : int[] = prim::ListConstruct(%3374, %3375), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1
  %3377 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3378 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3379 : int[] = prim::ListConstruct(%3377, %3378), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1
  %3380 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3381 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3382 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3383 : int[] = prim::ListConstruct(%3381, %3382), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1
  %3384 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3385 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3386 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3387 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3388 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.51 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.95, %3369, %3370, %3373, %3376, %3379, %3380, %3383, %3384, %3385, %3386, %3387, %3388), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3390 : Tensor = prim::GetAttr[name="running_mean"](%3367)
  %3391 : Tensor = prim::GetAttr[name="running_var"](%3367)
  %3392 : Tensor = prim::GetAttr[name="bias"](%3367)
  %3393 : Tensor = prim::GetAttr[name="weight"](%3367)
  %3394 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3395 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3396 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3397 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3398 : int[] = prim::ListConstruct(%3394, %3395, %3396, %3397), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1
  %w.51 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3393, %3398), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:48:0
  %3400 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3401 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3402 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3403 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3404 : int[] = prim::ListConstruct(%3400, %3401, %3402, %3403), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1
  %b.51 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3392, %3404), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:49:0
  %3406 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3407 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3408 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3409 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3410 : int[] = prim::ListConstruct(%3406, %3407, %3408, %3409), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1
  %rv.51 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3391, %3410), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:50:0
  %3412 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3413 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3414 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3415 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3416 : int[] = prim::ListConstruct(%3412, %3413, %3414, %3415), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1
  %rm.51 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3390, %3416), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:51:0
  %3418 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3419 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3420 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.51, %3418, %3419), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3421 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3420), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %scale.51 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.51, %3421), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:53:0
  %3423 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.51, %scale.51), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %3424 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %bias.51 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.51, %3423, %3424), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:54:0
  %3426 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.51, %scale.51), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %3427 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.96 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3426, %bias.51, %3427), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn1 # ../../ml/detr/models/backbone.py:55:0
  %input.97 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.96), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3430 : Tensor = prim::GetAttr[name="weight"](%3365)
  %3431 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2
  %3432 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3433 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3434 : int[] = prim::ListConstruct(%3432, %3433), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2
  %3435 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3436 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3437 : int[] = prim::ListConstruct(%3435, %3436), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2
  %3438 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3439 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3440 : int[] = prim::ListConstruct(%3438, %3439), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2
  %3441 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3442 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3443 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3444 : int[] = prim::ListConstruct(%3442, %3443), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2
  %3445 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3446 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3447 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3448 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3449 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.52 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.97, %3430, %3431, %3434, %3437, %3440, %3441, %3444, %3445, %3446, %3447, %3448, %3449), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3451 : Tensor = prim::GetAttr[name="running_mean"](%3364)
  %3452 : Tensor = prim::GetAttr[name="running_var"](%3364)
  %3453 : Tensor = prim::GetAttr[name="bias"](%3364)
  %3454 : Tensor = prim::GetAttr[name="weight"](%3364)
  %3455 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3456 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3457 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3458 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3459 : int[] = prim::ListConstruct(%3455, %3456, %3457, %3458), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2
  %w.52 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3454, %3459), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:48:0
  %3461 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3462 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3463 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3464 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3465 : int[] = prim::ListConstruct(%3461, %3462, %3463, %3464), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2
  %b.52 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3453, %3465), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:49:0
  %3467 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3468 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3469 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3470 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3471 : int[] = prim::ListConstruct(%3467, %3468, %3469, %3470), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2
  %rv.52 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3452, %3471), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:50:0
  %3473 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3474 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3475 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3476 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3477 : int[] = prim::ListConstruct(%3473, %3474, %3475, %3476), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2
  %rm.52 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3451, %3477), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:51:0
  %3479 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3480 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3481 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv.52, %3479, %3480), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3482 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3481), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %scale.52 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.52, %3482), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:53:0
  %3484 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm.52, %scale.52), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %3485 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %bias.52 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b.52, %3484, %3485), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:54:0
  %3487 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.52, %scale.52), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %3488 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.98 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3487, %bias.52, %3488), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn2 # ../../ml/detr/models/backbone.py:55:0
  %input.99 : Float(1:307200, 512:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.98), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3491 : Tensor = prim::GetAttr[name="weight"](%3363)
  %3492 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3
  %3493 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3494 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3495 : int[] = prim::ListConstruct(%3493, %3494), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3
  %3496 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3497 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3498 : int[] = prim::ListConstruct(%3496, %3497), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3
  %3499 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3500 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3501 : int[] = prim::ListConstruct(%3499, %3500), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3
  %3502 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3503 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3504 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3505 : int[] = prim::ListConstruct(%3503, %3504), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3
  %3506 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3507 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3508 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3509 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3510 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %x.53 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%input.99, %3491, %3492, %3495, %3498, %3501, %3502, %3505, %3506, %3507, %3508, %3509, %3510), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.conv3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3512 : Tensor = prim::GetAttr[name="running_mean"](%3362)
  %3513 : Tensor = prim::GetAttr[name="running_var"](%3362)
  %3514 : Tensor = prim::GetAttr[name="bias"](%3362)
  %3515 : Tensor = prim::GetAttr[name="weight"](%3362)
  %3516 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3517 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3518 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3519 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3520 : int[] = prim::ListConstruct(%3516, %3517, %3518, %3519), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3
  %w.53 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3515, %3520), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:48:0
  %3522 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3523 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3524 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3525 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3526 : int[] = prim::ListConstruct(%3522, %3523, %3524, %3525), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3
  %b : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3514, %3526), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:49:0
  %3528 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3529 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3530 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3531 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3532 : int[] = prim::ListConstruct(%3528, %3529, %3530, %3531), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3
  %rv : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3513, %3532), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:50:0
  %3534 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3535 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3536 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3537 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3538 : int[] = prim::ListConstruct(%3534, %3535, %3536, %3537), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3
  %rm : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::reshape(%3512, %3538), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:51:0
  %3540 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3541 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3542 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::add(%rv, %3540, %3541), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3543 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::rsqrt(%3542), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %scale : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%w.53, %3543), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:53:0
  %3545 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::mul(%rm, %scale), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %3546 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %bias.53 : Float(1:2048, 2048:1, 1:1, 1:1, requires_grad=0, device=cpu) = aten::sub(%b, %3545, %3546), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:54:0
  %3548 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%x.53, %scale), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %3549 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %out : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3548, %bias.53, %3549), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.bn3 # ../../ml/detr/models/backbone.py:55:0
  %3551 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %input.100 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::add_(%out, %input.95, %3551), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torchvision/models/resnet.py:118:0
  %x : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::relu_(%input.100), scope: __module.model/__module.model.backbone/__module.model.backbone.0/__module.model.backbone.0.body/__module.model.backbone.0.body.layer4/__module.model.backbone.0.body.layer4.2/__module.model.backbone.0.body.layer4.2.relu # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1134:0
  %3554 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3555 : Bool(1:600000, 1:600000, 750:800, 800:1, requires_grad=0, device=cpu) = aten::unsqueeze(%m, %3554), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3556 : int = prim::Constant[value=6](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3557 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3558 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3559 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %input.101 : Float(1:600000, 1:600000, 750:800, 800:1, requires_grad=0, device=cpu) = aten::to(%3555, %3556, %3557, %3558, %3559), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3561 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3562 : int = aten::size(%x, %3561), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3563 : Long(device=cpu) = prim::NumToTensor(%3562), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %3564 : int = aten::Int(%3563), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %3565 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3566 : int = aten::size(%x, %3565), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3567 : Long(device=cpu) = prim::NumToTensor(%3566), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %3568 : int = aten::Int(%3567), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %3569 : int[] = prim::ListConstruct(%3564, %3568), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %3570 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %3571 : Float(1:600, 1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::upsample_nearest2d(%input.101, %3569, %3570), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:3132:0
  %3572 : int = prim::Constant[value=11](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3573 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3574 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3575 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.0
  %3576 : Bool(1:600, 1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::to(%3571, %3572, %3573, %3574, %3575), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3577 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3578 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %mask : Bool(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::select(%3576, %3577, %3578), scope: __module.model/__module.model.backbone/__module.model.backbone.0 # ../../ml/detr/models/backbone.py:78:0
  %3580 : (Bool(1:600, 24:25, 25:1, requires_grad=0, device=cpu), Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu)) = prim::TupleConstruct(%mask, %x)
  %3581 : Bool(1:600, 24:25, 25:1, requires_grad=0, device=cpu), %3582 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu) = prim::TupleUnpack(%3580)
  %not_mask : Bool(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::bitwise_not(%3581), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:32:0
  %3584 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:33:0
  %3585 : int = prim::Constant[value=6](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:33:0
  %y_embed.1 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::cumsum(%not_mask, %3584, %3585), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:33:0
  %3587 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:34:0
  %3588 : int = prim::Constant[value=6](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:34:0
  %x_embed.1 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::cumsum(%not_mask, %3587, %3588), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:34:0
  %3590 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3591 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3592 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3593 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3594 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%y_embed.1, %3590, %3591, %3592, %3593), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3595 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3596 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3597 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3598 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3599 : Float(1:600, 1:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%3594, %3595, %3596, %3597, %3598), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3600 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3601 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3602 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3603 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3604 : Float(1:600, 1:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%3599, %3600, %3601, %3602, %3603), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3605 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3606 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3607 : Float(1:25, 1:25, 25:1, requires_grad=0, device=cpu) = aten::add(%3604, %3605, %3606), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3608 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::div(%y_embed.1, %3607), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3609 : Double(requires_grad=0, device=cpu) = prim::Constant[value={6.28319}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %y_embed : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%3608, %3609), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:37:0
  %3611 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3612 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3613 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3614 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3615 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%x_embed.1, %3611, %3612, %3613, %3614), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3616 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3617 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3618 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3619 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3620 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%3615, %3616, %3617, %3618, %3619), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3621 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3622 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3623 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3624 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3625 : Float(1:600, 24:25, 1:1, requires_grad=0, device=cpu) = aten::slice(%3620, %3621, %3622, %3623, %3624), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3626 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-06}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3627 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3628 : Float(1:24, 24:1, 1:1, requires_grad=0, device=cpu) = aten::add(%3625, %3626, %3627), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3629 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::div(%x_embed.1, %3628), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3630 : Double(requires_grad=0, device=cpu) = prim::Constant[value={6.28319}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %x_embed : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::mul(%3629, %3630), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:38:0
  %3632 : int = prim::Constant[value=128](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:40:0
  %3633 : int = prim::Constant[value=6](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:40:0
  %3634 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:40:0
  %3635 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:40:0
  %3636 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:40:0
  %3637 : Float(128:1, requires_grad=0, device=cpu) = aten::arange(%3632, %3633, %3634, %3635, %3636), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:40:0
  %3638 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %3639 : Float(128:1, requires_grad=0, device=cpu) = aten::floor_divide(%3637, %3638), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %3640 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:41:0
  %3641 : Float(128:1, requires_grad=0, device=cpu) = aten::mul(%3639, %3640), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:41:0
  %3642 : Long(requires_grad=0, device=cpu) = prim::Constant[value={128}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:41:0
  %3643 : Float(128:1, requires_grad=0, device=cpu) = aten::div(%3641, %3642), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:41:0
  %3644 : Float(requires_grad=0, device=cpu) = prim::Constant[value={10000}](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %3645 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %3646 : int = prim::Constant[value=6](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %3647 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %3648 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %3649 : None = prim::Constant(), scope: __module.model/__module.model.backbone/__module.model.backbone.1
  %3650 : Float(requires_grad=0, device=cpu) = aten::to(%3644, %3645, %3646, %3647, %3648, %3649), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %3651 : Float(requires_grad=0, device=cpu) = aten::detach(%3650), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %dim_t : Float(128:1, requires_grad=0, device=cpu) = aten::pow(%3651, %3643), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:547:0
  %3653 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3654 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3655 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3656 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3657 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%x_embed, %3653, %3654, %3655, %3656), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3658 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3659 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3660 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3661 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3662 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%3657, %3658, %3659, %3660, %3661), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3663 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3664 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3665 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3666 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3667 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%3662, %3663, %3664, %3665, %3666), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3668 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3669 : Float(1:600, 24:25, 25:1, 1:1, requires_grad=0, device=cpu) = aten::unsqueeze(%3667, %3668), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %pos_x.1 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::div(%3669, %dim_t), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:43:0
  %3671 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3672 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3673 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3674 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3675 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%y_embed, %3671, %3672, %3673, %3674), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3676 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3677 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3678 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3679 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3680 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%3675, %3676, %3677, %3678, %3679), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3681 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3682 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3683 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3684 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3685 : Float(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::slice(%3680, %3681, %3682, %3683, %3684), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3686 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3687 : Float(1:600, 24:25, 25:1, 1:1, requires_grad=0, device=cpu) = aten::unsqueeze(%3685, %3686), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %pos_y.1 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::div(%3687, %dim_t), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:44:0
  %3689 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3690 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3691 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3692 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3693 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%pos_x.1, %3689, %3690, %3691, %3692), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3694 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3695 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3696 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3697 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3698 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3693, %3694, %3695, %3696, %3697), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3699 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3700 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3701 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3702 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3703 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3698, %3699, %3700, %3701, %3702), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3704 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3705 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3706 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3707 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3708 : Float(1:76800, 24:3200, 25:128, 64:2, requires_grad=0, device=cpu) = aten::slice(%3703, %3704, %3705, %3706, %3707), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3709 : Float(1:38400, 24:1600, 25:64, 64:1, requires_grad=0, device=cpu) = aten::sin(%3708), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3710 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3711 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3712 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3713 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3714 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%pos_x.1, %3710, %3711, %3712, %3713), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3715 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3716 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3717 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3718 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3719 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3714, %3715, %3716, %3717, %3718), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3720 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3721 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3722 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3723 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3724 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3719, %3720, %3721, %3722, %3723), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3725 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3726 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3727 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3728 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3729 : Float(1:76800, 24:3200, 25:128, 64:2, requires_grad=0, device=cpu) = aten::slice(%3724, %3725, %3726, %3727, %3728), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3730 : Float(1:38400, 24:1600, 25:64, 64:1, requires_grad=0, device=cpu) = aten::cos(%3729), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3731 : Tensor[] = prim::ListConstruct(%3709, %3730), scope: __module.model/__module.model.backbone/__module.model.backbone.1
  %3732 : int = prim::Constant[value=4](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3733 : Float(1:76800, 24:3200, 25:128, 64:2, 2:1, requires_grad=0, device=cpu) = aten::stack(%3731, %3732), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3734 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3735 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %pos_x : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::flatten(%3733, %3734, %3735), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:45:0
  %3737 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3738 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3739 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3740 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3741 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%pos_y.1, %3737, %3738, %3739, %3740), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3742 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3743 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3744 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3745 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3746 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3741, %3742, %3743, %3744, %3745), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3747 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3748 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3749 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3750 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3751 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3746, %3747, %3748, %3749, %3750), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3752 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3753 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3754 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3755 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3756 : Float(1:76800, 24:3200, 25:128, 64:2, requires_grad=0, device=cpu) = aten::slice(%3751, %3752, %3753, %3754, %3755), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3757 : Float(1:38400, 24:1600, 25:64, 64:1, requires_grad=0, device=cpu) = aten::sin(%3756), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3758 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3759 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3760 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3761 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3762 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%pos_y.1, %3758, %3759, %3760, %3761), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3763 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3764 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3765 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3766 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3767 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3762, %3763, %3764, %3765, %3766), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3768 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3769 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3770 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3771 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3772 : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::slice(%3767, %3768, %3769, %3770, %3771), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3773 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3774 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3775 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3776 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3777 : Float(1:76800, 24:3200, 25:128, 64:2, requires_grad=0, device=cpu) = aten::slice(%3772, %3773, %3774, %3775, %3776), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3778 : Float(1:38400, 24:1600, 25:64, 64:1, requires_grad=0, device=cpu) = aten::cos(%3777), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3779 : Tensor[] = prim::ListConstruct(%3757, %3778), scope: __module.model/__module.model.backbone/__module.model.backbone.1
  %3780 : int = prim::Constant[value=4](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3781 : Float(1:76800, 24:3200, 25:128, 64:2, 2:1, requires_grad=0, device=cpu) = aten::stack(%3779, %3780), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3782 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3783 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %pos_y : Float(1:76800, 24:3200, 25:128, 128:1, requires_grad=0, device=cpu) = aten::flatten(%3781, %3782, %3783), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:46:0
  %3785 : Tensor[] = prim::ListConstruct(%pos_y, %pos_x), scope: __module.model/__module.model.backbone/__module.model.backbone.1
  %3786 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:47:0
  %3787 : Float(1:153600, 24:6400, 25:256, 256:1, requires_grad=0, device=cpu) = aten::cat(%3785, %3786), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:47:0
  %3788 : int = prim::Constant[value=0](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:47:0
  %3789 : int = prim::Constant[value=3](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:47:0
  %3790 : int = prim::Constant[value=1](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:47:0
  %3791 : int = prim::Constant[value=2](), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:47:0
  %3792 : int[] = prim::ListConstruct(%3788, %3789, %3790, %3791), scope: __module.model/__module.model.backbone/__module.model.backbone.1
  %3793 : Float(1:153600, 256:1, 24:6400, 25:256, requires_grad=0, device=cpu) = aten::permute(%3787, %3792), scope: __module.model/__module.model.backbone/__module.model.backbone.1 # ../../ml/detr/models/position_encoding.py:47:0
  %3794 : int = prim::Constant[value=6](), scope: __module.model/__module.model.backbone # ../../ml/detr/models/backbone.py:107:0
  %3795 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone # ../../ml/detr/models/backbone.py:107:0
  %3796 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.backbone # ../../ml/detr/models/backbone.py:107:0
  %3797 : None = prim::Constant(), scope: __module.model/__module.model.backbone
  %pos_embed : Float(1:153600, 256:1, 24:6400, 25:256, requires_grad=0, device=cpu) = aten::to(%3793, %3794, %3795, %3796, %3797), scope: __module.model/__module.model.backbone # ../../ml/detr/models/backbone.py:107:0
  %3799 : (Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu), Float(1:153600, 256:1, 24:6400, 25:256, requires_grad=0, device=cpu), Bool(1:600, 24:25, 25:1, requires_grad=0, device=cpu)) = prim::TupleConstruct(%3582, %pos_embed, %3581)
  %3800 : Float(1:1228800, 2048:600, 24:25, 25:1, requires_grad=0, device=cpu), %3801 : Float(1:153600, 256:1, 24:6400, 25:256, requires_grad=0, device=cpu), %3802 : Bool(1:600, 24:25, 25:1, requires_grad=0, device=cpu) = prim::TupleUnpack(%3799)
  %3803 : Tensor = prim::GetAttr[name="bias"](%12)
  %3804 : Tensor = prim::GetAttr[name="weight"](%12)
  %3805 : int = prim::Constant[value=1](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3806 : int = prim::Constant[value=1](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3807 : int[] = prim::ListConstruct(%3805, %3806), scope: __module.model/__module.model.input_proj
  %3808 : int = prim::Constant[value=0](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3809 : int = prim::Constant[value=0](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3810 : int[] = prim::ListConstruct(%3808, %3809), scope: __module.model/__module.model.input_proj
  %3811 : int = prim::Constant[value=1](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3812 : int = prim::Constant[value=1](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3813 : int[] = prim::ListConstruct(%3811, %3812), scope: __module.model/__module.model.input_proj
  %3814 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3815 : int = prim::Constant[value=0](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3816 : int = prim::Constant[value=0](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3817 : int[] = prim::ListConstruct(%3815, %3816), scope: __module.model/__module.model.input_proj
  %3818 : int = prim::Constant[value=1](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3819 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3820 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3821 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3822 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %src : Float(1:153600, 256:600, 24:25, 25:1, requires_grad=0, device=cpu) = aten::_convolution(%3800, %3804, %3803, %3807, %3810, %3813, %3814, %3817, %3818, %3819, %3820, %3821, %3822), scope: __module.model/__module.model.input_proj # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0
  %3824 : __torch__.models.transformer.TransformerDecoder = prim::GetAttr[name="decoder"](%11)
  %3825 : __torch__.models.transformer.TransformerEncoder = prim::GetAttr[name="encoder"](%11)
  %3826 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:49:0
  %3827 : int = aten::size(%src, %3826), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:49:0
  %bs : Long(device=cpu) = prim::NumToTensor(%3827), scope: __module.model/__module.model.transformer
  %3829 : int = aten::Int(%bs), scope: __module.model/__module.model.transformer
  %3830 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:50:0
  %3831 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:50:0
  %3832 : Float(1:153600, 256:600, 600:1, requires_grad=0, device=cpu) = aten::flatten(%src, %3830, %3831), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:50:0
  %3833 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:50:0
  %3834 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:50:0
  %3835 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:50:0
  %3836 : int[] = prim::ListConstruct(%3833, %3834, %3835), scope: __module.model/__module.model.transformer
  %tensor.1 : Float(600:1, 1:153600, 256:600, requires_grad=0, device=cpu) = aten::permute(%3832, %3836), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:50:0
  %3838 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:51:0
  %3839 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:51:0
  %3840 : Float(1:256, 256:1, 600:256, requires_grad=0, device=cpu) = aten::flatten(%3801, %3838, %3839), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:51:0
  %3841 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:51:0
  %3842 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:51:0
  %3843 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:51:0
  %3844 : int[] = prim::ListConstruct(%3841, %3842, %3843), scope: __module.model/__module.model.transformer
  %pos : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::permute(%3840, %3844), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:51:0
  %3846 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:52:0
  %3847 : Float(100:256, 1:256, 256:1, requires_grad=1, device=cpu) = aten::unsqueeze(%10, %3846), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:52:0
  %3848 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:52:0
  %3849 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:52:0
  %3850 : int[] = prim::ListConstruct(%3848, %3829, %3849), scope: __module.model/__module.model.transformer
  %query_embed : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::repeat(%3847, %3850), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:52:0
  %3852 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:53:0
  %3853 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:53:0
  %key_padding_mask : Bool(1:600, 600:1, requires_grad=0, device=cpu) = aten::flatten(%3802, %3852, %3853), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:53:0
  %3855 : int = prim::Constant[value=6](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:55:0
  %3856 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:55:0
  %3857 : Device = prim::Constant[value="cpu"](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:55:0
  %3858 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:55:0
  %3859 : None = prim::Constant(), scope: __module.model/__module.model.transformer
  %tensor.7 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::zeros_like(%query_embed, %3855, %3856, %3857, %3858, %3859), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:55:0
  %3861 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%3825)
  %3862 : __torch__.models.transformer.___torch_mangle_53.TransformerEncoderLayer = prim::GetAttr[name="5"](%3861)
  %3863 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%3825)
  %3864 : __torch__.models.transformer.___torch_mangle_43.TransformerEncoderLayer = prim::GetAttr[name="4"](%3863)
  %3865 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%3825)
  %3866 : __torch__.models.transformer.___torch_mangle_33.TransformerEncoderLayer = prim::GetAttr[name="3"](%3865)
  %3867 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%3825)
  %3868 : __torch__.models.transformer.___torch_mangle_23.TransformerEncoderLayer = prim::GetAttr[name="2"](%3867)
  %3869 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%3825)
  %3870 : __torch__.models.transformer.___torch_mangle_13.TransformerEncoderLayer = prim::GetAttr[name="1"](%3869)
  %3871 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%3825)
  %3872 : __torch__.models.transformer.TransformerEncoderLayer = prim::GetAttr[name="0"](%3871)
  %3873 : __torch__.torch.nn.modules.normalization.___torch_mangle_1.LayerNorm = prim::GetAttr[name="norm2"](%3872)
  %3874 : __torch__.torch.nn.modules.dropout.___torch_mangle_3.Dropout = prim::GetAttr[name="dropout2"](%3872)
  %3875 : __torch__.torch.nn.modules.linear.___torch_mangle_0.Linear = prim::GetAttr[name="linear2"](%3872)
  %3876 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%3872)
  %3877 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="linear1"](%3872)
  %3878 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="norm1"](%3872)
  %3879 : __torch__.torch.nn.modules.dropout.___torch_mangle_2.Dropout = prim::GetAttr[name="dropout1"](%3872)
  %3880 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name="self_attn"](%3872)
  %3881 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0 # ../../ml/detr/models/transformer.py:147:0
  %query.1 : Float(600:1, 1:153600, 256:600, requires_grad=0, device=cpu) = aten::add(%tensor.1, %pos, %3881), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0 # ../../ml/detr/models/transformer.py:147:0
  %3883 : __torch__.torch.nn.modules.linear._LinearWithBias = prim::GetAttr[name="out_proj"](%3880)
  %3884 : Tensor = prim::GetAttr[name="bias"](%3883)
  %3885 : __torch__.torch.nn.modules.linear._LinearWithBias = prim::GetAttr[name="out_proj"](%3880)
  %3886 : Tensor = prim::GetAttr[name="weight"](%3885)
  %3887 : Tensor = prim::GetAttr[name="in_proj_bias"](%3880)
  %3888 : Tensor = prim::GetAttr[name="in_proj_weight"](%3880)
  %3889 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %3890 : int = aten::size(%query.1, %3889), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.1 : Long(device=cpu) = prim::NumToTensor(%3890), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3892 : int = aten::Int(%tgt_len.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3893 : int = aten::Int(%tgt_len.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3894 : int = aten::Int(%tgt_len.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3895 : int = aten::Int(%tgt_len.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3896 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %3897 : int = aten::size(%query.1, %3896), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.1 : Long(device=cpu) = prim::NumToTensor(%3897), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3899 : int = aten::Int(%bsz.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3900 : int = aten::Int(%bsz.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3901 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %3902 : int = aten::size(%query.1, %3901), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.1 : Long(device=cpu) = prim::NumToTensor(%3902), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3904 : int = aten::Int(%embed_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3905 : int = aten::Int(%embed_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3906 : int = aten::Int(%embed_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3907 : int = aten::Int(%embed_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3908 : int = aten::Int(%embed_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3909 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.1 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.1, %3909), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %3911 : int = aten::Int(%head_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3912 : int = aten::Int(%head_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3913 : int = aten::Int(%head_dim.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3914 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3915 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3916 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3917 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%3888, %3914, %3915, %3908, %3916), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3918 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3919 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3920 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3921 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.55 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%3917, %3918, %3919, %3920, %3921), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %3923 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %3924 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %3925 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.54 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%3887, %3923, %3924, %3907, %3925), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %3927 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.55), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.1 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.1, %3927), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %3929 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.1 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.1, %bias.54, %3929), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %3931 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.1 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.1, %3931), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %3933 : int = aten::Int(%_end.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3934 : int = aten::Int(%_end.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3935 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %3936 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %3937 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%3888, %3935, %3906, %3934, %3936), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %3938 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %3939 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %3940 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %3941 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.56 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%3937, %3938, %3939, %3940, %3941), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %3943 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %3944 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.55 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%3887, %3943, %3905, %3933, %3944), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %3946 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.56), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.1, %3946), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %3948 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.1 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.2, %bias.55, %3948), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %3950 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.1 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.1, %3950), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %3952 : int = aten::Int(%_start.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3953 : int = aten::Int(%_start.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3954 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3955 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3956 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3957 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%3888, %3954, %3953, %3955, %3956), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3958 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3959 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3960 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3961 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.57 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%3957, %3958, %3959, %3960, %3961), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %3963 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %3964 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %3965 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.56 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%3887, %3963, %3952, %3964, %3965), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %3967 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.57), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.3 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.1, %3967), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %3969 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.1 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.3, %bias.56, %3969), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %3971 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.1, %3971), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %3973 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.3 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.2, %3973), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %3975 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %3976 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.1, %3975), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %3977 : int = aten::Int(%3976), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3978 : int[] = prim::ListConstruct(%3895, %3977, %3913), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3979 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.3, %3978), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %3980 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %3981 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.4 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%3979, %3980, %3981), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %3983 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.1, %3983), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %3985 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %3986 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.1, %3985), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %3987 : int = aten::Int(%3986), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3988 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %3989 : int[] = prim::ListConstruct(%3988, %3987, %3912), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3990 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.2, %3989), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %3991 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %3992 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.3 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%3990, %3991, %3992), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %3994 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.1, %3994), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %3996 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %3997 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.1, %3996), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %3998 : int = aten::Int(%3997), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %3999 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4000 : int[] = prim::ListConstruct(%3999, %3998, %3911), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %4001 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.2, %4000), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4002 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4003 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.3 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4001, %4002, %4003), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4005 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %4006 : int = aten::size(%k.3, %4005), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.1 : Long(device=cpu) = prim::NumToTensor(%4006), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %4008 : int = aten::Int(%src_len.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %4009 : int = aten::Int(%src_len.1), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %4010 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4011 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4012 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.3, %4010, %4011), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.1 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.4, %4012), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4014 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4015 : int[] = prim::ListConstruct(%3900, %4014, %3894, %4009), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %attn_output_weights.2 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.1, %4015), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4017 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4018 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %4017), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4019 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4020 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%4018, %4019), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4021 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.3 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.2, %4020, %4021), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %4023 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4024 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.1, %4023), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4025 : int = aten::Int(%4024), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %4026 : int[] = prim::ListConstruct(%4025, %3893, %4008), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %input.102 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.3, %4026), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4028 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4029 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %input.103 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.102, %4028, %4029), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4031 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4032 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.4 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.103, %4031, %4032), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.1 : Float(8:19200, 600:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.4, %v.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %4035 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4036 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4037 : Float(600:32, 8:19200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.1, %4035, %4036), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4038 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4039 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%4037, %4038), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4040 : int[] = prim::ListConstruct(%3892, %3899, %3904), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn
  %input.104 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%4039, %4040), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4042 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%3886), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.4 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.104, %4042), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4044 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.105 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.4, %3884, %4044), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4046 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4047 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.1 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.105, %4046, %4047), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4049 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0 # ../../ml/detr/models/transformer.py:157:0
  %input.106 : Float(600:1, 1:153600, 256:600, requires_grad=0, device=cpu) = aten::add(%tensor.1, %src2.1, %4049), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0 # ../../ml/detr/models/transformer.py:157:0
  %4051 : Tensor = prim::GetAttr[name="bias"](%3878)
  %4052 : Tensor = prim::GetAttr[name="weight"](%3878)
  %4053 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4054 : int[] = prim::ListConstruct(%4053), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm1
  %4055 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4056 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.107 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.106, %4054, %4052, %4051, %4055, %4056), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4058 : Tensor = prim::GetAttr[name="bias"](%3877)
  %4059 : Tensor = prim::GetAttr[name="weight"](%3877)
  %4060 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%4059), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.5 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.107, %4060), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4062 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.108 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.5, %4058, %4062), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.109 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.108), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %4065 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4066 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.110 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.109, %4065, %4066), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4068 : Tensor = prim::GetAttr[name="bias"](%3875)
  %4069 : Tensor = prim::GetAttr[name="weight"](%3875)
  %4070 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%4069), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.6 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.110, %4070), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4072 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.111 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.6, %4068, %4072), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4074 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4075 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.111, %4074, %4075), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4077 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0 # ../../ml/detr/models/transformer.py:160:0
  %input.112 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.107, %src2.2, %4077), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0 # ../../ml/detr/models/transformer.py:160:0
  %4079 : Tensor = prim::GetAttr[name="bias"](%3873)
  %4080 : Tensor = prim::GetAttr[name="weight"](%3873)
  %4081 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4082 : int[] = prim::ListConstruct(%4081), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm2
  %4083 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4084 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.112, %4082, %4080, %4079, %4083, %4084), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.0/__module.model.transformer.encoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4086 : __torch__.torch.nn.modules.normalization.___torch_mangle_10.LayerNorm = prim::GetAttr[name="norm2"](%3870)
  %4087 : __torch__.torch.nn.modules.dropout.___torch_mangle_12.Dropout = prim::GetAttr[name="dropout2"](%3870)
  %4088 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Linear = prim::GetAttr[name="linear2"](%3870)
  %4089 : __torch__.torch.nn.modules.dropout.___torch_mangle_7.Dropout = prim::GetAttr[name="dropout"](%3870)
  %4090 : __torch__.torch.nn.modules.linear.___torch_mangle_6.Linear = prim::GetAttr[name="linear1"](%3870)
  %4091 : __torch__.torch.nn.modules.normalization.___torch_mangle_9.LayerNorm = prim::GetAttr[name="norm1"](%3870)
  %4092 : __torch__.torch.nn.modules.dropout.___torch_mangle_11.Dropout = prim::GetAttr[name="dropout1"](%3870)
  %4093 : __torch__.torch.nn.modules.activation.___torch_mangle_5.MultiheadAttention = prim::GetAttr[name="self_attn"](%3870)
  %4094 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1 # ../../ml/detr/models/transformer.py:147:0
  %query.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.2, %pos, %4094), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1 # ../../ml/detr/models/transformer.py:147:0
  %4096 : __torch__.torch.nn.modules.linear.___torch_mangle_4._LinearWithBias = prim::GetAttr[name="out_proj"](%4093)
  %4097 : Tensor = prim::GetAttr[name="bias"](%4096)
  %4098 : __torch__.torch.nn.modules.linear.___torch_mangle_4._LinearWithBias = prim::GetAttr[name="out_proj"](%4093)
  %4099 : Tensor = prim::GetAttr[name="weight"](%4098)
  %4100 : Tensor = prim::GetAttr[name="in_proj_bias"](%4093)
  %4101 : Tensor = prim::GetAttr[name="in_proj_weight"](%4093)
  %4102 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4103 : int = aten::size(%query.2, %4102), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.2 : Long(device=cpu) = prim::NumToTensor(%4103), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4105 : int = aten::Int(%tgt_len.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4106 : int = aten::Int(%tgt_len.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4107 : int = aten::Int(%tgt_len.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4108 : int = aten::Int(%tgt_len.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4109 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4110 : int = aten::size(%query.2, %4109), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.2 : Long(device=cpu) = prim::NumToTensor(%4110), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4112 : int = aten::Int(%bsz.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4113 : int = aten::Int(%bsz.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4114 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4115 : int = aten::size(%query.2, %4114), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.2 : Long(device=cpu) = prim::NumToTensor(%4115), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4117 : int = aten::Int(%embed_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4118 : int = aten::Int(%embed_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4119 : int = aten::Int(%embed_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4120 : int = aten::Int(%embed_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4121 : int = aten::Int(%embed_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4122 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.2 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.2, %4122), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %4124 : int = aten::Int(%head_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4125 : int = aten::Int(%head_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4126 : int = aten::Int(%head_dim.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4127 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4128 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4129 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4130 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4101, %4127, %4128, %4121, %4129), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4131 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4132 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4133 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4134 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.63 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4130, %4131, %4132, %4133, %4134), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4136 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4137 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4138 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.62 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4100, %4136, %4137, %4120, %4138), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4140 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.63), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.7 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.2, %4140), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4142 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.5 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.7, %bias.62, %4142), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4144 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.2 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.2, %4144), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %4146 : int = aten::Int(%_end.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4147 : int = aten::Int(%_end.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4148 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4149 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4150 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4101, %4148, %4119, %4147, %4149), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4151 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4152 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4153 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4154 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.64 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4150, %4151, %4152, %4153, %4154), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4156 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4157 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.63 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4100, %4156, %4118, %4146, %4157), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4159 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.64), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.8 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.2, %4159), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4161 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.4 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.8, %bias.63, %4161), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4163 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.2 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.2, %4163), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %4165 : int = aten::Int(%_start.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4166 : int = aten::Int(%_start.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4167 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4168 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4169 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4170 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4101, %4167, %4166, %4168, %4169), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4171 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4172 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4173 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4174 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.65 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4170, %4171, %4172, %4173, %4174), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4176 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4177 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4178 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.64 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4100, %4176, %4165, %4177, %4178), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4180 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.65), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.9 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.2, %4180), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4182 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.4 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.9, %bias.64, %4182), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4184 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.6 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.5, %4184), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %4186 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.7 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.6, %4186), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4188 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4189 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.2, %4188), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4190 : int = aten::Int(%4189), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4191 : int[] = prim::ListConstruct(%4108, %4190, %4126), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4192 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.7, %4191), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4193 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4194 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.8 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4192, %4193, %4194), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4196 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.5 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.4, %4196), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4198 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4199 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.2, %4198), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4200 : int = aten::Int(%4199), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4201 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4202 : int[] = prim::ListConstruct(%4201, %4200, %4125), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4203 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.5, %4202), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4204 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4205 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.6 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4203, %4204, %4205), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4207 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.5 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.4, %4207), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4209 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4210 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.2, %4209), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4211 : int = aten::Int(%4210), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4212 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4213 : int[] = prim::ListConstruct(%4212, %4211, %4124), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4214 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.5, %4213), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4215 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4216 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.6 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4214, %4215, %4216), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4218 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %4219 : int = aten::size(%k.6, %4218), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.2 : Long(device=cpu) = prim::NumToTensor(%4219), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4221 : int = aten::Int(%src_len.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4222 : int = aten::Int(%src_len.2), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4223 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4224 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4225 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.6, %4223, %4224), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.6 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.8, %4225), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4227 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4228 : int[] = prim::ListConstruct(%4113, %4227, %4107, %4222), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %attn_output_weights.7 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.6, %4228), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4230 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4231 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %4230), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4232 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4233 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%4231, %4232), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4234 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.8 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.7, %4233, %4234), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %4236 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4237 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.2, %4236), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4238 : int = aten::Int(%4237), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %4239 : int[] = prim::ListConstruct(%4238, %4106, %4221), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %input.113 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.8, %4239), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4241 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4242 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %input.114 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.113, %4241, %4242), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4244 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4245 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.9 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.114, %4244, %4245), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.2 : Float(8:19200, 600:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.9, %v.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %4248 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4249 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4250 : Float(600:32, 8:19200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.2, %4248, %4249), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4251 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4252 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%4250, %4251), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4253 : int[] = prim::ListConstruct(%4105, %4112, %4117), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn
  %input.115 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%4252, %4253), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4255 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%4099), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.10 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.115, %4255), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4257 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.116 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.10, %4097, %4257), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4259 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4260 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.3 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.116, %4259, %4260), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4262 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1 # ../../ml/detr/models/transformer.py:157:0
  %input.117 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.2, %src2.3, %4262), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1 # ../../ml/detr/models/transformer.py:157:0
  %4264 : Tensor = prim::GetAttr[name="bias"](%4091)
  %4265 : Tensor = prim::GetAttr[name="weight"](%4091)
  %4266 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4267 : int[] = prim::ListConstruct(%4266), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm1
  %4268 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4269 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.118 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.117, %4267, %4265, %4264, %4268, %4269), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4271 : Tensor = prim::GetAttr[name="bias"](%4090)
  %4272 : Tensor = prim::GetAttr[name="weight"](%4090)
  %4273 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%4272), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.11 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.118, %4273), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4275 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.119 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.11, %4271, %4275), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.120 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.119), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %4278 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4279 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.121 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.120, %4278, %4279), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4281 : Tensor = prim::GetAttr[name="bias"](%4088)
  %4282 : Tensor = prim::GetAttr[name="weight"](%4088)
  %4283 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%4282), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.12 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.121, %4283), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4285 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.122 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.12, %4281, %4285), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4287 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4288 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.4 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.122, %4287, %4288), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4290 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1 # ../../ml/detr/models/transformer.py:160:0
  %input.123 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.118, %src2.4, %4290), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1 # ../../ml/detr/models/transformer.py:160:0
  %4292 : Tensor = prim::GetAttr[name="bias"](%4086)
  %4293 : Tensor = prim::GetAttr[name="weight"](%4086)
  %4294 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4295 : int[] = prim::ListConstruct(%4294), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm2
  %4296 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4297 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.3 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.123, %4295, %4293, %4292, %4296, %4297), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.1/__module.model.transformer.encoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4299 : __torch__.torch.nn.modules.normalization.___torch_mangle_20.LayerNorm = prim::GetAttr[name="norm2"](%3868)
  %4300 : __torch__.torch.nn.modules.dropout.___torch_mangle_22.Dropout = prim::GetAttr[name="dropout2"](%3868)
  %4301 : __torch__.torch.nn.modules.linear.___torch_mangle_18.Linear = prim::GetAttr[name="linear2"](%3868)
  %4302 : __torch__.torch.nn.modules.dropout.___torch_mangle_17.Dropout = prim::GetAttr[name="dropout"](%3868)
  %4303 : __torch__.torch.nn.modules.linear.___torch_mangle_16.Linear = prim::GetAttr[name="linear1"](%3868)
  %4304 : __torch__.torch.nn.modules.normalization.___torch_mangle_19.LayerNorm = prim::GetAttr[name="norm1"](%3868)
  %4305 : __torch__.torch.nn.modules.dropout.___torch_mangle_21.Dropout = prim::GetAttr[name="dropout1"](%3868)
  %4306 : __torch__.torch.nn.modules.activation.___torch_mangle_15.MultiheadAttention = prim::GetAttr[name="self_attn"](%3868)
  %4307 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2 # ../../ml/detr/models/transformer.py:147:0
  %query.3 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.3, %pos, %4307), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2 # ../../ml/detr/models/transformer.py:147:0
  %4309 : __torch__.torch.nn.modules.linear.___torch_mangle_14._LinearWithBias = prim::GetAttr[name="out_proj"](%4306)
  %4310 : Tensor = prim::GetAttr[name="bias"](%4309)
  %4311 : __torch__.torch.nn.modules.linear.___torch_mangle_14._LinearWithBias = prim::GetAttr[name="out_proj"](%4306)
  %4312 : Tensor = prim::GetAttr[name="weight"](%4311)
  %4313 : Tensor = prim::GetAttr[name="in_proj_bias"](%4306)
  %4314 : Tensor = prim::GetAttr[name="in_proj_weight"](%4306)
  %4315 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4316 : int = aten::size(%query.3, %4315), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.3 : Long(device=cpu) = prim::NumToTensor(%4316), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4318 : int = aten::Int(%tgt_len.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4319 : int = aten::Int(%tgt_len.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4320 : int = aten::Int(%tgt_len.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4321 : int = aten::Int(%tgt_len.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4322 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4323 : int = aten::size(%query.3, %4322), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.3 : Long(device=cpu) = prim::NumToTensor(%4323), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4325 : int = aten::Int(%bsz.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4326 : int = aten::Int(%bsz.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4327 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4328 : int = aten::size(%query.3, %4327), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.3 : Long(device=cpu) = prim::NumToTensor(%4328), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4330 : int = aten::Int(%embed_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4331 : int = aten::Int(%embed_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4332 : int = aten::Int(%embed_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4333 : int = aten::Int(%embed_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4334 : int = aten::Int(%embed_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4335 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.3 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.3, %4335), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %4337 : int = aten::Int(%head_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4338 : int = aten::Int(%head_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4339 : int = aten::Int(%head_dim.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4340 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4341 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4342 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4343 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4314, %4340, %4341, %4334, %4342), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4344 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4345 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4346 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4347 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.71 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4343, %4344, %4345, %4346, %4347), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4349 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4350 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4351 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.70 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4313, %4349, %4350, %4333, %4351), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4353 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.71), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.13 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.3, %4353), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4355 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.9 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.13, %bias.70, %4355), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4357 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.3 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.3, %4357), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %4359 : int = aten::Int(%_end.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4360 : int = aten::Int(%_end.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4361 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4362 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4363 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4314, %4361, %4332, %4360, %4362), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4364 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4365 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4366 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4367 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.72 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4363, %4364, %4365, %4366, %4367), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4369 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4370 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.71 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4313, %4369, %4331, %4359, %4370), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4372 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.72), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.14 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.3, %4372), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4374 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.7 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.14, %bias.71, %4374), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4376 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.3 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.3, %4376), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %4378 : int = aten::Int(%_start.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4379 : int = aten::Int(%_start.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4380 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4381 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4382 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4383 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4314, %4380, %4379, %4381, %4382), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4384 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4385 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4386 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4387 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.73 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4383, %4384, %4385, %4386, %4387), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4389 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4390 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4391 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.72 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4313, %4389, %4378, %4390, %4391), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4393 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.73), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.15 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.3, %4393), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4395 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.7 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.15, %bias.72, %4395), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4397 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.10 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.9, %4397), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %4399 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.11 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.10, %4399), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4401 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4402 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.3, %4401), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4403 : int = aten::Int(%4402), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4404 : int[] = prim::ListConstruct(%4321, %4403, %4339), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4405 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.11, %4404), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4406 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4407 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.12 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4405, %4406, %4407), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4409 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.8 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.7, %4409), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4411 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4412 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.3, %4411), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4413 : int = aten::Int(%4412), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4414 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4415 : int[] = prim::ListConstruct(%4414, %4413, %4338), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4416 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.8, %4415), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4417 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4418 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.9 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4416, %4417, %4418), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4420 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.8 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.7, %4420), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4422 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4423 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.3, %4422), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4424 : int = aten::Int(%4423), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4425 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4426 : int[] = prim::ListConstruct(%4425, %4424, %4337), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4427 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.8, %4426), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4428 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4429 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.9 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4427, %4428, %4429), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4431 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %4432 : int = aten::size(%k.9, %4431), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.3 : Long(device=cpu) = prim::NumToTensor(%4432), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4434 : int = aten::Int(%src_len.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4435 : int = aten::Int(%src_len.3), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4436 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4437 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4438 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.9, %4436, %4437), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.11 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.12, %4438), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4440 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4441 : int[] = prim::ListConstruct(%4326, %4440, %4320, %4435), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %attn_output_weights.12 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.11, %4441), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4443 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4444 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %4443), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4445 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4446 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%4444, %4445), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4447 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.13 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.12, %4446, %4447), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %4449 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4450 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.3, %4449), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4451 : int = aten::Int(%4450), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %4452 : int[] = prim::ListConstruct(%4451, %4319, %4434), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %input.124 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.13, %4452), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4454 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4455 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %input.125 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.124, %4454, %4455), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4457 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4458 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.14 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.125, %4457, %4458), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.3 : Float(8:19200, 600:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.14, %v.9), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %4461 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4462 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4463 : Float(600:32, 8:19200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.3, %4461, %4462), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4464 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4465 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%4463, %4464), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4466 : int[] = prim::ListConstruct(%4318, %4325, %4330), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn
  %input.126 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%4465, %4466), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4468 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%4312), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.16 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.126, %4468), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4470 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.127 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.16, %4310, %4470), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4472 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4473 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.5 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.127, %4472, %4473), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4475 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2 # ../../ml/detr/models/transformer.py:157:0
  %input.128 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.3, %src2.5, %4475), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2 # ../../ml/detr/models/transformer.py:157:0
  %4477 : Tensor = prim::GetAttr[name="bias"](%4304)
  %4478 : Tensor = prim::GetAttr[name="weight"](%4304)
  %4479 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4480 : int[] = prim::ListConstruct(%4479), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm1
  %4481 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4482 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.129 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.128, %4480, %4478, %4477, %4481, %4482), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4484 : Tensor = prim::GetAttr[name="bias"](%4303)
  %4485 : Tensor = prim::GetAttr[name="weight"](%4303)
  %4486 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%4485), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.17 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.129, %4486), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4488 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.130 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.17, %4484, %4488), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.131 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.130), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %4491 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4492 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.132 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.131, %4491, %4492), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4494 : Tensor = prim::GetAttr[name="bias"](%4301)
  %4495 : Tensor = prim::GetAttr[name="weight"](%4301)
  %4496 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%4495), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.18 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.132, %4496), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4498 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.133 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.18, %4494, %4498), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4500 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4501 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.6 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.133, %4500, %4501), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4503 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2 # ../../ml/detr/models/transformer.py:160:0
  %input.134 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.129, %src2.6, %4503), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2 # ../../ml/detr/models/transformer.py:160:0
  %4505 : Tensor = prim::GetAttr[name="bias"](%4299)
  %4506 : Tensor = prim::GetAttr[name="weight"](%4299)
  %4507 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4508 : int[] = prim::ListConstruct(%4507), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm2
  %4509 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4510 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.4 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.134, %4508, %4506, %4505, %4509, %4510), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.2/__module.model.transformer.encoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4512 : __torch__.torch.nn.modules.normalization.___torch_mangle_30.LayerNorm = prim::GetAttr[name="norm2"](%3866)
  %4513 : __torch__.torch.nn.modules.dropout.___torch_mangle_32.Dropout = prim::GetAttr[name="dropout2"](%3866)
  %4514 : __torch__.torch.nn.modules.linear.___torch_mangle_28.Linear = prim::GetAttr[name="linear2"](%3866)
  %4515 : __torch__.torch.nn.modules.dropout.___torch_mangle_27.Dropout = prim::GetAttr[name="dropout"](%3866)
  %4516 : __torch__.torch.nn.modules.linear.___torch_mangle_26.Linear = prim::GetAttr[name="linear1"](%3866)
  %4517 : __torch__.torch.nn.modules.normalization.___torch_mangle_29.LayerNorm = prim::GetAttr[name="norm1"](%3866)
  %4518 : __torch__.torch.nn.modules.dropout.___torch_mangle_31.Dropout = prim::GetAttr[name="dropout1"](%3866)
  %4519 : __torch__.torch.nn.modules.activation.___torch_mangle_25.MultiheadAttention = prim::GetAttr[name="self_attn"](%3866)
  %4520 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3 # ../../ml/detr/models/transformer.py:147:0
  %query.4 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.4, %pos, %4520), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3 # ../../ml/detr/models/transformer.py:147:0
  %4522 : __torch__.torch.nn.modules.linear.___torch_mangle_24._LinearWithBias = prim::GetAttr[name="out_proj"](%4519)
  %4523 : Tensor = prim::GetAttr[name="bias"](%4522)
  %4524 : __torch__.torch.nn.modules.linear.___torch_mangle_24._LinearWithBias = prim::GetAttr[name="out_proj"](%4519)
  %4525 : Tensor = prim::GetAttr[name="weight"](%4524)
  %4526 : Tensor = prim::GetAttr[name="in_proj_bias"](%4519)
  %4527 : Tensor = prim::GetAttr[name="in_proj_weight"](%4519)
  %4528 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4529 : int = aten::size(%query.4, %4528), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.4 : Long(device=cpu) = prim::NumToTensor(%4529), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4531 : int = aten::Int(%tgt_len.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4532 : int = aten::Int(%tgt_len.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4533 : int = aten::Int(%tgt_len.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4534 : int = aten::Int(%tgt_len.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4535 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4536 : int = aten::size(%query.4, %4535), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.4 : Long(device=cpu) = prim::NumToTensor(%4536), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4538 : int = aten::Int(%bsz.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4539 : int = aten::Int(%bsz.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4540 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4541 : int = aten::size(%query.4, %4540), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.4 : Long(device=cpu) = prim::NumToTensor(%4541), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4543 : int = aten::Int(%embed_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4544 : int = aten::Int(%embed_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4545 : int = aten::Int(%embed_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4546 : int = aten::Int(%embed_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4547 : int = aten::Int(%embed_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4548 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.4 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.4, %4548), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %4550 : int = aten::Int(%head_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4551 : int = aten::Int(%head_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4552 : int = aten::Int(%head_dim.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4553 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4554 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4555 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4556 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4527, %4553, %4554, %4547, %4555), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4557 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4558 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4559 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4560 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.79 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4556, %4557, %4558, %4559, %4560), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4562 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4563 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4564 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.78 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4526, %4562, %4563, %4546, %4564), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4566 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.79), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.19 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.4, %4566), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4568 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.13 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.19, %bias.78, %4568), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4570 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.4 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.4, %4570), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %4572 : int = aten::Int(%_end.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4573 : int = aten::Int(%_end.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4574 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4575 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4576 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4527, %4574, %4545, %4573, %4575), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4577 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4578 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4579 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4580 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.80 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4576, %4577, %4578, %4579, %4580), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4582 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4583 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.79 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4526, %4582, %4544, %4572, %4583), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4585 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.80), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.20 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.4, %4585), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4587 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.10 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.20, %bias.79, %4587), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4589 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.4 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.4, %4589), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %4591 : int = aten::Int(%_start.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4592 : int = aten::Int(%_start.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4593 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4594 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4595 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4596 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4527, %4593, %4592, %4594, %4595), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4597 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4598 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4599 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4600 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.81 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4596, %4597, %4598, %4599, %4600), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4602 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4603 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4604 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.80 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4526, %4602, %4591, %4603, %4604), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4606 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.81), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.21 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.4, %4606), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4608 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.10 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.21, %bias.80, %4608), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4610 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.14 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.13, %4610), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %4612 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.15 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.14, %4612), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4614 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4615 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.4, %4614), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4616 : int = aten::Int(%4615), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4617 : int[] = prim::ListConstruct(%4534, %4616, %4552), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4618 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.15, %4617), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4619 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4620 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.16 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4618, %4619, %4620), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4622 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.11 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.10, %4622), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4624 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4625 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.4, %4624), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4626 : int = aten::Int(%4625), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4627 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4628 : int[] = prim::ListConstruct(%4627, %4626, %4551), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4629 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.11, %4628), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4630 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4631 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.12 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4629, %4630, %4631), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4633 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.11 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.10, %4633), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4635 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4636 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.4, %4635), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4637 : int = aten::Int(%4636), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4638 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4639 : int[] = prim::ListConstruct(%4638, %4637, %4550), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4640 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.11, %4639), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4641 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4642 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.12 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4640, %4641, %4642), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4644 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %4645 : int = aten::size(%k.12, %4644), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.4 : Long(device=cpu) = prim::NumToTensor(%4645), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4647 : int = aten::Int(%src_len.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4648 : int = aten::Int(%src_len.4), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4649 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4650 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4651 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.12, %4649, %4650), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.16 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.16, %4651), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4653 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4654 : int[] = prim::ListConstruct(%4539, %4653, %4533, %4648), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %attn_output_weights.17 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.16, %4654), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4656 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4657 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %4656), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4658 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4659 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%4657, %4658), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4660 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.18 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.17, %4659, %4660), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %4662 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4663 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.4, %4662), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4664 : int = aten::Int(%4663), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %4665 : int[] = prim::ListConstruct(%4664, %4532, %4647), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %input.135 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.18, %4665), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4667 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4668 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %input.136 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.135, %4667, %4668), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4670 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4671 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.19 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.136, %4670, %4671), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.4 : Float(8:19200, 600:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.19, %v.12), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %4674 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4675 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4676 : Float(600:32, 8:19200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.4, %4674, %4675), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4677 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4678 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%4676, %4677), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4679 : int[] = prim::ListConstruct(%4531, %4538, %4543), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn
  %input.137 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%4678, %4679), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4681 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%4525), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.22 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.137, %4681), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4683 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.138 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.22, %4523, %4683), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4685 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4686 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.7 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.138, %4685, %4686), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4688 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3 # ../../ml/detr/models/transformer.py:157:0
  %input.139 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.4, %src2.7, %4688), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3 # ../../ml/detr/models/transformer.py:157:0
  %4690 : Tensor = prim::GetAttr[name="bias"](%4517)
  %4691 : Tensor = prim::GetAttr[name="weight"](%4517)
  %4692 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4693 : int[] = prim::ListConstruct(%4692), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm1
  %4694 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4695 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.140 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.139, %4693, %4691, %4690, %4694, %4695), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4697 : Tensor = prim::GetAttr[name="bias"](%4516)
  %4698 : Tensor = prim::GetAttr[name="weight"](%4516)
  %4699 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%4698), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.23 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.140, %4699), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4701 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.141 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.23, %4697, %4701), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.142 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.141), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %4704 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4705 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.143 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.142, %4704, %4705), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4707 : Tensor = prim::GetAttr[name="bias"](%4514)
  %4708 : Tensor = prim::GetAttr[name="weight"](%4514)
  %4709 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%4708), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.24 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.143, %4709), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4711 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.144 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.24, %4707, %4711), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4713 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4714 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.8 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.144, %4713, %4714), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4716 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3 # ../../ml/detr/models/transformer.py:160:0
  %input.145 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.140, %src2.8, %4716), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3 # ../../ml/detr/models/transformer.py:160:0
  %4718 : Tensor = prim::GetAttr[name="bias"](%4512)
  %4719 : Tensor = prim::GetAttr[name="weight"](%4512)
  %4720 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4721 : int[] = prim::ListConstruct(%4720), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm2
  %4722 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4723 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.5 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.145, %4721, %4719, %4718, %4722, %4723), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.3/__module.model.transformer.encoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4725 : __torch__.torch.nn.modules.normalization.___torch_mangle_40.LayerNorm = prim::GetAttr[name="norm2"](%3864)
  %4726 : __torch__.torch.nn.modules.dropout.___torch_mangle_42.Dropout = prim::GetAttr[name="dropout2"](%3864)
  %4727 : __torch__.torch.nn.modules.linear.___torch_mangle_38.Linear = prim::GetAttr[name="linear2"](%3864)
  %4728 : __torch__.torch.nn.modules.dropout.___torch_mangle_37.Dropout = prim::GetAttr[name="dropout"](%3864)
  %4729 : __torch__.torch.nn.modules.linear.___torch_mangle_36.Linear = prim::GetAttr[name="linear1"](%3864)
  %4730 : __torch__.torch.nn.modules.normalization.___torch_mangle_39.LayerNorm = prim::GetAttr[name="norm1"](%3864)
  %4731 : __torch__.torch.nn.modules.dropout.___torch_mangle_41.Dropout = prim::GetAttr[name="dropout1"](%3864)
  %4732 : __torch__.torch.nn.modules.activation.___torch_mangle_35.MultiheadAttention = prim::GetAttr[name="self_attn"](%3864)
  %4733 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4 # ../../ml/detr/models/transformer.py:147:0
  %query.5 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.5, %pos, %4733), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4 # ../../ml/detr/models/transformer.py:147:0
  %4735 : __torch__.torch.nn.modules.linear.___torch_mangle_34._LinearWithBias = prim::GetAttr[name="out_proj"](%4732)
  %4736 : Tensor = prim::GetAttr[name="bias"](%4735)
  %4737 : __torch__.torch.nn.modules.linear.___torch_mangle_34._LinearWithBias = prim::GetAttr[name="out_proj"](%4732)
  %4738 : Tensor = prim::GetAttr[name="weight"](%4737)
  %4739 : Tensor = prim::GetAttr[name="in_proj_bias"](%4732)
  %4740 : Tensor = prim::GetAttr[name="in_proj_weight"](%4732)
  %4741 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4742 : int = aten::size(%query.5, %4741), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.5 : Long(device=cpu) = prim::NumToTensor(%4742), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4744 : int = aten::Int(%tgt_len.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4745 : int = aten::Int(%tgt_len.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4746 : int = aten::Int(%tgt_len.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4747 : int = aten::Int(%tgt_len.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4748 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4749 : int = aten::size(%query.5, %4748), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.5 : Long(device=cpu) = prim::NumToTensor(%4749), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4751 : int = aten::Int(%bsz.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4752 : int = aten::Int(%bsz.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4753 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4754 : int = aten::size(%query.5, %4753), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.5 : Long(device=cpu) = prim::NumToTensor(%4754), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4756 : int = aten::Int(%embed_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4757 : int = aten::Int(%embed_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4758 : int = aten::Int(%embed_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4759 : int = aten::Int(%embed_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4760 : int = aten::Int(%embed_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4761 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.5 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.5, %4761), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %4763 : int = aten::Int(%head_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4764 : int = aten::Int(%head_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4765 : int = aten::Int(%head_dim.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4766 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4767 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4768 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4769 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4740, %4766, %4767, %4760, %4768), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4770 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4771 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4772 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4773 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.87 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4769, %4770, %4771, %4772, %4773), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4775 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4776 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4777 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.86 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4739, %4775, %4776, %4759, %4777), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4779 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.87), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.25 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.5, %4779), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4781 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.17 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.25, %bias.86, %4781), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4783 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.5 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.5, %4783), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %4785 : int = aten::Int(%_end.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4786 : int = aten::Int(%_end.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4787 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4788 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4789 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4740, %4787, %4758, %4786, %4788), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4790 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4791 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4792 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4793 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.88 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4789, %4790, %4791, %4792, %4793), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %4795 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4796 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.87 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4739, %4795, %4757, %4785, %4796), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %4798 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.88), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.26 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.5, %4798), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4800 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.13 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.26, %bias.87, %4800), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4802 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.5 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.5, %4802), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %4804 : int = aten::Int(%_start.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4805 : int = aten::Int(%_start.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4806 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4807 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4808 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4809 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4740, %4806, %4805, %4807, %4808), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4810 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4811 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4812 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4813 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.89 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4809, %4810, %4811, %4812, %4813), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %4815 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4816 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4817 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.88 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4739, %4815, %4804, %4816, %4817), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %4819 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.89), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.27 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.5, %4819), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4821 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.13 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.27, %bias.88, %4821), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4823 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.18 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.17, %4823), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %4825 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.19 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.18, %4825), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4827 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4828 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.5, %4827), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4829 : int = aten::Int(%4828), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4830 : int[] = prim::ListConstruct(%4747, %4829, %4765), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4831 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.19, %4830), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4832 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4833 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.20 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4831, %4832, %4833), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %4835 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.14 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.13, %4835), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4837 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4838 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.5, %4837), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4839 : int = aten::Int(%4838), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4840 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4841 : int[] = prim::ListConstruct(%4840, %4839, %4764), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4842 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.14, %4841), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4843 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4844 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.15 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4842, %4843, %4844), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %4846 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.14 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.13, %4846), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4848 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4849 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.5, %4848), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4850 : int = aten::Int(%4849), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4851 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4852 : int[] = prim::ListConstruct(%4851, %4850, %4763), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4853 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.14, %4852), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4854 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4855 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.15 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%4853, %4854, %4855), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %4857 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %4858 : int = aten::size(%k.15, %4857), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.5 : Long(device=cpu) = prim::NumToTensor(%4858), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4860 : int = aten::Int(%src_len.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4861 : int = aten::Int(%src_len.5), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4862 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4863 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4864 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.15, %4862, %4863), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.21 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.20, %4864), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %4866 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4867 : int[] = prim::ListConstruct(%4752, %4866, %4746, %4861), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %attn_output_weights.22 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.21, %4867), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %4869 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4870 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %4869), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4871 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4872 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%4870, %4871), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %4873 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.23 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.22, %4872, %4873), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %4875 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4876 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.5, %4875), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4877 : int = aten::Int(%4876), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %4878 : int[] = prim::ListConstruct(%4877, %4745, %4860), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %input.146 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.23, %4878), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %4880 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4881 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %input.147 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.146, %4880, %4881), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %4883 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4884 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.24 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.147, %4883, %4884), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.5 : Float(8:19200, 600:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.24, %v.15), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %4887 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4888 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4889 : Float(600:32, 8:19200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.5, %4887, %4888), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4890 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4891 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%4889, %4890), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4892 : int[] = prim::ListConstruct(%4744, %4751, %4756), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn
  %input.148 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%4891, %4892), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %4894 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%4738), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.28 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.148, %4894), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4896 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.149 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.28, %4736, %4896), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4898 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4899 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.9 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.149, %4898, %4899), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4901 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4 # ../../ml/detr/models/transformer.py:157:0
  %input.150 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.5, %src2.9, %4901), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4 # ../../ml/detr/models/transformer.py:157:0
  %4903 : Tensor = prim::GetAttr[name="bias"](%4730)
  %4904 : Tensor = prim::GetAttr[name="weight"](%4730)
  %4905 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4906 : int[] = prim::ListConstruct(%4905), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm1
  %4907 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4908 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.151 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.150, %4906, %4904, %4903, %4907, %4908), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4910 : Tensor = prim::GetAttr[name="bias"](%4729)
  %4911 : Tensor = prim::GetAttr[name="weight"](%4729)
  %4912 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%4911), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.29 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.151, %4912), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4914 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.152 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.29, %4910, %4914), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.153 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.152), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %4917 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4918 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.154 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.153, %4917, %4918), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4920 : Tensor = prim::GetAttr[name="bias"](%4727)
  %4921 : Tensor = prim::GetAttr[name="weight"](%4727)
  %4922 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%4921), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.30 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.154, %4922), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4924 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.155 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.30, %4920, %4924), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4926 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4927 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.10 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.155, %4926, %4927), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %4929 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4 # ../../ml/detr/models/transformer.py:160:0
  %input.156 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.151, %src2.10, %4929), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4 # ../../ml/detr/models/transformer.py:160:0
  %4931 : Tensor = prim::GetAttr[name="bias"](%4725)
  %4932 : Tensor = prim::GetAttr[name="weight"](%4725)
  %4933 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4934 : int[] = prim::ListConstruct(%4933), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm2
  %4935 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4936 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.6 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.156, %4934, %4932, %4931, %4935, %4936), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.4/__module.model.transformer.encoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %4938 : __torch__.torch.nn.modules.normalization.___torch_mangle_50.LayerNorm = prim::GetAttr[name="norm2"](%3862)
  %4939 : __torch__.torch.nn.modules.dropout.___torch_mangle_52.Dropout = prim::GetAttr[name="dropout2"](%3862)
  %4940 : __torch__.torch.nn.modules.linear.___torch_mangle_48.Linear = prim::GetAttr[name="linear2"](%3862)
  %4941 : __torch__.torch.nn.modules.dropout.___torch_mangle_47.Dropout = prim::GetAttr[name="dropout"](%3862)
  %4942 : __torch__.torch.nn.modules.linear.___torch_mangle_46.Linear = prim::GetAttr[name="linear1"](%3862)
  %4943 : __torch__.torch.nn.modules.normalization.___torch_mangle_49.LayerNorm = prim::GetAttr[name="norm1"](%3862)
  %4944 : __torch__.torch.nn.modules.dropout.___torch_mangle_51.Dropout = prim::GetAttr[name="dropout1"](%3862)
  %4945 : __torch__.torch.nn.modules.activation.___torch_mangle_45.MultiheadAttention = prim::GetAttr[name="self_attn"](%3862)
  %4946 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5 # ../../ml/detr/models/transformer.py:147:0
  %query.6 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.6, %pos, %4946), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5 # ../../ml/detr/models/transformer.py:147:0
  %4948 : __torch__.torch.nn.modules.linear.___torch_mangle_44._LinearWithBias = prim::GetAttr[name="out_proj"](%4945)
  %4949 : Tensor = prim::GetAttr[name="bias"](%4948)
  %4950 : __torch__.torch.nn.modules.linear.___torch_mangle_44._LinearWithBias = prim::GetAttr[name="out_proj"](%4945)
  %4951 : Tensor = prim::GetAttr[name="weight"](%4950)
  %4952 : Tensor = prim::GetAttr[name="in_proj_bias"](%4945)
  %4953 : Tensor = prim::GetAttr[name="in_proj_weight"](%4945)
  %4954 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4955 : int = aten::size(%query.6, %4954), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.6 : Long(device=cpu) = prim::NumToTensor(%4955), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4957 : int = aten::Int(%tgt_len.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4958 : int = aten::Int(%tgt_len.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4959 : int = aten::Int(%tgt_len.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4960 : int = aten::Int(%tgt_len.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4961 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4962 : int = aten::size(%query.6, %4961), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.6 : Long(device=cpu) = prim::NumToTensor(%4962), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4964 : int = aten::Int(%bsz.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4965 : int = aten::Int(%bsz.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4966 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %4967 : int = aten::size(%query.6, %4966), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.6 : Long(device=cpu) = prim::NumToTensor(%4967), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4969 : int = aten::Int(%embed_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4970 : int = aten::Int(%embed_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4971 : int = aten::Int(%embed_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4972 : int = aten::Int(%embed_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4973 : int = aten::Int(%embed_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4974 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.6 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.6, %4974), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %4976 : int = aten::Int(%head_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4977 : int = aten::Int(%head_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4978 : int = aten::Int(%head_dim.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4979 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4980 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4981 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4982 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4953, %4979, %4980, %4973, %4981), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4983 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4984 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4985 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4986 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.95 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4982, %4983, %4984, %4985, %4986), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %4988 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4989 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4990 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.94 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4952, %4988, %4989, %4972, %4990), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %4992 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.95), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.31 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.6, %4992), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %4994 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.21 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.31, %bias.94, %4994), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %4996 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.6 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.6, %4996), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %4998 : int = aten::Int(%_end.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %4999 : int = aten::Int(%_end.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5000 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5001 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5002 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4953, %5000, %4971, %4999, %5001), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5003 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5004 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5005 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5006 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.96 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5002, %5003, %5004, %5005, %5006), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5008 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5009 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.95 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4952, %5008, %4970, %4998, %5009), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5011 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.96), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.32 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.6, %5011), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5013 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.16 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.32, %bias.95, %5013), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5015 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.6 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.6, %5015), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %5017 : int = aten::Int(%_start.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5018 : int = aten::Int(%_start.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5019 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5020 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5021 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5022 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%4953, %5019, %5018, %5020, %5021), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5023 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5024 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5025 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5026 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.97 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5022, %5023, %5024, %5025, %5026), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5028 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5029 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5030 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.96 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%4952, %5028, %5017, %5029, %5030), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5032 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.97), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.33 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.6, %5032), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5034 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.16 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.33, %bias.96, %5034), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5036 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.22 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.21, %5036), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %5038 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.23 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.22, %5038), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5040 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5041 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.6, %5040), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5042 : int = aten::Int(%5041), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5043 : int[] = prim::ListConstruct(%4960, %5042, %4978), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5044 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.23, %5043), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5045 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5046 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.24 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5044, %5045, %5046), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5048 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.17 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.16, %5048), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5050 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5051 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.6, %5050), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5052 : int = aten::Int(%5051), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5053 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5054 : int[] = prim::ListConstruct(%5053, %5052, %4977), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5055 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.17, %5054), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5056 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5057 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.18 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5055, %5056, %5057), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5059 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.17 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.16, %5059), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5061 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5062 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.6, %5061), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5063 : int = aten::Int(%5062), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5064 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5065 : int[] = prim::ListConstruct(%5064, %5063, %4976), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5066 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.17, %5065), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5067 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5068 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.18 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5066, %5067, %5068), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5070 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %5071 : int = aten::size(%k.18, %5070), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.6 : Long(device=cpu) = prim::NumToTensor(%5071), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5073 : int = aten::Int(%src_len.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5074 : int = aten::Int(%src_len.6), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5075 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5076 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5077 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.18, %5075, %5076), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.26 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.24, %5077), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5079 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %5080 : int[] = prim::ListConstruct(%4965, %5079, %4959, %5074), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %attn_output_weights.27 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.26, %5080), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %5082 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5083 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %5082), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5084 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5085 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%5083, %5084), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5086 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.28 : Float(1:2880000, 8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.27, %5085, %5086), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %5088 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5089 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.6, %5088), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5090 : int = aten::Int(%5089), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %5091 : int[] = prim::ListConstruct(%5090, %4958, %5073), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %input.157 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.28, %5091), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5093 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5094 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %input.158 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.157, %5093, %5094), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5096 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5097 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.29 : Float(8:360000, 600:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.158, %5096, %5097), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.6 : Float(8:19200, 600:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.29, %v.18), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %5100 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5101 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5102 : Float(600:32, 8:19200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.6, %5100, %5101), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5103 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5104 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%5102, %5103), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5105 : int[] = prim::ListConstruct(%4957, %4964, %4969), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn
  %input.159 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%5104, %5105), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5107 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%4951), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.34 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.159, %5107), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5109 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.160 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.34, %4949, %5109), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5111 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5112 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2.11 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.160, %5111, %5112), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5114 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5 # ../../ml/detr/models/transformer.py:157:0
  %input.161 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.6, %src2.11, %5114), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5 # ../../ml/detr/models/transformer.py:157:0
  %5116 : Tensor = prim::GetAttr[name="bias"](%4943)
  %5117 : Tensor = prim::GetAttr[name="weight"](%4943)
  %5118 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5119 : int[] = prim::ListConstruct(%5118), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm1
  %5120 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5121 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.162 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.161, %5119, %5117, %5116, %5120, %5121), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5123 : Tensor = prim::GetAttr[name="bias"](%4942)
  %5124 : Tensor = prim::GetAttr[name="weight"](%4942)
  %5125 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%5124), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.35 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.162, %5125), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5127 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.163 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.35, %5123, %5127), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.164 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.163), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %5130 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5131 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.165 : Float(600:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.164, %5130, %5131), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5133 : Tensor = prim::GetAttr[name="bias"](%4940)
  %5134 : Tensor = prim::GetAttr[name="weight"](%4940)
  %5135 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%5134), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.36 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.165, %5135), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5137 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.166 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.36, %5133, %5137), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5139 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5140 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %src2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.166, %5139, %5140), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5142 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5 # ../../ml/detr/models/transformer.py:160:0
  %input.167 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.162, %src2, %5142), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5 # ../../ml/detr/models/transformer.py:160:0
  %5144 : Tensor = prim::GetAttr[name="bias"](%4938)
  %5145 : Tensor = prim::GetAttr[name="weight"](%4938)
  %5146 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5147 : int[] = prim::ListConstruct(%5146), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm2
  %5148 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5149 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.9 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.167, %5147, %5145, %5144, %5148, %5149), scope: __module.model/__module.model.transformer/__module.model.transformer.encoder/__module.model.transformer.encoder.layers.5/__module.model.transformer.encoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5151 : __torch__.torch.nn.modules.container.___torch_mangle_137.ModuleList = prim::GetAttr[name="layers"](%3824)
  %5152 : __torch__.models.transformer.___torch_mangle_136.TransformerDecoderLayer = prim::GetAttr[name="5"](%5151)
  %5153 : __torch__.torch.nn.modules.container.___torch_mangle_137.ModuleList = prim::GetAttr[name="layers"](%3824)
  %5154 : __torch__.models.transformer.___torch_mangle_122.TransformerDecoderLayer = prim::GetAttr[name="4"](%5153)
  %5155 : __torch__.torch.nn.modules.container.___torch_mangle_137.ModuleList = prim::GetAttr[name="layers"](%3824)
  %5156 : __torch__.models.transformer.___torch_mangle_108.TransformerDecoderLayer = prim::GetAttr[name="3"](%5155)
  %5157 : __torch__.torch.nn.modules.container.___torch_mangle_137.ModuleList = prim::GetAttr[name="layers"](%3824)
  %5158 : __torch__.models.transformer.___torch_mangle_94.TransformerDecoderLayer = prim::GetAttr[name="2"](%5157)
  %5159 : __torch__.torch.nn.modules.container.___torch_mangle_137.ModuleList = prim::GetAttr[name="layers"](%3824)
  %5160 : __torch__.models.transformer.___torch_mangle_80.TransformerDecoderLayer = prim::GetAttr[name="1"](%5159)
  %5161 : __torch__.torch.nn.modules.normalization.___torch_mangle_138.LayerNorm = prim::GetAttr[name="norm"](%3824)
  %5162 : __torch__.torch.nn.modules.container.___torch_mangle_137.ModuleList = prim::GetAttr[name="layers"](%3824)
  %5163 : __torch__.models.transformer.TransformerDecoderLayer = prim::GetAttr[name="0"](%5162)
  %5164 : __torch__.torch.nn.modules.normalization.___torch_mangle_63.LayerNorm = prim::GetAttr[name="norm3"](%5163)
  %5165 : __torch__.torch.nn.modules.dropout.___torch_mangle_66.Dropout = prim::GetAttr[name="dropout3"](%5163)
  %5166 : __torch__.torch.nn.modules.linear.___torch_mangle_60.Linear = prim::GetAttr[name="linear2"](%5163)
  %5167 : __torch__.torch.nn.modules.dropout.___torch_mangle_59.Dropout = prim::GetAttr[name="dropout"](%5163)
  %5168 : __torch__.torch.nn.modules.linear.___torch_mangle_58.Linear = prim::GetAttr[name="linear1"](%5163)
  %5169 : __torch__.torch.nn.modules.normalization.___torch_mangle_62.LayerNorm = prim::GetAttr[name="norm2"](%5163)
  %5170 : __torch__.torch.nn.modules.dropout.___torch_mangle_65.Dropout = prim::GetAttr[name="dropout2"](%5163)
  %5171 : __torch__.torch.nn.modules.activation.___torch_mangle_57.MultiheadAttention = prim::GetAttr[name="multihead_attn"](%5163)
  %5172 : __torch__.torch.nn.modules.normalization.___torch_mangle_61.LayerNorm = prim::GetAttr[name="norm1"](%5163)
  %5173 : __torch__.torch.nn.modules.dropout.___torch_mangle_64.Dropout = prim::GetAttr[name="dropout1"](%5163)
  %5174 : __torch__.torch.nn.modules.activation.___torch_mangle_55.MultiheadAttention = prim::GetAttr[name="self_attn"](%5163)
  %5175 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:210:0
  %query.7 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.7, %query_embed, %5175), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:210:0
  %5177 : __torch__.torch.nn.modules.linear.___torch_mangle_54._LinearWithBias = prim::GetAttr[name="out_proj"](%5174)
  %5178 : Tensor = prim::GetAttr[name="bias"](%5177)
  %5179 : __torch__.torch.nn.modules.linear.___torch_mangle_54._LinearWithBias = prim::GetAttr[name="out_proj"](%5174)
  %5180 : Tensor = prim::GetAttr[name="weight"](%5179)
  %5181 : Tensor = prim::GetAttr[name="in_proj_bias"](%5174)
  %5182 : Tensor = prim::GetAttr[name="in_proj_weight"](%5174)
  %5183 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5184 : int = aten::size(%query.7, %5183), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.7 : Long(device=cpu) = prim::NumToTensor(%5184), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5186 : int = aten::Int(%tgt_len.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5187 : int = aten::Int(%tgt_len.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5188 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5189 : int = aten::size(%query.7, %5188), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.7 : Long(device=cpu) = prim::NumToTensor(%5189), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5191 : int = aten::Int(%bsz.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5192 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5193 : int = aten::size(%query.7, %5192), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.7 : Long(device=cpu) = prim::NumToTensor(%5193), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5195 : int = aten::Int(%embed_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5196 : int = aten::Int(%embed_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5197 : int = aten::Int(%embed_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5198 : int = aten::Int(%embed_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5199 : int = aten::Int(%embed_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5200 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.7 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.7, %5200), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %5202 : int = aten::Int(%head_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5203 : int = aten::Int(%head_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5204 : int = aten::Int(%head_dim.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5205 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5206 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5207 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5208 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5182, %5205, %5206, %5199, %5207), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5209 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5210 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5211 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5212 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.103 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5208, %5209, %5210, %5211, %5212), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5214 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5215 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5216 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.102 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5181, %5214, %5215, %5198, %5216), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5218 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.103), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.37 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.7, %5218), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5220 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.25 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.37, %bias.102, %5220), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5222 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.7 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.7, %5222), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %5224 : int = aten::Int(%_end.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5225 : int = aten::Int(%_end.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5226 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5227 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5228 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5182, %5226, %5197, %5225, %5227), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5229 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5230 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5231 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5232 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.104 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5228, %5229, %5230, %5231, %5232), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5234 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5235 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.103 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5181, %5234, %5196, %5224, %5235), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5237 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.104), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.38 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.7, %5237), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5239 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.19 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.38, %bias.103, %5239), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5241 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.7 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.7, %5241), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %5243 : int = aten::Int(%_start.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5244 : int = aten::Int(%_start.7), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5245 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5246 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5248 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5182, %5245, %5244, %5246, %5247), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5249 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5250 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5251 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5252 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.105 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5248, %5249, %5250, %5251, %5252), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5254 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5255 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5256 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.104 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5181, %5254, %5243, %5255, %5256), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5258 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.105), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.39 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.7, %5258), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5260 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.19 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.39, %bias.104, %5260), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5262 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.26 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.25, %5262), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %5264 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.27 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.26, %5264), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5266 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5267 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.7, %5266), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5268 : int = aten::Int(%5267), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5269 : int[] = prim::ListConstruct(%5187, %5268, %5204), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5270 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.27, %5269), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5271 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5272 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.28 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5270, %5271, %5272), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5274 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.20 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.19, %5274), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5276 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5277 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.7, %5276), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5278 : int = aten::Int(%5277), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5279 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5280 : int[] = prim::ListConstruct(%5279, %5278, %5203), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5281 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.20, %5280), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5282 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.21 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5281, %5282, %5283), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5285 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.20 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.19, %5285), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5287 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5288 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.7, %5287), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5289 : int = aten::Int(%5288), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5290 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5291 : int[] = prim::ListConstruct(%5290, %5289, %5202), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %5292 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.20, %5291), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5293 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5294 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.21 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5292, %5293, %5294), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5296 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5297 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5298 : Float(8:32, 32:1, 100:256, requires_grad=0, device=cpu) = aten::transpose(%k.21, %5296, %5297), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.31 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::bmm(%q.28, %5298), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5300 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5301 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %input.168 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::softmax(%attn_output_weights.31, %5300, %5301), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5303 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5304 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.32 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::dropout(%input.168, %5303, %5304), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.7 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.32, %v.21), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %5307 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5308 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5309 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.7, %5307, %5308), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5310 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5311 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%5309, %5310), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5312 : int[] = prim::ListConstruct(%5186, %5191, %5195), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn
  %input.169 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%5311, %5312), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5314 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%5180), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.40 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.169, %5314), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5316 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.170 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.40, %5178, %5316), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5318 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5319 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.1 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.170, %5318, %5319), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5321 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:222:0
  %input.171 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.7, %tgt2.1, %5321), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:222:0
  %5323 : Tensor = prim::GetAttr[name="bias"](%5172)
  %5324 : Tensor = prim::GetAttr[name="weight"](%5172)
  %5325 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5326 : int[] = prim::ListConstruct(%5325), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm1
  %5327 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5328 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.8 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.171, %5326, %5324, %5323, %5327, %5328), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5330 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:210:0
  %query.8 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.8, %query_embed, %5330), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:210:0
  %5332 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:210:0
  %key.1 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.9, %pos, %5332), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:210:0
  %5334 : __torch__.torch.nn.modules.linear.___torch_mangle_56._LinearWithBias = prim::GetAttr[name="out_proj"](%5171)
  %5335 : Tensor = prim::GetAttr[name="bias"](%5334)
  %5336 : __torch__.torch.nn.modules.linear.___torch_mangle_56._LinearWithBias = prim::GetAttr[name="out_proj"](%5171)
  %5337 : Tensor = prim::GetAttr[name="weight"](%5336)
  %5338 : Tensor = prim::GetAttr[name="in_proj_bias"](%5171)
  %5339 : Tensor = prim::GetAttr[name="in_proj_weight"](%5171)
  %5340 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5341 : int = aten::size(%query.8, %5340), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.8 : Long(device=cpu) = prim::NumToTensor(%5341), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5343 : int = aten::Int(%tgt_len.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5344 : int = aten::Int(%tgt_len.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5345 : int = aten::Int(%tgt_len.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5346 : int = aten::Int(%tgt_len.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5347 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5348 : int = aten::size(%query.8, %5347), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.8 : Long(device=cpu) = prim::NumToTensor(%5348), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5350 : int = aten::Int(%bsz.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5351 : int = aten::Int(%bsz.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5352 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5353 : int = aten::size(%query.8, %5352), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.8 : Long(device=cpu) = prim::NumToTensor(%5353), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5355 : int = aten::Int(%embed_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5356 : int = aten::Int(%embed_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5357 : int = aten::Int(%embed_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5358 : int = aten::Int(%embed_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5359 : int = aten::Int(%embed_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5360 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.8 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.8, %5360), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %5362 : int = aten::Int(%head_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5363 : int = aten::Int(%head_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5364 : int = aten::Int(%head_dim.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5365 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5366 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5367 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5368 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5339, %5365, %5366, %5359, %5367), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5369 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5370 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5371 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5372 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.108 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5368, %5369, %5370, %5371, %5372), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5374 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5375 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5376 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.107 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5338, %5374, %5375, %5358, %5376), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5378 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.108), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.41 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.8, %5378), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5380 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.29 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.41, %bias.107, %5380), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5382 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.8 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.8, %5382), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %5384 : int = aten::Int(%_end.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5385 : int = aten::Int(%_end.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5386 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5387 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5388 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5339, %5386, %5357, %5385, %5387), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5389 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5390 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5391 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5392 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.109 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5388, %5389, %5390, %5391, %5392), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5394 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5395 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.108 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5338, %5394, %5356, %5384, %5395), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5397 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.109), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.42 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%key.1, %5397), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5399 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.22 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.42, %bias.108, %5399), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5401 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.8 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.8, %5401), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %5403 : int = aten::Int(%_start.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5404 : int = aten::Int(%_start.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5405 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5406 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5407 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5408 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5339, %5405, %5404, %5406, %5407), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5409 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5410 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5411 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5412 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.110 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5408, %5409, %5410, %5411, %5412), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5414 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5415 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5416 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.109 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5338, %5414, %5403, %5415, %5416), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5418 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.110), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.43 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.9, %5418), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5420 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.22 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.43, %bias.109, %5420), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5422 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.30 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.29, %5422), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %5424 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.31 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.30, %5424), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5426 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5427 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.8, %5426), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5428 : int = aten::Int(%5427), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5429 : int[] = prim::ListConstruct(%5346, %5428, %5364), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5430 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.31, %5429), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5431 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5432 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.32 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5430, %5431, %5432), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5434 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.23 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.22, %5434), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5436 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5437 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.8, %5436), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5438 : int = aten::Int(%5437), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5439 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5440 : int[] = prim::ListConstruct(%5439, %5438, %5363), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5441 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.23, %5440), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5442 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5443 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.24 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5441, %5442, %5443), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5445 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.23 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.22, %5445), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5447 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5448 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.8, %5447), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5449 : int = aten::Int(%5448), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5450 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5451 : int[] = prim::ListConstruct(%5450, %5449, %5362), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5452 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.23, %5451), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5453 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5454 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.24 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5452, %5453, %5454), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5456 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %5457 : int = aten::size(%k.24, %5456), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.8 : Long(device=cpu) = prim::NumToTensor(%5457), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5459 : int = aten::Int(%src_len.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5460 : int = aten::Int(%src_len.8), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5461 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5462 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5463 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.24, %5461, %5462), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.34 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.32, %5463), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5465 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %5466 : int[] = prim::ListConstruct(%5351, %5465, %5345, %5460), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %attn_output_weights.35 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.34, %5466), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %5468 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5469 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %5468), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5470 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5471 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%5469, %5470), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5472 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.36 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.35, %5471, %5472), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %5474 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5475 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.8, %5474), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5476 : int = aten::Int(%5475), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %5477 : int[] = prim::ListConstruct(%5476, %5344, %5459), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %input.172 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.36, %5477), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5479 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5480 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %input.173 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.172, %5479, %5480), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5482 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5483 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.37 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.173, %5482, %5483), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.8 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.37, %v.24), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %5486 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5487 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5488 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.8, %5486, %5487), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5489 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5490 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%5488, %5489), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5491 : int[] = prim::ListConstruct(%5343, %5350, %5355), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn
  %input.174 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%5490, %5491), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5493 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%5337), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.44 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.174, %5493), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5495 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.175 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.44, %5335, %5495), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5497 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5498 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.2 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.175, %5497, %5498), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5500 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:228:0
  %input.176 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.8, %tgt2.2, %5500), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:228:0
  %5502 : Tensor = prim::GetAttr[name="bias"](%5169)
  %5503 : Tensor = prim::GetAttr[name="weight"](%5169)
  %5504 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5505 : int[] = prim::ListConstruct(%5504), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm2
  %5506 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5507 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.177 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.176, %5505, %5503, %5502, %5506, %5507), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5509 : Tensor = prim::GetAttr[name="bias"](%5168)
  %5510 : Tensor = prim::GetAttr[name="weight"](%5168)
  %5511 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%5510), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.45 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.177, %5511), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5513 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.178 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.45, %5509, %5513), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.179 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.178), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %5516 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5517 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.180 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.179, %5516, %5517), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5519 : Tensor = prim::GetAttr[name="bias"](%5166)
  %5520 : Tensor = prim::GetAttr[name="weight"](%5166)
  %5521 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%5520), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.46 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.180, %5521), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5523 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.181 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.46, %5519, %5523), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5525 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5526 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.3 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.181, %5525, %5526), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5528 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:231:0
  %input.182 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.177, %tgt2.3, %5528), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0 # ../../ml/detr/models/transformer.py:231:0
  %5530 : Tensor = prim::GetAttr[name="bias"](%5164)
  %5531 : Tensor = prim::GetAttr[name="weight"](%5164)
  %5532 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5533 : int[] = prim::ListConstruct(%5532), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm3
  %5534 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5535 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.183 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.182, %5533, %5531, %5530, %5534, %5535), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.0/__module.model.transformer.decoder.layers.0.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5537 : Tensor = prim::GetAttr[name="bias"](%5161)
  %5538 : Tensor = prim::GetAttr[name="weight"](%5161)
  %5539 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5540 : int[] = prim::ListConstruct(%5539), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm
  %5541 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5542 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5543 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.183, %5540, %5538, %5537, %5541, %5542), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5544 : __torch__.torch.nn.modules.normalization.___torch_mangle_76.LayerNorm = prim::GetAttr[name="norm3"](%5160)
  %5545 : __torch__.torch.nn.modules.dropout.___torch_mangle_79.Dropout = prim::GetAttr[name="dropout3"](%5160)
  %5546 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Linear = prim::GetAttr[name="linear2"](%5160)
  %5547 : __torch__.torch.nn.modules.dropout.___torch_mangle_72.Dropout = prim::GetAttr[name="dropout"](%5160)
  %5548 : __torch__.torch.nn.modules.linear.___torch_mangle_71.Linear = prim::GetAttr[name="linear1"](%5160)
  %5549 : __torch__.torch.nn.modules.normalization.___torch_mangle_75.LayerNorm = prim::GetAttr[name="norm2"](%5160)
  %5550 : __torch__.torch.nn.modules.dropout.___torch_mangle_78.Dropout = prim::GetAttr[name="dropout2"](%5160)
  %5551 : __torch__.torch.nn.modules.activation.___torch_mangle_70.MultiheadAttention = prim::GetAttr[name="multihead_attn"](%5160)
  %5552 : __torch__.torch.nn.modules.normalization.___torch_mangle_74.LayerNorm = prim::GetAttr[name="norm1"](%5160)
  %5553 : __torch__.torch.nn.modules.dropout.___torch_mangle_77.Dropout = prim::GetAttr[name="dropout1"](%5160)
  %5554 : __torch__.torch.nn.modules.activation.___torch_mangle_68.MultiheadAttention = prim::GetAttr[name="self_attn"](%5160)
  %5555 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:210:0
  %query.9 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.183, %query_embed, %5555), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:210:0
  %5557 : __torch__.torch.nn.modules.linear.___torch_mangle_67._LinearWithBias = prim::GetAttr[name="out_proj"](%5554)
  %5558 : Tensor = prim::GetAttr[name="bias"](%5557)
  %5559 : __torch__.torch.nn.modules.linear.___torch_mangle_67._LinearWithBias = prim::GetAttr[name="out_proj"](%5554)
  %5560 : Tensor = prim::GetAttr[name="weight"](%5559)
  %5561 : Tensor = prim::GetAttr[name="in_proj_bias"](%5554)
  %5562 : Tensor = prim::GetAttr[name="in_proj_weight"](%5554)
  %5563 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5564 : int = aten::size(%query.9, %5563), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.9 : Long(device=cpu) = prim::NumToTensor(%5564), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5566 : int = aten::Int(%tgt_len.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5567 : int = aten::Int(%tgt_len.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5568 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5569 : int = aten::size(%query.9, %5568), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.9 : Long(device=cpu) = prim::NumToTensor(%5569), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5571 : int = aten::Int(%bsz.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5572 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5573 : int = aten::size(%query.9, %5572), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.9 : Long(device=cpu) = prim::NumToTensor(%5573), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5575 : int = aten::Int(%embed_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5576 : int = aten::Int(%embed_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5577 : int = aten::Int(%embed_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5578 : int = aten::Int(%embed_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5579 : int = aten::Int(%embed_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5580 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.9 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.9, %5580), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %5582 : int = aten::Int(%head_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5583 : int = aten::Int(%head_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5584 : int = aten::Int(%head_dim.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5585 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5586 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5587 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5588 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5562, %5585, %5586, %5579, %5587), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5589 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5590 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5591 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5592 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.117 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5588, %5589, %5590, %5591, %5592), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5594 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5595 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5596 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.116 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5561, %5594, %5595, %5578, %5596), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5598 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.117), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.47 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.9, %5598), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5600 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.33 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.47, %bias.116, %5600), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5602 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.9 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.9, %5602), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %5604 : int = aten::Int(%_end.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5605 : int = aten::Int(%_end.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5606 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5607 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5608 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5562, %5606, %5577, %5605, %5607), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5609 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5610 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5611 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5612 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.118 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5608, %5609, %5610, %5611, %5612), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5614 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5615 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.117 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5561, %5614, %5576, %5604, %5615), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5617 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.118), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.48 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.9, %5617), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5619 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.25 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.48, %bias.117, %5619), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5621 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.9 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.9, %5621), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %5623 : int = aten::Int(%_start.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5624 : int = aten::Int(%_start.9), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5625 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5626 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5627 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5628 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5562, %5625, %5624, %5626, %5627), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5629 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5630 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5631 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5632 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.119 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5628, %5629, %5630, %5631, %5632), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5634 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5635 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5636 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.118 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5561, %5634, %5623, %5635, %5636), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5638 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.119), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.49 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.183, %5638), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5640 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.25 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.49, %bias.118, %5640), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5642 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.34 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.33, %5642), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %5644 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.35 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.34, %5644), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5646 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5647 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.9, %5646), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5648 : int = aten::Int(%5647), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5649 : int[] = prim::ListConstruct(%5567, %5648, %5584), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5650 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.35, %5649), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5651 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5652 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.36 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5650, %5651, %5652), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5654 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.26 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.25, %5654), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5656 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5657 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.9, %5656), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5658 : int = aten::Int(%5657), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5659 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5660 : int[] = prim::ListConstruct(%5659, %5658, %5583), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5661 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.26, %5660), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5662 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5663 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.27 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5661, %5662, %5663), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5665 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.26 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.25, %5665), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5667 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5668 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.9, %5667), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5669 : int = aten::Int(%5668), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5670 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5671 : int[] = prim::ListConstruct(%5670, %5669, %5582), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %5672 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.26, %5671), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5673 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5674 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.27 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5672, %5673, %5674), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5676 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5677 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5678 : Float(8:32, 32:1, 100:256, requires_grad=0, device=cpu) = aten::transpose(%k.27, %5676, %5677), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.39 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::bmm(%q.36, %5678), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5680 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5681 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %input.184 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::softmax(%attn_output_weights.39, %5680, %5681), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5683 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5684 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.40 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::dropout(%input.184, %5683, %5684), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.9 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.40, %v.27), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %5687 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5688 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5689 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.9, %5687, %5688), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5690 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5691 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%5689, %5690), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5692 : int[] = prim::ListConstruct(%5566, %5571, %5575), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn
  %input.185 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%5691, %5692), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5694 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%5560), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.50 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.185, %5694), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5696 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.186 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.50, %5558, %5696), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5698 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5699 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.4 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.186, %5698, %5699), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5701 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:222:0
  %input.187 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.183, %tgt2.4, %5701), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:222:0
  %5703 : Tensor = prim::GetAttr[name="bias"](%5552)
  %5704 : Tensor = prim::GetAttr[name="weight"](%5552)
  %5705 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5706 : int[] = prim::ListConstruct(%5705), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm1
  %5707 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5708 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.10 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.187, %5706, %5704, %5703, %5707, %5708), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5710 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:210:0
  %query.10 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.10, %query_embed, %5710), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:210:0
  %5712 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:210:0
  %key.2 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.9, %pos, %5712), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:210:0
  %5714 : __torch__.torch.nn.modules.linear.___torch_mangle_69._LinearWithBias = prim::GetAttr[name="out_proj"](%5551)
  %5715 : Tensor = prim::GetAttr[name="bias"](%5714)
  %5716 : __torch__.torch.nn.modules.linear.___torch_mangle_69._LinearWithBias = prim::GetAttr[name="out_proj"](%5551)
  %5717 : Tensor = prim::GetAttr[name="weight"](%5716)
  %5718 : Tensor = prim::GetAttr[name="in_proj_bias"](%5551)
  %5719 : Tensor = prim::GetAttr[name="in_proj_weight"](%5551)
  %5720 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5721 : int = aten::size(%query.10, %5720), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.10 : Long(device=cpu) = prim::NumToTensor(%5721), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5723 : int = aten::Int(%tgt_len.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5724 : int = aten::Int(%tgt_len.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5725 : int = aten::Int(%tgt_len.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5726 : int = aten::Int(%tgt_len.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5727 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5728 : int = aten::size(%query.10, %5727), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.10 : Long(device=cpu) = prim::NumToTensor(%5728), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5730 : int = aten::Int(%bsz.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5731 : int = aten::Int(%bsz.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5732 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5733 : int = aten::size(%query.10, %5732), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.10 : Long(device=cpu) = prim::NumToTensor(%5733), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5735 : int = aten::Int(%embed_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5736 : int = aten::Int(%embed_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5737 : int = aten::Int(%embed_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5738 : int = aten::Int(%embed_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5739 : int = aten::Int(%embed_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5740 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.10 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.10, %5740), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %5742 : int = aten::Int(%head_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5743 : int = aten::Int(%head_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5744 : int = aten::Int(%head_dim.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5745 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5746 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5747 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5748 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5719, %5745, %5746, %5739, %5747), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5749 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5750 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5751 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5752 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.122 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5748, %5749, %5750, %5751, %5752), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5754 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5755 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5756 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.121 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5718, %5754, %5755, %5738, %5756), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5758 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.122), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.51 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.10, %5758), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5760 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.37 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.51, %bias.121, %5760), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5762 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.10 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.10, %5762), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %5764 : int = aten::Int(%_end.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5765 : int = aten::Int(%_end.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5766 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5767 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5768 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5719, %5766, %5737, %5765, %5767), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5769 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5770 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5771 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5772 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.123 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5768, %5769, %5770, %5771, %5772), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5774 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5775 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.122 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5718, %5774, %5736, %5764, %5775), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5777 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.123), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.52 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%key.2, %5777), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5779 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.28 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.52, %bias.122, %5779), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5781 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.10 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.10, %5781), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %5783 : int = aten::Int(%_start.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5784 : int = aten::Int(%_start.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5785 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5786 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5787 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5788 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5719, %5785, %5784, %5786, %5787), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5789 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5790 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5791 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5792 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.124 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5788, %5789, %5790, %5791, %5792), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %5794 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5795 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5796 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.123 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5718, %5794, %5783, %5795, %5796), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %5798 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.124), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.53 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.9, %5798), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5800 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.28 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.53, %bias.123, %5800), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5802 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.38 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.37, %5802), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %5804 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.39 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.38, %5804), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5806 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5807 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.10, %5806), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5808 : int = aten::Int(%5807), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5809 : int[] = prim::ListConstruct(%5726, %5808, %5744), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5810 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.39, %5809), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5811 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5812 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.40 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5810, %5811, %5812), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %5814 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.29 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.28, %5814), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5816 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5817 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.10, %5816), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5818 : int = aten::Int(%5817), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5819 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5820 : int[] = prim::ListConstruct(%5819, %5818, %5743), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5821 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.29, %5820), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5822 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5823 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.30 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5821, %5822, %5823), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %5825 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.29 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.28, %5825), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5827 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5828 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.10, %5827), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5829 : int = aten::Int(%5828), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5830 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5831 : int[] = prim::ListConstruct(%5830, %5829, %5742), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5832 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.29, %5831), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5833 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5834 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.30 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%5832, %5833, %5834), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %5836 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %5837 : int = aten::size(%k.30, %5836), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.10 : Long(device=cpu) = prim::NumToTensor(%5837), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5839 : int = aten::Int(%src_len.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5840 : int = aten::Int(%src_len.10), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5841 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5842 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5843 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.30, %5841, %5842), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.42 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.40, %5843), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %5845 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %5846 : int[] = prim::ListConstruct(%5731, %5845, %5725, %5840), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %attn_output_weights.43 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.42, %5846), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %5848 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5849 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %5848), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5850 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5851 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%5849, %5850), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %5852 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.44 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.43, %5851, %5852), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %5854 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5855 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.10, %5854), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5856 : int = aten::Int(%5855), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %5857 : int[] = prim::ListConstruct(%5856, %5724, %5839), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %input.188 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.44, %5857), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %5859 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5860 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %input.189 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.188, %5859, %5860), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %5862 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5863 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.45 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.189, %5862, %5863), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.10 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.45, %v.30), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %5866 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5867 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5868 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.10, %5866, %5867), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5869 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5870 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%5868, %5869), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5871 : int[] = prim::ListConstruct(%5723, %5730, %5735), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn
  %input.190 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%5870, %5871), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %5873 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%5717), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.54 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.190, %5873), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5875 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.191 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.54, %5715, %5875), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5877 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5878 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.5 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.191, %5877, %5878), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5880 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:228:0
  %input.192 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.10, %tgt2.5, %5880), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:228:0
  %5882 : Tensor = prim::GetAttr[name="bias"](%5549)
  %5883 : Tensor = prim::GetAttr[name="weight"](%5549)
  %5884 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5885 : int[] = prim::ListConstruct(%5884), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm2
  %5886 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5887 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.193 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.192, %5885, %5883, %5882, %5886, %5887), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5889 : Tensor = prim::GetAttr[name="bias"](%5548)
  %5890 : Tensor = prim::GetAttr[name="weight"](%5548)
  %5891 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%5890), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.55 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.193, %5891), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5893 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.194 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.55, %5889, %5893), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.195 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.194), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %5896 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5897 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.196 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.195, %5896, %5897), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5899 : Tensor = prim::GetAttr[name="bias"](%5546)
  %5900 : Tensor = prim::GetAttr[name="weight"](%5546)
  %5901 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%5900), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.56 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.196, %5901), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5903 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.197 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.56, %5899, %5903), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5905 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5906 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.6 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.197, %5905, %5906), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %5908 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:231:0
  %input.198 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.193, %tgt2.6, %5908), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1 # ../../ml/detr/models/transformer.py:231:0
  %5910 : Tensor = prim::GetAttr[name="bias"](%5544)
  %5911 : Tensor = prim::GetAttr[name="weight"](%5544)
  %5912 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5913 : int[] = prim::ListConstruct(%5912), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm3
  %5914 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5915 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.199 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.198, %5913, %5911, %5910, %5914, %5915), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.1/__module.model.transformer.decoder.layers.1.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5917 : Tensor = prim::GetAttr[name="bias"](%5161)
  %5918 : Tensor = prim::GetAttr[name="weight"](%5161)
  %5919 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5920 : int[] = prim::ListConstruct(%5919), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm
  %5921 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5922 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5923 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.199, %5920, %5918, %5917, %5921, %5922), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %5924 : __torch__.torch.nn.modules.normalization.___torch_mangle_90.LayerNorm = prim::GetAttr[name="norm3"](%5158)
  %5925 : __torch__.torch.nn.modules.dropout.___torch_mangle_93.Dropout = prim::GetAttr[name="dropout3"](%5158)
  %5926 : __torch__.torch.nn.modules.linear.___torch_mangle_87.Linear = prim::GetAttr[name="linear2"](%5158)
  %5927 : __torch__.torch.nn.modules.dropout.___torch_mangle_86.Dropout = prim::GetAttr[name="dropout"](%5158)
  %5928 : __torch__.torch.nn.modules.linear.___torch_mangle_85.Linear = prim::GetAttr[name="linear1"](%5158)
  %5929 : __torch__.torch.nn.modules.normalization.___torch_mangle_89.LayerNorm = prim::GetAttr[name="norm2"](%5158)
  %5930 : __torch__.torch.nn.modules.dropout.___torch_mangle_92.Dropout = prim::GetAttr[name="dropout2"](%5158)
  %5931 : __torch__.torch.nn.modules.activation.___torch_mangle_84.MultiheadAttention = prim::GetAttr[name="multihead_attn"](%5158)
  %5932 : __torch__.torch.nn.modules.normalization.___torch_mangle_88.LayerNorm = prim::GetAttr[name="norm1"](%5158)
  %5933 : __torch__.torch.nn.modules.dropout.___torch_mangle_91.Dropout = prim::GetAttr[name="dropout1"](%5158)
  %5934 : __torch__.torch.nn.modules.activation.___torch_mangle_82.MultiheadAttention = prim::GetAttr[name="self_attn"](%5158)
  %5935 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:210:0
  %query.11 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.199, %query_embed, %5935), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:210:0
  %5937 : __torch__.torch.nn.modules.linear.___torch_mangle_81._LinearWithBias = prim::GetAttr[name="out_proj"](%5934)
  %5938 : Tensor = prim::GetAttr[name="bias"](%5937)
  %5939 : __torch__.torch.nn.modules.linear.___torch_mangle_81._LinearWithBias = prim::GetAttr[name="out_proj"](%5934)
  %5940 : Tensor = prim::GetAttr[name="weight"](%5939)
  %5941 : Tensor = prim::GetAttr[name="in_proj_bias"](%5934)
  %5942 : Tensor = prim::GetAttr[name="in_proj_weight"](%5934)
  %5943 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5944 : int = aten::size(%query.11, %5943), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.11 : Long(device=cpu) = prim::NumToTensor(%5944), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5946 : int = aten::Int(%tgt_len.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5947 : int = aten::Int(%tgt_len.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5948 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5949 : int = aten::size(%query.11, %5948), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.11 : Long(device=cpu) = prim::NumToTensor(%5949), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5951 : int = aten::Int(%bsz.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5952 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %5953 : int = aten::size(%query.11, %5952), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.11 : Long(device=cpu) = prim::NumToTensor(%5953), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5955 : int = aten::Int(%embed_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5956 : int = aten::Int(%embed_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5957 : int = aten::Int(%embed_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5958 : int = aten::Int(%embed_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5959 : int = aten::Int(%embed_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5960 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.11 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.11, %5960), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %5962 : int = aten::Int(%head_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5963 : int = aten::Int(%head_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5964 : int = aten::Int(%head_dim.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5965 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5966 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5967 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5968 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5942, %5965, %5966, %5959, %5967), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5969 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5970 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5971 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5972 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.130 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5968, %5969, %5970, %5971, %5972), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %5974 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5975 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5976 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.129 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5941, %5974, %5975, %5958, %5976), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %5978 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.130), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.57 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.11, %5978), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5980 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.41 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.57, %bias.129, %5980), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %5982 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.11 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.11, %5982), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %5984 : int = aten::Int(%_end.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5985 : int = aten::Int(%_end.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %5986 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5987 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5988 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5942, %5986, %5957, %5985, %5987), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5989 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5990 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5991 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5992 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.131 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5988, %5989, %5990, %5991, %5992), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %5994 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5995 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.130 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5941, %5994, %5956, %5984, %5995), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %5997 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.131), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.58 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.11, %5997), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %5999 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.31 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.58, %bias.130, %5999), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6001 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.11 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.11, %6001), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %6003 : int = aten::Int(%_start.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6004 : int = aten::Int(%_start.11), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6005 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6006 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6007 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6008 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%5942, %6005, %6004, %6006, %6007), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6009 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6010 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6011 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6012 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.132 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6008, %6009, %6010, %6011, %6012), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6014 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6015 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6016 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.131 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%5941, %6014, %6003, %6015, %6016), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6018 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.132), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.59 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.199, %6018), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6020 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.31 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.59, %bias.131, %6020), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6022 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.42 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.41, %6022), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %6024 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.43 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.42, %6024), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6026 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6027 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.11, %6026), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6028 : int = aten::Int(%6027), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6029 : int[] = prim::ListConstruct(%5947, %6028, %5964), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6030 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.43, %6029), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6031 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6032 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.44 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6030, %6031, %6032), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6034 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.32 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.31, %6034), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6036 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6037 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.11, %6036), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6038 : int = aten::Int(%6037), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6039 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6040 : int[] = prim::ListConstruct(%6039, %6038, %5963), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6041 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.32, %6040), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6042 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6043 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.33 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6041, %6042, %6043), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6045 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.32 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.31, %6045), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6047 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6048 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.11, %6047), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6049 : int = aten::Int(%6048), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6050 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6051 : int[] = prim::ListConstruct(%6050, %6049, %5962), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %6052 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.32, %6051), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6053 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6054 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.33 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6052, %6053, %6054), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6056 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6057 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6058 : Float(8:32, 32:1, 100:256, requires_grad=0, device=cpu) = aten::transpose(%k.33, %6056, %6057), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.47 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::bmm(%q.44, %6058), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6060 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6061 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %input.200 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::softmax(%attn_output_weights.47, %6060, %6061), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6063 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6064 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.48 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::dropout(%input.200, %6063, %6064), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.11 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.48, %v.33), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %6067 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6068 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6069 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.11, %6067, %6068), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6070 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6071 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%6069, %6070), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6072 : int[] = prim::ListConstruct(%5946, %5951, %5955), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn
  %input.201 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%6071, %6072), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6074 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%5940), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.60 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.201, %6074), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6076 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.202 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.60, %5938, %6076), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6078 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6079 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.7 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.202, %6078, %6079), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6081 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:222:0
  %input.203 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.199, %tgt2.7, %6081), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:222:0
  %6083 : Tensor = prim::GetAttr[name="bias"](%5932)
  %6084 : Tensor = prim::GetAttr[name="weight"](%5932)
  %6085 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6086 : int[] = prim::ListConstruct(%6085), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm1
  %6087 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6088 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.11 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.203, %6086, %6084, %6083, %6087, %6088), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6090 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:210:0
  %query.12 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.11, %query_embed, %6090), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:210:0
  %6092 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:210:0
  %key.3 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.9, %pos, %6092), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:210:0
  %6094 : __torch__.torch.nn.modules.linear.___torch_mangle_83._LinearWithBias = prim::GetAttr[name="out_proj"](%5931)
  %6095 : Tensor = prim::GetAttr[name="bias"](%6094)
  %6096 : __torch__.torch.nn.modules.linear.___torch_mangle_83._LinearWithBias = prim::GetAttr[name="out_proj"](%5931)
  %6097 : Tensor = prim::GetAttr[name="weight"](%6096)
  %6098 : Tensor = prim::GetAttr[name="in_proj_bias"](%5931)
  %6099 : Tensor = prim::GetAttr[name="in_proj_weight"](%5931)
  %6100 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6101 : int = aten::size(%query.12, %6100), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.12 : Long(device=cpu) = prim::NumToTensor(%6101), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6103 : int = aten::Int(%tgt_len.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6104 : int = aten::Int(%tgt_len.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6105 : int = aten::Int(%tgt_len.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6106 : int = aten::Int(%tgt_len.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6107 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6108 : int = aten::size(%query.12, %6107), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.12 : Long(device=cpu) = prim::NumToTensor(%6108), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6110 : int = aten::Int(%bsz.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6111 : int = aten::Int(%bsz.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6112 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6113 : int = aten::size(%query.12, %6112), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.12 : Long(device=cpu) = prim::NumToTensor(%6113), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6115 : int = aten::Int(%embed_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6116 : int = aten::Int(%embed_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6117 : int = aten::Int(%embed_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6118 : int = aten::Int(%embed_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6119 : int = aten::Int(%embed_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6120 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.12 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.12, %6120), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %6122 : int = aten::Int(%head_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6123 : int = aten::Int(%head_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6124 : int = aten::Int(%head_dim.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6125 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6126 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6127 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6128 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6099, %6125, %6126, %6119, %6127), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6129 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6130 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6131 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.135 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6128, %6129, %6130, %6131, %6132), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6134 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6135 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6136 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.134 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6098, %6134, %6135, %6118, %6136), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6138 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.135), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.61 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.12, %6138), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6140 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.45 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.61, %bias.134, %6140), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6142 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.12 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.12, %6142), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %6144 : int = aten::Int(%_end.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6145 : int = aten::Int(%_end.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6146 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6147 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6148 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6099, %6146, %6117, %6145, %6147), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6149 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6150 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6151 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6152 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.136 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6148, %6149, %6150, %6151, %6152), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6154 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6155 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.135 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6098, %6154, %6116, %6144, %6155), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6157 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.136), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.62 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%key.3, %6157), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6159 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.34 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.62, %bias.135, %6159), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6161 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.12 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.12, %6161), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %6163 : int = aten::Int(%_start.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6164 : int = aten::Int(%_start.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6165 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6166 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6167 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6168 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6099, %6165, %6164, %6166, %6167), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6169 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6170 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6171 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6172 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.137 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6168, %6169, %6170, %6171, %6172), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6174 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6175 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6176 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.136 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6098, %6174, %6163, %6175, %6176), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6178 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.137), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.63 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.9, %6178), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6180 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.34 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.63, %bias.136, %6180), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6182 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.46 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.45, %6182), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %6184 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.47 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.46, %6184), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6186 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6187 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.12, %6186), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6188 : int = aten::Int(%6187), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6189 : int[] = prim::ListConstruct(%6106, %6188, %6124), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6190 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.47, %6189), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6191 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6192 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.48 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6190, %6191, %6192), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6194 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.35 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.34, %6194), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6196 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6197 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.12, %6196), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6198 : int = aten::Int(%6197), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6199 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6200 : int[] = prim::ListConstruct(%6199, %6198, %6123), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6201 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.35, %6200), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6202 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6203 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.36 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6201, %6202, %6203), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6205 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.35 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.34, %6205), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6207 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6208 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.12, %6207), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6209 : int = aten::Int(%6208), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6210 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6211 : int[] = prim::ListConstruct(%6210, %6209, %6122), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6212 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.35, %6211), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6213 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6214 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.36 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6212, %6213, %6214), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6216 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %6217 : int = aten::size(%k.36, %6216), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.12 : Long(device=cpu) = prim::NumToTensor(%6217), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6219 : int = aten::Int(%src_len.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6220 : int = aten::Int(%src_len.12), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6221 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6222 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6223 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.36, %6221, %6222), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.50 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.48, %6223), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6225 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %6226 : int[] = prim::ListConstruct(%6111, %6225, %6105, %6220), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %attn_output_weights.51 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.50, %6226), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %6228 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6229 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %6228), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6230 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6231 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%6229, %6230), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6232 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.52 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.51, %6231, %6232), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %6234 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6235 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.12, %6234), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6236 : int = aten::Int(%6235), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %6237 : int[] = prim::ListConstruct(%6236, %6104, %6219), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %input.204 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.52, %6237), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6239 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6240 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %input.205 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.204, %6239, %6240), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6242 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6243 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.53 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.205, %6242, %6243), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.12 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.53, %v.36), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %6246 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6248 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.12, %6246, %6247), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6249 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6250 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%6248, %6249), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6251 : int[] = prim::ListConstruct(%6103, %6110, %6115), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn
  %input.206 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%6250, %6251), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6253 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%6097), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.64 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.206, %6253), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6255 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.207 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.64, %6095, %6255), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6257 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6258 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.8 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.207, %6257, %6258), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6260 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:228:0
  %input.208 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.11, %tgt2.8, %6260), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:228:0
  %6262 : Tensor = prim::GetAttr[name="bias"](%5929)
  %6263 : Tensor = prim::GetAttr[name="weight"](%5929)
  %6264 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6265 : int[] = prim::ListConstruct(%6264), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm2
  %6266 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6267 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.209 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.208, %6265, %6263, %6262, %6266, %6267), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6269 : Tensor = prim::GetAttr[name="bias"](%5928)
  %6270 : Tensor = prim::GetAttr[name="weight"](%5928)
  %6271 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%6270), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.65 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.209, %6271), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6273 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.210 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.65, %6269, %6273), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.211 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.210), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %6276 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6277 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.212 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.211, %6276, %6277), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6279 : Tensor = prim::GetAttr[name="bias"](%5926)
  %6280 : Tensor = prim::GetAttr[name="weight"](%5926)
  %6281 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%6280), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.66 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.212, %6281), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6283 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.213 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.66, %6279, %6283), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6285 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6286 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.9 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.213, %6285, %6286), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6288 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:231:0
  %input.214 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.209, %tgt2.9, %6288), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2 # ../../ml/detr/models/transformer.py:231:0
  %6290 : Tensor = prim::GetAttr[name="bias"](%5924)
  %6291 : Tensor = prim::GetAttr[name="weight"](%5924)
  %6292 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6293 : int[] = prim::ListConstruct(%6292), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm3
  %6294 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6295 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.215 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.214, %6293, %6291, %6290, %6294, %6295), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.2/__module.model.transformer.decoder.layers.2.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6297 : Tensor = prim::GetAttr[name="bias"](%5161)
  %6298 : Tensor = prim::GetAttr[name="weight"](%5161)
  %6299 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6300 : int[] = prim::ListConstruct(%6299), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm
  %6301 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6302 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6303 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.215, %6300, %6298, %6297, %6301, %6302), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6304 : __torch__.torch.nn.modules.normalization.___torch_mangle_104.LayerNorm = prim::GetAttr[name="norm3"](%5156)
  %6305 : __torch__.torch.nn.modules.dropout.___torch_mangle_107.Dropout = prim::GetAttr[name="dropout3"](%5156)
  %6306 : __torch__.torch.nn.modules.linear.___torch_mangle_101.Linear = prim::GetAttr[name="linear2"](%5156)
  %6307 : __torch__.torch.nn.modules.dropout.___torch_mangle_100.Dropout = prim::GetAttr[name="dropout"](%5156)
  %6308 : __torch__.torch.nn.modules.linear.___torch_mangle_99.Linear = prim::GetAttr[name="linear1"](%5156)
  %6309 : __torch__.torch.nn.modules.normalization.___torch_mangle_103.LayerNorm = prim::GetAttr[name="norm2"](%5156)
  %6310 : __torch__.torch.nn.modules.dropout.___torch_mangle_106.Dropout = prim::GetAttr[name="dropout2"](%5156)
  %6311 : __torch__.torch.nn.modules.activation.___torch_mangle_98.MultiheadAttention = prim::GetAttr[name="multihead_attn"](%5156)
  %6312 : __torch__.torch.nn.modules.normalization.___torch_mangle_102.LayerNorm = prim::GetAttr[name="norm1"](%5156)
  %6313 : __torch__.torch.nn.modules.dropout.___torch_mangle_105.Dropout = prim::GetAttr[name="dropout1"](%5156)
  %6314 : __torch__.torch.nn.modules.activation.___torch_mangle_96.MultiheadAttention = prim::GetAttr[name="self_attn"](%5156)
  %6315 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:210:0
  %query.13 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.215, %query_embed, %6315), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:210:0
  %6317 : __torch__.torch.nn.modules.linear.___torch_mangle_95._LinearWithBias = prim::GetAttr[name="out_proj"](%6314)
  %6318 : Tensor = prim::GetAttr[name="bias"](%6317)
  %6319 : __torch__.torch.nn.modules.linear.___torch_mangle_95._LinearWithBias = prim::GetAttr[name="out_proj"](%6314)
  %6320 : Tensor = prim::GetAttr[name="weight"](%6319)
  %6321 : Tensor = prim::GetAttr[name="in_proj_bias"](%6314)
  %6322 : Tensor = prim::GetAttr[name="in_proj_weight"](%6314)
  %6323 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6324 : int = aten::size(%query.13, %6323), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.13 : Long(device=cpu) = prim::NumToTensor(%6324), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6326 : int = aten::Int(%tgt_len.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6327 : int = aten::Int(%tgt_len.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6328 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6329 : int = aten::size(%query.13, %6328), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.13 : Long(device=cpu) = prim::NumToTensor(%6329), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6331 : int = aten::Int(%bsz.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6332 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6333 : int = aten::size(%query.13, %6332), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.13 : Long(device=cpu) = prim::NumToTensor(%6333), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6335 : int = aten::Int(%embed_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6336 : int = aten::Int(%embed_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6337 : int = aten::Int(%embed_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6338 : int = aten::Int(%embed_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6339 : int = aten::Int(%embed_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6340 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.13 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.13, %6340), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %6342 : int = aten::Int(%head_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6343 : int = aten::Int(%head_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6344 : int = aten::Int(%head_dim.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6345 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6346 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6347 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6348 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6322, %6345, %6346, %6339, %6347), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6349 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6350 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6351 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6352 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.143 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6348, %6349, %6350, %6351, %6352), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6354 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6355 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6356 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.142 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6321, %6354, %6355, %6338, %6356), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6358 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.143), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.67 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.13, %6358), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6360 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.49 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.67, %bias.142, %6360), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6362 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.13 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.13, %6362), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %6364 : int = aten::Int(%_end.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6365 : int = aten::Int(%_end.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6366 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6367 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6368 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6322, %6366, %6337, %6365, %6367), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6369 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6370 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6371 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6372 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.144 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6368, %6369, %6370, %6371, %6372), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6374 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6375 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.143 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6321, %6374, %6336, %6364, %6375), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6377 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.144), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.68 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.13, %6377), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6379 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.37 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.68, %bias.143, %6379), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6381 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.13 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.13, %6381), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %6383 : int = aten::Int(%_start.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6384 : int = aten::Int(%_start.13), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6385 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6386 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6387 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6388 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6322, %6385, %6384, %6386, %6387), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6389 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6390 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6391 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6392 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.145 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6388, %6389, %6390, %6391, %6392), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6394 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6395 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6396 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.144 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6321, %6394, %6383, %6395, %6396), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6398 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.145), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.69 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.215, %6398), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6400 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.37 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.69, %bias.144, %6400), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6402 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.50 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.49, %6402), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %6404 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.51 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.50, %6404), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6406 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6407 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.13, %6406), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6408 : int = aten::Int(%6407), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6409 : int[] = prim::ListConstruct(%6327, %6408, %6344), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6410 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.51, %6409), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6411 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6412 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.52 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6410, %6411, %6412), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6414 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.38 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.37, %6414), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6416 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6417 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.13, %6416), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6418 : int = aten::Int(%6417), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6419 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6420 : int[] = prim::ListConstruct(%6419, %6418, %6343), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6421 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.38, %6420), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6422 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6423 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.39 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6421, %6422, %6423), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6425 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.38 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.37, %6425), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6427 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6428 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.13, %6427), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6429 : int = aten::Int(%6428), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6430 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6431 : int[] = prim::ListConstruct(%6430, %6429, %6342), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %6432 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.38, %6431), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6433 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6434 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.39 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6432, %6433, %6434), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6436 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6437 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6438 : Float(8:32, 32:1, 100:256, requires_grad=0, device=cpu) = aten::transpose(%k.39, %6436, %6437), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.55 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::bmm(%q.52, %6438), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6440 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6441 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %input.216 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::softmax(%attn_output_weights.55, %6440, %6441), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6443 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6444 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.56 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::dropout(%input.216, %6443, %6444), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.13 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.56, %v.39), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %6447 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6448 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6449 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.13, %6447, %6448), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6450 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6451 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%6449, %6450), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6452 : int[] = prim::ListConstruct(%6326, %6331, %6335), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn
  %input.217 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%6451, %6452), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6454 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%6320), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.70 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.217, %6454), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6456 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.218 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.70, %6318, %6456), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6458 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6459 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.10 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.218, %6458, %6459), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6461 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:222:0
  %input.219 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.215, %tgt2.10, %6461), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:222:0
  %6463 : Tensor = prim::GetAttr[name="bias"](%6312)
  %6464 : Tensor = prim::GetAttr[name="weight"](%6312)
  %6465 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6466 : int[] = prim::ListConstruct(%6465), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm1
  %6467 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6468 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.12 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.219, %6466, %6464, %6463, %6467, %6468), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6470 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:210:0
  %query.14 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.12, %query_embed, %6470), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:210:0
  %6472 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:210:0
  %key.4 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.9, %pos, %6472), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:210:0
  %6474 : __torch__.torch.nn.modules.linear.___torch_mangle_97._LinearWithBias = prim::GetAttr[name="out_proj"](%6311)
  %6475 : Tensor = prim::GetAttr[name="bias"](%6474)
  %6476 : __torch__.torch.nn.modules.linear.___torch_mangle_97._LinearWithBias = prim::GetAttr[name="out_proj"](%6311)
  %6477 : Tensor = prim::GetAttr[name="weight"](%6476)
  %6478 : Tensor = prim::GetAttr[name="in_proj_bias"](%6311)
  %6479 : Tensor = prim::GetAttr[name="in_proj_weight"](%6311)
  %6480 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6481 : int = aten::size(%query.14, %6480), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.14 : Long(device=cpu) = prim::NumToTensor(%6481), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6483 : int = aten::Int(%tgt_len.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6484 : int = aten::Int(%tgt_len.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6485 : int = aten::Int(%tgt_len.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6486 : int = aten::Int(%tgt_len.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6487 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6488 : int = aten::size(%query.14, %6487), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.14 : Long(device=cpu) = prim::NumToTensor(%6488), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6490 : int = aten::Int(%bsz.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6491 : int = aten::Int(%bsz.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6492 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6493 : int = aten::size(%query.14, %6492), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.14 : Long(device=cpu) = prim::NumToTensor(%6493), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6495 : int = aten::Int(%embed_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6496 : int = aten::Int(%embed_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6497 : int = aten::Int(%embed_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6498 : int = aten::Int(%embed_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6499 : int = aten::Int(%embed_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6500 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.14 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.14, %6500), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %6502 : int = aten::Int(%head_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6503 : int = aten::Int(%head_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6504 : int = aten::Int(%head_dim.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6505 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6506 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6507 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6508 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6479, %6505, %6506, %6499, %6507), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6509 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6510 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6511 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6512 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.148 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6508, %6509, %6510, %6511, %6512), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6514 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6515 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6516 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.147 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6478, %6514, %6515, %6498, %6516), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6518 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.148), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.71 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.14, %6518), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6520 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.53 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.71, %bias.147, %6520), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6522 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.14 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.14, %6522), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %6524 : int = aten::Int(%_end.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6525 : int = aten::Int(%_end.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6526 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6527 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6528 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6479, %6526, %6497, %6525, %6527), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6529 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6530 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6531 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6532 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.149 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6528, %6529, %6530, %6531, %6532), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6534 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6535 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.148 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6478, %6534, %6496, %6524, %6535), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6537 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.149), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.72 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%key.4, %6537), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6539 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.40 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.72, %bias.148, %6539), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6541 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.14 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.14, %6541), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %6543 : int = aten::Int(%_start.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6544 : int = aten::Int(%_start.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6545 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6546 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6547 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6548 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6479, %6545, %6544, %6546, %6547), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6549 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6550 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6551 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6552 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.150 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6548, %6549, %6550, %6551, %6552), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6554 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6555 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6556 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.149 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6478, %6554, %6543, %6555, %6556), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6558 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.150), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.73 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.9, %6558), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6560 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.40 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.73, %bias.149, %6560), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6562 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.54 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.53, %6562), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %6564 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.55 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.54, %6564), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6566 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6567 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.14, %6566), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6568 : int = aten::Int(%6567), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6569 : int[] = prim::ListConstruct(%6486, %6568, %6504), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6570 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.55, %6569), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6571 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6572 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.56 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6570, %6571, %6572), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6574 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.41 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.40, %6574), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6576 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6577 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.14, %6576), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6578 : int = aten::Int(%6577), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6579 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6580 : int[] = prim::ListConstruct(%6579, %6578, %6503), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6581 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.41, %6580), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6582 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6583 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.42 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6581, %6582, %6583), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6585 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.41 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.40, %6585), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6587 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6588 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.14, %6587), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6589 : int = aten::Int(%6588), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6590 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6591 : int[] = prim::ListConstruct(%6590, %6589, %6502), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6592 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.41, %6591), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6593 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6594 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.42 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6592, %6593, %6594), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6596 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %6597 : int = aten::size(%k.42, %6596), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.14 : Long(device=cpu) = prim::NumToTensor(%6597), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6599 : int = aten::Int(%src_len.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6600 : int = aten::Int(%src_len.14), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6601 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6602 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6603 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.42, %6601, %6602), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.58 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.56, %6603), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6605 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %6606 : int[] = prim::ListConstruct(%6491, %6605, %6485, %6600), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %attn_output_weights.59 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.58, %6606), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %6608 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6609 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %6608), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6610 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6611 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%6609, %6610), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6612 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.60 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.59, %6611, %6612), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %6614 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6615 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.14, %6614), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6616 : int = aten::Int(%6615), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %6617 : int[] = prim::ListConstruct(%6616, %6484, %6599), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %input.220 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.60, %6617), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6619 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6620 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %input.221 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.220, %6619, %6620), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6622 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6623 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.61 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.221, %6622, %6623), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.14 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.61, %v.42), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %6626 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6627 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6628 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.14, %6626, %6627), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6629 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6630 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%6628, %6629), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6631 : int[] = prim::ListConstruct(%6483, %6490, %6495), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn
  %input.222 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%6630, %6631), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6633 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%6477), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.74 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.222, %6633), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6635 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.223 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.74, %6475, %6635), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6637 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6638 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.11 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.223, %6637, %6638), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6640 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:228:0
  %input.224 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.12, %tgt2.11, %6640), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:228:0
  %6642 : Tensor = prim::GetAttr[name="bias"](%6309)
  %6643 : Tensor = prim::GetAttr[name="weight"](%6309)
  %6644 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6645 : int[] = prim::ListConstruct(%6644), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm2
  %6646 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6647 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.225 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.224, %6645, %6643, %6642, %6646, %6647), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6649 : Tensor = prim::GetAttr[name="bias"](%6308)
  %6650 : Tensor = prim::GetAttr[name="weight"](%6308)
  %6651 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%6650), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.75 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.225, %6651), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6653 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.226 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.75, %6649, %6653), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.227 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.226), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %6656 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6657 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.228 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.227, %6656, %6657), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6659 : Tensor = prim::GetAttr[name="bias"](%6306)
  %6660 : Tensor = prim::GetAttr[name="weight"](%6306)
  %6661 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%6660), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.76 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.228, %6661), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6663 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.229 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.76, %6659, %6663), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6665 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6666 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.12 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.229, %6665, %6666), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6668 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:231:0
  %input.230 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.225, %tgt2.12, %6668), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3 # ../../ml/detr/models/transformer.py:231:0
  %6670 : Tensor = prim::GetAttr[name="bias"](%6304)
  %6671 : Tensor = prim::GetAttr[name="weight"](%6304)
  %6672 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6673 : int[] = prim::ListConstruct(%6672), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm3
  %6674 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6675 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.231 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.230, %6673, %6671, %6670, %6674, %6675), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.3/__module.model.transformer.decoder.layers.3.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6677 : Tensor = prim::GetAttr[name="bias"](%5161)
  %6678 : Tensor = prim::GetAttr[name="weight"](%5161)
  %6679 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6680 : int[] = prim::ListConstruct(%6679), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm
  %6681 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6682 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6683 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.231, %6680, %6678, %6677, %6681, %6682), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6684 : __torch__.torch.nn.modules.normalization.___torch_mangle_118.LayerNorm = prim::GetAttr[name="norm3"](%5154)
  %6685 : __torch__.torch.nn.modules.dropout.___torch_mangle_121.Dropout = prim::GetAttr[name="dropout3"](%5154)
  %6686 : __torch__.torch.nn.modules.linear.___torch_mangle_115.Linear = prim::GetAttr[name="linear2"](%5154)
  %6687 : __torch__.torch.nn.modules.dropout.___torch_mangle_114.Dropout = prim::GetAttr[name="dropout"](%5154)
  %6688 : __torch__.torch.nn.modules.linear.___torch_mangle_113.Linear = prim::GetAttr[name="linear1"](%5154)
  %6689 : __torch__.torch.nn.modules.normalization.___torch_mangle_117.LayerNorm = prim::GetAttr[name="norm2"](%5154)
  %6690 : __torch__.torch.nn.modules.dropout.___torch_mangle_120.Dropout = prim::GetAttr[name="dropout2"](%5154)
  %6691 : __torch__.torch.nn.modules.activation.___torch_mangle_112.MultiheadAttention = prim::GetAttr[name="multihead_attn"](%5154)
  %6692 : __torch__.torch.nn.modules.normalization.___torch_mangle_116.LayerNorm = prim::GetAttr[name="norm1"](%5154)
  %6693 : __torch__.torch.nn.modules.dropout.___torch_mangle_119.Dropout = prim::GetAttr[name="dropout1"](%5154)
  %6694 : __torch__.torch.nn.modules.activation.___torch_mangle_110.MultiheadAttention = prim::GetAttr[name="self_attn"](%5154)
  %6695 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:210:0
  %query.15 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.231, %query_embed, %6695), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:210:0
  %6697 : __torch__.torch.nn.modules.linear.___torch_mangle_109._LinearWithBias = prim::GetAttr[name="out_proj"](%6694)
  %6698 : Tensor = prim::GetAttr[name="bias"](%6697)
  %6699 : __torch__.torch.nn.modules.linear.___torch_mangle_109._LinearWithBias = prim::GetAttr[name="out_proj"](%6694)
  %6700 : Tensor = prim::GetAttr[name="weight"](%6699)
  %6701 : Tensor = prim::GetAttr[name="in_proj_bias"](%6694)
  %6702 : Tensor = prim::GetAttr[name="in_proj_weight"](%6694)
  %6703 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6704 : int = aten::size(%query.15, %6703), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.15 : Long(device=cpu) = prim::NumToTensor(%6704), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6706 : int = aten::Int(%tgt_len.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6707 : int = aten::Int(%tgt_len.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6708 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6709 : int = aten::size(%query.15, %6708), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.15 : Long(device=cpu) = prim::NumToTensor(%6709), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6711 : int = aten::Int(%bsz.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6712 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6713 : int = aten::size(%query.15, %6712), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.15 : Long(device=cpu) = prim::NumToTensor(%6713), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6715 : int = aten::Int(%embed_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6716 : int = aten::Int(%embed_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6717 : int = aten::Int(%embed_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6718 : int = aten::Int(%embed_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6719 : int = aten::Int(%embed_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6720 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.15 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.15, %6720), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %6722 : int = aten::Int(%head_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6723 : int = aten::Int(%head_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6724 : int = aten::Int(%head_dim.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6725 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6726 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6727 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6728 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6702, %6725, %6726, %6719, %6727), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6729 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6730 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6731 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6732 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.156 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6728, %6729, %6730, %6731, %6732), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6734 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6735 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6736 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.155 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6701, %6734, %6735, %6718, %6736), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6738 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.156), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.77 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.15, %6738), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6740 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.57 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.77, %bias.155, %6740), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6742 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.15 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.15, %6742), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %6744 : int = aten::Int(%_end.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6745 : int = aten::Int(%_end.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6746 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6747 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6748 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6702, %6746, %6717, %6745, %6747), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6749 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6750 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6751 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6752 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.157 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6748, %6749, %6750, %6751, %6752), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6754 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6755 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.156 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6701, %6754, %6716, %6744, %6755), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6757 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.157), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.78 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.15, %6757), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6759 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.43 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.78, %bias.156, %6759), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6761 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.15 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.15, %6761), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %6763 : int = aten::Int(%_start.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6764 : int = aten::Int(%_start.15), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6765 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6766 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6767 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6768 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6702, %6765, %6764, %6766, %6767), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6769 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6770 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6771 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6772 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.158 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6768, %6769, %6770, %6771, %6772), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6774 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6775 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6776 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.157 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6701, %6774, %6763, %6775, %6776), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6778 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.158), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.79 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.231, %6778), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6780 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.43 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.79, %bias.157, %6780), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6782 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.58 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.57, %6782), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %6784 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.59 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.58, %6784), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6786 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6787 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.15, %6786), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6788 : int = aten::Int(%6787), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6789 : int[] = prim::ListConstruct(%6707, %6788, %6724), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6790 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.59, %6789), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6791 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6792 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.60 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6790, %6791, %6792), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6794 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.44 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.43, %6794), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6796 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6797 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.15, %6796), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6798 : int = aten::Int(%6797), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6799 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6800 : int[] = prim::ListConstruct(%6799, %6798, %6723), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6801 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.44, %6800), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6802 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6803 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.45 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6801, %6802, %6803), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6805 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.44 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.43, %6805), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6807 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6808 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.15, %6807), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6809 : int = aten::Int(%6808), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6810 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6811 : int[] = prim::ListConstruct(%6810, %6809, %6722), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %6812 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.44, %6811), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6813 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6814 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.45 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6812, %6813, %6814), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6816 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6817 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6818 : Float(8:32, 32:1, 100:256, requires_grad=0, device=cpu) = aten::transpose(%k.45, %6816, %6817), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.63 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::bmm(%q.60, %6818), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6820 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6821 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %input.232 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::softmax(%attn_output_weights.63, %6820, %6821), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %6823 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6824 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.64 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::dropout(%input.232, %6823, %6824), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.15 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.64, %v.45), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %6827 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6828 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6829 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.15, %6827, %6828), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6830 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6831 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%6829, %6830), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6832 : int[] = prim::ListConstruct(%6706, %6711, %6715), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn
  %input.233 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%6831, %6832), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %6834 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%6700), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.80 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.233, %6834), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6836 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.234 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.80, %6698, %6836), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6838 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6839 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.13 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.234, %6838, %6839), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %6841 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:222:0
  %input.235 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.231, %tgt2.13, %6841), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:222:0
  %6843 : Tensor = prim::GetAttr[name="bias"](%6692)
  %6844 : Tensor = prim::GetAttr[name="weight"](%6692)
  %6845 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6846 : int[] = prim::ListConstruct(%6845), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm1
  %6847 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6848 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor.13 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.235, %6846, %6844, %6843, %6847, %6848), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %6850 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:210:0
  %query.16 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.13, %query_embed, %6850), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:210:0
  %6852 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:210:0
  %key.5 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.9, %pos, %6852), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:210:0
  %6854 : __torch__.torch.nn.modules.linear.___torch_mangle_111._LinearWithBias = prim::GetAttr[name="out_proj"](%6691)
  %6855 : Tensor = prim::GetAttr[name="bias"](%6854)
  %6856 : __torch__.torch.nn.modules.linear.___torch_mangle_111._LinearWithBias = prim::GetAttr[name="out_proj"](%6691)
  %6857 : Tensor = prim::GetAttr[name="weight"](%6856)
  %6858 : Tensor = prim::GetAttr[name="in_proj_bias"](%6691)
  %6859 : Tensor = prim::GetAttr[name="in_proj_weight"](%6691)
  %6860 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6861 : int = aten::size(%query.16, %6860), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.16 : Long(device=cpu) = prim::NumToTensor(%6861), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6863 : int = aten::Int(%tgt_len.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6864 : int = aten::Int(%tgt_len.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6865 : int = aten::Int(%tgt_len.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6866 : int = aten::Int(%tgt_len.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6867 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6868 : int = aten::size(%query.16, %6867), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.16 : Long(device=cpu) = prim::NumToTensor(%6868), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6870 : int = aten::Int(%bsz.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6871 : int = aten::Int(%bsz.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6872 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %6873 : int = aten::size(%query.16, %6872), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.16 : Long(device=cpu) = prim::NumToTensor(%6873), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6875 : int = aten::Int(%embed_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6876 : int = aten::Int(%embed_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6877 : int = aten::Int(%embed_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6878 : int = aten::Int(%embed_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6879 : int = aten::Int(%embed_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6880 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.16 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.16, %6880), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %6882 : int = aten::Int(%head_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6883 : int = aten::Int(%head_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6884 : int = aten::Int(%head_dim.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6885 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6886 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6887 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6888 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6859, %6885, %6886, %6879, %6887), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6889 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6890 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6891 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6892 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.161 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6888, %6889, %6890, %6891, %6892), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %6894 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6895 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6896 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.160 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6858, %6894, %6895, %6878, %6896), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %6898 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.161), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.81 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.16, %6898), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6900 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.61 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.81, %bias.160, %6900), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6902 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.16 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.16, %6902), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %6904 : int = aten::Int(%_end.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6905 : int = aten::Int(%_end.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6906 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6907 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6908 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6859, %6906, %6877, %6905, %6907), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6909 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6910 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6911 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6912 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.162 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6908, %6909, %6910, %6911, %6912), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %6914 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6915 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.161 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6858, %6914, %6876, %6904, %6915), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %6917 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.162), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.82 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%key.5, %6917), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6919 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.46 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.82, %bias.161, %6919), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6921 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.16 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.16, %6921), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %6923 : int = aten::Int(%_start.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6924 : int = aten::Int(%_start.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6925 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6926 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6927 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6928 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6859, %6925, %6924, %6926, %6927), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6929 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6930 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6931 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6932 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.163 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%6928, %6929, %6930, %6931, %6932), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %6934 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6935 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6936 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.162 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%6858, %6934, %6923, %6935, %6936), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %6938 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.163), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.83 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.9, %6938), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %6940 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.46 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.83, %bias.162, %6940), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %6942 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.62 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.61, %6942), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %6944 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.63 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.62, %6944), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6946 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6947 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.16, %6946), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6948 : int = aten::Int(%6947), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6949 : int[] = prim::ListConstruct(%6866, %6948, %6884), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6950 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.63, %6949), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6951 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6952 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.64 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6950, %6951, %6952), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %6954 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.47 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.46, %6954), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6956 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6957 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.16, %6956), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6958 : int = aten::Int(%6957), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6959 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6960 : int[] = prim::ListConstruct(%6959, %6958, %6883), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6961 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.47, %6960), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6962 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6963 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.48 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6961, %6962, %6963), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %6965 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.47 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.46, %6965), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6967 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6968 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.16, %6967), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6969 : int = aten::Int(%6968), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6970 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6971 : int[] = prim::ListConstruct(%6970, %6969, %6882), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6972 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.47, %6971), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6973 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6974 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.48 : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%6972, %6973, %6974), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %6976 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %6977 : int = aten::size(%k.48, %6976), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len.16 : Long(device=cpu) = prim::NumToTensor(%6977), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6979 : int = aten::Int(%src_len.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6980 : int = aten::Int(%src_len.16), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6981 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6982 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6983 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k.48, %6981, %6982), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.66 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q.64, %6983), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %6985 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %6986 : int[] = prim::ListConstruct(%6871, %6985, %6865, %6980), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %attn_output_weights.67 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.66, %6986), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %6988 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6989 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %6988), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6990 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6991 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%6989, %6990), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %6992 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.68 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.67, %6991, %6992), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %6994 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6995 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.16, %6994), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6996 : int = aten::Int(%6995), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %6997 : int[] = prim::ListConstruct(%6996, %6864, %6979), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %input.236 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.68, %6997), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %6999 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %7000 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %input.237 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.236, %6999, %7000), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %7002 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7003 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.69 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.237, %7002, %7003), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.16 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.69, %v.48), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %7006 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7007 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7008 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.16, %7006, %7007), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7009 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7010 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%7008, %7009), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7011 : int[] = prim::ListConstruct(%6863, %6870, %6875), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn
  %input.238 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%7010, %7011), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7013 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%6857), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.84 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.238, %7013), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7015 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.239 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.84, %6855, %7015), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7017 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7018 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.14 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.239, %7017, %7018), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7020 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:228:0
  %input.240 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.13, %tgt2.14, %7020), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:228:0
  %7022 : Tensor = prim::GetAttr[name="bias"](%6689)
  %7023 : Tensor = prim::GetAttr[name="weight"](%6689)
  %7024 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7025 : int[] = prim::ListConstruct(%7024), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm2
  %7026 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7027 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.241 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.240, %7025, %7023, %7022, %7026, %7027), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7029 : Tensor = prim::GetAttr[name="bias"](%6688)
  %7030 : Tensor = prim::GetAttr[name="weight"](%6688)
  %7031 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%7030), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.85 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.241, %7031), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7033 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.242 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.85, %7029, %7033), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.243 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.242), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %7036 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7037 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.244 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.243, %7036, %7037), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7039 : Tensor = prim::GetAttr[name="bias"](%6686)
  %7040 : Tensor = prim::GetAttr[name="weight"](%6686)
  %7041 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%7040), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.86 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.244, %7041), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7043 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.245 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.86, %7039, %7043), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7045 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7046 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.15 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.245, %7045, %7046), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7048 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:231:0
  %input.246 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.241, %tgt2.15, %7048), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4 # ../../ml/detr/models/transformer.py:231:0
  %7050 : Tensor = prim::GetAttr[name="bias"](%6684)
  %7051 : Tensor = prim::GetAttr[name="weight"](%6684)
  %7052 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7053 : int[] = prim::ListConstruct(%7052), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm3
  %7054 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7055 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.247 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.246, %7053, %7051, %7050, %7054, %7055), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.4/__module.model.transformer.decoder.layers.4.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7057 : Tensor = prim::GetAttr[name="bias"](%5161)
  %7058 : Tensor = prim::GetAttr[name="weight"](%5161)
  %7059 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7060 : int[] = prim::ListConstruct(%7059), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm
  %7061 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7062 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7063 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.247, %7060, %7058, %7057, %7061, %7062), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7064 : __torch__.torch.nn.modules.normalization.___torch_mangle_132.LayerNorm = prim::GetAttr[name="norm3"](%5152)
  %7065 : __torch__.torch.nn.modules.dropout.___torch_mangle_135.Dropout = prim::GetAttr[name="dropout3"](%5152)
  %7066 : __torch__.torch.nn.modules.linear.___torch_mangle_129.Linear = prim::GetAttr[name="linear2"](%5152)
  %7067 : __torch__.torch.nn.modules.dropout.___torch_mangle_128.Dropout = prim::GetAttr[name="dropout"](%5152)
  %7068 : __torch__.torch.nn.modules.linear.___torch_mangle_127.Linear = prim::GetAttr[name="linear1"](%5152)
  %7069 : __torch__.torch.nn.modules.normalization.___torch_mangle_131.LayerNorm = prim::GetAttr[name="norm2"](%5152)
  %7070 : __torch__.torch.nn.modules.dropout.___torch_mangle_134.Dropout = prim::GetAttr[name="dropout2"](%5152)
  %7071 : __torch__.torch.nn.modules.activation.___torch_mangle_126.MultiheadAttention = prim::GetAttr[name="multihead_attn"](%5152)
  %7072 : __torch__.torch.nn.modules.normalization.___torch_mangle_130.LayerNorm = prim::GetAttr[name="norm1"](%5152)
  %7073 : __torch__.torch.nn.modules.dropout.___torch_mangle_133.Dropout = prim::GetAttr[name="dropout1"](%5152)
  %7074 : __torch__.torch.nn.modules.activation.___torch_mangle_124.MultiheadAttention = prim::GetAttr[name="self_attn"](%5152)
  %7075 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:210:0
  %query.17 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.247, %query_embed, %7075), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:210:0
  %7077 : __torch__.torch.nn.modules.linear.___torch_mangle_123._LinearWithBias = prim::GetAttr[name="out_proj"](%7074)
  %7078 : Tensor = prim::GetAttr[name="bias"](%7077)
  %7079 : __torch__.torch.nn.modules.linear.___torch_mangle_123._LinearWithBias = prim::GetAttr[name="out_proj"](%7074)
  %7080 : Tensor = prim::GetAttr[name="weight"](%7079)
  %7081 : Tensor = prim::GetAttr[name="in_proj_bias"](%7074)
  %7082 : Tensor = prim::GetAttr[name="in_proj_weight"](%7074)
  %7083 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %7084 : int = aten::size(%query.17, %7083), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len.17 : Long(device=cpu) = prim::NumToTensor(%7084), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7086 : int = aten::Int(%tgt_len.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7087 : int = aten::Int(%tgt_len.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7088 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %7089 : int = aten::size(%query.17, %7088), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz.17 : Long(device=cpu) = prim::NumToTensor(%7089), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7091 : int = aten::Int(%bsz.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7092 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %7093 : int = aten::size(%query.17, %7092), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim.17 : Long(device=cpu) = prim::NumToTensor(%7093), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7095 : int = aten::Int(%embed_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7096 : int = aten::Int(%embed_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7097 : int = aten::Int(%embed_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7098 : int = aten::Int(%embed_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7099 : int = aten::Int(%embed_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7100 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim.17 : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim.17, %7100), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %7102 : int = aten::Int(%head_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7103 : int = aten::Int(%head_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7104 : int = aten::Int(%head_dim.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7105 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7106 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7107 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7108 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7082, %7105, %7106, %7099, %7107), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7109 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7110 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7111 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7112 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.169 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7108, %7109, %7110, %7111, %7112), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7114 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %7115 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %7116 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.168 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%7081, %7114, %7115, %7098, %7116), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %7118 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.169), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.87 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.17, %7118), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7120 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.65 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.87, %bias.168, %7120), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7122 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end.17 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.17, %7122), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %7124 : int = aten::Int(%_end.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7125 : int = aten::Int(%_end.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7126 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7127 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7128 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7082, %7126, %7097, %7125, %7127), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7129 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7130 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7131 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7132 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.170 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7128, %7129, %7130, %7131, %7132), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7134 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %7135 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.169 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%7081, %7134, %7096, %7124, %7135), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %7137 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.170), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.88 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query.17, %7137), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7139 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.49 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.88, %bias.169, %7139), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7141 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start.17 : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim.17, %7141), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %7143 : int = aten::Int(%_start.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7144 : int = aten::Int(%_start.17), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7145 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7146 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7147 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7148 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7082, %7145, %7144, %7146, %7147), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7149 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7150 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7151 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7152 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.171 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7148, %7149, %7150, %7151, %7152), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7154 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %7155 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %7156 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.170 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%7081, %7154, %7143, %7155, %7156), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %7158 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.171), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.89 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.247, %7158), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7160 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.49 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.89, %bias.170, %7160), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7162 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.66 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.65, %7162), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %7164 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.67 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.66, %7164), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7166 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7167 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.17, %7166), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7168 : int = aten::Int(%7167), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7169 : int[] = prim::ListConstruct(%7087, %7168, %7104), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7170 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.67, %7169), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7171 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7172 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.68 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%7170, %7171, %7172), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7174 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.50 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.49, %7174), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7176 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7177 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.17, %7176), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7178 : int = aten::Int(%7177), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7179 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7180 : int[] = prim::ListConstruct(%7179, %7178, %7103), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7181 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.50, %7180), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7182 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7183 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.51 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%7181, %7182, %7183), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7185 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.50 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.49, %7185), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7187 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7188 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz.17, %7187), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7189 : int = aten::Int(%7188), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7190 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7191 : int[] = prim::ListConstruct(%7190, %7189, %7102), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %7192 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.50, %7191), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7193 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7194 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.51 : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%7192, %7193, %7194), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7196 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %7197 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %7198 : Float(8:32, 32:1, 100:256, requires_grad=0, device=cpu) = aten::transpose(%k.51, %7196, %7197), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.71 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::bmm(%q.68, %7198), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %7200 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %7201 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %input.248 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::softmax(%attn_output_weights.71, %7200, %7201), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %7203 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7204 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.72 : Float(8:10000, 100:100, 100:1, requires_grad=0, device=cpu) = aten::dropout(%input.248, %7203, %7204), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output.17 : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.72, %v.51), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %7207 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7208 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7209 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output.17, %7207, %7208), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7210 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7211 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%7209, %7210), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7212 : int[] = prim::ListConstruct(%7086, %7091, %7095), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn
  %input.249 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%7211, %7212), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7214 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%7080), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.90 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.249, %7214), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7216 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.250 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.90, %7078, %7216), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.self_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7218 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7219 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.16 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.250, %7218, %7219), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7221 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:222:0
  %input.251 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.247, %tgt2.16, %7221), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:222:0
  %7223 : Tensor = prim::GetAttr[name="bias"](%7072)
  %7224 : Tensor = prim::GetAttr[name="weight"](%7072)
  %7225 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7226 : int[] = prim::ListConstruct(%7225), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm1
  %7227 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7228 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %tensor : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.251, %7226, %7224, %7223, %7227, %7228), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7230 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:210:0
  %query : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor, %query_embed, %7230), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:210:0
  %7232 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:210:0
  %key : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor.9, %pos, %7232), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:210:0
  %7234 : __torch__.torch.nn.modules.linear.___torch_mangle_125._LinearWithBias = prim::GetAttr[name="out_proj"](%7071)
  %7235 : Tensor = prim::GetAttr[name="bias"](%7234)
  %7236 : __torch__.torch.nn.modules.linear.___torch_mangle_125._LinearWithBias = prim::GetAttr[name="out_proj"](%7071)
  %7237 : Tensor = prim::GetAttr[name="weight"](%7236)
  %7238 : Tensor = prim::GetAttr[name="in_proj_bias"](%7071)
  %7239 : Tensor = prim::GetAttr[name="in_proj_weight"](%7071)
  %7240 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %7241 : int = aten::size(%query, %7240), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %tgt_len : Long(device=cpu) = prim::NumToTensor(%7241), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7243 : int = aten::Int(%tgt_len), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7244 : int = aten::Int(%tgt_len), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7245 : int = aten::Int(%tgt_len), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7246 : int = aten::Int(%tgt_len), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7247 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %7248 : int = aten::size(%query, %7247), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %bsz : Long(device=cpu) = prim::NumToTensor(%7248), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7250 : int = aten::Int(%bsz), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7251 : int = aten::Int(%bsz), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7252 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %7253 : int = aten::size(%query, %7252), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4134:0
  %embed_dim : Long(device=cpu) = prim::NumToTensor(%7253), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7255 : int = aten::Int(%embed_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7256 : int = aten::Int(%embed_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7257 : int = aten::Int(%embed_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7258 : int = aten::Int(%embed_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7259 : int = aten::Int(%embed_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7260 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %head_dim : Long(requires_grad=0, device=cpu) = aten::floor_divide(%embed_dim, %7260), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/tensor.py:551:0
  %7262 : int = aten::Int(%head_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7263 : int = aten::Int(%head_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7264 : int = aten::Int(%head_dim), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7265 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7266 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7267 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7268 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7239, %7265, %7266, %7259, %7267), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7269 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7270 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7271 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7272 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %weight.174 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7268, %7269, %7270, %7271, %7272), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4179:0
  %7274 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %7275 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %7276 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %bias.173 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%7238, %7274, %7275, %7258, %7276), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4181:0
  %7278 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.174), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.91 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%query, %7278), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7280 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %q.69 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.91, %bias.173, %7280), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7282 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %_end : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim, %7282), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4187:0
  %7284 : int = aten::Int(%_end), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7285 : int = aten::Int(%_end), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7286 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7287 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7288 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7239, %7286, %7257, %7285, %7287), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7289 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7290 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7291 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7292 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %weight.175 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7288, %7289, %7290, %7291, %7292), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4188:0
  %7294 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %7295 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %bias.174 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%7238, %7294, %7256, %7284, %7295), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4190:0
  %7297 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.175), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.92 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%key, %7297), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7299 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %k.52 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.92, %bias.174, %7299), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7301 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %_start : Long(requires_grad=0, device=cpu) = aten::mul(%embed_dim, %7301), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4195:0
  %7303 : int = aten::Int(%_start), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7304 : int = aten::Int(%_start), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7305 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7306 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7307 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7308 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7239, %7305, %7304, %7306, %7307), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7309 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7310 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7311 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7312 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %weight.176 : Float(256:256, 256:1, requires_grad=1, device=cpu) = aten::slice(%7308, %7309, %7310, %7311, %7312), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4197:0
  %7314 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %7315 : int = prim::Constant[value=9223372036854775807](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %7316 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %bias.175 : Float(256:1, requires_grad=1, device=cpu) = aten::slice(%7238, %7314, %7303, %7315, %7316), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4199:0
  %7318 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%weight.176), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.93 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%tensor.9, %7318), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7320 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %v.52 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.93, %bias.175, %7320), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7322 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.176777}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %q.70 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::mul(%q.69, %7322), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4222:0
  %7324 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q.71 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%q.70, %7324), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7326 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7327 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz, %7326), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7328 : int = aten::Int(%7327), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7329 : int[] = prim::ListConstruct(%7246, %7328, %7264), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7330 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%q.71, %7329), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7331 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7332 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %q : Float(8:32, 100:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%7330, %7331, %7332), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4263:0
  %7334 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k.53 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%k.52, %7334), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7336 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7337 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz, %7336), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7338 : int = aten::Int(%7337), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7339 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7340 : int[] = prim::ListConstruct(%7339, %7338, %7263), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7341 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%k.53, %7340), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7342 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7343 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %k : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%7341, %7342, %7343), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4265:0
  %7345 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v.53 : Float(600:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::contiguous(%v.52, %7345), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7347 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7348 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz, %7347), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7349 : int = aten::Int(%7348), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7350 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7351 : int[] = prim::ListConstruct(%7350, %7349, %7262), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7352 : Float(600:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::view(%v.53, %7351), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7353 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7354 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %v : Float(8:32, 600:256, 32:1, requires_grad=0, device=cpu) = aten::transpose(%7352, %7353, %7354), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4267:0
  %7356 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %7357 : int = aten::size(%k, %7356), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4279:0
  %src_len : Long(device=cpu) = prim::NumToTensor(%7357), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7359 : int = aten::Int(%src_len), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7360 : int = aten::Int(%src_len), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7361 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %7362 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %7363 : Float(8:32, 32:1, 600:256, requires_grad=0, device=cpu) = aten::transpose(%k, %7361, %7362), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %attn_output_weights.74 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::bmm(%q, %7363), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4294:0
  %7365 : int = prim::Constant[value=8](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %7366 : int[] = prim::ListConstruct(%7251, %7365, %7245, %7360), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %attn_output_weights.75 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.74, %7366), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4305:0
  %7368 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %7369 : Bool(1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%key_padding_mask, %7368), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %7370 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %7371 : Bool(1:600, 1:600, 1:600, 600:1, requires_grad=0, device=cpu) = aten::unsqueeze(%7369, %7370), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4307:0
  %7372 : float = prim::Constant[value=-inf](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %attn_output_weights.76 : Float(1:480000, 8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::masked_fill(%attn_output_weights.75, %7371, %7372), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4306:0
  %7374 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %7375 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz, %7374), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %7376 : int = aten::Int(%7375), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %7377 : int[] = prim::ListConstruct(%7376, %7244, %7359), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %input.252 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::view(%attn_output_weights.76, %7377), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4310:0
  %7379 : int = prim::Constant[value=-1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %7380 : None = prim::Constant(), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %input.253 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::softmax(%input.252, %7379, %7380), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1512:0
  %7382 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7383 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output_weights.77 : Float(8:60000, 100:600, 600:1, requires_grad=0, device=cpu) = aten::dropout(%input.253, %7382, %7383), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %attn_output : Float(8:3200, 100:32, 32:1, requires_grad=0, device=cpu) = aten::bmm(%attn_output_weights.77, %v), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4316:0
  %7386 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7387 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7388 : Float(100:32, 8:3200, 32:1, requires_grad=0, device=cpu) = aten::transpose(%attn_output, %7386, %7387), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7389 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7390 : Float(100:256, 8:32, 32:1, requires_grad=0, device=cpu) = aten::contiguous(%7388, %7389), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7391 : int[] = prim::ListConstruct(%7243, %7250, %7255), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn
  %input.254 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::view(%7390, %7391), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:4318:0
  %7393 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%7237), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.94 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.254, %7393), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7395 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.255 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.94, %7235, %7395), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.multihead_attn # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7397 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7398 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2.17 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.255, %7397, %7398), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7400 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:228:0
  %input.256 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%tensor, %tgt2.17, %7400), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:228:0
  %7402 : Tensor = prim::GetAttr[name="bias"](%7069)
  %7403 : Tensor = prim::GetAttr[name="weight"](%7069)
  %7404 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7405 : int[] = prim::ListConstruct(%7404), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm2
  %7406 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7407 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.257 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.256, %7405, %7403, %7402, %7406, %7407), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7409 : Tensor = prim::GetAttr[name="bias"](%7068)
  %7410 : Tensor = prim::GetAttr[name="weight"](%7068)
  %7411 : Float(256:1, 2048:256, requires_grad=1, device=cpu) = aten::t(%7410), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.95 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::matmul(%input.257, %7411), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7413 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.258 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::add_(%output.95, %7409, %7413), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.259 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::relu(%input.258), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %7416 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7417 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %input.260 : Float(100:2048, 1:2048, 2048:1, requires_grad=0, device=cpu) = aten::dropout(%input.259, %7416, %7417), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7419 : Tensor = prim::GetAttr[name="bias"](%7066)
  %7420 : Tensor = prim::GetAttr[name="weight"](%7066)
  %7421 : Float(2048:1, 256:2048, requires_grad=1, device=cpu) = aten::t(%7420), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.96 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.260, %7421), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7423 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.261 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.96, %7419, %7423), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.linear2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7425 : float = prim::Constant[value=0.10000000000000001](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7426 : bool = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %tgt2 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::dropout(%input.261, %7425, %7426), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.dropout3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:983:0
  %7428 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:231:0
  %input.262 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::add(%input.257, %tgt2, %7428), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5 # ../../ml/detr/models/transformer.py:231:0
  %7430 : Tensor = prim::GetAttr[name="bias"](%7064)
  %7431 : Tensor = prim::GetAttr[name="weight"](%7064)
  %7432 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7433 : int[] = prim::ListConstruct(%7432), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm3
  %7434 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7435 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %input.263 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.262, %7433, %7431, %7430, %7434, %7435), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.layers.5/__module.model.transformer.decoder.layers.5.norm3 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7437 : None = prim::Constant()
  %7438 : Tensor = prim::GetAttr[name="bias"](%5161)
  %7439 : Tensor = prim::GetAttr[name="weight"](%5161)
  %7440 : int = prim::Constant[value=256](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7441 : int[] = prim::ListConstruct(%7440), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm
  %7442 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7443 : bool = prim::Constant[value=1](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %output.97 : Float(100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::layer_norm(%input.263, %7441, %7439, %7438, %7442, %7443), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder/__module.model.transformer.decoder.norm # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:2094:0
  %7445 : Tensor[] = prim::ListConstruct(%5543, %5923, %6303, %6683, %7063, %output.97), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder
  %7446 : int = prim::Constant[value=0](), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder # ../../ml/detr/models/transformer.py:122:0
  %hs : Float(6:25600, 100:256, 1:256, 256:1, requires_grad=0, device=cpu) = aten::stack(%7445, %7446), scope: __module.model/__module.model.transformer/__module.model.transformer.decoder # ../../ml/detr/models/transformer.py:122:0
  %7448 : int = prim::Constant[value=1](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:59:0
  %7449 : int = prim::Constant[value=2](), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:59:0
  %input.264 : Float(6:25600, 1:256, 100:256, 256:1, requires_grad=0, device=cpu) = aten::transpose(%hs, %7448, %7449), scope: __module.model/__module.model.transformer # ../../ml/detr/models/transformer.py:59:0
  %7451 : Tensor = prim::GetAttr[name="bias"](%8)
  %7452 : Tensor = prim::GetAttr[name="weight"](%8)
  %7453 : Float(256:1, 92:256, requires_grad=1, device=cpu) = aten::t(%7452), scope: __module.model/__module.model.class_embed # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.98 : Float(6:9200, 1:9200, 100:92, 92:1, requires_grad=0, device=cpu) = aten::matmul(%input.264, %7453), scope: __module.model/__module.model.class_embed # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7455 : int = prim::Constant[value=1](), scope: __module.model/__module.model.class_embed # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %outputs_class : Float(6:9200, 1:9200, 100:92, 92:1, requires_grad=0, device=cpu) = aten::add_(%output.98, %7451, %7455), scope: __module.model/__module.model.class_embed # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7457 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%7)
  %7458 : __torch__.torch.nn.modules.linear.___torch_mangle_142.Linear = prim::GetAttr[name="2"](%7457)
  %7459 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%7)
  %7460 : __torch__.torch.nn.modules.linear.___torch_mangle_141.Linear = prim::GetAttr[name="1"](%7459)
  %7461 : __torch__.torch.nn.modules.container.___torch_mangle_143.ModuleList = prim::GetAttr[name="layers"](%7)
  %7462 : __torch__.torch.nn.modules.linear.___torch_mangle_140.Linear = prim::GetAttr[name="0"](%7461)
  %7463 : Tensor = prim::GetAttr[name="bias"](%7462)
  %7464 : Tensor = prim::GetAttr[name="weight"](%7462)
  %7465 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%7464), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.99 : Float(6:25600, 1:25600, 100:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.264, %7465), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7467 : int = prim::Constant[value=1](), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.265 : Float(6:25600, 1:25600, 100:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.99, %7463, %7467), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.0 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.266 : Float(6:25600, 1:25600, 100:256, 256:1, requires_grad=0, device=cpu) = aten::relu(%input.265), scope: __module.model/__module.model.bbox_embed # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %7470 : Tensor = prim::GetAttr[name="bias"](%7460)
  %7471 : Tensor = prim::GetAttr[name="weight"](%7460)
  %7472 : Float(256:1, 256:256, requires_grad=1, device=cpu) = aten::t(%7471), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output.100 : Float(6:25600, 1:25600, 100:256, 256:1, requires_grad=0, device=cpu) = aten::matmul(%input.266, %7472), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7474 : int = prim::Constant[value=1](), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input.267 : Float(6:25600, 1:25600, 100:256, 256:1, requires_grad=0, device=cpu) = aten::add_(%output.100, %7470, %7474), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.1 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %input : Float(6:25600, 1:25600, 100:256, 256:1, requires_grad=0, device=cpu) = aten::relu(%input.267), scope: __module.model/__module.model.bbox_embed # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1136:0
  %7477 : Tensor = prim::GetAttr[name="bias"](%7458)
  %7478 : Tensor = prim::GetAttr[name="weight"](%7458)
  %7479 : Float(256:1, 4:256, requires_grad=1, device=cpu) = aten::t(%7478), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %output : Float(6:400, 1:400, 100:4, 4:1, requires_grad=0, device=cpu) = aten::matmul(%input, %7479), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1692:0
  %7481 : int = prim::Constant[value=1](), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %7482 : Float(6:400, 1:400, 100:4, 4:1, requires_grad=0, device=cpu) = aten::add_(%output, %7477, %7481), scope: __module.model/__module.model.bbox_embed/__module.model.bbox_embed.layers.2 # /home/masa/anaconda3/envs/torch-1.7/lib/python3.8/site-packages/torch/nn/functional.py:1694:0
  %outputs_coord : Float(6:400, 1:400, 100:4, 4:1, requires_grad=0, device=cpu) = aten::sigmoid(%7482), scope: __module.model # ../../ml/detr/models/detr.py:68:0
  %7484 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/models/detr.py:69:0
  %7485 : int = prim::Constant[value=-1](), scope: __module.model # ../../ml/detr/models/detr.py:69:0
  %7486 : Float(1:9200, 100:92, 92:1, requires_grad=0, device=cpu) = aten::select(%outputs_class, %7484, %7485), scope: __module.model # ../../ml/detr/models/detr.py:69:0
  %7487 : int = prim::Constant[value=0](), scope: __module.model # ../../ml/detr/models/detr.py:69:0
  %7488 : int = prim::Constant[value=-1](), scope: __module.model # ../../ml/detr/models/detr.py:69:0
  %7489 : Float(1:400, 100:4, 4:1, requires_grad=0, device=cpu) = aten::select(%outputs_coord, %7487, %7488), scope: __module.model # ../../ml/detr/models/detr.py:69:0
  %7490 : (Float(1:9200, 100:92, 92:1, requires_grad=0, device=cpu), Float(1:400, 100:4, 4:1, requires_grad=0, device=cpu)) = prim::TupleConstruct(%7486, %7489)
  %4 : Float(1:9200, 100:92, 92:1, requires_grad=0, device=cpu), %5 : Float(1:400, 100:4, 4:1, requires_grad=0, device=cpu) = prim::TupleUnpack(%7490)
  %6 : (Float(1:9200, 100:92, 92:1, requires_grad=0, device=cpu), Float(1:400, 100:4, 4:1, requires_grad=0, device=cpu)) = prim::TupleConstruct(%4, %5)
  return (%6)
