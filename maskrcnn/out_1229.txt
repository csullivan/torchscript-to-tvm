File test_street_small.jpg exists, skip.
Get errors with GraphRuntimeCodegen for task extraction. Fallback to VMCompiler.
========== Task 0  (workload key: ["4f7db19fc10bb35fd2e4f6aa3a3e9074"]) ==========
placeholder = PLACEHOLDER [1, 3, 800, 800]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 3) && (i2 < 803)) && (i3 >= 3)) && (i3 < 803)), placeholder[i0, i1, (i2 - 3), (i3 - 3)], 0f)
placeholder = PLACEHOLDER [64, 3, 7, 7]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, ((yy*2) + ry), ((xx*2) + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 64, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 1  (workload key: ["84b9f96c199fa0d8e51c84a93c5881ed"]) ==========
placeholder = PLACEHOLDER [1, 64, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [64, 64, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 64, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 2  (workload key: ["afe04dcd7f0bdb2a96b69e96759a4cd9"]) ==========
placeholder = PLACEHOLDER [1, 64, 200, 200]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 201)) && (i3 >= 1)) && (i3 < 201)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [64, 64, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 64, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 3  (workload key: ["16121f974bad7b37c835e3dc5ea1c8f9"]) ==========
placeholder = PLACEHOLDER [1, 64, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 64, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 4  (workload key: ["8e068b345d3019fd9b460244ff63b39d"]) ==========
placeholder = PLACEHOLDER [1, 64, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 64, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
placeholder = PLACEHOLDER [1, 256, 200, 200]
T_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 5  (workload key: ["aef68798e904cb78192c42b70995ee3a"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [64, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 64, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 6  (workload key: ["58f1a0913767a83818023f8c1e489aba"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [128, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 128, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 7  (workload key: ["3b409a7998e237b950295fa387f4393d"]) ==========
placeholder = PLACEHOLDER [1, 128, 200, 200]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 201)) && (i3 >= 1)) && (i3 < 201)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [128, 128, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, ((yy*2) + ry), ((xx*2) + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 128, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 8  (workload key: ["c768baa9f435d1d7310a8d7813ad98f3"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [512, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, ((yy*2) + ry), ((xx*2) + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 9  (workload key: ["7c39c3f6e5c1831c3605b6c2afb71e64"]) ==========
placeholder = PLACEHOLDER [1, 128, 100, 100]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [512, 128, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
placeholder = PLACEHOLDER [1, 512, 100, 100]
T_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 10  (workload key: ["77137d5af6d9d72508dd40b3f86c1f63"]) ==========
placeholder = PLACEHOLDER [1, 512, 100, 100]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [128, 512, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 128, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 11  (workload key: ["ee85645b063a7323cba93bafb207ec21"]) ==========
placeholder = PLACEHOLDER [1, 128, 100, 100]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 101)) && (i3 >= 1)) && (i3 < 101)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [128, 128, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 128, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 12  (workload key: ["49c00040bfd6dcec3ff1bb46513eead3"]) ==========
placeholder = PLACEHOLDER [1, 512, 100, 100]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 512, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 13  (workload key: ["a4a87dbfc88fd79d85a838cb8f61a021"]) ==========
placeholder = PLACEHOLDER [1, 256, 100, 100]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 101)) && (i3 >= 1)) && (i3 < 101)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, ((yy*2) + ry), ((xx*2) + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 14  (workload key: ["c6b56bd2fe4caf1374537f3d392ccecb"]) ==========
placeholder = PLACEHOLDER [1, 512, 100, 100]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [1024, 512, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, ((yy*2) + ry), ((xx*2) + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 1024, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 15  (workload key: ["06a8675bddee15c742771771d067efd7"]) ==========
placeholder = PLACEHOLDER [1, 256, 50, 50]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [1024, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 1024, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
placeholder = PLACEHOLDER [1, 1024, 50, 50]
T_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 16  (workload key: ["335bbef89e5f82a72ec30b5c6f99b792"]) ==========
placeholder = PLACEHOLDER [1, 1024, 50, 50]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 1024, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 17  (workload key: ["859634af3e72b92ab508dd7cd1ffca96"]) ==========
placeholder = PLACEHOLDER [1, 256, 50, 50]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 51)) && (i3 >= 1)) && (i3 < 51)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 18  (workload key: ["9a42e7acd727cfb0c75d4fc36a365837"]) ==========
placeholder = PLACEHOLDER [1, 1024, 50, 50]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [512, 1024, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 19  (workload key: ["36e74d32274232b6186a8c5abbf90d7b"]) ==========
placeholder = PLACEHOLDER [1, 512, 50, 50]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 51)) && (i3 >= 1)) && (i3 < 51)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [512, 512, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, ((yy*2) + ry), ((xx*2) + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 20  (workload key: ["c718faceed66930311ef18109fbb1ae8"]) ==========
placeholder = PLACEHOLDER [1, 1024, 50, 50]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [2048, 1024, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, ((yy*2) + ry), ((xx*2) + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 2048, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 21  (workload key: ["eb263ee731fc52548dfaee67c383a911"]) ==========
placeholder = PLACEHOLDER [1, 512, 25, 25]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [2048, 512, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 2048, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
placeholder = PLACEHOLDER [1, 2048, 25, 25]
T_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 22  (workload key: ["bb5ab95cf8fc84b5c5a6ff2bd9ade9a8"]) ==========
placeholder = PLACEHOLDER [1, 2048, 25, 25]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [512, 2048, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 23  (workload key: ["13c54e708749345bb50a16dababaa6fe"]) ==========
placeholder = PLACEHOLDER [1, 512, 25, 25]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 26)) && (i3 >= 1)) && (i3 < 26)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [512, 512, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 24  (workload key: ["87466afa05472b6a57bba923e3ee27a8"]) ==========
placeholder = PLACEHOLDER [1, 2048, 25, 25]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 2048, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 25  (workload key: ["c593825bd1e62474cc1776a276d36f27"]) ==========
placeholder = PLACEHOLDER [1, 1024, 50, 50]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 1024, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
placeholder = PLACEHOLDER [1, 256, 50, 50]
T_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])

========== Task 26  (workload key: ["84277663192d02a6ef00945c708002b7"]) ==========
placeholder = PLACEHOLDER [1, 512, 100, 100]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 512, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
placeholder = PLACEHOLDER [1, 256, 100, 100]
T_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])

========== Task 27  (workload key: ["4411a8f0966fe5203cadd05accfe7682"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [256, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
placeholder = PLACEHOLDER [1, 256, 200, 200]
T_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])

========== Task 28  (workload key: ["340c88ec11d6541d170d9908a7455893"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 201)) && (i3 >= 1)) && (i3 < 201)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 29  (workload key: ["be8194b91565b8e5aab1805287c8cb72"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 201)) && (i3 >= 1)) && (i3 < 201)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 30  (workload key: ["e3b70acefb5cb4c59a37449603452aa8"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [12, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 12, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 31  (workload key: ["f31dcb4d64c111ce0b9bf4e67f798ca0"]) ==========
placeholder = PLACEHOLDER [1, 256, 100, 100]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 101)) && (i3 >= 1)) && (i3 < 101)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 32  (workload key: ["387d57405e598bb8ee818c7e0e518acd"]) ==========
placeholder = PLACEHOLDER [1, 256, 100, 100]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 101)) && (i3 >= 1)) && (i3 < 101)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 33  (workload key: ["e8231c2732055c8a545f5f82ff037076"]) ==========
placeholder = PLACEHOLDER [1, 256, 100, 100]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [12, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 12, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 34  (workload key: ["2ecd94a760bae59a3177b02e48707dd3"]) ==========
placeholder = PLACEHOLDER [1, 256, 50, 50]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 51)) && (i3 >= 1)) && (i3 < 51)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 35  (workload key: ["09b77da634f42230e0565292e14e8a45"]) ==========
placeholder = PLACEHOLDER [1, 256, 50, 50]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [12, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 12, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 36  (workload key: ["0ac98783efde11ddbe5a8ed1f0ed1bfe"]) ==========
placeholder = PLACEHOLDER [1, 256, 25, 25]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 26)) && (i3 >= 1)) && (i3 < 26)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 37  (workload key: ["3a87a0078e3614f266a9f3fe322ad603"]) ==========
placeholder = PLACEHOLDER [1, 256, 25, 25]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 26)) && (i3 >= 1)) && (i3 < 26)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 38  (workload key: ["264489d34488b0c8658f8c4a3f462141"]) ==========
placeholder = PLACEHOLDER [1, 256, 25, 25]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [12, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 12, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 39  (workload key: ["d19859b192abcefb252f6ea36ca4b5c5"]) ==========
placeholder = PLACEHOLDER [1, 256, 13, 13]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 >= 1) && (i2 < 14)) && (i3 >= 1)) && (i3 < 14)), placeholder[i0, i1, (i2 - 1), (i3 - 1)], 0f)
placeholder = PLACEHOLDER [256, 256, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 256, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

========== Task 40  (workload key: ["73728fa237979585c824c6ee25836781"]) ==========
placeholder = PLACEHOLDER [1, 256, 13, 13]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [12, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 12, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 41  (workload key: ["e4181bbf68a218d1d50708da96099d8f"]) ==========
placeholder = PLACEHOLDER [1, 256, 200, 200]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [3, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 3, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 42  (workload key: ["21ae59d506a708ab985d30b390054bcb"]) ==========
placeholder = PLACEHOLDER [1, 256, 100, 100]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [3, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 3, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 43  (workload key: ["af5429667645d02d45eb0dd1f5c42761"]) ==========
placeholder = PLACEHOLDER [1, 256, 50, 50]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [3, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 3, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 44  (workload key: ["d69417cd67f06454353d63890db95a11"]) ==========
placeholder = PLACEHOLDER [1, 256, 25, 25]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [3, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 3, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

========== Task 45  (workload key: ["a9debb7f34a851d25f4b5da690b13e99"]) ==========
placeholder = PLACEHOLDER [1, 256, 13, 13]
pad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]
placeholder = PLACEHOLDER [3, 256, 1, 1]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*placeholder[ff, rc, ry, rx])
placeholder = PLACEHOLDER [1, 3, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, 0, 0])

----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 77	fail_ct: 6067	Time elapsed: 6.76
GA Iter: 0	Max score: 0.9983	Min score: 0.0544	#Pop: 77	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9811	#Pop: 128	#M+: 1388	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
Get devices for measurement successfully!
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |            - |              - |      0 |
|    1 |            - |              - |      0 |
|    2 |            - |              - |      0 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 0	Used time : 1 s	Next ID: 0
.......T.T******
........*****E***
........*****E***
........********
........****E****
........********E
........T*****E**
........***E*****Time elapsed for measurement: 113.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.33 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 61	fail_ct: 1987	Time elapsed: 1.93
GA Iter: 0	Max score: 0.9884	Min score: 0.0021	#Pop: 61	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9815	#Pop: 128	#M+: 1381	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.34
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |            - |              - |      0 |
|    2 |            - |              - |      0 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 64	Used time : 150 s	Next ID: 1
........****E****
........********
........*****E***
........********
........***E*****
......T.T.T***E**
........********
........T****E***Time elapsed for measurement: 96.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.37 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 96	fail_ct: 4000	Time elapsed: 4.25
GA Iter: 0	Max score: 0.9944	Min score: 0.0122	#Pop: 96	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9773	#Pop: 128	#M+: 1395	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 28.79
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |            - |              - |      0 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 128	Used time : 269 s	Next ID: 2
........********
........*******E*
.......T.T******
........T**E*****
........T*******
........*****E**E*
........*******E*
.......T.T******Time elapsed for measurement: 131.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.58 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 117	fail_ct: 3979	Time elapsed: 3.81
GA Iter: 0	Max score: 0.9997	Min score: 0.0062	#Pop: 117	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9831	#Pop: 128	#M+: 1384	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |            - |              - |      0 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 192	Used time : 434 s	Next ID: 3
........***E**T***
........T*******
........********
........********
........T***E****
........T*******
........*****E***
........********ETime elapsed for measurement: 126.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.60 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 51	fail_ct: 1997	Time elapsed: 1.95
GA Iter: 0	Max score: 0.8828	Min score: 0.0299	#Pop: 51	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9780	#Pop: 128	#M+: 1387	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 21.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |            - |              - |      0 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 256	Used time : 586 s	Next ID: 4
........********E
........T*E**E****E
........*E*******
......T.T.T*****
........T*E******
........T*E******E
........***E*****
.......T.T******Time elapsed for measurement: 154.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.67 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 76	fail_ct: 4020	Time elapsed: 3.83
GA Iter: 0	Max score: 0.9855	Min score: 0.0044	#Pop: 76	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9793	#Pop: 128	#M+: 1408	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |            - |              - |      0 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 320	Used time : 764 s	Next ID: 5
........********
........********
........T*E******
........T******E*
........********
........********
......T.T.T*****
........T*******Time elapsed for measurement: 135.00 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.77 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 71	fail_ct: 4025	Time elapsed: 3.78
GA Iter: 0	Max score: 0.9888	Min score: 0.0272	#Pop: 71	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9995	Min score: 0.9733	#Pop: 128	#M+: 1387	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.52
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |            - |              - |      0 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 384	Used time : 924 s	Next ID: 6
........***E*****
........********
........*******E*
........*E*E*E****E*
.......T.T****E**
........T******E*
........T*E******
........********Time elapsed for measurement: 118.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.81 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 52	fail_ct: 4044	Time elapsed: 3.97
GA Iter: 0	Max score: 0.9908	Min score: 0.0144	#Pop: 52	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9800	#Pop: 128	#M+: 1388	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 25.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |            - |              - |      0 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 448	Used time : 1068 s	Next ID: 7
........********
.......T.T******
........********
........***E*****E
........***E*****
........********
........********
........********Time elapsed for measurement: 98.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 54	fail_ct: 4042	Time elapsed: 4.02
GA Iter: 0	Max score: 0.9951	Min score: 0.0067	#Pop: 54	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9825	#Pop: 128	#M+: 1398	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 21.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |            - |              - |      0 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 512	Used time : 1196 s	Next ID: 8
........*******E*
......T.T.T*E****
.......T.T*E***E**
........*****E***
........T*****E**E
........********
........T*******
........T****E*E**Time elapsed for measurement: 144.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.06 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 81	fail_ct: 1967	Time elapsed: 2.06
GA Iter: 0	Max score: 0.9756	Min score: 0.0017	#Pop: 81	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9793	#Pop: 128	#M+: 1387	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 21.71
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |            - |              - |      0 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 576	Used time : 1368 s	Next ID: 9
........*******E*
........**E******
......T.T.T*****
.......T.T******
.......T.T******
........T*******
........T*******
......T.T.T*****Time elapsed for measurement: 148.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 52	fail_ct: 1996	Time elapsed: 1.87
GA Iter: 0	Max score: 0.9911	Min score: 0.0681	#Pop: 52	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9797	#Pop: 128	#M+: 1387	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.68
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |            - |              - |      0 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 640	Used time : 1542 s	Next ID: 10
........********
........*****E*E*E*
........********
........********
........T*******
........********
........********
........T*******Time elapsed for measurement: 106.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 58	fail_ct: 1990	Time elapsed: 2.05
GA Iter: 0	Max score: 0.9895	Min score: 0.0261	#Pop: 58	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9813	#Pop: 128	#M+: 1399	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 28.38
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |            - |              - |      0 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 704	Used time : 1671 s	Next ID: 11
........*E*******
.......T.T******
.......T.T******
........T*******
........T*******
........********
........********
........********ETime elapsed for measurement: 121.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 65	fail_ct: 1983	Time elapsed: 1.88
GA Iter: 0	Max score: 0.9971	Min score: 0.0150	#Pop: 65	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9791	#Pop: 128	#M+: 1386	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.53
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |            - |              - |      0 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 768	Used time : 1824 s	Next ID: 12
........******E**
........T*******
.......T.T******
........T*******
........********
........T******E*
........********
........***E*****Time elapsed for measurement: 134.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.62 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 55	fail_ct: 1993	Time elapsed: 2.07
GA Iter: 0	Max score: 0.9665	Min score: 0.0282	#Pop: 55	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9805	#Pop: 128	#M+: 1405	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 23.62
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |            - |              - |      0 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 832	Used time : 1983 s	Next ID: 13
........********E
........*E*******
........T*******
........T*******
........*****E***
........**T******
........********
......T.T.T*****Time elapsed for measurement: 146.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.75 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 86	fail_ct: 4010	Time elapsed: 3.92
GA Iter: 0	Max score: 0.9993	Min score: 0.0026	#Pop: 86	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9818	#Pop: 128	#M+: 1391	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |            - |              - |      0 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 896	Used time : 2157 s	Next ID: 14
........***E*E***E*
........*E***E****
........T*******
........T*******
........T***E***
........T*******
........********
.......T.T******Time elapsed for measurement: 144.24 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.91 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 83	fail_ct: 1965	Time elapsed: 2.00
GA Iter: 0	Max score: 0.9995	Min score: 0.0007	#Pop: 83	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9834	#Pop: 128	#M+: 1389	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.93
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |            - |              - |      0 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 960	Used time : 2327 s	Next ID: 15
........***E*E****
........**E******
.......T.T******
.......T.T******
........T*E******
........********E
........****E****
........**E******Time elapsed for measurement: 119.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 84	fail_ct: 1964	Time elapsed: 1.78
GA Iter: 0	Max score: 0.9791	Min score: 0.0021	#Pop: 84	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9813	#Pop: 128	#M+: 1393	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |            - |              - |      0 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1024	Used time : 2472 s	Next ID: 16
........********
........**E******
.......T.T******
........*E*******
........T*******
........***E*****
........********
.......T.T***E***Time elapsed for measurement: 108.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.85 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 78	fail_ct: 1970	Time elapsed: 2.03
GA Iter: 0	Max score: 0.9377	Min score: 0.0034	#Pop: 78	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9808	#Pop: 128	#M+: 1385	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 27.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |            - |              - |      0 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1088	Used time : 2604 s	Next ID: 17
........T****E***
........T******
........*****E***
........T*******
........********
........****E****
........********
........*******E*Time elapsed for measurement: 124.08 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.26 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 75	fail_ct: 1973	Time elapsed: 1.87
GA Iter: 0	Max score: 0.9877	Min score: 0.0085	#Pop: 75	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9833	#Pop: 128	#M+: 1384	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |            - |              - |      0 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1152	Used time : 2759 s	Next ID: 18
........********
........**E******
........T*****E**
........********
........T*******
........*******
......T.T.T*****
......T.T.T*****Time elapsed for measurement: 126.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.41 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 84	fail_ct: 4012	Time elapsed: 3.81
GA Iter: 0	Max score: 0.9927	Min score: 0.0009	#Pop: 84	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9801	#Pop: 128	#M+: 1393	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 22.94
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |            - |              - |      0 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1216	Used time : 2909 s	Next ID: 19
........******E**
........*******E*
........*******
........********
........********
......T.T.T*****
........********
........*******Time elapsed for measurement: 105.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.39 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 60	fail_ct: 1988	Time elapsed: 2.08
GA Iter: 0	Max score: 0.9952	Min score: 0.0077	#Pop: 60	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9813	#Pop: 128	#M+: 1384	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 18.69
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |            - |              - |      0 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1280	Used time : 3044 s	Next ID: 20
.......T.T**E**E**
........T*E**E***
........********
........******E**
........********
........********
........********E
........T*******Time elapsed for measurement: 115.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.35 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 73	fail_ct: 1975	Time elapsed: 2.00
GA Iter: 0	Max score: 0.9936	Min score: 0.0209	#Pop: 73	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9802	#Pop: 128	#M+: 1395	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |            - |              - |      0 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1344	Used time : 3183 s	Next ID: 21
........********
........T*****E*
........******E**
........T*******
........********
........T*******
........*****E**E*
........***E*****Time elapsed for measurement: 111.19 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.63 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 104	fail_ct: 1944	Time elapsed: 1.81
GA Iter: 0	Max score: 0.9889	Min score: 0.0027	#Pop: 104	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9793	#Pop: 128	#M+: 1395	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 18.31
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |            - |              - |      0 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1408	Used time : 3318 s	Next ID: 22
........******E**
........********
......T.T.T*****
........T*******
........********
........********
........*E*******
......T.T.T*****Time elapsed for measurement: 125.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 2.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 71	fail_ct: 1977	Time elapsed: 2.07
GA Iter: 0	Max score: 0.9763	Min score: 0.0538	#Pop: 71	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9769	#Pop: 128	#M+: 1389	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 25.28
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |            - |              - |      0 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1472	Used time : 3466 s	Next ID: 23
........********
......T.T.T*****
........***E*****
........****E****E
........T*******
........T******E*
........********
........*******E*Time elapsed for measurement: 115.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.24 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 92	fail_ct: 1956	Time elapsed: 1.63
GA Iter: 0	Max score: 0.9989	Min score: 0.0035	#Pop: 92	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9816	#Pop: 128	#M+: 1401	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 17.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |            - |              - |      0 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1536	Used time : 3613 s	Next ID: 24
........********
........T*******
.......T.T******
........********
........********
........T*******
.......T.T******
........*E*******Time elapsed for measurement: 119.57 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 106	fail_ct: 1942	Time elapsed: 1.89
GA Iter: 0	Max score: 0.9850	Min score: 0.0123	#Pop: 106	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9779	#Pop: 128	#M+: 1403	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |            - |              - |      0 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1600	Used time : 3755 s	Next ID: 25
........*E*******
........T*******
........********E
......T.T.T**E***
........********E
........********
........********
........********Time elapsed for measurement: 104.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.23 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 58	fail_ct: 1990	Time elapsed: 1.97
GA Iter: 0	Max score: 0.8685	Min score: 0.0020	#Pop: 58	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9778	#Pop: 128	#M+: 1398	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.30
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |            - |              - |      0 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1664	Used time : 3884 s	Next ID: 26
........********
........********
........***E*****
........********
........********E
........********
........********
........******E**Time elapsed for measurement: 95.54 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 63	fail_ct: 4033	Time elapsed: 4.18
GA Iter: 0	Max score: 0.9700	Min score: 0.0257	#Pop: 63	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9793	#Pop: 128	#M+: 1398	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 21.79
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |            - |              - |      0 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1728	Used time : 4005 s	Next ID: 27
........**E******
........*******E*
......T.T.T*****
........T******E*
......T.T.T*****E
........**E******
........T*E**E****
........**E*E*****ETime elapsed for measurement: 139.62 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.97 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 56	fail_ct: 4040	Time elapsed: 4.42
GA Iter: 0	Max score: 0.9913	Min score: 0.0056	#Pop: 56	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9809	#Pop: 128	#M+: 1391	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |            - |              - |      0 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1792	Used time : 4175 s	Next ID: 28
........****E****
.......T.T******
......T.T.T*****
........**E******
......T.T.T*****
........********
........T*******T
........T*****E**Time elapsed for measurement: 236.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 54	fail_ct: 4042	Time elapsed: 4.51
GA Iter: 0	Max score: 0.9993	Min score: 0.0454	#Pop: 54	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9815	#Pop: 128	#M+: 1392	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |            - |              - |      0 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1856	Used time : 4449 s	Next ID: 29
........*E**E*****
........*E**T****E*
........***E****E*
........****E****
........********E
........T*E***E*E*
.......T.T******
........****E****Time elapsed for measurement: 188.69 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.30 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 55	fail_ct: 4041	Time elapsed: 3.42
GA Iter: 0	Max score: 0.9951	Min score: 0.0292	#Pop: 55	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9814	#Pop: 128	#M+: 1383	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |            - |              - |      0 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1920	Used time : 4675 s	Next ID: 30
........********
........********
........********
........********
........********
........********
........T*******
......T.T.T*****Time elapsed for measurement: 109.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.55 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 55	fail_ct: 1993	Time elapsed: 2.24
GA Iter: 0	Max score: 0.9983	Min score: 0.0651	#Pop: 55	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9996	Min score: 0.9783	#Pop: 128	#M+: 1395	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 27.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |            - |              - |      0 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 1984	Used time : 4811 s	Next ID: 31
........***E*E****
........******E**
........T*E****E**
........********
........********
........T**E*****E
.......T.T****E**
........**E******Time elapsed for measurement: 124.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.68 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 87	fail_ct: 4009	Time elapsed: 4.30
GA Iter: 0	Max score: 0.9772	Min score: 0.0035	#Pop: 87	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9774	#Pop: 128	#M+: 1385	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 28.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |            - |              - |      0 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2048	Used time : 4969 s	Next ID: 32
........***E*****
........*E*******
........T*******E
.......T.T******
........****E****
......T.T.T*****
........*****E*E**
.......T.T****E**Time elapsed for measurement: 132.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.94 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 61	fail_ct: 1987	Time elapsed: 1.59
GA Iter: 0	Max score: 0.9605	Min score: 0.0027	#Pop: 61	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9997	Min score: 0.9803	#Pop: 128	#M+: 1382	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 18.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |            - |              - |      0 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2112	Used time : 5138 s	Next ID: 33
........**E******
........T*******
........********
........********
........T***E****E
........********
........***E*****
........********Time elapsed for measurement: 100.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 3.76 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 76	fail_ct: 1972	Time elapsed: 2.02
GA Iter: 0	Max score: 0.9082	Min score: 0.0468	#Pop: 76	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9800	#Pop: 128	#M+: 1398	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 26.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |            - |              - |      0 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2176	Used time : 5263 s	Next ID: 34
........****E****
........*****E***
........**E******E
......T.T.T**E***
........*E*******
........***E*****
.......T.T******
........**E******Time elapsed for measurement: 100.06 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.08 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 80	fail_ct: 1968	Time elapsed: 1.38
GA Iter: 0	Max score: 0.9880	Min score: 0.0213	#Pop: 80	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9823	#Pop: 128	#M+: 1390	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 17.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |            - |              - |      0 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2240	Used time : 5396 s	Next ID: 35
........********
........********
........T*******
........T*******
......T.T.T**E**
.......T.T***E***
........********
........********Time elapsed for measurement: 123.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.93 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 98	fail_ct: 1950	Time elapsed: 1.91
GA Iter: 0	Max score: 0.9897	Min score: 0.0000	#Pop: 98	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9818	#Pop: 128	#M+: 1400	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 24.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |            - |              - |      0 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2304	Used time : 5543 s	Next ID: 36
........********
........********
.......T.T****E**
........***E*****
........*******E*
........********
........T*******E
........T*E***E***Time elapsed for measurement: 116.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 98	fail_ct: 1950	Time elapsed: 1.83
GA Iter: 0	Max score: 0.9893	Min score: 0.0007	#Pop: 98	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9818	#Pop: 128	#M+: 1389	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 24.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |            - |              - |      0 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2368	Used time : 5691 s	Next ID: 37
........********E
........********
.......T.T***E***
........T*******
........********
........********
.......T.T******
........********Time elapsed for measurement: 121.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.12 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 113	fail_ct: 1935	Time elapsed: 1.22
GA Iter: 0	Max score: 0.9934	Min score: 0.0002	#Pop: 113	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9827	#Pop: 128	#M+: 1388	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 16.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |            - |              - |      0 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2432	Used time : 5845 s	Next ID: 38
........********
........T*******
......T.T.T*****
........********
........********
........********
........********
........T*******Time elapsed for measurement: 113.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 107	fail_ct: 1941	Time elapsed: 1.82
GA Iter: 0	Max score: 0.9953	Min score: 0.0105	#Pop: 107	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9802	#Pop: 128	#M+: 1391	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 22.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |            - |              - |      0 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2496	Used time : 5981 s	Next ID: 39
........******E**
......T.T.T*****
........T*******
........********
......T.T.T*****
........********
........******E**
........********Time elapsed for measurement: 108.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.99 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 142	fail_ct: 1906	Time elapsed: 1.06
GA Iter: 0	Max score: 0.9903	Min score: 0.1301	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9811	#Pop: 128	#M+: 1393	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 15.36
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |            - |              - |      0 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2560	Used time : 6120 s	Next ID: 40
........********
........********
........********
........********
........T*******
........********
.......T.T******
........T*******Time elapsed for measurement: 113.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.85 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 69	fail_ct: 6075	Time elapsed: 4.64
GA Iter: 0	Max score: 0.9999	Min score: 0.0052	#Pop: 69	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9817	#Pop: 128	#M+: 1393	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 17.65
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |            - |              - |      0 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2624	Used time : 6255 s	Next ID: 41
........********
......T.T.T*****
........********
......T.T.T*****
........********
......T.T.T*****
.......T.T******
........********Time elapsed for measurement: 126.35 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.71 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 59	fail_ct: 4037	Time elapsed: 2.68
GA Iter: 0	Max score: 0.9836	Min score: 0.0008	#Pop: 59	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9994	Min score: 0.9810	#Pop: 128	#M+: 1401	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 16.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |            - |              - |      0 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2688	Used time : 6410 s	Next ID: 42
........********
......T.T.T*****
........********
.......T.T******
......T.T.T*****
........********
........********
........********Time elapsed for measurement: 111.20 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.42 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 52	fail_ct: 1996	Time elapsed: 1.20
GA Iter: 0	Max score: 0.9879	Min score: 0.0069	#Pop: 52	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9797	#Pop: 128	#M+: 1399	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 16.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |            - |              - |      0 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2752	Used time : 6546 s	Next ID: 43
........********
........T*******
........T*******
........********
........********
........********
........T*******
........********Time elapsed for measurement: 118.26 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 5.15 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 65	fail_ct: 1983	Time elapsed: 0.97
GA Iter: 0	Max score: 0.9930	Min score: 0.0004	#Pop: 65	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9829	#Pop: 128	#M+: 1401	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 15.01
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |            - |              - |      0 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2816	Used time : 6687 s	Next ID: 44
........********
........********
.......T.T******
........********
........*******
......T.T.T*****
......T.T.T*****
........T*******Time elapsed for measurement: 121.89 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 4.89 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 117	fail_ct: 1931	Time elapsed: 0.93
GA Iter: 0	Max score: 0.9868	Min score: 0.0018	#Pop: 117	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9801	#Pop: 128	#M+: 1392	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 13.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |            - |              - |      0 |
-------------------------------------------------
Estimated total latency: - ms	Trials: 2880	Used time : 6830 s	Next ID: 45
........********
.......T.T******
........********
........********
........********
........T*******
........********
........********Time elapsed for measurement: 100.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.59 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 64	fail_ct: 4032	Time elapsed: 4.69
GA Iter: 0	Max score: 0.9932	Min score: 0.0132	#Pop: 64	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9811	#Pop: 128	#M+: 1402	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.37
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |       12.751 |        3701.39 |     64 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 85.738 ms	Trials: 2944	Used time : 6951 s	Next ID: 28
........*****E**E*
........**E***T***
........T*E*****T*
........**E*E*****E
.......T.T******
........****E****
........T*******E
........********Time elapsed for measurement: 249.41 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.06 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 82	fail_ct: 6062	Time elapsed: 6.93
GA Iter: 0	Max score: 0.5726	Min score: -0.1088	#Pop: 82	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.7732	#Pop: 128	#M+: 1388	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 30.69
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.342 |        5052.31 |    128 |
|   29 |       10.828 |        4359.69 |     64 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 82.329 ms	Trials: 3008	Used time : 7241 s	Next ID: 29
........********
........********
........T*******
........********
........********
.......T.T******
......T.T.T*****
........********Time elapsed for measurement: 122.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.44 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 77	fail_ct: 1971	Time elapsed: 2.10
GA Iter: 0	Max score: 0.7457	Min score: -0.0936	#Pop: 77	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0141	Min score: 0.7703	#Pop: 128	#M+: 1391	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 28.43
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        1.170 |        2520.76 |     64 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.342 |        5052.31 |    128 |
|   29 |        9.339 |        5055.00 |    128 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 80.839 ms	Trials: 3072	Used time : 7409 s	Next ID: 17
........********
......T.T.T*****
........********
.......T.T******
........*E*******
........T*******
........T****E***E
........********Time elapsed for measurement: 119.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.02 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 95	fail_ct: 1953	Time elapsed: 2.04
GA Iter: 0	Max score: 0.9577	Min score: -0.1223	#Pop: 95	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0237	Min score: 0.9021	#Pop: 128	#M+: 1392	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 22.18
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.784 |        1681.52 |     64 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.342 |        5052.31 |    128 |
|   29 |        9.339 |        5055.00 |    128 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 78.916 ms	Trials: 3136	Used time : 7565 s	Next ID: 15
........T*******
........********
.......T.T******
........********
........********
........********
........********
........********Time elapsed for measurement: 105.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.50 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 56	fail_ct: 4040	Time elapsed: 4.62
GA Iter: 0	Max score: 0.5690	Min score: -0.1569	#Pop: 56	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0201	Min score: 0.7808	#Pop: 128	#M+: 1387	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.342 |        5052.31 |    128 |
|   29 |        9.339 |        5055.00 |    128 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 77.623 ms	Trials: 3200	Used time : 7704 s	Next ID: 28
........********
........********
........********
........********
........********
........T*******
......T.T.T*****
........********Time elapsed for measurement: 109.71 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.44 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 61	fail_ct: 4035	Time elapsed: 4.55
GA Iter: 0	Max score: 0.6553	Min score: -0.2360	#Pop: 61	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0007	Min score: 0.8992	#Pop: 128	#M+: 1396	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 30.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.106 |        5182.76 |    192 |
|   29 |        9.339 |        5055.00 |    128 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 77.388 ms	Trials: 3264	Used time : 7855 s	Next ID: 29
........********
........T*******
........T*******
........********
........********
........T*******
........********
........T******Time elapsed for measurement: 132.82 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.05 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 109	fail_ct: 3987	Time elapsed: 4.06
GA Iter: 0	Max score: 0.8109	Min score: -0.0359	#Pop: 109	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9917	Min score: 0.8330	#Pop: 128	#M+: 1392	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 27.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        2.333 |        1264.46 |     64 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.106 |        5182.76 |    192 |
|   29 |        9.017 |        5235.40 |    192 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 77.066 ms	Trials: 3328	Used time : 8032 s	Next ID: 23
........********
......T.T.T**E*E**
........*******
........********
........********
........********
......T.T.T*****
........********Time elapsed for measurement: 91.97 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.06 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 51	fail_ct: 1997	Time elapsed: 2.24
GA Iter: 0	Max score: 0.7832	Min score: -0.0764	#Pop: 51	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0256	Min score: 0.7887	#Pop: 128	#M+: 1384	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.106 |        5182.76 |    192 |
|   29 |        9.017 |        5235.40 |    192 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        3.908 |        3019.58 |     64 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 74.394 ms	Trials: 3392	Used time : 8163 s	Next ID: 31
........*******
........********
......T.T.T*****
........********
........********
......T.T.T*****
......T.T.T*****
........T*******Time elapsed for measurement: 112.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.09 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 52	fail_ct: 4044	Time elapsed: 4.58
GA Iter: 0	Max score: 0.5319	Min score: -0.2049	#Pop: 52	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9959	Min score: 0.9179	#Pop: 128	#M+: 1394	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 26.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.106 |        5182.76 |    192 |
|   29 |        9.017 |        5235.40 |    192 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 72.818 ms	Trials: 3456	Used time : 8315 s	Next ID: 28
........********
.......T.T******
........********
......T.T.T*****
........********
........T*******
........T*******
........********Time elapsed for measurement: 132.03 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 7.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 57	fail_ct: 4039	Time elapsed: 4.63
GA Iter: 0	Max score: 0.6526	Min score: -0.1335	#Pop: 57	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9950	Min score: 0.9023	#Pop: 128	#M+: 1398	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 30.59
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    256 |
|   29 |        9.017 |        5235.40 |    192 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 72.792 ms	Trials: 3520	Used time : 8486 s	Next ID: 29
........********
........********
........********
........T*******
........********
........********
........********
......T.T.T*****Time elapsed for measurement: 100.90 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 6.90 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 52	fail_ct: 1996	Time elapsed: 2.19
GA Iter: 0	Max score: 0.7135	Min score: -0.1557	#Pop: 52	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9895	Min score: 0.7587	#Pop: 128	#M+: 1386	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 28.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    256 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.856 |        4132.22 |     64 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 72.311 ms	Trials: 3584	Used time : 8629 s	Next ID: 32
........********
........T*******
......T.T.T*****
......T.T.T*****
........********
........********
........T*******
........T*******Time elapsed for measurement: 133.11 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 9.04 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 74	fail_ct: 1974	Time elapsed: 2.10
GA Iter: 0	Max score: 0.6627	Min score: -0.2533	#Pop: 74	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0223	Min score: 0.7685	#Pop: 128	#M+: 1397	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 22.61
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.699 |        1898.23 |     64 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    256 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 71.676 ms	Trials: 3648	Used time : 8803 s	Next ID: 9
........*******
........********
......T.T.T*****
........********
........T*******
......T.T.T*****
........T*******
......T.T.T*****Time elapsed for measurement: 135.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.73 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 87	fail_ct: 4009	Time elapsed: 4.57
GA Iter: 0	Max score: 0.6370	Min score: -0.1949	#Pop: 87	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9993	Min score: 0.7528	#Pop: 128	#M+: 1390	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.03
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.916 |        3226.69 |     64 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    256 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 71.596 ms	Trials: 3712	Used time : 8972 s	Next ID: 2
......T.T.T*****
........********
........********
......T.T.T*****
......T.T.T*****
........*******
........********
........********Time elapsed for measurement: 114.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 8.64 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 60	fail_ct: 1988	Time elapsed: 2.08
GA Iter: 0	Max score: 0.6270	Min score: -0.1651	#Pop: 60	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9884	Min score: 0.7927	#Pop: 128	#M+: 1392	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 29.18
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:

|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.906 |        3257.82 |     64 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    256 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.772 ms	Trials: 3776	Used time : 9128 s	Next ID: 11
........T*******
........********
........********
........T*******
........********
........***T*T*T*T*T*T
........*T*T*T*T*T*T*T*T
........*T*T*T*T*T*T*TTime elapsed for measurement: 300.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.47 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 79	fail_ct: 6065	Time elapsed: 6.97
GA Iter: 0	Max score: 0.5240	Min score: -0.1551	#Pop: 79	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0069	Min score: 0.9141	#Pop: 128	#M+: 1393	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 26.76
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    256 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 3840	Used time : 9471 s	Next ID: 28
........T*T*T*T*T*T*T*T
........*T*T*T*T*T*T*T*T
......T.T.T*T*T*T*T*T
........*T*T*T*T*T*T*T*T
........T*T*T*T*T*T*T*T
........T*T*T*T*T*T*T*T
........*T*T*T*T*T*T*T*T
........*T*T*T*T*T*T*TTime elapsed for measurement: 654.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.54 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 92	fail_ct: 1956	Time elapsed: 1.79
GA Iter: 0	Max score: 0.7078	Min score: -0.0358	#Pop: 92	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9826	Min score: 0.7796	#Pop: 128	#M+: 1405	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 20.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |     64 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 3904	Used time : 10170 s	Next ID: 16
........*T*T*T*T*T*T*T*T
........T*T*T*T*T*T*T*T
........T*T*T*T*T*T*T*T
........*T*T*T*T*T*T*T*T
.......T.T*T*T*T*T*T*T
......T.T.T*T*T*T*T*T
........*T*T*T*T*T*T*T*T
........*T*T*T*T*T*T*TTime elapsed for measurement: 639.23 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.24 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 75	fail_ct: 1973	Time elapsed: 2.05
GA Iter: 0	Max score: 0.6430	Min score: -0.0683	#Pop: 75	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9989	Min score: 0.8736	#Pop: 128	#M+: 1397	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 27.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |    128 |
|   17 |        0.850 |        3471.51 |    128 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 3968	Used time : 10842 s	Next ID: 17
........*T*T*T*T*T*T*T*T
........T*T*T*T*T*T*T==================================================
No: 3977	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609227245.52)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3978	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.22, Tstamp:1609227255.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3979	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.24, Tstamp:1609227265.61)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3980	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.26, Tstamp:1609227275.66)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.3 (0,5)
                for rc.2 (0,2)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3981	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.17, Tstamp:1609227285.71)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.3 (0,5)
                for rc.2 (0,2)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3982	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.14, Tstamp:1609227295.76)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,18)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3983	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.16, Tstamp:1609227305.80)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,18)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3984	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609227315.85)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.2 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 3985	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609227327.53)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3986	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609227337.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3987	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609227347.62)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.3 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3988	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.60, Tstamp:1609227357.67)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3989	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.66, Tstamp:1609227367.72)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3990	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.67, Tstamp:1609227377.76)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3991	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.67, Tstamp:1609227387.81)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3992	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609227397.86)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.2 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 3993	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.20, Tstamp:1609227410.38)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for rc.2 (0,2)
                for ry.2 (0,3)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3994	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.67, Tstamp:1609227420.43)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3995	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609227430.48)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3996	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.16, Tstamp:1609227440.52)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for rc.2 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3997	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.15, Tstamp:1609227450.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3998	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.67, Tstamp:1609227460.62)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,25)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,10)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,512)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,512)
          vectorize ax0@ax1@ax2@ax3@.1 (0,12)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,512)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 3999	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.07, Tstamp:1609227470.66)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for yy.3 (0,5)
              for rx.2 (0,3)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4000	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609227480.71)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.2 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              compute = ...
      for ax2.3 (0,5)
        T_relu = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4001	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609227495.93)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4002	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.60, Tstamp:1609227506.00)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.3 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4003	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609227516.05)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.4 (0,5)
              compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4004	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609227526.10)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4005	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.12, Tstamp:1609227536.14)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for ry.2 (0,3)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4006	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.14, Tstamp:1609227546.19)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,6)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.2 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4007	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.14, Tstamp:1609227556.24)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,6)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4008	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.70, Tstamp:1609227566.28)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for rc.2 (0,2)
                for ry.2 (0,3)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4009	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609227581.51)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 16
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4010	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609227591.56)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 16
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4011	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609227601.61)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 16
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4012	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.17, Tstamp:1609227611.65)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4013	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.12, Tstamp:1609227621.70)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4014	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.13, Tstamp:1609227631.75)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4015	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.10, Tstamp:1609227641.80)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for rx.1 (0,3)
            for ry.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4016	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.04, Tstamp:1609227651.84)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rx.1 (0,3)
          for rc.2 (0,4)
            for ry.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4017	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.41, Tstamp:1609227664.03)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 16
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for rc.2 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                for yy.4 (0,5)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4018	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.66, Tstamp:1609227674.08)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.2 (0,2)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4019	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.64, Tstamp:1609227684.13)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for rx.1 (0,3)
          for rc.2 (0,4)
            for ry.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4020	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.70, Tstamp:1609227694.17)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.2 (0,2)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4021	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.16, Tstamp:1609227704.22)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.2 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4022	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.11, Tstamp:1609227714.27)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4023	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.64, Tstamp:1609227724.32)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for rx.1 (0,3)
          for rc.2 (0,4)
            for ry.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4024	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609227734.36)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,128)
        for ry.0 (0,3)
          for ax0@ax1@ax2@ax3@.0.0 (0,3)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
              placeholder.shared = ...
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
          for rc.1 (0,2)
            for yy.3 (0,2)
              for xx.3 (0,5)
                for rx.2 (0,3)
                  compute = ...
      for ax2.3 (0,2)
        for ax3.3 (0,5)
          T_relu = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4025	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609227749.48)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for rc.2 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                for yy.4 (0,5)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4026	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.67, Tstamp:1609227759.52)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4027	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.84, Tstamp:1609227769.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for yy.3 (0,5)
                for rc.2 (0,2)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4028	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609227779.62)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 16
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.2 (0,4)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4029	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609227789.66)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,64)
        for rx.0 (0,3)
          for ax0@ax1@ax2@ax3@.0.0 (0,3)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
              placeholder.shared = ...
          for ax0@ax1@ax2@ax3@.0.0 (0,2)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
              vectorize ax0@ax1@ax2@ax3@.1 (0,4)
                pad_temp.shared = ...
          for rc.1 (0,2)
            for ry.1 (0,3)
              for yy.3 (0,5)
                for rc.2 (0,2)
                  compute = ...
      for ax2.3 (0,5)
        T_relu = ...

==================================================
No: 4030	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.49, Tstamp:1609227799.71)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
    compute auto_unroll: 1024
    for rc.0 (0,32)
      for ry.0 (0,3)
        for ax0@ax1@ax2@ax3@.0.0 (0,96)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,30)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,8)
          for rx.1 (0,3)
            for ff.3 (0,4)
              for yy.3 (0,5)
                for yy.4 (0,2)
                  for xx.4 (0,10)
                    compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        for ax3.3 (0,10)
          T_relu = ...

==================================================
No: 4031	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609227809.76)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,128)
        for ry.0 (0,3)
          for ax0@ax1@ax2@ax3@.0.0 (0,3)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
              placeholder.shared = ...
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
          for yy.3 (0,2)
            for rc.2 (0,2)
              for rx.2 (0,3)
                for xx.4 (0,5)
                  compute = ...
      for ax2.3 (0,2)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4032	GFLOPS: 0.00 / 3471.51	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609227819.81)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,128)
        for ry.0 (0,3)
          for ax0@ax1@ax2@ax3@.0.0 (0,3)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
              placeholder.shared = ...
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
          for rc.1 (0,2)
            for yy.3 (0,2)
              for rx.2 (0,3)
                for xx.4 (0,5)
                  compute = ...
      for ax2.3 (0,2)
        for ax3.3 (0,5)
          T_relu = ...

Time elapsed for measurement: 672.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.38 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 75	fail_ct: 6069	Time elapsed: 7.00
GA Iter: 0	Max score: 0.6325	Min score: -0.1722	#Pop: 75	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9802	Min score: 0.8914	#Pop: 128	#M+: 1406	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 30.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |    128 |
|   17 |        0.850 |        3471.51 |    192 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    256 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 4032	Used time : 11555 s	Next ID: 29
........*T*T*T*T*T*T*T==================================================
No: 4033	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609227879.83)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4034	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609227889.88)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ry.2 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4035	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609227899.93)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for rx.1 (0,3)
          for ry.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4036	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609227909.97)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.2 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4037	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609227920.02)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4038	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609227930.06)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.3 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4039	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609227940.11)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for xx.3 (0,2)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4040	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609227950.16)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4041	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609227961.71)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for xx.3 (0,2)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4042	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609227971.76)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for xx.3 (0,2)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4043	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609227981.80)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for xx.3 (0,2)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4044	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609227991.85)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4045	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609228001.90)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.3 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4046	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609228011.95)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for xx.3 (0,2)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4047	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609228021.99)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for xx.3 (0,2)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4048	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609228032.04)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4049	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609228047.28)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4050	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228057.33)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for xx.3 (0,2)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4051	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609228067.38)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for rx.1 (0,3)
          for ry.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4052	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228077.43)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for rx.1 (0,3)
          for xx.3 (0,2)
            for ry.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4053	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609228087.47)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4054	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228097.52)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for xx.3 (0,2)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4055	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228107.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for rx.1 (0,3)
          for xx.3 (0,2)
            for ry.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4056	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.50, Tstamp:1609228117.61)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for yy.3 (0,5)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4057	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.60, Tstamp:1609228129.20)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4058	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609228139.24)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for yy.3 (0,5)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4059	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609228149.29)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for yy.3 (0,5)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4060	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.61, Tstamp:1609228159.34)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for yy.3 (0,5)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4061	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609228169.38)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4062	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228179.43)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4063	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228189.48)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4064	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228199.53)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.3 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

*T
.......T.T*T*T*T*T*T==================================================
No: 4065	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609228214.74)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4066	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609228214.74)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for yy.3 (0,5)
          for xx.3 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4067	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228224.82)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.2 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4068	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228234.86)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.3 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4069	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609228244.91)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4070	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609228254.96)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.2 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4071	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.52, Tstamp:1609228265.01)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.3 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4072	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.52, Tstamp:1609228275.05)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4073	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609228290.30)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for yy.3 (0,5)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4074	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228300.37)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for yy.3 (0,5)
          for xx.3 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4075	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228310.42)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for yy.3 (0,5)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4076	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228320.46)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for yy.3 (0,5)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4077	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609228330.51)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for yy.3 (0,5)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4078	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.54, Tstamp:1609228340.55)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ry.1 (0,3)
          for yy.3 (0,5)
            for xx.3 (0,2)
              for rx.2 (0,3)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4079	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.54, Tstamp:1609228350.59)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.3 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4080	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609228360.64)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rx.2 (0,3)
              for yy.4 (0,5)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4081	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.89, Tstamp:1609228372.43)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for xx.3 (0,2)
                for yy.4 (0,5)
                  compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4082	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609228382.48)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for yy.3 (0,5)
          for xx.3 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4083	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228392.53)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4084	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609228402.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4085	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.58, Tstamp:1609228412.62)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4086	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609228422.66)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ry.2 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4087	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228432.70)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4088	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609228442.75)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.3 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4089	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.88, Tstamp:1609228456.29)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ry.1 (0,3)
            for rx.1 (0,3)
              for xx.3 (0,2)
                for yy.4 (0,5)
                  compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4090	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609228466.34)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.2 (0,3)
          for rx.2 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4091	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609228476.39)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for rx.1 (0,3)
            for yy.4 (0,5)
              for xx.4 (0,2)
                compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4092	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.87, Tstamp:1609228486.43)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ry.1 (0,3)
          for xx.3 (0,2)
            for rc.2 (0,2)
              for rx.2 (0,3)
                for yy.4 (0,5)
                  compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4093	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.89, Tstamp:1609228496.48)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for xx.3 (0,2)
          for rc.2 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                for yy.4 (0,5)
                  compute = ...
      for ax2.3 (0,5)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4094	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:12.61, Tstamp:1609228506.53)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,10)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ry.0 (0,3)
          for ax0@ax1@ax2@ax3@.0.0 (0,10)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
              placeholder.shared = ...
          for ax0@ax1@ax2@ax3@.0.0 (0,51)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
              pad_temp.shared = ...
          for rx.1 (0,3)
            for ff.3 (0,2)
              for yy.3 (0,10)
                for rc.2 (0,2)
                  for ff.4 (0,8)
                    for yy.4 (0,2)
                      for xx.4 (0,4)
                        compute = ...
      for ax1.3 (0,16)
        for ax2.3 (0,20)
          for ax3.3 (0,4)
            T_relu = ...

==================================================
No: 4095	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609228516.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,40)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ry.0 (0,3)
          for rx.0 (0,3)
            for ax0@ax1@ax2@ax3@.0.0 (0,52)
              threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,40)
                placeholder.shared = ...
            for ax0@ax1@ax2@ax3@.0.0 (0,40)
              threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,40)
                pad_temp.shared = ...
            for rc.1 (0,4)
              for ff.3 (0,128)
                for xx.3 (0,5)
                  for rc.2 (0,2)
                    compute = ...
      for ax1.3 (0,128)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4096	GFLOPS: 0.00 / 5530.45	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.08, Tstamp:1609228526.62)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,32)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 64
      for rc.0 (0,64)
        for rx.0 (0,3)
          for ax0@ax1@ax2@ax3@.0.0 (0,20)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
              placeholder.shared = ...
          for ax0@ax1@ax2@ax3@.0.0 (0,130)
            threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
              pad_temp.shared = ...
          for rc.1 (0,4)
            for ff.3 (0,4)
              for xx.3 (0,2)
                for ry.2 (0,3)
                  for ff.4 (0,2)
                    for yy.4 (0,5)
                      for xx.4 (0,25)
                        compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,5)
          for ax3.3 (0,50)
            T_relu = ...

Time elapsed for measurement: 658.29 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.40 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 91	fail_ct: 4005	Time elapsed: 4.10
GA Iter: 0	Max score: 0.8438	Min score: -0.1129	#Pop: 91	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0018	Min score: 0.8359	#Pop: 128	#M+: 1399	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 19.58
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |    128 |
|   17 |        0.850 |        3471.51 |    192 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |     64 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    320 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 4096	Used time : 12262 s	Next ID: 20
........*T*T*T*T*T*T*T==================================================
No: 4097	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.41, Tstamp:1609228572.28)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4098	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609228582.33)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4099	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609228592.38)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,512)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,2)
          for yy.4 (0,5)
            compute = ...
    for ax1.3 (0,2)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4100	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228602.42)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4101	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609228612.47)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4102	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.74, Tstamp:1609228622.52)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 1024
    for rc.0 (0,32)
      for ax0@ax1@ax2@ax3@.0.0 (0,13)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,10)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,8)
        for yy.3 (0,5)
          for rc.2 (0,4)
            for ff.4 (0,4)
              compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4103	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609228632.57)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,320)
    compute auto_unroll: 16
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,32)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,4)
          for ff.4 (0,8)
            for yy.4 (0,5)
              compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4104	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609228642.61)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.4 (0,2)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,2)
      for ax3.3 (0,5)
        T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4105	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609228654.05)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,320)
    compute auto_unroll: 64
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,32)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,8)
              for yy.4 (0,5)
                compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4106	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.80, Tstamp:1609228664.09)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 1024
    for rc.0 (0,32)
      for ax0@ax1@ax2@ax3@.0.0 (0,26)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,10)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,8)
        for yy.3 (0,5)
          for rc.2 (0,4)
            for ff.4 (0,4)
              compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4107	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.34, Tstamp:1609228674.14)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.3 (0,8)
        compute = ...
    for ax1.3 (0,8)
      T_add = ...

==================================================
No: 4108	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228684.19)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for ff.4 (0,4)
          for xx.4 (0,5)
            compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4109	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609228694.23)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,320)
    compute auto_unroll: 64
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,32)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,4)
          for ff.4 (0,8)
            for yy.4 (0,5)
              compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4110	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228704.28)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4111	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228714.32)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4112	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.32, Tstamp:1609228724.37)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.3 (0,4)
        for ff.4 (0,2)
          for xx.4 (0,5)
            compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4113	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228735.50)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4114	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228745.54)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.3 (0,4)
        for ff.4 (0,2)
          for xx.4 (0,5)
            compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4115	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228755.59)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    compute auto_unroll: 64
    for rc.0 (0,128)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,8)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4116	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609228765.63)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for xx.3 (0,5)
        for ff.4 (0,8)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4117	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228775.68)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,1024)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
        for ff.3 (0,2)
          for ff.4 (0,2)
            for yy.4 (0,5)
              compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,5)
          T_add = ...

==================================================
No: 4118	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609228785.73)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for xx.3 (0,5)
        for ff.4 (0,8)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4119	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228795.77)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,128)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,8)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4120	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228805.81)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,1024)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
        for ff.3 (0,8)
          compute = ...
      for ax1.3 (0,8)
        T_add = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4121	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609228831.12)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    compute auto_unroll: 64
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,3)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for rc.2 (0,8)
            for ff.4 (0,2)
              compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4122	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609228831.12)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4123	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228841.16)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    compute auto_unroll: 16
    for rc.0 (0,128)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,8)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4124	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228851.21)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 16
      for rc.0 (0,1024)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
        for ff.4 (0,8)
          compute = ...
      for ax1.3 (0,8)
        T_add = ...

==================================================
No: 4125	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609228861.25)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4126	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609228871.30)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4127	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228881.35)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4128	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.31, Tstamp:1609228891.40)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,128)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,8)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4129	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228902.66)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4130	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228912.71)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    compute auto_unroll: 16
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for rc.2 (0,8)
            for ff.4 (0,2)
              compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4131	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228922.76)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    compute auto_unroll: 16
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for rc.2 (0,8)
            for ff.4 (0,2)
              compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4132	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609228932.80)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,320)
    compute auto_unroll: 64
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,32)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,36)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,4)
          for ff.4 (0,8)
            for yy.4 (0,5)
              compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4133	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228942.85)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4134	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228952.90)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.4 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4135	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609228962.95)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for ff.4 (0,4)
          for xx.4 (0,5)
            compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4136	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609228972.99)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,16)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4137	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609228984.21)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,16)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4138	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609228994.26)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,320)
    compute auto_unroll: 64
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,32)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,4)
          for ff.4 (0,8)
            for yy.4 (0,5)
              compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4139	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609229004.31)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4140	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609229014.35)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.3 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4141	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609229024.40)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,16)
        for ff.3 (0,2)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4142	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609229034.44)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          pad_temp.shared = ...
      for rc.1 (0,16)
        for ff.3 (0,2)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4143	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229044.49)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,320)
    compute auto_unroll: 64
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,32)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,54)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,4)
          for ff.4 (0,8)
            for yy.4 (0,5)
              compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4144	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609229054.53)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
        for rc.1 (0,2)
          for rc.2 (0,4)
            compute = ...
      T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4145	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609229065.65)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4146	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609229075.70)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for rc.2 (0,8)
            for ff.4 (0,2)
              compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4147	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609229085.75)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 16
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for ff.4 (0,8)
          for xx.4 (0,5)
            compute = ...
    for ax1.3 (0,16)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4148	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609229095.79)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,512)
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        pad_temp.shared = ...
      for ff.3 (0,8)
        for rc.2 (0,2)
          compute = ...
    for ax1.3 (0,8)
      T_add = ...

==================================================
No: 4149	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609229105.84)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,64)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for rc.2 (0,8)
            for ff.4 (0,2)
              compute = ...
    for ax1.3 (0,4)
      T_add = ...

==================================================
No: 4150	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.41, Tstamp:1609229115.89)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    compute auto_unroll: 16
    for rc.0 (0,32)
      for ax0@ax1@ax2@ax3@.0.0 (0,11)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,4)
          for rc.2 (0,16)
            for ff.4 (0,2)
              compute = ...
    for ax1.3 (0,8)
      T_add = ...

==================================================
No: 4151	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609229125.93)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 512
    for rc.0 (0,1024)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4152	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609229135.98)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
        vectorize ax0@ax1@ax2@ax3@.1 (0,2)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for rc.2 (0,4)
          for ff.4 (0,2)
            compute = ...
    for ax1.3 (0,4)
      T_add = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4153	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229151.20)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4154	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609229161.25)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,200)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,3)
          pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.3 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4155	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609229171.29)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
    compute auto_unroll: 512
    for rc.0 (0,1024)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          pad_temp.shared = ...
      for ff.4 (0,8)
        for xx.4 (0,5)
          compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4156	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609229181.34)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,50)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,320)
    for rc.0 (0,256)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        vectorize ax0@ax1@ax2@ax3@.1 (0,32)
          placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,320)
        pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,8)
              for yy.4 (0,5)
                compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        T_add = ...

==================================================
No: 4157	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.82, Tstamp:1609229191.39)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,20)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for xx.3 (0,5)
            for rc.2 (0,4)
              compute = ...
      for ax3.3 (0,5)
        T_add = ...

==================================================
No: 4158	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609229201.44)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 1024
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,52)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for rc.2 (0,4)
            compute = ...
      T_add = ...

==================================================
No: 4159	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:14.28, Tstamp:1609229211.48)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,40)
      compute auto_unroll: 1024
      for rc.0 (0,1024)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,40)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,61)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,40)
            pad_temp.shared = ...
        for yy.3 (0,5)
          for xx.3 (0,5)
            for ff.4 (0,16)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,16)
        for ax2.3 (0,5)
          for ax3.3 (0,25)
            T_add = ...

==================================================
No: 4160	GFLOPS: 0.00 / 1133.85	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609229221.53)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,40)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
      compute auto_unroll: 16
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,6)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,9)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,2)
            for yy.3 (0,5)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,5)
          T_add = ...

Time elapsed for measurement: 660.75 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.48 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 75	fail_ct: 4021	Time elapsed: 4.33
GA Iter: 0	Max score: 0.8856	Min score: -0.2421	#Pop: 75	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0082	Min score: 0.8680	#Pop: 128	#M+: 1393	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 22.67
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |    128 |
|   17 |        0.850 |        3471.51 |    192 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |    128 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |     64 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    320 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 4160	Used time : 12957 s	Next ID: 27
........*T*T*T*T*T*T*T==================================================
No: 4161	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609229270.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4162	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.50, Tstamp:1609229280.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.3 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4163	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609229290.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4164	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609229300.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,32)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4165	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229310.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4166	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229320.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4167	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229330.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.3 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4168	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229340.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,4)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

*T
.......T.T*T*T*T*T*T==================================================
No: 4169	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229356.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for yy.4 (0,20)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,20)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4170	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229356.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for yy.3 (0,2)
            for ff.4 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4171	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.41, Tstamp:1609229366.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 16
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          pad_temp.shared = ...
        for ff.3 (0,2)
          for yy.3 (0,5)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,10)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4172	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609229376.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 16
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          pad_temp.shared = ...
        for ff.3 (0,2)
          for yy.3 (0,5)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,10)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4173	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609229386.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4174	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609229396.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.3 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4175	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.45, Tstamp:1609229406.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4176	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229416.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for yy.3 (0,2)
            for ff.4 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4177	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609229427.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4178	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609229437.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,32)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4179	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229447.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4180	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.52, Tstamp:1609229457.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4181	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.52, Tstamp:1609229467.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for yy.3 (0,2)
            for ff.4 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4182	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229477.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4183	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609229487.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,2)
            for yy.4 (0,5)
              for xx.4 (0,4)
                compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,5)
          for ax3.3 (0,4)
            T_add = ...

==================================================
No: 4184	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609229497.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

*T
.......T.T*T*T*T*T*T==================================================
No: 4185	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229523.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4186	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229523.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4187	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.50, Tstamp:1609229533.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4188	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229533.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4189	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609229543.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for yy.3 (0,5)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,10)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4190	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609229553.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,32)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4191	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609229563.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,32)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,2)
            for ff.4 (0,2)
              for yy.4 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4192	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609229573.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,32)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4193	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609229585.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,8)
            for xx.4 (0,4)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,4)
          T_add = ...

==================================================
No: 4194	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609229595.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,32)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4195	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229605.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4196	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609229615.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4197	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609229625.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4198	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.50, Tstamp:1609229635.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4199	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.67, Tstamp:1609229645.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 1024
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4200	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.61, Tstamp:1609229655.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 16
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.2 (0,4)
          for ff.4 (0,2)
            for yy.4 (0,20)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,20)
          for ax3.3 (0,2)
            T_add = ...

*T
......T.T.T*T*T*T*T==================================================
No: 4201	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229670.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,32)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for xx.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,4)
          T_add = ...

==================================================
No: 4202	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229670.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for ff.4 (0,2)
              for xx.4 (0,4)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,4)
          T_add = ...

==================================================
No: 4203	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.61, Tstamp:1609229680.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for yy.4 (0,5)
              for xx.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,5)
          for ax3.3 (0,4)
            T_add = ...

==================================================
No: 4204	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609229680.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for xx.3 (0,2)
              for yy.4 (0,5)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,5)
          for ax3.3 (0,4)
            T_add = ...

==================================================
No: 4205	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609229690.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 16
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,40)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for yy.3 (0,4)
          for rc.2 (0,16)
            for ff.4 (0,2)
              for yy.4 (0,5)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,20)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4206	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609229700.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,40)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for rc.2 (0,8)
            for ff.4 (0,2)
              for yy.4 (0,20)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,20)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4207	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609229710.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          pad_temp.shared = ...
        for ff.3 (0,2)
          for yy.3 (0,5)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,10)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4208	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609229720.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,10)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for xx.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,4)
          T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4209	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.66, Tstamp:1609229733.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,20)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for rc.2 (0,4)
            for ff.4 (0,2)
              for yy.4 (0,20)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,20)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4210	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.65, Tstamp:1609229743.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 16
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,20)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for rc.2 (0,4)
            for ff.4 (0,2)
              for yy.4 (0,20)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,20)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4211	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.96, Tstamp:1609229753.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,500)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,128)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,128)
            pad_temp.shared = ...
        for yy.3 (0,5)
          for rc.2 (0,4)
            for ff.4 (0,2)
              for yy.4 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,10)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4212	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.29, Tstamp:1609229763.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 1024
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4213	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.64, Tstamp:1609229773.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,4)
            for yy.4 (0,5)
              for xx.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,5)
          for ax3.3 (0,4)
            T_add = ...

==================================================
No: 4214	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609229783.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for ff.3 (0,4)
          for yy.3 (0,2)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4215	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.52, Tstamp:1609229793.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for xx.3 (0,2)
            for ff.4 (0,4)
              for yy.4 (0,5)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,5)
          for ax3.3 (0,4)
            T_add = ...

==================================================
No: 4216	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.14, Tstamp:1609229803.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 1024
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,32)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4217	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229815.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4218	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229826.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,4)
            for yy.4 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4219	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609229836.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for ff.3 (0,4)
          for yy.3 (0,2)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4220	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229846.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4221	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229856.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.3 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4222	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609229866.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 64
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            pad_temp.shared = ...
        for ff.3 (0,4)
          for xx.4 (0,5)
            compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4223	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.03, Tstamp:1609229876.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
    compute auto_unroll: 512
    for rc.0 (0,8)
      for ax0@ax1@ax2@ax3@.0.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,80)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          pad_temp.shared = ...
      for rc.1 (0,32)
        for ff.3 (0,16)
          for yy.3 (0,5)
            for xx.3 (0,4)
              compute = ...
    for ax1.3 (0,16)
      for ax2.3 (0,5)
        for ax3.3 (0,4)
          T_add = ...

==================================================
No: 4224	GFLOPS: 0.00 / 2329.80	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:11.30, Tstamp:1609229886.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2500)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,64)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for yy.3 (0,4)
            for xx.3 (0,2)
              for rc.2 (0,8)
                compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,4)
          for ax3.3 (0,2)
            T_add = ...

Time elapsed for measurement: 627.13 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.66 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 59	fail_ct: 1989	Time elapsed: 2.23
GA Iter: 0	Max score: 0.9209	Min score: -0.1797	#Pop: 59	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0088	Min score: 0.8747	#Pop: 128	#M+: 1392	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 22.66
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |     64 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |    128 |
|   17 |        0.850 |        3471.51 |    192 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |    128 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |    128 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    320 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 4224	Used time : 13622 s	Next ID: 4
........*T*T*T*T*T*T*T==================================================
No: 4225	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.50, Tstamp:1609229933.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4226	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229943.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4227	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609229953.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4228	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229963.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,6)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4229	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609229973.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,6)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4230	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609229983.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,4)
        for ax0@ax1@ax2@ax3@.0.0 (0,11)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4231	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609229993.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for ff.4 (0,2)
              compute = ...
      for ax1.3 (0,2)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4232	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.80, Tstamp:1609230003.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,20)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4233	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609230015.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,6)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4234	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609230025.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4235	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609230035.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4236	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609230045.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 64
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,6)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4237	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609230055.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,6)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4238	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.84, Tstamp:1609230065.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,4000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,20)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4239	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609230075.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4240	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609230085.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,8)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4241	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609230097.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4242	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609230107.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for ff.3 (0,8)
          for rc.2 (0,4)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4243	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609230117.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2500)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for yy.3 (0,2)
            for ff.4 (0,8)
              compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,2)
          T_relu = ...

==================================================
No: 4244	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609230127.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2500)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for yy.3 (0,2)
            for ff.4 (0,8)
              compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,2)
          T_relu = ...

==================================================
No: 4245	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.45, Tstamp:1609230137.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for ff.3 (0,8)
          for rc.2 (0,4)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4246	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609230147.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4247	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609230157.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,4)
        for ax0@ax1@ax2@ax3@.0.0 (0,11)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4248	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.46, Tstamp:1609230167.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2500)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,4)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for yy.3 (0,2)
            for ff.4 (0,8)
              compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,2)
          T_relu = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4249	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609230182.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,4)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,8)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,16)
          for ff.3 (0,8)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4250	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609230192.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for xx.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4251	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609230202.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4252	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609230212.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4253	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609230223.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4254	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.53, Tstamp:1609230233.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4255	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609230243.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for xx.3 (0,5)
          for rc.2 (0,2)
            for ff.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4256	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609230253.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for xx.3 (0,5)
          for rc.2 (0,8)
            for ff.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4257	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609230264.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 16
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            pad_temp.shared = ...
        for ff.3 (0,8)
          for rc.2 (0,4)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4258	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.61, Tstamp:1609230274.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          vectorize ax0@ax1@ax2@ax3@.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4259	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.45, Tstamp:1609230284.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4260	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.45, Tstamp:1609230294.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 16
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for ff.3 (0,8)
          for rc.2 (0,4)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4261	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609230304.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4262	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609230314.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4263	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.60, Tstamp:1609230324.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,8)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for xx.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4264	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609230334.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,8)
              pad_temp.shared = ...
        for xx.3 (0,5)
          for rc.2 (0,8)
            for ff.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4265	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609230350.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2500)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for rc.2 (0,2)
            for ff.4 (0,8)
              for yy.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,2)
          T_relu = ...

==================================================
No: 4266	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609230360.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4267	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.80, Tstamp:1609230370.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,4)
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,20)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,8)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4268	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609230380.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for xx.3 (0,5)
          for rc.2 (0,2)
            for ff.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4269	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609230390.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            pad_temp.shared = ...
        for ff.3 (0,8)
          for rc.2 (0,4)
            for xx.4 (0,2)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4270	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.79, Tstamp:1609230400.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,4)
        for ax0@ax1@ax2@ax3@.0.0 (0,16)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,20)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4271	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.54, Tstamp:1609230410.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4272	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.54, Tstamp:1609230420.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for xx.3 (0,5)
          for rc.2 (0,8)
            for ff.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4273	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609230432.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          vectorize ax0@ax1@ax2@ax3@.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for xx.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4274	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609230442.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for xx.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4275	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609230452.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for xx.3 (0,5)
          for rc.2 (0,8)
            for ff.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4276	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.46, Tstamp:1609230462.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,5000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 64
      for rc.0 (0,2)
        for ax0@ax1@ax2@ax3@.0.0 (0,128)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,16)
          for rc.2 (0,2)
            for ff.4 (0,8)
              for yy.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,2)
          T_relu = ...

==================================================
No: 4277	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.57, Tstamp:1609230472.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for xx.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4278	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.55, Tstamp:1609230482.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for xx.3 (0,5)
          for rc.2 (0,8)
            for ff.4 (0,4)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4279	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.56, Tstamp:1609230492.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,8)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4280	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609230502.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          vectorize ax0@ax1@ax2@ax3@.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4281	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609230514.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          vectorize ax0@ax1@ax2@ax3@.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4282	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.49, Tstamp:1609230524.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1600)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,100)
      compute auto_unroll: 16
      for rc.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
          vectorize ax0@ax1@ax2@ax3@.1 (0,16)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,100)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,8)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,2)
          T_relu = ...

==================================================
No: 4283	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609230534.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,5000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 16
      for rc.0 (0,2)
        for ax0@ax1@ax2@ax3@.0.0 (0,128)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,16)
          for rc.2 (0,2)
            for ff.4 (0,8)
              for yy.4 (0,2)
                compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,2)
          T_relu = ...

==================================================
No: 4284	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609230544.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,16000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 1024
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,5)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              compute = ...
      for ax3.3 (0,5)
        T_relu = ...

==================================================
No: 4285	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609230554.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,8000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 512
      for rc.0 (0,8)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
          vectorize ax0@ax1@ax2@ax3@.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,10)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,5)
            for rc.2 (0,2)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_relu = ...

==================================================
No: 4286	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.64, Tstamp:1609230564.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,128)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,200)
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,200)
            pad_temp.shared = ...
        for ff.3 (0,4)
          for yy.3 (0,5)
            for xx.3 (0,5)
              compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,5)
          for ax3.3 (0,5)
            T_relu = ...

==================================================
No: 4287	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.99, Tstamp:1609230574.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,125)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,8)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,40)
      compute auto_unroll: 16
      for rc.0 (0,4)
        for ax0@ax1@ax2@ax3@.0.0 (0,103)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,40)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,128)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,40)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,8)
            for xx.3 (0,2)
              for rc.2 (0,4)
                for ff.4 (0,2)
                  for yy.4 (0,2)
                    for xx.4 (0,4)
                      compute = ...
      for ax1.3 (0,16)
        for ax2.3 (0,2)
          for ax3.3 (0,8)
            T_relu = ...

==================================================
No: 4288	GFLOPS: 0.00 / 2147.82	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.71, Tstamp:1609230584.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,500)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,32)
      compute auto_unroll: 64
      for rc.0 (0,2)
        for ax0@ax1@ax2@ax3@.0.0 (0,128)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,160)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,32)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,2)
            for yy.3 (0,5)
              for xx.3 (0,2)
                for rc.2 (0,16)
                  for ff.4 (0,4)
                    for yy.4 (0,2)
                      for xx.4 (0,2)
                        compute = ...
      for ax1.3 (0,8)
        for ax2.3 (0,10)
          for ax3.3 (0,4)
            T_relu = ...

Time elapsed for measurement: 662.58 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 10.96 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 57	fail_ct: 4039	Time elapsed: 4.02
GA Iter: 0	Max score: 0.8356	Min score: -0.1077	#Pop: 57	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0027	Min score: 0.9115	#Pop: 128	#M+: 1385	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 21.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |    128 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |     64 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |    128 |
|   17 |        0.850 |        3471.51 |    192 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |    128 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |    128 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    320 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 4288	Used time : 14321 s	Next ID: 8
........*T*T*T*T*T*T*T==================================================
No: 4289	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609230632.55)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for yy.3 (0,2)
          for rc.2 (0,4)
            for ff.4 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4290	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609230642.59)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4291	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609230652.64)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4292	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609230662.68)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4293	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609230672.73)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,8)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4294	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609230682.77)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4295	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609230692.82)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4296	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.41, Tstamp:1609230702.86)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 16
      for rc.0 (0,32)
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,8)
          for ff.3 (0,8)
            for xx.4 (0,5)
              compute = ...
      for ax1.3 (0,8)
        for ax3.3 (0,5)
          T_add = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4297	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.46, Tstamp:1609230728.13)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,12)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for yy.3 (0,2)
            for xx.3 (0,2)
              for rc.2 (0,8)
                for ff.4 (0,4)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4298	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609230728.13)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 16
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4299	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609230738.17)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,6)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4300	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609230748.22)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,6)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for xx.4 (0,5)
              compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4301	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609230758.27)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,6)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4302	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609230768.31)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 16
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,6)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4303	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609230778.36)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,10)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,10)
            for ff.4 (0,2)
              compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4304	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.35, Tstamp:1609230788.41)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,6)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4305	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609230799.70)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for rc.2 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4306	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609230809.74)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,8)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,4)
            for xx.4 (0,4)
              compute = ...
      for ax1.3 (0,2)
        for ax3.3 (0,4)
          T_add = ...

==================================================
No: 4307	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.37, Tstamp:1609230819.79)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,4)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,4)
            for xx.4 (0,4)
              compute = ...
      for ax1.3 (0,2)
        for ax3.3 (0,4)
          T_add = ...

==================================================
No: 4308	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609230829.84)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for ff.3 (0,4)
          for yy.3 (0,2)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4309	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609230839.89)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,10)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for yy.3 (0,5)
          for ff.4 (0,4)
            for yy.4 (0,2)
              compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4310	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609230849.93)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for rc.2 (0,2)
              for yy.4 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4311	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609230859.98)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,10)
            for rc.2 (0,4)
              for ff.4 (0,2)
                compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4312	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.41, Tstamp:1609230870.03)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for rc.2 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4313	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609230881.24)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for rc.2 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4314	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.45, Tstamp:1609230891.28)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,8)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4315	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609230901.33)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,6)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4316	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609230911.37)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 512
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,6)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4317	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609230921.42)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for rc.2 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4318	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609230931.47)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4319	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.45, Tstamp:1609230941.51)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,4)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for yy.4 (0,2)
                compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4320	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609230951.55)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,64)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            vectorize ax0@ax1@ax2@ax3@.1 (0,2)
              placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,4)
            for xx.4 (0,4)
              compute = ...
      for ax1.3 (0,2)
        for ax3.3 (0,4)
          T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4321	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609230962.79)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4322	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609230972.84)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,13)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,12)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for yy.3 (0,2)
          for xx.3 (0,2)
            for rc.2 (0,16)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4323	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609230982.89)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,80)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,80)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4324	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609230992.93)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              pad_temp.shared = ...
        for ff.3 (0,4)
          for yy.3 (0,2)
            for rc.2 (0,4)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4325	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609231002.98)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,3)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4326	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609231013.03)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,64)
      compute auto_unroll: 64
      for rc.0 (0,128)
        for ax0@ax1@ax2@ax3@.0.0 (0,4)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,64)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for xx.4 (0,4)
              compute = ...
      for ax1.3 (0,2)
        for ax3.3 (0,4)
          T_add = ...

==================================================
No: 4327	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609231023.08)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for rc.2 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4328	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.46, Tstamp:1609231033.12)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,400)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,32)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,19)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for yy.3 (0,5)
          for xx.3 (0,2)
            for rc.2 (0,4)
              for ff.4 (0,4)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        for ax3.3 (0,2)
          T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4329	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.44, Tstamp:1609231044.38)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,4)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4330	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.36, Tstamp:1609231054.42)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for rc.2 (0,2)
            for ff.4 (0,2)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,5)
          T_add = ...

==================================================
No: 4331	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609231064.47)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 1024
    for rc.0 (0,32)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,64)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,6)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for xx.3 (0,2)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,2)
        for ax3.3 (0,2)
          T_add = ...

==================================================
No: 4332	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609231074.51)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,2000)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 1024
    for rc.0 (0,32)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,64)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,3)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for xx.3 (0,2)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,2)
        for ax3.3 (0,2)
          T_add = ...

==================================================
No: 4333	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.46, Tstamp:1609231084.56)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,28)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,2)
            for yy.3 (0,2)
              for rc.2 (0,4)
                for ff.4 (0,2)
                  for yy.4 (0,2)
                    compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,4)
          T_add = ...

==================================================
No: 4334	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.48, Tstamp:1609231094.60)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,19)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,8)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4335	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609231104.64)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4336	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609231114.69)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,10)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for ff.4 (0,2)
              for yy.4 (0,2)
                compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

*T
........*T*T*T*T*T*T*T==================================================
No: 4337	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609231126.06)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for ff.3 (0,4)
          for yy.3 (0,2)
            for rc.2 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4338	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609231136.11)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,10)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for ff.3 (0,2)
        for yy.3 (0,5)
          for rc.2 (0,4)
            for ff.4 (0,2)
              for yy.4 (0,2)
                compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4339	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.39, Tstamp:1609231146.15)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,64)
      for ax0@ax1@ax2@ax3@.0.0 (0,2)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,5)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for ff.4 (0,2)
              for yy.4 (0,2)
                compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4340	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.59, Tstamp:1609231156.20)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 1024
    for rc.0 (0,32)
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,19)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for yy.3 (0,5)
          for xx.3 (0,2)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,2)
      for ax2.3 (0,10)
        for ax3.3 (0,2)
          T_add = ...

==================================================
No: 4341	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.42, Tstamp:1609231166.25)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 1024
    for rc.0 (0,64)
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
        vectorize ax0@ax1@ax2@ax3@.1 (0,8)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for ff.3 (0,8)
        for yy.3 (0,2)
          for rc.2 (0,4)
            for xx.4 (0,2)
              compute = ...
    for ax1.3 (0,8)
      for ax2.3 (0,2)
        for ax3.3 (0,2)
          T_add = ...

==================================================
No: 4342	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609231176.29)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,8)
        for ax0@ax1@ax2@ax3@.0.0 (0,26)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,24)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for xx.3 (0,2)
            for rc.2 (0,8)
              for ff.4 (0,4)
                compute = ...
      for ax1.3 (0,4)
        for ax3.3 (0,2)
          T_add = ...

==================================================
No: 4343	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.47, Tstamp:1609231186.34)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,37)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for rc.2 (0,4)
            for ff.4 (0,2)
              for yy.4 (0,10)
                compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4344	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.41, Tstamp:1609231196.39)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,16)
      for ax0@ax1@ax2@ax3@.0.0 (0,7)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,19)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,4)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

*T
........T*T*T*T*T*T*T==================================================
No: 4345	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:BuildTimeoutError, error_msg:, all_cost:15.00, Tstamp:1609231211.61)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,32)
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,19)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

==================================================
No: 4346	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.43, Tstamp:1609231221.66)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,16)
        for ax0@ax1@ax2@ax3@.0.0 (0,7)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,28)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,4)
          for ff.3 (0,2)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,4)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,4)
          T_add = ...

==================================================
No: 4347	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.40, Tstamp:1609231231.71)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for xx.4 (0,2)
                compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4348	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.46, Tstamp:1609231241.75)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 64
      for rc.0 (0,64)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            vectorize ax0@ax1@ax2@ax3@.1 (0,3)
              pad_temp.shared = ...
        for rc.1 (0,2)
          for ff.3 (0,4)
            for yy.3 (0,2)
              for rc.2 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4349	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609231251.80)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1000)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,2)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
      compute auto_unroll: 1024
      for rc.0 (0,128)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,8)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,2)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for yy.3 (0,2)
            for rc.2 (0,2)
              for ff.4 (0,2)
                for xx.4 (0,2)
                  compute = ...
      for ax1.3 (0,4)
        for ax2.3 (0,2)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4350	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.51, Tstamp:1609231261.85)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1280)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,5)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,50)
      compute auto_unroll: 1024
      for rc.0 (0,256)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,50)
          placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,78)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,50)
            pad_temp.shared = ...
        for ff.3 (0,2)
          for xx.3 (0,2)
            for yy.4 (0,4)
              compute = ...
      for ax1.3 (0,2)
        for ax2.3 (0,4)
          for ax3.3 (0,2)
            T_add = ...

==================================================
No: 4351	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.74, Tstamp:1609231271.90)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,80)
  vthread ax0.1@ax1.1@ax2.1@ax3.1@ (0,4)
    threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,50)
      compute auto_unroll: 512
      for rc.0 (0,256)
        for ax0@ax1@ax2@ax3@.0.0 (0,3)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,50)
            placeholder.shared = ...
        for ax0@ax1@ax2@ax3@.0.0 (0,38)
          threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,50)
            pad_temp.shared = ...
        for ff.3 (0,8)
          for xx.3 (0,2)
            for ff.4 (0,4)
              for xx.4 (0,5)
                compute = ...
      for ax1.3 (0,32)
        for ax3.3 (0,10)
          T_add = ...

==================================================
No: 4352	GFLOPS: 0.00 / 1402.42	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.38, Tstamp:1609231281.94)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,800)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,160)
    compute auto_unroll: 64
    for rc.0 (0,32)
      for ax0@ax1@ax2@ax3@.0.0 (0,4)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          placeholder.shared = ...
      for ax0@ax1@ax2@ax3@.0.0 (0,10)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,160)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for yy.3 (0,5)
            for rc.2 (0,4)
              for ff.4 (0,2)
                for yy.4 (0,2)
                  compute = ...
    for ax1.3 (0,4)
      for ax2.3 (0,10)
        T_add = ...

Time elapsed for measurement: 660.67 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 11.20 s
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 57	fail_ct: 4039	Time elapsed: 4.70
GA Iter: 0	Max score: 0.5082	Min score: -0.1481	#Pop: 57	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9955	Min score: 0.9131	#Pop: 128	#M+: 1394	#M-: 0
EvolutionarySearch		#s: 128	Time elapsed: 27.58
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
*T
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        1.237 |        2451.18 |     64 |
|    1 |        0.152 |        2189.60 |     64 |
|    2 |        0.641 |        4607.93 |    128 |
|    3 |        0.473 |        2793.45 |     64 |
|    4 |        0.625 |        2147.82 |    128 |
|    5 |        0.599 |        2197.28 |     64 |
|    6 |        1.000 |        2632.70 |     64 |
|    7 |        1.425 |        2070.76 |     64 |
|    8 |        1.873 |        1402.42 |    128 |
|    9 |        0.679 |        1954.22 |    128 |
|   10 |        0.519 |        2528.27 |     64 |
|   11 |        0.695 |        4249.28 |    128 |
|   12 |        0.905 |        2903.40 |     64 |
|   13 |        1.239 |        2380.78 |     64 |
|   14 |        1.810 |        1449.85 |     64 |
|   15 |        0.568 |        2319.21 |    128 |
|   16 |        0.513 |        2557.18 |    128 |
|   17 |        0.850 |        3471.51 |    192 |
|   18 |        0.843 |        3113.74 |     64 |
|   19 |        1.031 |        2860.25 |     64 |
|   20 |        2.313 |        1133.85 |    128 |
|   21 |        0.584 |        2251.89 |     64 |
|   22 |        0.460 |        2848.79 |     64 |
|   23 |        0.997 |        2959.15 |    128 |
|   24 |        0.294 |        2228.65 |     64 |
|   25 |        0.488 |        2686.27 |     64 |
|   26 |        1.386 |        1895.30 |     64 |
|   27 |        2.259 |        2329.80 |    128 |
|   28 |        9.080 |        5197.94 |    320 |
|   29 |        8.536 |        5530.45 |    320 |
|   30 |        0.212 |        1160.75 |     64 |
|   31 |        2.332 |        5059.76 |    128 |
|   32 |        2.221 |        5313.23 |    128 |
|   33 |        0.073 |         839.87 |     64 |
|   34 |        0.788 |        3745.44 |     64 |
|   35 |        0.022 |         691.59 |     64 |
|   36 |        0.320 |        2306.84 |     64 |
|   37 |        0.297 |        2483.70 |     64 |
|   38 |        0.009 |         447.42 |     64 |
|   39 |        0.142 |        1401.72 |     64 |
|   40 |        0.006 |         160.53 |     64 |
|   41 |        0.196 |         314.74 |     64 |
|   42 |        0.057 |         268.31 |     64 |
|   43 |        0.018 |         215.36 |     64 |
|   44 |        0.006 |         171.33 |     64 |
|   45 |        0.004 |          68.66 |     64 |
-------------------------------------------------
Estimated total latency: 70.138 ms	Trials: 4352	Used time : 15018 s	Next ID: 28
........*T*T*T*T*T*T*T==================================================
No: 4353	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.83, Tstamp:1609231337.64)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for rx.1 (0,3)
          for ff.3 (0,4)
            for xx.3 (0,2)
              for ry.2 (0,3)
                for ff.4 (0,2)
                  for xx.4 (0,2)
                    compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

==================================================
No: 4354	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.81, Tstamp:1609231347.69)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for rx.1 (0,3)
        for xx.3 (0,4)
          for rc.2 (0,2)
            for ry.2 (0,3)
              for ff.4 (0,8)
                compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

==================================================
No: 4355	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.78, Tstamp:1609231357.74)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        pad_temp.shared = ...
      for ff.3 (0,8)
        for xx.3 (0,2)
          for rc.2 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                for xx.4 (0,2)
                  compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

==================================================
No: 4356	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.80, Tstamp:1609231367.78)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ry.1 (0,3)
          for ff.3 (0,4)
            for xx.3 (0,2)
              for rx.2 (0,3)
                for ff.4 (0,2)
                  for xx.4 (0,2)
                    compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

==================================================
No: 4357	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.80, Tstamp:1609231377.83)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ry.1 (0,3)
          for rx.1 (0,3)
            for ff.3 (0,4)
              for xx.3 (0,2)
                for ff.4 (0,2)
                  for xx.4 (0,2)
                    compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

==================================================
No: 4358	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.79, Tstamp:1609231387.88)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ry.1 (0,3)
          for rx.1 (0,3)
            for ff.3 (0,4)
              for ff.4 (0,2)
                for xx.4 (0,4)
                  compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

==================================================
No: 4359	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.82, Tstamp:1609231397.93)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for rc.1 (0,2)
        for ff.3 (0,2)
          for xx.3 (0,2)
            for ry.2 (0,3)
              for rx.2 (0,3)
                for ff.4 (0,4)
                  for xx.4 (0,2)
                    compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

==================================================
No: 4360	GFLOPS: 0.00 / 5197.94	results: MeasureResult(error_type:RunTimeoutError, error_msg:, all_cost:10.82, Tstamp:1609231407.97)
==================================================
Placeholder: placeholder, placeholder, placeholder
blockIdx.x ax0.0@ax1.0@ax2.0@ax3.0@ (0,1250)
  threadIdx.x ax0.2@ax1.2@ax2.2@ax3.2@ (0,256)
    compute auto_unroll: 1024
    for rc.0 (0,128)
      for ax0@ax1@ax2@ax3@.0.0 (0,9)
        threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
          vectorize ax0@ax1@ax2@ax3@.1 (0,2)
            placeholder.shared = ...
      threadIdx.x ax0@ax1@ax2@ax3@.0.1 (0,256)
        vectorize ax0@ax1@ax2@ax3@.1 (0,4)
          pad_temp.shared = ...
      for ff.3 (0,4)
        for rc.2 (0,2)
          for ry.2 (0,3)
            for rx.2 (0,3)
              for ff.4 (0,2)
                for xx.4 (0,4)
                  compute = ...
    for ax1.3 (0,8)
      for ax3.3 (0,4)
        T_add = ...

*T
.......