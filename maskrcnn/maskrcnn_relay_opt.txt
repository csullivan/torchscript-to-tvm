fn (%input0: Tensor[(1, 3, 300, 300), float32], %model.backbone.body.conv1.weight: Tensor[(64, 3, 7, 7), float32], %model.backbone.body.bn1.weight: Tensor[(64), float32], %model.backbone.body.bn1.running_var: Tensor[(64), float32], %model.backbone.body.bn1.bias: Tensor[(64), float32], %model.backbone.body.bn1.running_mean: Tensor[(64), float32], %model.backbone.body.layer1.0.conv1.weight: Tensor[(64, 64, 1, 1), float32], %model.backbone.body.layer1.0.bn1.weight: Tensor[(64), float32], %model.backbone.body.layer1.0.bn1.running_var: Tensor[(64), float32], %model.backbone.body.layer1.0.bn1.bias: Tensor[(64), float32], %model.backbone.body.layer1.0.bn1.running_mean: Tensor[(64), float32], %model.backbone.body.layer1.0.conv2.weight: Tensor[(64, 64, 3, 3), float32], %model.backbone.body.layer1.0.bn2.weight: Tensor[(64), float32], %model.backbone.body.layer1.0.bn2.running_var: Tensor[(64), float32], %model.backbone.body.layer1.0.bn2.bias: Tensor[(64), float32], %model.backbone.body.layer1.0.bn2.running_mean: Tensor[(64), float32], %model.backbone.body.layer1.0.conv3.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.body.layer1.0.bn3.weight: Tensor[(256), float32], %model.backbone.body.layer1.0.bn3.running_var: Tensor[(256), float32], %model.backbone.body.layer1.0.bn3.bias: Tensor[(256), float32], %model.backbone.body.layer1.0.bn3.running_mean: Tensor[(256), float32], %model.backbone.body.layer1.0.downsample.0.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.body.layer1.0.downsample.1.weight: Tensor[(256), float32], %model.backbone.body.layer1.0.downsample.1.running_var: Tensor[(256), float32], %model.backbone.body.layer1.0.downsample.1.bias: Tensor[(256), float32], %model.backbone.body.layer1.0.downsample.1.running_mean: Tensor[(256), float32], %model.backbone.body.layer1.1.conv1.weight: Tensor[(64, 256, 1, 1), float32], %model.backbone.body.layer1.1.bn1.weight: Tensor[(64), float32], %model.backbone.body.layer1.1.bn1.running_var: Tensor[(64), float32], %model.backbone.body.layer1.1.bn1.bias: Tensor[(64), float32], %model.backbone.body.layer1.1.bn1.running_mean: Tensor[(64), float32], %model.backbone.body.layer1.1.conv2.weight: Tensor[(64, 64, 3, 3), float32], %model.backbone.body.layer1.1.bn2.weight: Tensor[(64), float32], %model.backbone.body.layer1.1.bn2.running_var: Tensor[(64), float32], %model.backbone.body.layer1.1.bn2.bias: Tensor[(64), float32], %model.backbone.body.layer1.1.bn2.running_mean: Tensor[(64), float32], %model.backbone.body.layer1.1.conv3.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.body.layer1.1.bn3.weight: Tensor[(256), float32], %model.backbone.body.layer1.1.bn3.running_var: Tensor[(256), float32], %model.backbone.body.layer1.1.bn3.bias: Tensor[(256), float32], %model.backbone.body.layer1.1.bn3.running_mean: Tensor[(256), float32], %model.backbone.body.layer1.2.conv1.weight: Tensor[(64, 256, 1, 1), float32], %model.backbone.body.layer1.2.bn1.weight: Tensor[(64), float32], %model.backbone.body.layer1.2.bn1.running_var: Tensor[(64), float32], %model.backbone.body.layer1.2.bn1.bias: Tensor[(64), float32], %model.backbone.body.layer1.2.bn1.running_mean: Tensor[(64), float32], %model.backbone.body.layer1.2.conv2.weight: Tensor[(64, 64, 3, 3), float32], %model.backbone.body.layer1.2.bn2.weight: Tensor[(64), float32], %model.backbone.body.layer1.2.bn2.running_var: Tensor[(64), float32], %model.backbone.body.layer1.2.bn2.bias: Tensor[(64), float32], %model.backbone.body.layer1.2.bn2.running_mean: Tensor[(64), float32], %model.backbone.body.layer1.2.conv3.weight: Tensor[(256, 64, 1, 1), float32], %model.backbone.body.layer1.2.bn3.weight: Tensor[(256), float32], %model.backbone.body.layer1.2.bn3.running_var: Tensor[(256), float32], %model.backbone.body.layer1.2.bn3.bias: Tensor[(256), float32], %model.backbone.body.layer1.2.bn3.running_mean: Tensor[(256), float32], %model.backbone.body.layer2.0.conv1.weight: Tensor[(128, 256, 1, 1), float32], %model.backbone.body.layer2.0.bn1.weight: Tensor[(128), float32], %model.backbone.body.layer2.0.bn1.running_var: Tensor[(128), float32], %model.backbone.body.layer2.0.bn1.bias: Tensor[(128), float32], %model.backbone.body.layer2.0.bn1.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.0.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.body.layer2.0.bn2.weight: Tensor[(128), float32], %model.backbone.body.layer2.0.bn2.running_var: Tensor[(128), float32], %model.backbone.body.layer2.0.bn2.bias: Tensor[(128), float32], %model.backbone.body.layer2.0.bn2.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.0.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.body.layer2.0.bn3.weight: Tensor[(512), float32], %model.backbone.body.layer2.0.bn3.running_var: Tensor[(512), float32], %model.backbone.body.layer2.0.bn3.bias: Tensor[(512), float32], %model.backbone.body.layer2.0.bn3.running_mean: Tensor[(512), float32], %model.backbone.body.layer2.0.downsample.0.weight: Tensor[(512, 256, 1, 1), float32], %model.backbone.body.layer2.0.downsample.1.weight: Tensor[(512), float32], %model.backbone.body.layer2.0.downsample.1.running_var: Tensor[(512), float32], %model.backbone.body.layer2.0.downsample.1.bias: Tensor[(512), float32], %model.backbone.body.layer2.0.downsample.1.running_mean: Tensor[(512), float32], %model.backbone.body.layer2.1.conv1.weight: Tensor[(128, 512, 1, 1), float32], %model.backbone.body.layer2.1.bn1.weight: Tensor[(128), float32], %model.backbone.body.layer2.1.bn1.running_var: Tensor[(128), float32], %model.backbone.body.layer2.1.bn1.bias: Tensor[(128), float32], %model.backbone.body.layer2.1.bn1.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.1.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.body.layer2.1.bn2.weight: Tensor[(128), float32], %model.backbone.body.layer2.1.bn2.running_var: Tensor[(128), float32], %model.backbone.body.layer2.1.bn2.bias: Tensor[(128), float32], %model.backbone.body.layer2.1.bn2.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.1.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.body.layer2.1.bn3.weight: Tensor[(512), float32], %model.backbone.body.layer2.1.bn3.running_var: Tensor[(512), float32], %model.backbone.body.layer2.1.bn3.bias: Tensor[(512), float32], %model.backbone.body.layer2.1.bn3.running_mean: Tensor[(512), float32], %model.backbone.body.layer2.2.conv1.weight: Tensor[(128, 512, 1, 1), float32], %model.backbone.body.layer2.2.bn1.weight: Tensor[(128), float32], %model.backbone.body.layer2.2.bn1.running_var: Tensor[(128), float32], %model.backbone.body.layer2.2.bn1.bias: Tensor[(128), float32], %model.backbone.body.layer2.2.bn1.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.2.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.body.layer2.2.bn2.weight: Tensor[(128), float32], %model.backbone.body.layer2.2.bn2.running_var: Tensor[(128), float32], %model.backbone.body.layer2.2.bn2.bias: Tensor[(128), float32], %model.backbone.body.layer2.2.bn2.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.2.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.body.layer2.2.bn3.weight: Tensor[(512), float32], %model.backbone.body.layer2.2.bn3.running_var: Tensor[(512), float32], %model.backbone.body.layer2.2.bn3.bias: Tensor[(512), float32], %model.backbone.body.layer2.2.bn3.running_mean: Tensor[(512), float32], %model.backbone.body.layer2.3.conv1.weight: Tensor[(128, 512, 1, 1), float32], %model.backbone.body.layer2.3.bn1.weight: Tensor[(128), float32], %model.backbone.body.layer2.3.bn1.running_var: Tensor[(128), float32], %model.backbone.body.layer2.3.bn1.bias: Tensor[(128), float32], %model.backbone.body.layer2.3.bn1.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.3.conv2.weight: Tensor[(128, 128, 3, 3), float32], %model.backbone.body.layer2.3.bn2.weight: Tensor[(128), float32], %model.backbone.body.layer2.3.bn2.running_var: Tensor[(128), float32], %model.backbone.body.layer2.3.bn2.bias: Tensor[(128), float32], %model.backbone.body.layer2.3.bn2.running_mean: Tensor[(128), float32], %model.backbone.body.layer2.3.conv3.weight: Tensor[(512, 128, 1, 1), float32], %model.backbone.body.layer2.3.bn3.weight: Tensor[(512), float32], %model.backbone.body.layer2.3.bn3.running_var: Tensor[(512), float32], %model.backbone.body.layer2.3.bn3.bias: Tensor[(512), float32], %model.backbone.body.layer2.3.bn3.running_mean: Tensor[(512), float32], %model.backbone.body.layer3.0.conv1.weight: Tensor[(256, 512, 1, 1), float32], %model.backbone.body.layer3.0.bn1.weight: Tensor[(256), float32], %model.backbone.body.layer3.0.bn1.running_var: Tensor[(256), float32], %model.backbone.body.layer3.0.bn1.bias: Tensor[(256), float32], %model.backbone.body.layer3.0.bn1.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.0.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.body.layer3.0.bn2.weight: Tensor[(256), float32], %model.backbone.body.layer3.0.bn2.running_var: Tensor[(256), float32], %model.backbone.body.layer3.0.bn2.bias: Tensor[(256), float32], %model.backbone.body.layer3.0.bn2.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.0.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.body.layer3.0.bn3.weight: Tensor[(1024), float32], %model.backbone.body.layer3.0.bn3.running_var: Tensor[(1024), float32], %model.backbone.body.layer3.0.bn3.bias: Tensor[(1024), float32], %model.backbone.body.layer3.0.bn3.running_mean: Tensor[(1024), float32], %model.backbone.body.layer3.0.downsample.0.weight: Tensor[(1024, 512, 1, 1), float32], %model.backbone.body.layer3.0.downsample.1.weight: Tensor[(1024), float32], %model.backbone.body.layer3.0.downsample.1.running_var: Tensor[(1024), float32], %model.backbone.body.layer3.0.downsample.1.bias: Tensor[(1024), float32], %model.backbone.body.layer3.0.downsample.1.running_mean: Tensor[(1024), float32], %model.backbone.body.layer3.1.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.body.layer3.1.bn1.weight: Tensor[(256), float32], %model.backbone.body.layer3.1.bn1.running_var: Tensor[(256), float32], %model.backbone.body.layer3.1.bn1.bias: Tensor[(256), float32], %model.backbone.body.layer3.1.bn1.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.1.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.body.layer3.1.bn2.weight: Tensor[(256), float32], %model.backbone.body.layer3.1.bn2.running_var: Tensor[(256), float32], %model.backbone.body.layer3.1.bn2.bias: Tensor[(256), float32], %model.backbone.body.layer3.1.bn2.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.1.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.body.layer3.1.bn3.weight: Tensor[(1024), float32], %model.backbone.body.layer3.1.bn3.running_var: Tensor[(1024), float32], %model.backbone.body.layer3.1.bn3.bias: Tensor[(1024), float32], %model.backbone.body.layer3.1.bn3.running_mean: Tensor[(1024), float32], %model.backbone.body.layer3.2.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.body.layer3.2.bn1.weight: Tensor[(256), float32], %model.backbone.body.layer3.2.bn1.running_var: Tensor[(256), float32], %model.backbone.body.layer3.2.bn1.bias: Tensor[(256), float32], %model.backbone.body.layer3.2.bn1.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.2.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.body.layer3.2.bn2.weight: Tensor[(256), float32], %model.backbone.body.layer3.2.bn2.running_var: Tensor[(256), float32], %model.backbone.body.layer3.2.bn2.bias: Tensor[(256), float32], %model.backbone.body.layer3.2.bn2.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.2.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.body.layer3.2.bn3.weight: Tensor[(1024), float32], %model.backbone.body.layer3.2.bn3.running_var: Tensor[(1024), float32], %model.backbone.body.layer3.2.bn3.bias: Tensor[(1024), float32], %model.backbone.body.layer3.2.bn3.running_mean: Tensor[(1024), float32], %model.backbone.body.layer3.3.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.body.layer3.3.bn1.weight: Tensor[(256), float32], %model.backbone.body.layer3.3.bn1.running_var: Tensor[(256), float32], %model.backbone.body.layer3.3.bn1.bias: Tensor[(256), float32], %model.backbone.body.layer3.3.bn1.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.3.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.body.layer3.3.bn2.weight: Tensor[(256), float32], %model.backbone.body.layer3.3.bn2.running_var: Tensor[(256), float32], %model.backbone.body.layer3.3.bn2.bias: Tensor[(256), float32], %model.backbone.body.layer3.3.bn2.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.3.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.body.layer3.3.bn3.weight: Tensor[(1024), float32], %model.backbone.body.layer3.3.bn3.running_var: Tensor[(1024), float32], %model.backbone.body.layer3.3.bn3.bias: Tensor[(1024), float32], %model.backbone.body.layer3.3.bn3.running_mean: Tensor[(1024), float32], %model.backbone.body.layer3.4.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.body.layer3.4.bn1.weight: Tensor[(256), float32], %model.backbone.body.layer3.4.bn1.running_var: Tensor[(256), float32], %model.backbone.body.layer3.4.bn1.bias: Tensor[(256), float32], %model.backbone.body.layer3.4.bn1.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.4.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.body.layer3.4.bn2.weight: Tensor[(256), float32], %model.backbone.body.layer3.4.bn2.running_var: Tensor[(256), float32], %model.backbone.body.layer3.4.bn2.bias: Tensor[(256), float32], %model.backbone.body.layer3.4.bn2.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.4.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.body.layer3.4.bn3.weight: Tensor[(1024), float32], %model.backbone.body.layer3.4.bn3.running_var: Tensor[(1024), float32], %model.backbone.body.layer3.4.bn3.bias: Tensor[(1024), float32], %model.backbone.body.layer3.4.bn3.running_mean: Tensor[(1024), float32], %model.backbone.body.layer3.5.conv1.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.body.layer3.5.bn1.weight: Tensor[(256), float32], %model.backbone.body.layer3.5.bn1.running_var: Tensor[(256), float32], %model.backbone.body.layer3.5.bn1.bias: Tensor[(256), float32], %model.backbone.body.layer3.5.bn1.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.5.conv2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.body.layer3.5.bn2.weight: Tensor[(256), float32], %model.backbone.body.layer3.5.bn2.running_var: Tensor[(256), float32], %model.backbone.body.layer3.5.bn2.bias: Tensor[(256), float32], %model.backbone.body.layer3.5.bn2.running_mean: Tensor[(256), float32], %model.backbone.body.layer3.5.conv3.weight: Tensor[(1024, 256, 1, 1), float32], %model.backbone.body.layer3.5.bn3.weight: Tensor[(1024), float32], %model.backbone.body.layer3.5.bn3.running_var: Tensor[(1024), float32], %model.backbone.body.layer3.5.bn3.bias: Tensor[(1024), float32], %model.backbone.body.layer3.5.bn3.running_mean: Tensor[(1024), float32], %model.backbone.body.layer4.0.conv1.weight: Tensor[(512, 1024, 1, 1), float32], %model.backbone.body.layer4.0.bn1.weight: Tensor[(512), float32], %model.backbone.body.layer4.0.bn1.running_var: Tensor[(512), float32], %model.backbone.body.layer4.0.bn1.bias: Tensor[(512), float32], %model.backbone.body.layer4.0.bn1.running_mean: Tensor[(512), float32], %model.backbone.body.layer4.0.conv2.weight: Tensor[(512, 512, 3, 3), float32], %model.backbone.body.layer4.0.bn2.weight: Tensor[(512), float32], %model.backbone.body.layer4.0.bn2.running_var: Tensor[(512), float32], %model.backbone.body.layer4.0.bn2.bias: Tensor[(512), float32], %model.backbone.body.layer4.0.bn2.running_mean: Tensor[(512), float32], %model.backbone.body.layer4.0.conv3.weight: Tensor[(2048, 512, 1, 1), float32], %model.backbone.body.layer4.0.bn3.weight: Tensor[(2048), float32], %model.backbone.body.layer4.0.bn3.running_var: Tensor[(2048), float32], %model.backbone.body.layer4.0.bn3.bias: Tensor[(2048), float32], %model.backbone.body.layer4.0.bn3.running_mean: Tensor[(2048), float32], %model.backbone.body.layer4.0.downsample.0.weight: Tensor[(2048, 1024, 1, 1), float32], %model.backbone.body.layer4.0.downsample.1.weight: Tensor[(2048), float32], %model.backbone.body.layer4.0.downsample.1.running_var: Tensor[(2048), float32], %model.backbone.body.layer4.0.downsample.1.bias: Tensor[(2048), float32], %model.backbone.body.layer4.0.downsample.1.running_mean: Tensor[(2048), float32], %model.backbone.body.layer4.1.conv1.weight: Tensor[(512, 2048, 1, 1), float32], %model.backbone.body.layer4.1.bn1.weight: Tensor[(512), float32], %model.backbone.body.layer4.1.bn1.running_var: Tensor[(512), float32], %model.backbone.body.layer4.1.bn1.bias: Tensor[(512), float32], %model.backbone.body.layer4.1.bn1.running_mean: Tensor[(512), float32], %model.backbone.body.layer4.1.conv2.weight: Tensor[(512, 512, 3, 3), float32], %model.backbone.body.layer4.1.bn2.weight: Tensor[(512), float32], %model.backbone.body.layer4.1.bn2.running_var: Tensor[(512), float32], %model.backbone.body.layer4.1.bn2.bias: Tensor[(512), float32], %model.backbone.body.layer4.1.bn2.running_mean: Tensor[(512), float32], %model.backbone.body.layer4.1.conv3.weight: Tensor[(2048, 512, 1, 1), float32], %model.backbone.body.layer4.1.bn3.weight: Tensor[(2048), float32], %model.backbone.body.layer4.1.bn3.running_var: Tensor[(2048), float32], %model.backbone.body.layer4.1.bn3.bias: Tensor[(2048), float32], %model.backbone.body.layer4.1.bn3.running_mean: Tensor[(2048), float32], %model.backbone.body.layer4.2.conv1.weight: Tensor[(512, 2048, 1, 1), float32], %model.backbone.body.layer4.2.bn1.weight: Tensor[(512), float32], %model.backbone.body.layer4.2.bn1.running_var: Tensor[(512), float32], %model.backbone.body.layer4.2.bn1.bias: Tensor[(512), float32], %model.backbone.body.layer4.2.bn1.running_mean: Tensor[(512), float32], %model.backbone.body.layer4.2.conv2.weight: Tensor[(512, 512, 3, 3), float32], %model.backbone.body.layer4.2.bn2.weight: Tensor[(512), float32], %model.backbone.body.layer4.2.bn2.running_var: Tensor[(512), float32], %model.backbone.body.layer4.2.bn2.bias: Tensor[(512), float32], %model.backbone.body.layer4.2.bn2.running_mean: Tensor[(512), float32], %model.backbone.body.layer4.2.conv3.weight: Tensor[(2048, 512, 1, 1), float32], %model.backbone.body.layer4.2.bn3.weight: Tensor[(2048), float32], %model.backbone.body.layer4.2.bn3.running_var: Tensor[(2048), float32], %model.backbone.body.layer4.2.bn3.bias: Tensor[(2048), float32], %model.backbone.body.layer4.2.bn3.running_mean: Tensor[(2048), float32], %model.backbone.fpn.inner_blocks.0.weight: Tensor[(256, 256, 1, 1), float32], %model.backbone.fpn.inner_blocks.0.bias: Tensor[(256), float32], %model.backbone.fpn.inner_blocks.1.weight: Tensor[(256, 512, 1, 1), float32], %model.backbone.fpn.inner_blocks.1.bias: Tensor[(256), float32], %model.backbone.fpn.inner_blocks.2.weight: Tensor[(256, 1024, 1, 1), float32], %model.backbone.fpn.inner_blocks.2.bias: Tensor[(256), float32], %model.backbone.fpn.inner_blocks.3.weight: Tensor[(256, 2048, 1, 1), float32], %model.backbone.fpn.inner_blocks.3.bias: Tensor[(256), float32], %model.backbone.fpn.layer_blocks.0.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.fpn.layer_blocks.0.bias: Tensor[(256), float32], %model.backbone.fpn.layer_blocks.1.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.fpn.layer_blocks.1.bias: Tensor[(256), float32], %model.backbone.fpn.layer_blocks.2.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.fpn.layer_blocks.2.bias: Tensor[(256), float32], %model.backbone.fpn.layer_blocks.3.weight: Tensor[(256, 256, 3, 3), float32], %model.backbone.fpn.layer_blocks.3.bias: Tensor[(256), float32], %model.rpn.head.conv.weight: Tensor[(256, 256, 3, 3), float32], %model.rpn.head.conv.bias: Tensor[(256), float32], %model.rpn.head.cls_logits.weight: Tensor[(3, 256, 1, 1), float32], %model.rpn.head.cls_logits.bias: Tensor[(3), float32], %model.rpn.head.bbox_pred.weight: Tensor[(12, 256, 1, 1), float32], %model.rpn.head.bbox_pred.bias: Tensor[(12), float32], %model.roi_heads.box_head.fc6.weight: Tensor[(1024, 12544), float32], %model.roi_heads.box_head.fc6.bias: Tensor[(1024), float32], %model.roi_heads.box_head.fc7.weight: Tensor[(1024, 1024), float32], %model.roi_heads.box_head.fc7.bias: Tensor[(1024), float32], %model.roi_heads.box_predictor.cls_score.weight: Tensor[(91, 1024), float32], %model.roi_heads.box_predictor.cls_score.bias: Tensor[(91), float32], %model.roi_heads.box_predictor.bbox_pred.weight: Tensor[(364, 1024), float32], %model.roi_heads.box_predictor.bbox_pred.bias: Tensor[(364), float32], %model.roi_heads.mask_head.mask_fcn1.weight: Tensor[(256, 256, 3, 3), float32], %model.roi_heads.mask_head.mask_fcn1.bias: Tensor[(256), float32], %model.roi_heads.mask_head.mask_fcn2.weight: Tensor[(256, 256, 3, 3), float32], %model.roi_heads.mask_head.mask_fcn2.bias: Tensor[(256), float32], %model.roi_heads.mask_head.mask_fcn3.weight: Tensor[(256, 256, 3, 3), float32], %model.roi_heads.mask_head.mask_fcn3.bias: Tensor[(256), float32], %model.roi_heads.mask_head.mask_fcn4.weight: Tensor[(256, 256, 3, 3), float32], %model.roi_heads.mask_head.mask_fcn4.bias: Tensor[(256), float32], %model.roi_heads.mask_predictor.conv5_mask.weight: Tensor[(256, 256, 2, 2), float32], %model.roi_heads.mask_predictor.conv5_mask.bias: Tensor[(256), float32], %model.roi_heads.mask_predictor.mask_fcn_logits.weight: Tensor[(91, 256, 1, 1), float32], %model.roi_heads.mask_predictor.mask_fcn_logits.bias: Tensor[(91), float32]) -> (Tensor[(?, 4), float32], Tensor[(?), float32], Tensor[(?), int64], Tensor[(?, 1, ?, ?), float32]) {
  let %x: (Tensor[(?, 4), float32], Tensor[(?), float32], Tensor[(?), int64], Tensor[(?, 1, ?, ?), float32]) = let %storage_0: Storage[] = memory.alloc_storage(7680000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][0]) /* ty=Storage[] */;
  let %tensor_0: Tensor[(1, 3, 800, 800), float32] = memory.alloc_tensor(%storage_0, 0 /* ty=int64 */, meta[relay.Constant][0] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][0]) /* ty=Tensor[(1, 3, 800, 800), float32] */;
  %10 = fn (%p0: Tensor[(1, 3, 300, 300), float32], %p1: Tensor[(3, 1, 1), float32], %p2: Tensor[(3, 1, 1), float32], Primitive=1) -> Tensor[(1, 3, 800, 800), float32] {
    %0 = split(%p0, indices_or_sections=1) /* ty=(Tensor[(1, 3, 300, 300), float32],) */;
    %1 = %0.0;
    %2 = squeeze(%1, axis=[0]) /* ty=Tensor[(3, 300, 300), float32] */;
    %3 = subtract(%2, %p1) /* ty=Tensor[(3, 300, 300), float32] */;
    %4 = divide(%3, %p2) /* ty=Tensor[(3, 300, 300), float32] */;
    %5 = expand_dims(%4, axis=0) /* ty=Tensor[(1, 3, 300, 300), float32] */;
    %6 = image.resize(%5, size=[800, 800]) /* ty=Tensor[(1, 3, 800, 800), float32] */;
    %7 = take(%6, 0 /* ty=int32 */, axis=0) /* ty=Tensor[(3, 800, 800), float32] */;
    %8 = nn.pad(%7, pad_width=[[0, 0], [0, 0], [0, 0]]) /* ty=Tensor[(3, 800, 800), float32] */;
    %9 = (%8,);
    stack(%9) /* ty=Tensor[(1, 3, 800, 800), float32] */
  };
  %11 = (%input0, meta[relay.Constant][1] /* ty=Tensor[(3, 1, 1), float32] */, meta[relay.Constant][2] /* ty=Tensor[(3, 1, 1), float32] */);
  %12 = (%tensor_0,);
  let %v: () = vm.invoke_tvm_op(%10, %11, %12) /* ty=() */;
  let %x1: Tensor[(1, 3, 800, 800), float32] = %tensor_0;
  let %storage_01: Storage[] = memory.alloc_storage(256 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1]) /* ty=Storage[] */;
  let %tensor_01: Tensor[(1, 64, 1, 1), float32] = memory.alloc_tensor(%storage_01, 0 /* ty=int64 */, meta[relay.Constant][3] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %17 = fn (%p01: Tensor[(64), float32], %p11: Tensor[(64), float32], Primitive=1) -> Tensor[(1, 64, 1, 1), float32] {
    %13 = reshape(%p01, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %14 = reshape(%p11, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %15 = add(%14, 0f /* ty=float32 */) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %16 = rsqrt(%15) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    multiply(%13, %16) /* ty=Tensor[(1, 64, 1, 1), float32] */
  };
  %18 = (%model.backbone.body.bn1.weight, %model.backbone.body.bn1.running_var);
  %19 = (%tensor_01,);
  let %v1: () = vm.invoke_tvm_op(%17, %18, %19) /* ty=() */;
  let %x2: Tensor[(1, 64, 1, 1), float32] = %tensor_01;
  let %storage_02: Storage[] = memory.alloc_storage(37632 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][2]) /* ty=Storage[] */;
  let %tensor_02: Tensor[(64, 3, 7, 7), float32] = memory.alloc_tensor(%storage_02, 0 /* ty=int64 */, meta[relay.Constant][4] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][2]) /* ty=Tensor[(64, 3, 7, 7), float32] */;
  %22 = fn (%p02: Tensor[(64, 3, 7, 7), float32], %p12: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(64, 3, 7, 7), float32] {
    %20 = squeeze(%p12, axis=[0, 2, 3]) /* ty=Tensor[(64), float32] */;
    %21 = expand_dims(%20, axis=1, num_newaxis=3) /* ty=Tensor[(64, 1, 1, 1), float32] */;
    multiply(%p02, %21) /* ty=Tensor[(64, 3, 7, 7), float32] */
  };
  %23 = (%model.backbone.body.conv1.weight, %x2);
  %24 = (%tensor_02,);
  let %v2: () = vm.invoke_tvm_op(%22, %23, %24) /* ty=() */;
  let %x3: Tensor[(64, 3, 7, 7), float32] = %tensor_02;
  let %x4: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.bn1.bias, meta[relay.Constant][5] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][0]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %x5: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.bn1.running_mean, meta[relay.Constant][6] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %storage_03: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][3]) /* ty=Storage[] */;
  let %tensor_03: Tensor[(1, 64, 400, 400), float32] = memory.alloc_tensor(%storage_03, 0 /* ty=int64 */, meta[relay.Constant][7] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][3]) /* ty=Tensor[(1, 64, 400, 400), float32] */;
  %29 = fn (%p03: Tensor[(1, 3, 800, 800), float32], %p13: Tensor[(64, 3, 7, 7), float32], %p21: Tensor[(1, 64, 1, 1), float32], %p3: Tensor[(1, 64, 1, 1), float32], %p4: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(1, 64, 400, 400), float32] {
    %25 = nn.conv2d(%p03, %p13, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 400, 400), float32] */;
    %26 = multiply(%p3, %p4) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %27 = subtract(%p21, %26) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %28 = add(%25, %27) /* ty=Tensor[(1, 64, 400, 400), float32] */;
    nn.relu(%28) /* ty=Tensor[(1, 64, 400, 400), float32] */
  };
  %30 = (%x1, %x3, %x4, %x5, %x2);
  %31 = (%tensor_03,);
  let %v3: () = vm.invoke_tvm_op(%29, %30, %31) /* ty=() */;
  let %x6: Tensor[(1, 64, 400, 400), float32] = %tensor_03;
  let %storage_04: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][4]) /* ty=Storage[] */;
  let %tensor_04: Tensor[(1, 64, 200, 200), float32] = memory.alloc_tensor(%storage_04, 0 /* ty=int64 */, meta[relay.Constant][8] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][4]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
  %32 = fn (%p04: Tensor[(1, 64, 400, 400), float32], Primitive=1) -> Tensor[(1, 64, 200, 200), float32] {
    nn.max_pool2d(%p04, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 200, 200), float32] */
  };
  %33 = (%x6,);
  %34 = (%tensor_04,);
  let %v4: () = vm.invoke_tvm_op(%32, %33, %34) /* ty=() */;
  let %x7: Tensor[(1, 64, 200, 200), float32] = %tensor_04;
  let %storage_05: Storage[] = memory.alloc_storage(256 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][5]) /* ty=Storage[] */;
  let %tensor_05: Tensor[(1, 64, 1, 1), float32] = memory.alloc_tensor(%storage_05, 0 /* ty=int64 */, meta[relay.Constant][9] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][5]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %39 = fn (%p05: Tensor[(64), float32], %p14: Tensor[(64), float32], Primitive=1) -> Tensor[(1, 64, 1, 1), float32] {
    %35 = reshape(%p05, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %36 = reshape(%p14, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %37 = add(%36, 0f /* ty=float32 */) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %38 = rsqrt(%37) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    multiply(%35, %38) /* ty=Tensor[(1, 64, 1, 1), float32] */
  };
  %40 = (%model.backbone.body.layer1.0.bn1.weight, %model.backbone.body.layer1.0.bn1.running_var);
  %41 = (%tensor_05,);
  let %v5: () = vm.invoke_tvm_op(%39, %40, %41) /* ty=() */;
  let %x8: Tensor[(1, 64, 1, 1), float32] = %tensor_05;
  let %storage_06: Storage[] = memory.alloc_storage(16384 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][6]) /* ty=Storage[] */;
  let %tensor_06: Tensor[(64, 64, 1, 1), float32] = memory.alloc_tensor(%storage_06, 0 /* ty=int64 */, meta[relay.Constant][10] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][6]) /* ty=Tensor[(64, 64, 1, 1), float32] */;
  %44 = fn (%p06: Tensor[(64, 64, 1, 1), float32], %p15: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(64, 64, 1, 1), float32] {
    %42 = squeeze(%p15, axis=[0, 2, 3]) /* ty=Tensor[(64), float32] */;
    %43 = expand_dims(%42, axis=1, num_newaxis=3) /* ty=Tensor[(64, 1, 1, 1), float32] */;
    multiply(%p06, %43) /* ty=Tensor[(64, 64, 1, 1), float32] */
  };
  %45 = (%model.backbone.body.layer1.0.conv1.weight, %x8);
  %46 = (%tensor_06,);
  let %v6: () = vm.invoke_tvm_op(%44, %45, %46) /* ty=() */;
  let %x9: Tensor[(64, 64, 1, 1), float32] = %tensor_06;
  let %x10: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.bn1.bias, meta[relay.Constant][11] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][2]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %x11: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.bn1.running_mean, meta[relay.Constant][12] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][3]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %storage_07: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][7]) /* ty=Storage[] */;
  let %tensor_07: Tensor[(1, 64, 200, 200), float32] = memory.alloc_tensor(%storage_07, 0 /* ty=int64 */, meta[relay.Constant][13] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][7]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
  %51 = fn (%p07: Tensor[(1, 64, 200, 200), float32], %p16: Tensor[(64, 64, 1, 1), float32], %p22: Tensor[(1, 64, 1, 1), float32], %p31: Tensor[(1, 64, 1, 1), float32], %p41: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(1, 64, 200, 200), float32] {
    %47 = nn.conv2d(%p07, %p16, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    %48 = multiply(%p31, %p41) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %49 = subtract(%p22, %48) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %50 = add(%47, %49) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    nn.relu(%50) /* ty=Tensor[(1, 64, 200, 200), float32] */
  };
  %52 = (%x7, %x9, %x10, %x11, %x8);
  %53 = (%tensor_07,);
  let %v7: () = vm.invoke_tvm_op(%51, %52, %53) /* ty=() */;
  let %x12: Tensor[(1, 64, 200, 200), float32] = %tensor_07;
  let %storage_08: Storage[] = memory.alloc_storage(256 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][8]) /* ty=Storage[] */;
  let %tensor_08: Tensor[(1, 64, 1, 1), float32] = memory.alloc_tensor(%storage_08, 0 /* ty=int64 */, meta[relay.Constant][14] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][8]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %58 = fn (%p08: Tensor[(64), float32], %p17: Tensor[(64), float32], Primitive=1) -> Tensor[(1, 64, 1, 1), float32] {
    %54 = reshape(%p08, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %55 = reshape(%p17, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %56 = add(%55, 0f /* ty=float32 */) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %57 = rsqrt(%56) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    multiply(%54, %57) /* ty=Tensor[(1, 64, 1, 1), float32] */
  };
  %59 = (%model.backbone.body.layer1.0.bn2.weight, %model.backbone.body.layer1.0.bn2.running_var);
  %60 = (%tensor_08,);
  let %v8: () = vm.invoke_tvm_op(%58, %59, %60) /* ty=() */;
  let %x13: Tensor[(1, 64, 1, 1), float32] = %tensor_08;
  let %storage_09: Storage[] = memory.alloc_storage(147456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][9]) /* ty=Storage[] */;
  let %tensor_09: Tensor[(64, 64, 3, 3), float32] = memory.alloc_tensor(%storage_09, 0 /* ty=int64 */, meta[relay.Constant][15] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][9]) /* ty=Tensor[(64, 64, 3, 3), float32] */;
  %63 = fn (%p09: Tensor[(64, 64, 3, 3), float32], %p18: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(64, 64, 3, 3), float32] {
    %61 = squeeze(%p18, axis=[0, 2, 3]) /* ty=Tensor[(64), float32] */;
    %62 = expand_dims(%61, axis=1, num_newaxis=3) /* ty=Tensor[(64, 1, 1, 1), float32] */;
    multiply(%p09, %62) /* ty=Tensor[(64, 64, 3, 3), float32] */
  };
  %64 = (%model.backbone.body.layer1.0.conv2.weight, %x13);
  %65 = (%tensor_09,);
  let %v9: () = vm.invoke_tvm_op(%63, %64, %65) /* ty=() */;
  let %x14: Tensor[(64, 64, 3, 3), float32] = %tensor_09;
  let %x15: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.bn2.bias, meta[relay.Constant][16] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][4]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %x16: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.bn2.running_mean, meta[relay.Constant][17] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][5]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %storage_010: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][10]) /* ty=Storage[] */;
  let %tensor_010: Tensor[(1, 64, 200, 200), float32] = memory.alloc_tensor(%storage_010, 0 /* ty=int64 */, meta[relay.Constant][18] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][10]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
  %70 = fn (%p010: Tensor[(1, 64, 200, 200), float32], %p19: Tensor[(64, 64, 3, 3), float32], %p23: Tensor[(1, 64, 1, 1), float32], %p32: Tensor[(1, 64, 1, 1), float32], %p42: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(1, 64, 200, 200), float32] {
    %66 = nn.conv2d(%p010, %p19, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    %67 = multiply(%p32, %p42) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %68 = subtract(%p23, %67) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %69 = add(%66, %68) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    nn.relu(%69) /* ty=Tensor[(1, 64, 200, 200), float32] */
  };
  %71 = (%x12, %x14, %x15, %x16, %x13);
  %72 = (%tensor_010,);
  let %v10: () = vm.invoke_tvm_op(%70, %71, %72) /* ty=() */;
  let %x17: Tensor[(1, 64, 200, 200), float32] = %tensor_010;
  let %storage_011: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][11]) /* ty=Storage[] */;
  let %tensor_011: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_011, 0 /* ty=int64 */, meta[relay.Constant][19] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][11]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %77 = fn (%p011: Tensor[(256), float32], %p110: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %73 = reshape(%p011, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %74 = reshape(%p110, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %75 = add(%74, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %76 = rsqrt(%75) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%73, %76) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %78 = (%model.backbone.body.layer1.0.bn3.weight, %model.backbone.body.layer1.0.bn3.running_var);
  %79 = (%tensor_011,);
  let %v11: () = vm.invoke_tvm_op(%77, %78, %79) /* ty=() */;
  let %x18: Tensor[(1, 256, 1, 1), float32] = %tensor_011;
  let %storage_012: Storage[] = memory.alloc_storage(65536 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][12]) /* ty=Storage[] */;
  let %tensor_012: Tensor[(256, 64, 1, 1), float32] = memory.alloc_tensor(%storage_012, 0 /* ty=int64 */, meta[relay.Constant][20] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][12]) /* ty=Tensor[(256, 64, 1, 1), float32] */;
  %82 = fn (%p012: Tensor[(256, 64, 1, 1), float32], %p111: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 64, 1, 1), float32] {
    %80 = squeeze(%p111, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %81 = expand_dims(%80, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p012, %81) /* ty=Tensor[(256, 64, 1, 1), float32] */
  };
  %83 = (%model.backbone.body.layer1.0.conv3.weight, %x18);
  %84 = (%tensor_012,);
  let %v12: () = vm.invoke_tvm_op(%82, %83, %84) /* ty=() */;
  let %x19: Tensor[(256, 64, 1, 1), float32] = %tensor_012;
  let %x20: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.bn3.bias, meta[relay.Constant][21] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][6]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x21: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.bn3.running_mean, meta[relay.Constant][22] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][7]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_013: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][13]) /* ty=Storage[] */;
  let %tensor_013: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_013, 0 /* ty=int64 */, meta[relay.Constant][23] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][13]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %89 = fn (%p013: Tensor[(256), float32], %p112: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %85 = reshape(%p013, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %86 = reshape(%p112, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %87 = add(%86, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %88 = rsqrt(%87) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%85, %88) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %90 = (%model.backbone.body.layer1.0.downsample.1.weight, %model.backbone.body.layer1.0.downsample.1.running_var);
  %91 = (%tensor_013,);
  let %v13: () = vm.invoke_tvm_op(%89, %90, %91) /* ty=() */;
  let %x22: Tensor[(1, 256, 1, 1), float32] = %tensor_013;
  let %storage_014: Storage[] = memory.alloc_storage(65536 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][14]) /* ty=Storage[] */;
  let %tensor_014: Tensor[(256, 64, 1, 1), float32] = memory.alloc_tensor(%storage_014, 0 /* ty=int64 */, meta[relay.Constant][24] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][14]) /* ty=Tensor[(256, 64, 1, 1), float32] */;
  %94 = fn (%p014: Tensor[(256, 64, 1, 1), float32], %p113: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 64, 1, 1), float32] {
    %92 = squeeze(%p113, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %93 = expand_dims(%92, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p014, %93) /* ty=Tensor[(256, 64, 1, 1), float32] */
  };
  %95 = (%model.backbone.body.layer1.0.downsample.0.weight, %x22);
  %96 = (%tensor_014,);
  let %v14: () = vm.invoke_tvm_op(%94, %95, %96) /* ty=() */;
  let %x23: Tensor[(256, 64, 1, 1), float32] = %tensor_014;
  let %x24: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.downsample.1.bias, meta[relay.Constant][25] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][8]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x25: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.0.downsample.1.running_mean, meta[relay.Constant][26] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][9]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_015: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][15]) /* ty=Storage[] */;
  let %tensor_015: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_015, 0 /* ty=int64 */, meta[relay.Constant][27] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][15]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %100 = fn (%p015: Tensor[(1, 64, 200, 200), float32], %p114: Tensor[(256, 64, 1, 1), float32], %p24: Tensor[(1, 256, 1, 1), float32], %p33: Tensor[(1, 256, 1, 1), float32], %p43: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    %97 = nn.conv2d(%p015, %p114, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %98 = multiply(%p33, %p43) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %99 = subtract(%p24, %98) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    add(%97, %99) /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %101 = (%x7, %x23, %x24, %x25, %x22);
  %102 = (%tensor_015,);
  let %v15: () = vm.invoke_tvm_op(%100, %101, %102) /* ty=() */;
  let %x26: Tensor[(1, 256, 200, 200), float32] = %tensor_015;
  let %storage_016: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][16]) /* ty=Storage[] */;
  let %tensor_016: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_016, 0 /* ty=int64 */, meta[relay.Constant][28] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][16]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %108 = fn (%p016: Tensor[(1, 64, 200, 200), float32], %p115: Tensor[(256, 64, 1, 1), float32], %p25: Tensor[(1, 256, 1, 1), float32], %p34: Tensor[(1, 256, 1, 1), float32], %p44: Tensor[(1, 256, 1, 1), float32], %p5: Tensor[(1, 256, 200, 200), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    %103 = nn.conv2d(%p016, %p115, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %104 = multiply(%p34, %p44) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %105 = subtract(%p25, %104) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %106 = add(%103, %105) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %107 = add(%106, %p5) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    nn.relu(%107) /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %109 = (%x17, %x19, %x20, %x21, %x18, %x26);
  %110 = (%tensor_016,);
  let %v16: () = vm.invoke_tvm_op(%108, %109, %110) /* ty=() */;
  let %x27: Tensor[(1, 256, 200, 200), float32] = %tensor_016;
  let %storage_017: Storage[] = memory.alloc_storage(256 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][17]) /* ty=Storage[] */;
  let %tensor_017: Tensor[(1, 64, 1, 1), float32] = memory.alloc_tensor(%storage_017, 0 /* ty=int64 */, meta[relay.Constant][29] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][17]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %115 = fn (%p017: Tensor[(64), float32], %p116: Tensor[(64), float32], Primitive=1) -> Tensor[(1, 64, 1, 1), float32] {
    %111 = reshape(%p017, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %112 = reshape(%p116, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %113 = add(%112, 0f /* ty=float32 */) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %114 = rsqrt(%113) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    multiply(%111, %114) /* ty=Tensor[(1, 64, 1, 1), float32] */
  };
  %116 = (%model.backbone.body.layer1.1.bn1.weight, %model.backbone.body.layer1.1.bn1.running_var);
  %117 = (%tensor_017,);
  let %v17: () = vm.invoke_tvm_op(%115, %116, %117) /* ty=() */;
  let %x28: Tensor[(1, 64, 1, 1), float32] = %tensor_017;
  let %storage_018: Storage[] = memory.alloc_storage(65536 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][18]) /* ty=Storage[] */;
  let %tensor_018: Tensor[(64, 256, 1, 1), float32] = memory.alloc_tensor(%storage_018, 0 /* ty=int64 */, meta[relay.Constant][30] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][18]) /* ty=Tensor[(64, 256, 1, 1), float32] */;
  %120 = fn (%p018: Tensor[(64, 256, 1, 1), float32], %p117: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(64, 256, 1, 1), float32] {
    %118 = squeeze(%p117, axis=[0, 2, 3]) /* ty=Tensor[(64), float32] */;
    %119 = expand_dims(%118, axis=1, num_newaxis=3) /* ty=Tensor[(64, 1, 1, 1), float32] */;
    multiply(%p018, %119) /* ty=Tensor[(64, 256, 1, 1), float32] */
  };
  %121 = (%model.backbone.body.layer1.1.conv1.weight, %x28);
  %122 = (%tensor_018,);
  let %v18: () = vm.invoke_tvm_op(%120, %121, %122) /* ty=() */;
  let %x29: Tensor[(64, 256, 1, 1), float32] = %tensor_018;
  let %x30: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.1.bn1.bias, meta[relay.Constant][31] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][10]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %x31: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.1.bn1.running_mean, meta[relay.Constant][32] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][11]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %storage_019: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][19]) /* ty=Storage[] */;
  let %tensor_019: Tensor[(1, 64, 200, 200), float32] = memory.alloc_tensor(%storage_019, 0 /* ty=int64 */, meta[relay.Constant][33] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][19]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
  %127 = fn (%p019: Tensor[(1, 256, 200, 200), float32], %p118: Tensor[(64, 256, 1, 1), float32], %p26: Tensor[(1, 64, 1, 1), float32], %p35: Tensor[(1, 64, 1, 1), float32], %p45: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(1, 64, 200, 200), float32] {
    %123 = nn.conv2d(%p019, %p118, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    %124 = multiply(%p35, %p45) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %125 = subtract(%p26, %124) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %126 = add(%123, %125) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    nn.relu(%126) /* ty=Tensor[(1, 64, 200, 200), float32] */
  };
  %128 = (%x27, %x29, %x30, %x31, %x28);
  %129 = (%tensor_019,);
  let %v19: () = vm.invoke_tvm_op(%127, %128, %129) /* ty=() */;
  let %x32: Tensor[(1, 64, 200, 200), float32] = %tensor_019;
  let %storage_020: Storage[] = memory.alloc_storage(256 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][20]) /* ty=Storage[] */;
  let %tensor_020: Tensor[(1, 64, 1, 1), float32] = memory.alloc_tensor(%storage_020, 0 /* ty=int64 */, meta[relay.Constant][34] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][20]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %134 = fn (%p020: Tensor[(64), float32], %p119: Tensor[(64), float32], Primitive=1) -> Tensor[(1, 64, 1, 1), float32] {
    %130 = reshape(%p020, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %131 = reshape(%p119, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %132 = add(%131, 0f /* ty=float32 */) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %133 = rsqrt(%132) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    multiply(%130, %133) /* ty=Tensor[(1, 64, 1, 1), float32] */
  };
  %135 = (%model.backbone.body.layer1.1.bn2.weight, %model.backbone.body.layer1.1.bn2.running_var);
  %136 = (%tensor_020,);
  let %v20: () = vm.invoke_tvm_op(%134, %135, %136) /* ty=() */;
  let %x33: Tensor[(1, 64, 1, 1), float32] = %tensor_020;
  let %storage_021: Storage[] = memory.alloc_storage(147456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][21]) /* ty=Storage[] */;
  let %tensor_021: Tensor[(64, 64, 3, 3), float32] = memory.alloc_tensor(%storage_021, 0 /* ty=int64 */, meta[relay.Constant][35] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][21]) /* ty=Tensor[(64, 64, 3, 3), float32] */;
  %139 = fn (%p021: Tensor[(64, 64, 3, 3), float32], %p120: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(64, 64, 3, 3), float32] {
    %137 = squeeze(%p120, axis=[0, 2, 3]) /* ty=Tensor[(64), float32] */;
    %138 = expand_dims(%137, axis=1, num_newaxis=3) /* ty=Tensor[(64, 1, 1, 1), float32] */;
    multiply(%p021, %138) /* ty=Tensor[(64, 64, 3, 3), float32] */
  };
  %140 = (%model.backbone.body.layer1.1.conv2.weight, %x33);
  %141 = (%tensor_021,);
  let %v21: () = vm.invoke_tvm_op(%139, %140, %141) /* ty=() */;
  let %x34: Tensor[(64, 64, 3, 3), float32] = %tensor_021;
  let %x35: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.1.bn2.bias, meta[relay.Constant][36] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][12]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %x36: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.1.bn2.running_mean, meta[relay.Constant][37] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][13]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %storage_022: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][22]) /* ty=Storage[] */;
  let %tensor_022: Tensor[(1, 64, 200, 200), float32] = memory.alloc_tensor(%storage_022, 0 /* ty=int64 */, meta[relay.Constant][38] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][22]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
  %146 = fn (%p022: Tensor[(1, 64, 200, 200), float32], %p121: Tensor[(64, 64, 3, 3), float32], %p27: Tensor[(1, 64, 1, 1), float32], %p36: Tensor[(1, 64, 1, 1), float32], %p46: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(1, 64, 200, 200), float32] {
    %142 = nn.conv2d(%p022, %p121, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    %143 = multiply(%p36, %p46) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %144 = subtract(%p27, %143) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %145 = add(%142, %144) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    nn.relu(%145) /* ty=Tensor[(1, 64, 200, 200), float32] */
  };
  %147 = (%x32, %x34, %x35, %x36, %x33);
  %148 = (%tensor_022,);
  let %v22: () = vm.invoke_tvm_op(%146, %147, %148) /* ty=() */;
  let %x37: Tensor[(1, 64, 200, 200), float32] = %tensor_022;
  let %storage_023: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][23]) /* ty=Storage[] */;
  let %tensor_023: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_023, 0 /* ty=int64 */, meta[relay.Constant][39] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][23]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %153 = fn (%p023: Tensor[(256), float32], %p122: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %149 = reshape(%p023, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %150 = reshape(%p122, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %151 = add(%150, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %152 = rsqrt(%151) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%149, %152) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %154 = (%model.backbone.body.layer1.1.bn3.weight, %model.backbone.body.layer1.1.bn3.running_var);
  %155 = (%tensor_023,);
  let %v23: () = vm.invoke_tvm_op(%153, %154, %155) /* ty=() */;
  let %x38: Tensor[(1, 256, 1, 1), float32] = %tensor_023;
  let %storage_024: Storage[] = memory.alloc_storage(65536 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][24]) /* ty=Storage[] */;
  let %tensor_024: Tensor[(256, 64, 1, 1), float32] = memory.alloc_tensor(%storage_024, 0 /* ty=int64 */, meta[relay.Constant][40] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][24]) /* ty=Tensor[(256, 64, 1, 1), float32] */;
  %158 = fn (%p024: Tensor[(256, 64, 1, 1), float32], %p123: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 64, 1, 1), float32] {
    %156 = squeeze(%p123, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %157 = expand_dims(%156, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p024, %157) /* ty=Tensor[(256, 64, 1, 1), float32] */
  };
  %159 = (%model.backbone.body.layer1.1.conv3.weight, %x38);
  %160 = (%tensor_024,);
  let %v24: () = vm.invoke_tvm_op(%158, %159, %160) /* ty=() */;
  let %x39: Tensor[(256, 64, 1, 1), float32] = %tensor_024;
  let %x40: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.1.bn3.bias, meta[relay.Constant][41] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][14]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x41: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.1.bn3.running_mean, meta[relay.Constant][42] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][15]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_025: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][25]) /* ty=Storage[] */;
  let %tensor_025: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_025, 0 /* ty=int64 */, meta[relay.Constant][43] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][25]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %166 = fn (%p025: Tensor[(1, 64, 200, 200), float32], %p124: Tensor[(256, 64, 1, 1), float32], %p28: Tensor[(1, 256, 1, 1), float32], %p37: Tensor[(1, 256, 1, 1), float32], %p47: Tensor[(1, 256, 1, 1), float32], %p51: Tensor[(1, 256, 200, 200), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    %161 = nn.conv2d(%p025, %p124, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %162 = multiply(%p37, %p47) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %163 = subtract(%p28, %162) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %164 = add(%161, %163) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %165 = add(%164, %p51) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    nn.relu(%165) /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %167 = (%x37, %x39, %x40, %x41, %x38, %x27);
  %168 = (%tensor_025,);
  let %v25: () = vm.invoke_tvm_op(%166, %167, %168) /* ty=() */;
  let %x42: Tensor[(1, 256, 200, 200), float32] = %tensor_025;
  let %storage_026: Storage[] = memory.alloc_storage(256 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][26]) /* ty=Storage[] */;
  let %tensor_026: Tensor[(1, 64, 1, 1), float32] = memory.alloc_tensor(%storage_026, 0 /* ty=int64 */, meta[relay.Constant][44] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][26]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %173 = fn (%p026: Tensor[(64), float32], %p125: Tensor[(64), float32], Primitive=1) -> Tensor[(1, 64, 1, 1), float32] {
    %169 = reshape(%p026, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %170 = reshape(%p125, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %171 = add(%170, 0f /* ty=float32 */) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %172 = rsqrt(%171) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    multiply(%169, %172) /* ty=Tensor[(1, 64, 1, 1), float32] */
  };
  %174 = (%model.backbone.body.layer1.2.bn1.weight, %model.backbone.body.layer1.2.bn1.running_var);
  %175 = (%tensor_026,);
  let %v26: () = vm.invoke_tvm_op(%173, %174, %175) /* ty=() */;
  let %x43: Tensor[(1, 64, 1, 1), float32] = %tensor_026;
  let %storage_027: Storage[] = memory.alloc_storage(65536 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][27]) /* ty=Storage[] */;
  let %tensor_027: Tensor[(64, 256, 1, 1), float32] = memory.alloc_tensor(%storage_027, 0 /* ty=int64 */, meta[relay.Constant][45] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][27]) /* ty=Tensor[(64, 256, 1, 1), float32] */;
  %178 = fn (%p027: Tensor[(64, 256, 1, 1), float32], %p126: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(64, 256, 1, 1), float32] {
    %176 = squeeze(%p126, axis=[0, 2, 3]) /* ty=Tensor[(64), float32] */;
    %177 = expand_dims(%176, axis=1, num_newaxis=3) /* ty=Tensor[(64, 1, 1, 1), float32] */;
    multiply(%p027, %177) /* ty=Tensor[(64, 256, 1, 1), float32] */
  };
  %179 = (%model.backbone.body.layer1.2.conv1.weight, %x43);
  %180 = (%tensor_027,);
  let %v27: () = vm.invoke_tvm_op(%178, %179, %180) /* ty=() */;
  let %x44: Tensor[(64, 256, 1, 1), float32] = %tensor_027;
  let %x45: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.2.bn1.bias, meta[relay.Constant][46] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][16]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %x46: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.2.bn1.running_mean, meta[relay.Constant][47] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][17]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %storage_028: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][28]) /* ty=Storage[] */;
  let %tensor_028: Tensor[(1, 64, 200, 200), float32] = memory.alloc_tensor(%storage_028, 0 /* ty=int64 */, meta[relay.Constant][48] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][28]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
  %185 = fn (%p028: Tensor[(1, 256, 200, 200), float32], %p127: Tensor[(64, 256, 1, 1), float32], %p29: Tensor[(1, 64, 1, 1), float32], %p38: Tensor[(1, 64, 1, 1), float32], %p48: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(1, 64, 200, 200), float32] {
    %181 = nn.conv2d(%p028, %p127, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    %182 = multiply(%p38, %p48) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %183 = subtract(%p29, %182) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %184 = add(%181, %183) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    nn.relu(%184) /* ty=Tensor[(1, 64, 200, 200), float32] */
  };
  %186 = (%x42, %x44, %x45, %x46, %x43);
  %187 = (%tensor_028,);
  let %v28: () = vm.invoke_tvm_op(%185, %186, %187) /* ty=() */;
  let %x47: Tensor[(1, 64, 200, 200), float32] = %tensor_028;
  let %storage_029: Storage[] = memory.alloc_storage(256 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][29]) /* ty=Storage[] */;
  let %tensor_029: Tensor[(1, 64, 1, 1), float32] = memory.alloc_tensor(%storage_029, 0 /* ty=int64 */, meta[relay.Constant][49] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][29]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  %192 = fn (%p029: Tensor[(64), float32], %p128: Tensor[(64), float32], Primitive=1) -> Tensor[(1, 64, 1, 1), float32] {
    %188 = reshape(%p029, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %189 = reshape(%p128, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %190 = add(%189, 0f /* ty=float32 */) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %191 = rsqrt(%190) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    multiply(%188, %191) /* ty=Tensor[(1, 64, 1, 1), float32] */
  };
  %193 = (%model.backbone.body.layer1.2.bn2.weight, %model.backbone.body.layer1.2.bn2.running_var);
  %194 = (%tensor_029,);
  let %v29: () = vm.invoke_tvm_op(%192, %193, %194) /* ty=() */;
  let %x48: Tensor[(1, 64, 1, 1), float32] = %tensor_029;
  let %storage_030: Storage[] = memory.alloc_storage(147456 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][30]) /* ty=Storage[] */;
  let %tensor_030: Tensor[(64, 64, 3, 3), float32] = memory.alloc_tensor(%storage_030, 0 /* ty=int64 */, meta[relay.Constant][50] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][30]) /* ty=Tensor[(64, 64, 3, 3), float32] */;
  %197 = fn (%p030: Tensor[(64, 64, 3, 3), float32], %p129: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(64, 64, 3, 3), float32] {
    %195 = squeeze(%p129, axis=[0, 2, 3]) /* ty=Tensor[(64), float32] */;
    %196 = expand_dims(%195, axis=1, num_newaxis=3) /* ty=Tensor[(64, 1, 1, 1), float32] */;
    multiply(%p030, %196) /* ty=Tensor[(64, 64, 3, 3), float32] */
  };
  %198 = (%model.backbone.body.layer1.2.conv2.weight, %x48);
  %199 = (%tensor_030,);
  let %v30: () = vm.invoke_tvm_op(%197, %198, %199) /* ty=() */;
  let %x49: Tensor[(64, 64, 3, 3), float32] = %tensor_030;
  let %x50: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.2.bn2.bias, meta[relay.Constant][51] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][18]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %x51: Tensor[(1, 64, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.2.bn2.running_mean, meta[relay.Constant][52] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][19]) /* ty=Tensor[(1, 64, 1, 1), float32] */;
  let %storage_031: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][31]) /* ty=Storage[] */;
  let %tensor_031: Tensor[(1, 64, 200, 200), float32] = memory.alloc_tensor(%storage_031, 0 /* ty=int64 */, meta[relay.Constant][53] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][31]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
  %204 = fn (%p031: Tensor[(1, 64, 200, 200), float32], %p130: Tensor[(64, 64, 3, 3), float32], %p210: Tensor[(1, 64, 1, 1), float32], %p39: Tensor[(1, 64, 1, 1), float32], %p49: Tensor[(1, 64, 1, 1), float32], Primitive=1) -> Tensor[(1, 64, 200, 200), float32] {
    %200 = nn.conv2d(%p031, %p130, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    %201 = multiply(%p39, %p49) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %202 = subtract(%p210, %201) /* ty=Tensor[(1, 64, 1, 1), float32] */;
    %203 = add(%200, %202) /* ty=Tensor[(1, 64, 200, 200), float32] */;
    nn.relu(%203) /* ty=Tensor[(1, 64, 200, 200), float32] */
  };
  %205 = (%x47, %x49, %x50, %x51, %x48);
  %206 = (%tensor_031,);
  let %v31: () = vm.invoke_tvm_op(%204, %205, %206) /* ty=() */;
  let %x52: Tensor[(1, 64, 200, 200), float32] = %tensor_031;
  let %storage_032: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][32]) /* ty=Storage[] */;
  let %tensor_032: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_032, 0 /* ty=int64 */, meta[relay.Constant][54] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][32]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %211 = fn (%p032: Tensor[(256), float32], %p131: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %207 = reshape(%p032, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %208 = reshape(%p131, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %209 = add(%208, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %210 = rsqrt(%209) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%207, %210) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %212 = (%model.backbone.body.layer1.2.bn3.weight, %model.backbone.body.layer1.2.bn3.running_var);
  %213 = (%tensor_032,);
  let %v32: () = vm.invoke_tvm_op(%211, %212, %213) /* ty=() */;
  let %x53: Tensor[(1, 256, 1, 1), float32] = %tensor_032;
  let %storage_033: Storage[] = memory.alloc_storage(65536 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][33]) /* ty=Storage[] */;
  let %tensor_033: Tensor[(256, 64, 1, 1), float32] = memory.alloc_tensor(%storage_033, 0 /* ty=int64 */, meta[relay.Constant][55] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][33]) /* ty=Tensor[(256, 64, 1, 1), float32] */;
  %216 = fn (%p033: Tensor[(256, 64, 1, 1), float32], %p132: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 64, 1, 1), float32] {
    %214 = squeeze(%p132, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %215 = expand_dims(%214, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p033, %215) /* ty=Tensor[(256, 64, 1, 1), float32] */
  };
  %217 = (%model.backbone.body.layer1.2.conv3.weight, %x53);
  %218 = (%tensor_033,);
  let %v33: () = vm.invoke_tvm_op(%216, %217, %218) /* ty=() */;
  let %x54: Tensor[(256, 64, 1, 1), float32] = %tensor_033;
  let %x55: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.2.bn3.bias, meta[relay.Constant][56] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][20]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x56: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer1.2.bn3.running_mean, meta[relay.Constant][57] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][21]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_034: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][34]) /* ty=Storage[] */;
  let %tensor_034: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_034, 0 /* ty=int64 */, meta[relay.Constant][58] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][34]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %224 = fn (%p034: Tensor[(1, 64, 200, 200), float32], %p133: Tensor[(256, 64, 1, 1), float32], %p211: Tensor[(1, 256, 1, 1), float32], %p310: Tensor[(1, 256, 1, 1), float32], %p410: Tensor[(1, 256, 1, 1), float32], %p52: Tensor[(1, 256, 200, 200), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    %219 = nn.conv2d(%p034, %p133, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %220 = multiply(%p310, %p410) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %221 = subtract(%p211, %220) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %222 = add(%219, %221) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %223 = add(%222, %p52) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    nn.relu(%223) /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %225 = (%x52, %x54, %x55, %x56, %x53, %x42);
  %226 = (%tensor_034,);
  let %v34: () = vm.invoke_tvm_op(%224, %225, %226) /* ty=() */;
  let %x57: Tensor[(1, 256, 200, 200), float32] = %tensor_034;
  let %storage_035: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][35]) /* ty=Storage[] */;
  let %tensor_035: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_035, 0 /* ty=int64 */, meta[relay.Constant][59] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][35]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %231 = fn (%p035: Tensor[(128), float32], %p134: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %227 = reshape(%p035, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %228 = reshape(%p134, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %229 = add(%228, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %230 = rsqrt(%229) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%227, %230) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %232 = (%model.backbone.body.layer2.0.bn1.weight, %model.backbone.body.layer2.0.bn1.running_var);
  %233 = (%tensor_035,);
  let %v35: () = vm.invoke_tvm_op(%231, %232, %233) /* ty=() */;
  let %x58: Tensor[(1, 128, 1, 1), float32] = %tensor_035;
  let %storage_036: Storage[] = memory.alloc_storage(131072 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][36]) /* ty=Storage[] */;
  let %tensor_036: Tensor[(128, 256, 1, 1), float32] = memory.alloc_tensor(%storage_036, 0 /* ty=int64 */, meta[relay.Constant][60] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][36]) /* ty=Tensor[(128, 256, 1, 1), float32] */;
  %236 = fn (%p036: Tensor[(128, 256, 1, 1), float32], %p135: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 256, 1, 1), float32] {
    %234 = squeeze(%p135, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %235 = expand_dims(%234, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p036, %235) /* ty=Tensor[(128, 256, 1, 1), float32] */
  };
  %237 = (%model.backbone.body.layer2.0.conv1.weight, %x58);
  %238 = (%tensor_036,);
  let %v36: () = vm.invoke_tvm_op(%236, %237, %238) /* ty=() */;
  let %x59: Tensor[(128, 256, 1, 1), float32] = %tensor_036;
  let %x60: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.bn1.bias, meta[relay.Constant][61] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][22]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x61: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.bn1.running_mean, meta[relay.Constant][62] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][23]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_037: Storage[] = memory.alloc_storage(20480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][37]) /* ty=Storage[] */;
  let %tensor_037: Tensor[(1, 128, 200, 200), float32] = memory.alloc_tensor(%storage_037, 0 /* ty=int64 */, meta[relay.Constant][63] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][37]) /* ty=Tensor[(1, 128, 200, 200), float32] */;
  %243 = fn (%p037: Tensor[(1, 256, 200, 200), float32], %p136: Tensor[(128, 256, 1, 1), float32], %p212: Tensor[(1, 128, 1, 1), float32], %p311: Tensor[(1, 128, 1, 1), float32], %p411: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 200, 200), float32] {
    %239 = nn.conv2d(%p037, %p136, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 200, 200), float32] */;
    %240 = multiply(%p311, %p411) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %241 = subtract(%p212, %240) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %242 = add(%239, %241) /* ty=Tensor[(1, 128, 200, 200), float32] */;
    nn.relu(%242) /* ty=Tensor[(1, 128, 200, 200), float32] */
  };
  %244 = (%x57, %x59, %x60, %x61, %x58);
  %245 = (%tensor_037,);
  let %v37: () = vm.invoke_tvm_op(%243, %244, %245) /* ty=() */;
  let %x62: Tensor[(1, 128, 200, 200), float32] = %tensor_037;
  let %storage_038: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][38]) /* ty=Storage[] */;
  let %tensor_038: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_038, 0 /* ty=int64 */, meta[relay.Constant][64] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][38]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %250 = fn (%p038: Tensor[(128), float32], %p137: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %246 = reshape(%p038, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %247 = reshape(%p137, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %248 = add(%247, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %249 = rsqrt(%248) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%246, %249) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %251 = (%model.backbone.body.layer2.0.bn2.weight, %model.backbone.body.layer2.0.bn2.running_var);
  %252 = (%tensor_038,);
  let %v38: () = vm.invoke_tvm_op(%250, %251, %252) /* ty=() */;
  let %x63: Tensor[(1, 128, 1, 1), float32] = %tensor_038;
  let %storage_039: Storage[] = memory.alloc_storage(589824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][39]) /* ty=Storage[] */;
  let %tensor_039: Tensor[(128, 128, 3, 3), float32] = memory.alloc_tensor(%storage_039, 0 /* ty=int64 */, meta[relay.Constant][65] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][39]) /* ty=Tensor[(128, 128, 3, 3), float32] */;
  %255 = fn (%p039: Tensor[(128, 128, 3, 3), float32], %p138: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 128, 3, 3), float32] {
    %253 = squeeze(%p138, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %254 = expand_dims(%253, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p039, %254) /* ty=Tensor[(128, 128, 3, 3), float32] */
  };
  %256 = (%model.backbone.body.layer2.0.conv2.weight, %x63);
  %257 = (%tensor_039,);
  let %v39: () = vm.invoke_tvm_op(%255, %256, %257) /* ty=() */;
  let %x64: Tensor[(128, 128, 3, 3), float32] = %tensor_039;
  let %x65: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.bn2.bias, meta[relay.Constant][66] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][24]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x66: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.bn2.running_mean, meta[relay.Constant][67] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][25]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_040: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][40]) /* ty=Storage[] */;
  let %tensor_040: Tensor[(1, 128, 100, 100), float32] = memory.alloc_tensor(%storage_040, 0 /* ty=int64 */, meta[relay.Constant][68] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][40]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
  %262 = fn (%p040: Tensor[(1, 128, 200, 200), float32], %p139: Tensor[(128, 128, 3, 3), float32], %p213: Tensor[(1, 128, 1, 1), float32], %p312: Tensor[(1, 128, 1, 1), float32], %p412: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 100, 100), float32] {
    %258 = nn.conv2d(%p040, %p139, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    %259 = multiply(%p312, %p412) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %260 = subtract(%p213, %259) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %261 = add(%258, %260) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    nn.relu(%261) /* ty=Tensor[(1, 128, 100, 100), float32] */
  };
  %263 = (%x62, %x64, %x65, %x66, %x63);
  %264 = (%tensor_040,);
  let %v40: () = vm.invoke_tvm_op(%262, %263, %264) /* ty=() */;
  let %x67: Tensor[(1, 128, 100, 100), float32] = %tensor_040;
  let %storage_041: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][41]) /* ty=Storage[] */;
  let %tensor_041: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_041, 0 /* ty=int64 */, meta[relay.Constant][69] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][41]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %269 = fn (%p041: Tensor[(512), float32], %p140: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %265 = reshape(%p041, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %266 = reshape(%p140, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %267 = add(%266, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %268 = rsqrt(%267) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%265, %268) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %270 = (%model.backbone.body.layer2.0.bn3.weight, %model.backbone.body.layer2.0.bn3.running_var);
  %271 = (%tensor_041,);
  let %v41: () = vm.invoke_tvm_op(%269, %270, %271) /* ty=() */;
  let %x68: Tensor[(1, 512, 1, 1), float32] = %tensor_041;
  let %storage_042: Storage[] = memory.alloc_storage(262144 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][42]) /* ty=Storage[] */;
  let %tensor_042: Tensor[(512, 128, 1, 1), float32] = memory.alloc_tensor(%storage_042, 0 /* ty=int64 */, meta[relay.Constant][70] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][42]) /* ty=Tensor[(512, 128, 1, 1), float32] */;
  %274 = fn (%p042: Tensor[(512, 128, 1, 1), float32], %p141: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 128, 1, 1), float32] {
    %272 = squeeze(%p141, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %273 = expand_dims(%272, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p042, %273) /* ty=Tensor[(512, 128, 1, 1), float32] */
  };
  %275 = (%model.backbone.body.layer2.0.conv3.weight, %x68);
  %276 = (%tensor_042,);
  let %v42: () = vm.invoke_tvm_op(%274, %275, %276) /* ty=() */;
  let %x69: Tensor[(512, 128, 1, 1), float32] = %tensor_042;
  let %x70: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.bn3.bias, meta[relay.Constant][71] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][26]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x71: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.bn3.running_mean, meta[relay.Constant][72] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][27]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_043: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][43]) /* ty=Storage[] */;
  let %tensor_043: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_043, 0 /* ty=int64 */, meta[relay.Constant][73] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][43]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %281 = fn (%p043: Tensor[(512), float32], %p142: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %277 = reshape(%p043, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %278 = reshape(%p142, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %279 = add(%278, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %280 = rsqrt(%279) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%277, %280) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %282 = (%model.backbone.body.layer2.0.downsample.1.weight, %model.backbone.body.layer2.0.downsample.1.running_var);
  %283 = (%tensor_043,);
  let %v43: () = vm.invoke_tvm_op(%281, %282, %283) /* ty=() */;
  let %x72: Tensor[(1, 512, 1, 1), float32] = %tensor_043;
  let %storage_044: Storage[] = memory.alloc_storage(524288 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][44]) /* ty=Storage[] */;
  let %tensor_044: Tensor[(512, 256, 1, 1), float32] = memory.alloc_tensor(%storage_044, 0 /* ty=int64 */, meta[relay.Constant][74] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][44]) /* ty=Tensor[(512, 256, 1, 1), float32] */;
  %286 = fn (%p044: Tensor[(512, 256, 1, 1), float32], %p143: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 256, 1, 1), float32] {
    %284 = squeeze(%p143, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %285 = expand_dims(%284, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p044, %285) /* ty=Tensor[(512, 256, 1, 1), float32] */
  };
  %287 = (%model.backbone.body.layer2.0.downsample.0.weight, %x72);
  %288 = (%tensor_044,);
  let %v44: () = vm.invoke_tvm_op(%286, %287, %288) /* ty=() */;
  let %x73: Tensor[(512, 256, 1, 1), float32] = %tensor_044;
  let %x74: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.downsample.1.bias, meta[relay.Constant][75] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][28]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x75: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.0.downsample.1.running_mean, meta[relay.Constant][76] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][29]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_045: Storage[] = memory.alloc_storage(20480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][45]) /* ty=Storage[] */;
  let %tensor_045: Tensor[(1, 512, 100, 100), float32] = memory.alloc_tensor(%storage_045, 0 /* ty=int64 */, meta[relay.Constant][77] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][45]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
  %292 = fn (%p045: Tensor[(1, 256, 200, 200), float32], %p144: Tensor[(512, 256, 1, 1), float32], %p214: Tensor[(1, 512, 1, 1), float32], %p313: Tensor[(1, 512, 1, 1), float32], %p413: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(1, 512, 100, 100), float32] {
    %289 = nn.conv2d(%p045, %p144, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %290 = multiply(%p313, %p413) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %291 = subtract(%p214, %290) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    add(%289, %291) /* ty=Tensor[(1, 512, 100, 100), float32] */
  };
  %293 = (%x57, %x73, %x74, %x75, %x72);
  %294 = (%tensor_045,);
  let %v45: () = vm.invoke_tvm_op(%292, %293, %294) /* ty=() */;
  let %x76: Tensor[(1, 512, 100, 100), float32] = %tensor_045;
  let %storage_046: Storage[] = memory.alloc_storage(20480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][46]) /* ty=Storage[] */;
  let %tensor_046: Tensor[(1, 512, 100, 100), float32] = memory.alloc_tensor(%storage_046, 0 /* ty=int64 */, meta[relay.Constant][78] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][46]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
  %300 = fn (%p046: Tensor[(1, 128, 100, 100), float32], %p145: Tensor[(512, 128, 1, 1), float32], %p215: Tensor[(1, 512, 1, 1), float32], %p314: Tensor[(1, 512, 1, 1), float32], %p414: Tensor[(1, 512, 1, 1), float32], %p53: Tensor[(1, 512, 100, 100), float32], Primitive=1) -> Tensor[(1, 512, 100, 100), float32] {
    %295 = nn.conv2d(%p046, %p145, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %296 = multiply(%p314, %p414) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %297 = subtract(%p215, %296) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %298 = add(%295, %297) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %299 = add(%298, %p53) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    nn.relu(%299) /* ty=Tensor[(1, 512, 100, 100), float32] */
  };
  %301 = (%x67, %x69, %x70, %x71, %x68, %x76);
  %302 = (%tensor_046,);
  let %v46: () = vm.invoke_tvm_op(%300, %301, %302) /* ty=() */;
  let %x77: Tensor[(1, 512, 100, 100), float32] = %tensor_046;
  let %storage_047: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][47]) /* ty=Storage[] */;
  let %tensor_047: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_047, 0 /* ty=int64 */, meta[relay.Constant][79] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][47]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %307 = fn (%p047: Tensor[(128), float32], %p146: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %303 = reshape(%p047, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %304 = reshape(%p146, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %305 = add(%304, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %306 = rsqrt(%305) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%303, %306) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %308 = (%model.backbone.body.layer2.1.bn1.weight, %model.backbone.body.layer2.1.bn1.running_var);
  %309 = (%tensor_047,);
  let %v47: () = vm.invoke_tvm_op(%307, %308, %309) /* ty=() */;
  let %x78: Tensor[(1, 128, 1, 1), float32] = %tensor_047;
  let %storage_048: Storage[] = memory.alloc_storage(262144 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][48]) /* ty=Storage[] */;
  let %tensor_048: Tensor[(128, 512, 1, 1), float32] = memory.alloc_tensor(%storage_048, 0 /* ty=int64 */, meta[relay.Constant][80] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][48]) /* ty=Tensor[(128, 512, 1, 1), float32] */;
  %312 = fn (%p048: Tensor[(128, 512, 1, 1), float32], %p147: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 512, 1, 1), float32] {
    %310 = squeeze(%p147, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %311 = expand_dims(%310, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p048, %311) /* ty=Tensor[(128, 512, 1, 1), float32] */
  };
  %313 = (%model.backbone.body.layer2.1.conv1.weight, %x78);
  %314 = (%tensor_048,);
  let %v48: () = vm.invoke_tvm_op(%312, %313, %314) /* ty=() */;
  let %x79: Tensor[(128, 512, 1, 1), float32] = %tensor_048;
  let %x80: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.1.bn1.bias, meta[relay.Constant][81] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][30]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x81: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.1.bn1.running_mean, meta[relay.Constant][82] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][31]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_049: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][49]) /* ty=Storage[] */;
  let %tensor_049: Tensor[(1, 128, 100, 100), float32] = memory.alloc_tensor(%storage_049, 0 /* ty=int64 */, meta[relay.Constant][83] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][49]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
  %319 = fn (%p049: Tensor[(1, 512, 100, 100), float32], %p148: Tensor[(128, 512, 1, 1), float32], %p216: Tensor[(1, 128, 1, 1), float32], %p315: Tensor[(1, 128, 1, 1), float32], %p415: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 100, 100), float32] {
    %315 = nn.conv2d(%p049, %p148, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    %316 = multiply(%p315, %p415) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %317 = subtract(%p216, %316) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %318 = add(%315, %317) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    nn.relu(%318) /* ty=Tensor[(1, 128, 100, 100), float32] */
  };
  %320 = (%x77, %x79, %x80, %x81, %x78);
  %321 = (%tensor_049,);
  let %v49: () = vm.invoke_tvm_op(%319, %320, %321) /* ty=() */;
  let %x82: Tensor[(1, 128, 100, 100), float32] = %tensor_049;
  let %storage_050: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][50]) /* ty=Storage[] */;
  let %tensor_050: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_050, 0 /* ty=int64 */, meta[relay.Constant][84] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][50]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %326 = fn (%p050: Tensor[(128), float32], %p149: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %322 = reshape(%p050, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %323 = reshape(%p149, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %324 = add(%323, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %325 = rsqrt(%324) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%322, %325) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %327 = (%model.backbone.body.layer2.1.bn2.weight, %model.backbone.body.layer2.1.bn2.running_var);
  %328 = (%tensor_050,);
  let %v50: () = vm.invoke_tvm_op(%326, %327, %328) /* ty=() */;
  let %x83: Tensor[(1, 128, 1, 1), float32] = %tensor_050;
  let %storage_051: Storage[] = memory.alloc_storage(589824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][51]) /* ty=Storage[] */;
  let %tensor_051: Tensor[(128, 128, 3, 3), float32] = memory.alloc_tensor(%storage_051, 0 /* ty=int64 */, meta[relay.Constant][85] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][51]) /* ty=Tensor[(128, 128, 3, 3), float32] */;
  %331 = fn (%p051: Tensor[(128, 128, 3, 3), float32], %p150: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 128, 3, 3), float32] {
    %329 = squeeze(%p150, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %330 = expand_dims(%329, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p051, %330) /* ty=Tensor[(128, 128, 3, 3), float32] */
  };
  %332 = (%model.backbone.body.layer2.1.conv2.weight, %x83);
  %333 = (%tensor_051,);
  let %v51: () = vm.invoke_tvm_op(%331, %332, %333) /* ty=() */;
  let %x84: Tensor[(128, 128, 3, 3), float32] = %tensor_051;
  let %x85: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.1.bn2.bias, meta[relay.Constant][86] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][32]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x86: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.1.bn2.running_mean, meta[relay.Constant][87] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][33]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_052: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][52]) /* ty=Storage[] */;
  let %tensor_052: Tensor[(1, 128, 100, 100), float32] = memory.alloc_tensor(%storage_052, 0 /* ty=int64 */, meta[relay.Constant][88] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][52]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
  %338 = fn (%p052: Tensor[(1, 128, 100, 100), float32], %p151: Tensor[(128, 128, 3, 3), float32], %p217: Tensor[(1, 128, 1, 1), float32], %p316: Tensor[(1, 128, 1, 1), float32], %p416: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 100, 100), float32] {
    %334 = nn.conv2d(%p052, %p151, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    %335 = multiply(%p316, %p416) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %336 = subtract(%p217, %335) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %337 = add(%334, %336) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    nn.relu(%337) /* ty=Tensor[(1, 128, 100, 100), float32] */
  };
  %339 = (%x82, %x84, %x85, %x86, %x83);
  %340 = (%tensor_052,);
  let %v52: () = vm.invoke_tvm_op(%338, %339, %340) /* ty=() */;
  let %x87: Tensor[(1, 128, 100, 100), float32] = %tensor_052;
  let %storage_053: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][53]) /* ty=Storage[] */;
  let %tensor_053: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_053, 0 /* ty=int64 */, meta[relay.Constant][89] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][53]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %345 = fn (%p053: Tensor[(512), float32], %p152: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %341 = reshape(%p053, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %342 = reshape(%p152, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %343 = add(%342, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %344 = rsqrt(%343) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%341, %344) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %346 = (%model.backbone.body.layer2.1.bn3.weight, %model.backbone.body.layer2.1.bn3.running_var);
  %347 = (%tensor_053,);
  let %v53: () = vm.invoke_tvm_op(%345, %346, %347) /* ty=() */;
  let %x88: Tensor[(1, 512, 1, 1), float32] = %tensor_053;
  let %storage_054: Storage[] = memory.alloc_storage(262144 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][54]) /* ty=Storage[] */;
  let %tensor_054: Tensor[(512, 128, 1, 1), float32] = memory.alloc_tensor(%storage_054, 0 /* ty=int64 */, meta[relay.Constant][90] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][54]) /* ty=Tensor[(512, 128, 1, 1), float32] */;
  %350 = fn (%p054: Tensor[(512, 128, 1, 1), float32], %p153: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 128, 1, 1), float32] {
    %348 = squeeze(%p153, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %349 = expand_dims(%348, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p054, %349) /* ty=Tensor[(512, 128, 1, 1), float32] */
  };
  %351 = (%model.backbone.body.layer2.1.conv3.weight, %x88);
  %352 = (%tensor_054,);
  let %v54: () = vm.invoke_tvm_op(%350, %351, %352) /* ty=() */;
  let %x89: Tensor[(512, 128, 1, 1), float32] = %tensor_054;
  let %x90: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.1.bn3.bias, meta[relay.Constant][91] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][34]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x91: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.1.bn3.running_mean, meta[relay.Constant][92] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][35]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_055: Storage[] = memory.alloc_storage(20480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][55]) /* ty=Storage[] */;
  let %tensor_055: Tensor[(1, 512, 100, 100), float32] = memory.alloc_tensor(%storage_055, 0 /* ty=int64 */, meta[relay.Constant][93] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][55]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
  %358 = fn (%p055: Tensor[(1, 128, 100, 100), float32], %p154: Tensor[(512, 128, 1, 1), float32], %p218: Tensor[(1, 512, 1, 1), float32], %p317: Tensor[(1, 512, 1, 1), float32], %p417: Tensor[(1, 512, 1, 1), float32], %p54: Tensor[(1, 512, 100, 100), float32], Primitive=1) -> Tensor[(1, 512, 100, 100), float32] {
    %353 = nn.conv2d(%p055, %p154, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %354 = multiply(%p317, %p417) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %355 = subtract(%p218, %354) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %356 = add(%353, %355) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %357 = add(%356, %p54) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    nn.relu(%357) /* ty=Tensor[(1, 512, 100, 100), float32] */
  };
  %359 = (%x87, %x89, %x90, %x91, %x88, %x77);
  %360 = (%tensor_055,);
  let %v55: () = vm.invoke_tvm_op(%358, %359, %360) /* ty=() */;
  let %x92: Tensor[(1, 512, 100, 100), float32] = %tensor_055;
  let %storage_056: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][56]) /* ty=Storage[] */;
  let %tensor_056: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_056, 0 /* ty=int64 */, meta[relay.Constant][94] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][56]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %365 = fn (%p056: Tensor[(128), float32], %p155: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %361 = reshape(%p056, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %362 = reshape(%p155, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %363 = add(%362, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %364 = rsqrt(%363) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%361, %364) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %366 = (%model.backbone.body.layer2.2.bn1.weight, %model.backbone.body.layer2.2.bn1.running_var);
  %367 = (%tensor_056,);
  let %v56: () = vm.invoke_tvm_op(%365, %366, %367) /* ty=() */;
  let %x93: Tensor[(1, 128, 1, 1), float32] = %tensor_056;
  let %storage_057: Storage[] = memory.alloc_storage(262144 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][57]) /* ty=Storage[] */;
  let %tensor_057: Tensor[(128, 512, 1, 1), float32] = memory.alloc_tensor(%storage_057, 0 /* ty=int64 */, meta[relay.Constant][95] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][57]) /* ty=Tensor[(128, 512, 1, 1), float32] */;
  %370 = fn (%p057: Tensor[(128, 512, 1, 1), float32], %p156: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 512, 1, 1), float32] {
    %368 = squeeze(%p156, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %369 = expand_dims(%368, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p057, %369) /* ty=Tensor[(128, 512, 1, 1), float32] */
  };
  %371 = (%model.backbone.body.layer2.2.conv1.weight, %x93);
  %372 = (%tensor_057,);
  let %v57: () = vm.invoke_tvm_op(%370, %371, %372) /* ty=() */;
  let %x94: Tensor[(128, 512, 1, 1), float32] = %tensor_057;
  let %x95: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.2.bn1.bias, meta[relay.Constant][96] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][36]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x96: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.2.bn1.running_mean, meta[relay.Constant][97] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][37]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_058: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][58]) /* ty=Storage[] */;
  let %tensor_058: Tensor[(1, 128, 100, 100), float32] = memory.alloc_tensor(%storage_058, 0 /* ty=int64 */, meta[relay.Constant][98] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][58]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
  %377 = fn (%p058: Tensor[(1, 512, 100, 100), float32], %p157: Tensor[(128, 512, 1, 1), float32], %p219: Tensor[(1, 128, 1, 1), float32], %p318: Tensor[(1, 128, 1, 1), float32], %p418: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 100, 100), float32] {
    %373 = nn.conv2d(%p058, %p157, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    %374 = multiply(%p318, %p418) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %375 = subtract(%p219, %374) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %376 = add(%373, %375) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    nn.relu(%376) /* ty=Tensor[(1, 128, 100, 100), float32] */
  };
  %378 = (%x92, %x94, %x95, %x96, %x93);
  %379 = (%tensor_058,);
  let %v58: () = vm.invoke_tvm_op(%377, %378, %379) /* ty=() */;
  let %x97: Tensor[(1, 128, 100, 100), float32] = %tensor_058;
  let %storage_059: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][59]) /* ty=Storage[] */;
  let %tensor_059: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_059, 0 /* ty=int64 */, meta[relay.Constant][99] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][59]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %384 = fn (%p059: Tensor[(128), float32], %p158: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %380 = reshape(%p059, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %381 = reshape(%p158, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %382 = add(%381, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %383 = rsqrt(%382) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%380, %383) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %385 = (%model.backbone.body.layer2.2.bn2.weight, %model.backbone.body.layer2.2.bn2.running_var);
  %386 = (%tensor_059,);
  let %v59: () = vm.invoke_tvm_op(%384, %385, %386) /* ty=() */;
  let %x98: Tensor[(1, 128, 1, 1), float32] = %tensor_059;
  let %storage_060: Storage[] = memory.alloc_storage(589824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][60]) /* ty=Storage[] */;
  let %tensor_060: Tensor[(128, 128, 3, 3), float32] = memory.alloc_tensor(%storage_060, 0 /* ty=int64 */, meta[relay.Constant][100] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][60]) /* ty=Tensor[(128, 128, 3, 3), float32] */;
  %389 = fn (%p060: Tensor[(128, 128, 3, 3), float32], %p159: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 128, 3, 3), float32] {
    %387 = squeeze(%p159, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %388 = expand_dims(%387, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p060, %388) /* ty=Tensor[(128, 128, 3, 3), float32] */
  };
  %390 = (%model.backbone.body.layer2.2.conv2.weight, %x98);
  %391 = (%tensor_060,);
  let %v60: () = vm.invoke_tvm_op(%389, %390, %391) /* ty=() */;
  let %x99: Tensor[(128, 128, 3, 3), float32] = %tensor_060;
  let %x100: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.2.bn2.bias, meta[relay.Constant][101] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][38]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x101: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.2.bn2.running_mean, meta[relay.Constant][102] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][39]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_061: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][61]) /* ty=Storage[] */;
  let %tensor_061: Tensor[(1, 128, 100, 100), float32] = memory.alloc_tensor(%storage_061, 0 /* ty=int64 */, meta[relay.Constant][103] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][61]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
  %396 = fn (%p061: Tensor[(1, 128, 100, 100), float32], %p160: Tensor[(128, 128, 3, 3), float32], %p220: Tensor[(1, 128, 1, 1), float32], %p319: Tensor[(1, 128, 1, 1), float32], %p419: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 100, 100), float32] {
    %392 = nn.conv2d(%p061, %p160, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    %393 = multiply(%p319, %p419) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %394 = subtract(%p220, %393) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %395 = add(%392, %394) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    nn.relu(%395) /* ty=Tensor[(1, 128, 100, 100), float32] */
  };
  %397 = (%x97, %x99, %x100, %x101, %x98);
  %398 = (%tensor_061,);
  let %v61: () = vm.invoke_tvm_op(%396, %397, %398) /* ty=() */;
  let %x102: Tensor[(1, 128, 100, 100), float32] = %tensor_061;
  let %storage_062: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][62]) /* ty=Storage[] */;
  let %tensor_062: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_062, 0 /* ty=int64 */, meta[relay.Constant][104] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][62]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %403 = fn (%p062: Tensor[(512), float32], %p161: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %399 = reshape(%p062, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %400 = reshape(%p161, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %401 = add(%400, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %402 = rsqrt(%401) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%399, %402) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %404 = (%model.backbone.body.layer2.2.bn3.weight, %model.backbone.body.layer2.2.bn3.running_var);
  %405 = (%tensor_062,);
  let %v62: () = vm.invoke_tvm_op(%403, %404, %405) /* ty=() */;
  let %x103: Tensor[(1, 512, 1, 1), float32] = %tensor_062;
  let %storage_063: Storage[] = memory.alloc_storage(262144 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][63]) /* ty=Storage[] */;
  let %tensor_063: Tensor[(512, 128, 1, 1), float32] = memory.alloc_tensor(%storage_063, 0 /* ty=int64 */, meta[relay.Constant][105] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][63]) /* ty=Tensor[(512, 128, 1, 1), float32] */;
  %408 = fn (%p063: Tensor[(512, 128, 1, 1), float32], %p162: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 128, 1, 1), float32] {
    %406 = squeeze(%p162, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %407 = expand_dims(%406, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p063, %407) /* ty=Tensor[(512, 128, 1, 1), float32] */
  };
  %409 = (%model.backbone.body.layer2.2.conv3.weight, %x103);
  %410 = (%tensor_063,);
  let %v63: () = vm.invoke_tvm_op(%408, %409, %410) /* ty=() */;
  let %x104: Tensor[(512, 128, 1, 1), float32] = %tensor_063;
  let %x105: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.2.bn3.bias, meta[relay.Constant][106] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][40]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x106: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.2.bn3.running_mean, meta[relay.Constant][107] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][41]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_064: Storage[] = memory.alloc_storage(20480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][64]) /* ty=Storage[] */;
  let %tensor_064: Tensor[(1, 512, 100, 100), float32] = memory.alloc_tensor(%storage_064, 0 /* ty=int64 */, meta[relay.Constant][108] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][64]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
  %416 = fn (%p064: Tensor[(1, 128, 100, 100), float32], %p163: Tensor[(512, 128, 1, 1), float32], %p221: Tensor[(1, 512, 1, 1), float32], %p320: Tensor[(1, 512, 1, 1), float32], %p420: Tensor[(1, 512, 1, 1), float32], %p55: Tensor[(1, 512, 100, 100), float32], Primitive=1) -> Tensor[(1, 512, 100, 100), float32] {
    %411 = nn.conv2d(%p064, %p163, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %412 = multiply(%p320, %p420) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %413 = subtract(%p221, %412) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %414 = add(%411, %413) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %415 = add(%414, %p55) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    nn.relu(%415) /* ty=Tensor[(1, 512, 100, 100), float32] */
  };
  %417 = (%x102, %x104, %x105, %x106, %x103, %x92);
  %418 = (%tensor_064,);
  let %v64: () = vm.invoke_tvm_op(%416, %417, %418) /* ty=() */;
  let %x107: Tensor[(1, 512, 100, 100), float32] = %tensor_064;
  let %storage_065: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][65]) /* ty=Storage[] */;
  let %tensor_065: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_065, 0 /* ty=int64 */, meta[relay.Constant][109] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][65]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %423 = fn (%p065: Tensor[(128), float32], %p164: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %419 = reshape(%p065, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %420 = reshape(%p164, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %421 = add(%420, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %422 = rsqrt(%421) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%419, %422) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %424 = (%model.backbone.body.layer2.3.bn1.weight, %model.backbone.body.layer2.3.bn1.running_var);
  %425 = (%tensor_065,);
  let %v65: () = vm.invoke_tvm_op(%423, %424, %425) /* ty=() */;
  let %x108: Tensor[(1, 128, 1, 1), float32] = %tensor_065;
  let %storage_066: Storage[] = memory.alloc_storage(262144 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][66]) /* ty=Storage[] */;
  let %tensor_066: Tensor[(128, 512, 1, 1), float32] = memory.alloc_tensor(%storage_066, 0 /* ty=int64 */, meta[relay.Constant][110] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][66]) /* ty=Tensor[(128, 512, 1, 1), float32] */;
  %428 = fn (%p066: Tensor[(128, 512, 1, 1), float32], %p165: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 512, 1, 1), float32] {
    %426 = squeeze(%p165, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %427 = expand_dims(%426, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p066, %427) /* ty=Tensor[(128, 512, 1, 1), float32] */
  };
  %429 = (%model.backbone.body.layer2.3.conv1.weight, %x108);
  %430 = (%tensor_066,);
  let %v66: () = vm.invoke_tvm_op(%428, %429, %430) /* ty=() */;
  let %x109: Tensor[(128, 512, 1, 1), float32] = %tensor_066;
  let %x110: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.3.bn1.bias, meta[relay.Constant][111] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][42]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x111: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.3.bn1.running_mean, meta[relay.Constant][112] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][43]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_067: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][67]) /* ty=Storage[] */;
  let %tensor_067: Tensor[(1, 128, 100, 100), float32] = memory.alloc_tensor(%storage_067, 0 /* ty=int64 */, meta[relay.Constant][113] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][67]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
  %435 = fn (%p067: Tensor[(1, 512, 100, 100), float32], %p166: Tensor[(128, 512, 1, 1), float32], %p222: Tensor[(1, 128, 1, 1), float32], %p321: Tensor[(1, 128, 1, 1), float32], %p421: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 100, 100), float32] {
    %431 = nn.conv2d(%p067, %p166, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    %432 = multiply(%p321, %p421) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %433 = subtract(%p222, %432) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %434 = add(%431, %433) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    nn.relu(%434) /* ty=Tensor[(1, 128, 100, 100), float32] */
  };
  %436 = (%x107, %x109, %x110, %x111, %x108);
  %437 = (%tensor_067,);
  let %v67: () = vm.invoke_tvm_op(%435, %436, %437) /* ty=() */;
  let %x112: Tensor[(1, 128, 100, 100), float32] = %tensor_067;
  let %storage_068: Storage[] = memory.alloc_storage(512 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][68]) /* ty=Storage[] */;
  let %tensor_068: Tensor[(1, 128, 1, 1), float32] = memory.alloc_tensor(%storage_068, 0 /* ty=int64 */, meta[relay.Constant][114] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][68]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  %442 = fn (%p068: Tensor[(128), float32], %p167: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128, 1, 1), float32] {
    %438 = reshape(%p068, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %439 = reshape(%p167, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %440 = add(%439, 0f /* ty=float32 */) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %441 = rsqrt(%440) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    multiply(%438, %441) /* ty=Tensor[(1, 128, 1, 1), float32] */
  };
  %443 = (%model.backbone.body.layer2.3.bn2.weight, %model.backbone.body.layer2.3.bn2.running_var);
  %444 = (%tensor_068,);
  let %v68: () = vm.invoke_tvm_op(%442, %443, %444) /* ty=() */;
  let %x113: Tensor[(1, 128, 1, 1), float32] = %tensor_068;
  let %storage_069: Storage[] = memory.alloc_storage(589824 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][69]) /* ty=Storage[] */;
  let %tensor_069: Tensor[(128, 128, 3, 3), float32] = memory.alloc_tensor(%storage_069, 0 /* ty=int64 */, meta[relay.Constant][115] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][69]) /* ty=Tensor[(128, 128, 3, 3), float32] */;
  %447 = fn (%p069: Tensor[(128, 128, 3, 3), float32], %p168: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(128, 128, 3, 3), float32] {
    %445 = squeeze(%p168, axis=[0, 2, 3]) /* ty=Tensor[(128), float32] */;
    %446 = expand_dims(%445, axis=1, num_newaxis=3) /* ty=Tensor[(128, 1, 1, 1), float32] */;
    multiply(%p069, %446) /* ty=Tensor[(128, 128, 3, 3), float32] */
  };
  %448 = (%model.backbone.body.layer2.3.conv2.weight, %x113);
  %449 = (%tensor_069,);
  let %v69: () = vm.invoke_tvm_op(%447, %448, %449) /* ty=() */;
  let %x114: Tensor[(128, 128, 3, 3), float32] = %tensor_069;
  let %x115: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.3.bn2.bias, meta[relay.Constant][116] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][44]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %x116: Tensor[(1, 128, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.3.bn2.running_mean, meta[relay.Constant][117] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][45]) /* ty=Tensor[(1, 128, 1, 1), float32] */;
  let %storage_070: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][70]) /* ty=Storage[] */;
  let %tensor_070: Tensor[(1, 128, 100, 100), float32] = memory.alloc_tensor(%storage_070, 0 /* ty=int64 */, meta[relay.Constant][118] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][70]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
  %454 = fn (%p070: Tensor[(1, 128, 100, 100), float32], %p169: Tensor[(128, 128, 3, 3), float32], %p223: Tensor[(1, 128, 1, 1), float32], %p322: Tensor[(1, 128, 1, 1), float32], %p422: Tensor[(1, 128, 1, 1), float32], Primitive=1) -> Tensor[(1, 128, 100, 100), float32] {
    %450 = nn.conv2d(%p070, %p169, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    %451 = multiply(%p322, %p422) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %452 = subtract(%p223, %451) /* ty=Tensor[(1, 128, 1, 1), float32] */;
    %453 = add(%450, %452) /* ty=Tensor[(1, 128, 100, 100), float32] */;
    nn.relu(%453) /* ty=Tensor[(1, 128, 100, 100), float32] */
  };
  %455 = (%x112, %x114, %x115, %x116, %x113);
  %456 = (%tensor_070,);
  let %v70: () = vm.invoke_tvm_op(%454, %455, %456) /* ty=() */;
  let %x117: Tensor[(1, 128, 100, 100), float32] = %tensor_070;
  let %storage_071: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][71]) /* ty=Storage[] */;
  let %tensor_071: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_071, 0 /* ty=int64 */, meta[relay.Constant][119] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][71]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %461 = fn (%p071: Tensor[(512), float32], %p170: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %457 = reshape(%p071, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %458 = reshape(%p170, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %459 = add(%458, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %460 = rsqrt(%459) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%457, %460) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %462 = (%model.backbone.body.layer2.3.bn3.weight, %model.backbone.body.layer2.3.bn3.running_var);
  %463 = (%tensor_071,);
  let %v71: () = vm.invoke_tvm_op(%461, %462, %463) /* ty=() */;
  let %x118: Tensor[(1, 512, 1, 1), float32] = %tensor_071;
  let %storage_072: Storage[] = memory.alloc_storage(262144 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][72]) /* ty=Storage[] */;
  let %tensor_072: Tensor[(512, 128, 1, 1), float32] = memory.alloc_tensor(%storage_072, 0 /* ty=int64 */, meta[relay.Constant][120] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][72]) /* ty=Tensor[(512, 128, 1, 1), float32] */;
  %466 = fn (%p072: Tensor[(512, 128, 1, 1), float32], %p171: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 128, 1, 1), float32] {
    %464 = squeeze(%p171, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %465 = expand_dims(%464, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p072, %465) /* ty=Tensor[(512, 128, 1, 1), float32] */
  };
  %467 = (%model.backbone.body.layer2.3.conv3.weight, %x118);
  %468 = (%tensor_072,);
  let %v72: () = vm.invoke_tvm_op(%466, %467, %468) /* ty=() */;
  let %x119: Tensor[(512, 128, 1, 1), float32] = %tensor_072;
  let %x120: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.3.bn3.bias, meta[relay.Constant][121] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][46]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x121: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer2.3.bn3.running_mean, meta[relay.Constant][122] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][47]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_073: Storage[] = memory.alloc_storage(20480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][73]) /* ty=Storage[] */;
  let %tensor_073: Tensor[(1, 512, 100, 100), float32] = memory.alloc_tensor(%storage_073, 0 /* ty=int64 */, meta[relay.Constant][123] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][73]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
  %474 = fn (%p073: Tensor[(1, 128, 100, 100), float32], %p172: Tensor[(512, 128, 1, 1), float32], %p224: Tensor[(1, 512, 1, 1), float32], %p323: Tensor[(1, 512, 1, 1), float32], %p423: Tensor[(1, 512, 1, 1), float32], %p56: Tensor[(1, 512, 100, 100), float32], Primitive=1) -> Tensor[(1, 512, 100, 100), float32] {
    %469 = nn.conv2d(%p073, %p172, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %470 = multiply(%p323, %p423) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %471 = subtract(%p224, %470) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %472 = add(%469, %471) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    %473 = add(%472, %p56) /* ty=Tensor[(1, 512, 100, 100), float32] */;
    nn.relu(%473) /* ty=Tensor[(1, 512, 100, 100), float32] */
  };
  %475 = (%x117, %x119, %x120, %x121, %x118, %x107);
  %476 = (%tensor_073,);
  let %v73: () = vm.invoke_tvm_op(%474, %475, %476) /* ty=() */;
  let %x122: Tensor[(1, 512, 100, 100), float32] = %tensor_073;
  let %storage_074: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][74]) /* ty=Storage[] */;
  let %tensor_074: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_074, 0 /* ty=int64 */, meta[relay.Constant][124] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][74]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %481 = fn (%p074: Tensor[(256), float32], %p173: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %477 = reshape(%p074, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %478 = reshape(%p173, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %479 = add(%478, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %480 = rsqrt(%479) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%477, %480) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %482 = (%model.backbone.body.layer3.0.bn1.weight, %model.backbone.body.layer3.0.bn1.running_var);
  %483 = (%tensor_074,);
  let %v74: () = vm.invoke_tvm_op(%481, %482, %483) /* ty=() */;
  let %x123: Tensor[(1, 256, 1, 1), float32] = %tensor_074;
  let %storage_075: Storage[] = memory.alloc_storage(524288 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][75]) /* ty=Storage[] */;
  let %tensor_075: Tensor[(256, 512, 1, 1), float32] = memory.alloc_tensor(%storage_075, 0 /* ty=int64 */, meta[relay.Constant][125] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][75]) /* ty=Tensor[(256, 512, 1, 1), float32] */;
  %486 = fn (%p075: Tensor[(256, 512, 1, 1), float32], %p174: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 512, 1, 1), float32] {
    %484 = squeeze(%p174, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %485 = expand_dims(%484, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p075, %485) /* ty=Tensor[(256, 512, 1, 1), float32] */
  };
  %487 = (%model.backbone.body.layer3.0.conv1.weight, %x123);
  %488 = (%tensor_075,);
  let %v75: () = vm.invoke_tvm_op(%486, %487, %488) /* ty=() */;
  let %x124: Tensor[(256, 512, 1, 1), float32] = %tensor_075;
  let %x125: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.bn1.bias, meta[relay.Constant][126] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][48]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x126: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.bn1.running_mean, meta[relay.Constant][127] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][49]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_076: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][76]) /* ty=Storage[] */;
  let %tensor_076: Tensor[(1, 256, 100, 100), float32] = memory.alloc_tensor(%storage_076, 0 /* ty=int64 */, meta[relay.Constant][128] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][76]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
  %493 = fn (%p076: Tensor[(1, 512, 100, 100), float32], %p175: Tensor[(256, 512, 1, 1), float32], %p225: Tensor[(1, 256, 1, 1), float32], %p324: Tensor[(1, 256, 1, 1), float32], %p424: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 100, 100), float32] {
    %489 = nn.conv2d(%p076, %p175, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
    %490 = multiply(%p324, %p424) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %491 = subtract(%p225, %490) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %492 = add(%489, %491) /* ty=Tensor[(1, 256, 100, 100), float32] */;
    nn.relu(%492) /* ty=Tensor[(1, 256, 100, 100), float32] */
  };
  %494 = (%x122, %x124, %x125, %x126, %x123);
  %495 = (%tensor_076,);
  let %v76: () = vm.invoke_tvm_op(%493, %494, %495) /* ty=() */;
  let %x127: Tensor[(1, 256, 100, 100), float32] = %tensor_076;
  let %storage_077: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][77]) /* ty=Storage[] */;
  let %tensor_077: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_077, 0 /* ty=int64 */, meta[relay.Constant][129] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][77]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %500 = fn (%p077: Tensor[(256), float32], %p176: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %496 = reshape(%p077, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %497 = reshape(%p176, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %498 = add(%497, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %499 = rsqrt(%498) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%496, %499) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %501 = (%model.backbone.body.layer3.0.bn2.weight, %model.backbone.body.layer3.0.bn2.running_var);
  %502 = (%tensor_077,);
  let %v77: () = vm.invoke_tvm_op(%500, %501, %502) /* ty=() */;
  let %x128: Tensor[(1, 256, 1, 1), float32] = %tensor_077;
  let %storage_078: Storage[] = memory.alloc_storage(2359296 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][78]) /* ty=Storage[] */;
  let %tensor_078: Tensor[(256, 256, 3, 3), float32] = memory.alloc_tensor(%storage_078, 0 /* ty=int64 */, meta[relay.Constant][130] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][78]) /* ty=Tensor[(256, 256, 3, 3), float32] */;
  %505 = fn (%p078: Tensor[(256, 256, 3, 3), float32], %p177: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 256, 3, 3), float32] {
    %503 = squeeze(%p177, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %504 = expand_dims(%503, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p078, %504) /* ty=Tensor[(256, 256, 3, 3), float32] */
  };
  %506 = (%model.backbone.body.layer3.0.conv2.weight, %x128);
  %507 = (%tensor_078,);
  let %v78: () = vm.invoke_tvm_op(%505, %506, %507) /* ty=() */;
  let %x129: Tensor[(256, 256, 3, 3), float32] = %tensor_078;
  let %x130: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.bn2.bias, meta[relay.Constant][131] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][50]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x131: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.bn2.running_mean, meta[relay.Constant][132] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][51]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_079: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][79]) /* ty=Storage[] */;
  let %tensor_079: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_079, 0 /* ty=int64 */, meta[relay.Constant][133] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][79]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %512 = fn (%p079: Tensor[(1, 256, 100, 100), float32], %p178: Tensor[(256, 256, 3, 3), float32], %p226: Tensor[(1, 256, 1, 1), float32], %p325: Tensor[(1, 256, 1, 1), float32], %p425: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %508 = nn.conv2d(%p079, %p178, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %509 = multiply(%p325, %p425) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %510 = subtract(%p226, %509) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %511 = add(%508, %510) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%511) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %513 = (%x127, %x129, %x130, %x131, %x128);
  %514 = (%tensor_079,);
  let %v79: () = vm.invoke_tvm_op(%512, %513, %514) /* ty=() */;
  let %x132: Tensor[(1, 256, 50, 50), float32] = %tensor_079;
  let %storage_080: Storage[] = memory.alloc_storage(4096 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][80]) /* ty=Storage[] */;
  let %tensor_080: Tensor[(1, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_080, 0 /* ty=int64 */, meta[relay.Constant][134] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][80]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  %519 = fn (%p080: Tensor[(1024), float32], %p179: Tensor[(1024), float32], Primitive=1) -> Tensor[(1, 1024, 1, 1), float32] {
    %515 = reshape(%p080, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %516 = reshape(%p179, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %517 = add(%516, 0f /* ty=float32 */) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %518 = rsqrt(%517) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    multiply(%515, %518) /* ty=Tensor[(1, 1024, 1, 1), float32] */
  };
  %520 = (%model.backbone.body.layer3.0.bn3.weight, %model.backbone.body.layer3.0.bn3.running_var);
  %521 = (%tensor_080,);
  let %v80: () = vm.invoke_tvm_op(%519, %520, %521) /* ty=() */;
  let %x133: Tensor[(1, 1024, 1, 1), float32] = %tensor_080;
  let %storage_081: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][81]) /* ty=Storage[] */;
  let %tensor_081: Tensor[(1024, 256, 1, 1), float32] = memory.alloc_tensor(%storage_081, 0 /* ty=int64 */, meta[relay.Constant][135] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][81]) /* ty=Tensor[(1024, 256, 1, 1), float32] */;
  %524 = fn (%p081: Tensor[(1024, 256, 1, 1), float32], %p180: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1024, 256, 1, 1), float32] {
    %522 = squeeze(%p180, axis=[0, 2, 3]) /* ty=Tensor[(1024), float32] */;
    %523 = expand_dims(%522, axis=1, num_newaxis=3) /* ty=Tensor[(1024, 1, 1, 1), float32] */;
    multiply(%p081, %523) /* ty=Tensor[(1024, 256, 1, 1), float32] */
  };
  %525 = (%model.backbone.body.layer3.0.conv3.weight, %x133);
  %526 = (%tensor_081,);
  let %v81: () = vm.invoke_tvm_op(%524, %525, %526) /* ty=() */;
  let %x134: Tensor[(1024, 256, 1, 1), float32] = %tensor_081;
  let %x135: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.bn3.bias, meta[relay.Constant][136] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][52]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %x136: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.bn3.running_mean, meta[relay.Constant][137] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][53]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %storage_082: Storage[] = memory.alloc_storage(4096 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][82]) /* ty=Storage[] */;
  let %tensor_082: Tensor[(1, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_082, 0 /* ty=int64 */, meta[relay.Constant][138] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][82]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  %531 = fn (%p082: Tensor[(1024), float32], %p181: Tensor[(1024), float32], Primitive=1) -> Tensor[(1, 1024, 1, 1), float32] {
    %527 = reshape(%p082, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %528 = reshape(%p181, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %529 = add(%528, 0f /* ty=float32 */) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %530 = rsqrt(%529) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    multiply(%527, %530) /* ty=Tensor[(1, 1024, 1, 1), float32] */
  };
  %532 = (%model.backbone.body.layer3.0.downsample.1.weight, %model.backbone.body.layer3.0.downsample.1.running_var);
  %533 = (%tensor_082,);
  let %v82: () = vm.invoke_tvm_op(%531, %532, %533) /* ty=() */;
  let %x137: Tensor[(1, 1024, 1, 1), float32] = %tensor_082;
  let %storage_083: Storage[] = memory.alloc_storage(2097152 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][83]) /* ty=Storage[] */;
  let %tensor_083: Tensor[(1024, 512, 1, 1), float32] = memory.alloc_tensor(%storage_083, 0 /* ty=int64 */, meta[relay.Constant][139] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][83]) /* ty=Tensor[(1024, 512, 1, 1), float32] */;
  %536 = fn (%p083: Tensor[(1024, 512, 1, 1), float32], %p182: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1024, 512, 1, 1), float32] {
    %534 = squeeze(%p182, axis=[0, 2, 3]) /* ty=Tensor[(1024), float32] */;
    %535 = expand_dims(%534, axis=1, num_newaxis=3) /* ty=Tensor[(1024, 1, 1, 1), float32] */;
    multiply(%p083, %535) /* ty=Tensor[(1024, 512, 1, 1), float32] */
  };
  %537 = (%model.backbone.body.layer3.0.downsample.0.weight, %x137);
  %538 = (%tensor_083,);
  let %v83: () = vm.invoke_tvm_op(%536, %537, %538) /* ty=() */;
  let %x138: Tensor[(1024, 512, 1, 1), float32] = %tensor_083;
  let %x139: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.downsample.1.bias, meta[relay.Constant][140] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][54]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %x140: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.0.downsample.1.running_mean, meta[relay.Constant][141] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][55]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %storage_084: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][84]) /* ty=Storage[] */;
  let %tensor_084: Tensor[(1, 1024, 50, 50), float32] = memory.alloc_tensor(%storage_084, 0 /* ty=int64 */, meta[relay.Constant][142] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][84]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
  %542 = fn (%p084: Tensor[(1, 512, 100, 100), float32], %p183: Tensor[(1024, 512, 1, 1), float32], %p227: Tensor[(1, 1024, 1, 1), float32], %p326: Tensor[(1, 1024, 1, 1), float32], %p426: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1, 1024, 50, 50), float32] {
    %539 = nn.conv2d(%p084, %p183, strides=[2, 2], padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %540 = multiply(%p326, %p426) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %541 = subtract(%p227, %540) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    add(%539, %541) /* ty=Tensor[(1, 1024, 50, 50), float32] */
  };
  %543 = (%x122, %x138, %x139, %x140, %x137);
  %544 = (%tensor_084,);
  let %v84: () = vm.invoke_tvm_op(%542, %543, %544) /* ty=() */;
  let %x141: Tensor[(1, 1024, 50, 50), float32] = %tensor_084;
  let %storage_085: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][85]) /* ty=Storage[] */;
  let %tensor_085: Tensor[(1, 1024, 50, 50), float32] = memory.alloc_tensor(%storage_085, 0 /* ty=int64 */, meta[relay.Constant][143] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][85]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
  %550 = fn (%p085: Tensor[(1, 256, 50, 50), float32], %p184: Tensor[(1024, 256, 1, 1), float32], %p228: Tensor[(1, 1024, 1, 1), float32], %p327: Tensor[(1, 1024, 1, 1), float32], %p427: Tensor[(1, 1024, 1, 1), float32], %p57: Tensor[(1, 1024, 50, 50), float32], Primitive=1) -> Tensor[(1, 1024, 50, 50), float32] {
    %545 = nn.conv2d(%p085, %p184, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %546 = multiply(%p327, %p427) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %547 = subtract(%p228, %546) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %548 = add(%545, %547) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %549 = add(%548, %p57) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    nn.relu(%549) /* ty=Tensor[(1, 1024, 50, 50), float32] */
  };
  %551 = (%x132, %x134, %x135, %x136, %x133, %x141);
  %552 = (%tensor_085,);
  let %v85: () = vm.invoke_tvm_op(%550, %551, %552) /* ty=() */;
  let %x142: Tensor[(1, 1024, 50, 50), float32] = %tensor_085;
  let %storage_086: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][86]) /* ty=Storage[] */;
  let %tensor_086: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_086, 0 /* ty=int64 */, meta[relay.Constant][144] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][86]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %557 = fn (%p086: Tensor[(256), float32], %p185: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %553 = reshape(%p086, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %554 = reshape(%p185, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %555 = add(%554, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %556 = rsqrt(%555) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%553, %556) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %558 = (%model.backbone.body.layer3.1.bn1.weight, %model.backbone.body.layer3.1.bn1.running_var);
  %559 = (%tensor_086,);
  let %v86: () = vm.invoke_tvm_op(%557, %558, %559) /* ty=() */;
  let %x143: Tensor[(1, 256, 1, 1), float32] = %tensor_086;
  let %storage_087: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][87]) /* ty=Storage[] */;
  let %tensor_087: Tensor[(256, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_087, 0 /* ty=int64 */, meta[relay.Constant][145] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][87]) /* ty=Tensor[(256, 1024, 1, 1), float32] */;
  %562 = fn (%p087: Tensor[(256, 1024, 1, 1), float32], %p186: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 1024, 1, 1), float32] {
    %560 = squeeze(%p186, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %561 = expand_dims(%560, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p087, %561) /* ty=Tensor[(256, 1024, 1, 1), float32] */
  };
  %563 = (%model.backbone.body.layer3.1.conv1.weight, %x143);
  %564 = (%tensor_087,);
  let %v87: () = vm.invoke_tvm_op(%562, %563, %564) /* ty=() */;
  let %x144: Tensor[(256, 1024, 1, 1), float32] = %tensor_087;
  let %x145: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.1.bn1.bias, meta[relay.Constant][146] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][56]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x146: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.1.bn1.running_mean, meta[relay.Constant][147] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][57]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_088: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][88]) /* ty=Storage[] */;
  let %tensor_088: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_088, 0 /* ty=int64 */, meta[relay.Constant][148] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][88]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %569 = fn (%p088: Tensor[(1, 1024, 50, 50), float32], %p187: Tensor[(256, 1024, 1, 1), float32], %p229: Tensor[(1, 256, 1, 1), float32], %p328: Tensor[(1, 256, 1, 1), float32], %p428: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %565 = nn.conv2d(%p088, %p187, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %566 = multiply(%p328, %p428) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %567 = subtract(%p229, %566) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %568 = add(%565, %567) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%568) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %570 = (%x142, %x144, %x145, %x146, %x143);
  %571 = (%tensor_088,);
  let %v88: () = vm.invoke_tvm_op(%569, %570, %571) /* ty=() */;
  let %x147: Tensor[(1, 256, 50, 50), float32] = %tensor_088;
  let %storage_089: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][89]) /* ty=Storage[] */;
  let %tensor_089: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_089, 0 /* ty=int64 */, meta[relay.Constant][149] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][89]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %576 = fn (%p089: Tensor[(256), float32], %p188: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %572 = reshape(%p089, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %573 = reshape(%p188, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %574 = add(%573, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %575 = rsqrt(%574) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%572, %575) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %577 = (%model.backbone.body.layer3.1.bn2.weight, %model.backbone.body.layer3.1.bn2.running_var);
  %578 = (%tensor_089,);
  let %v89: () = vm.invoke_tvm_op(%576, %577, %578) /* ty=() */;
  let %x148: Tensor[(1, 256, 1, 1), float32] = %tensor_089;
  let %storage_090: Storage[] = memory.alloc_storage(2359296 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][90]) /* ty=Storage[] */;
  let %tensor_090: Tensor[(256, 256, 3, 3), float32] = memory.alloc_tensor(%storage_090, 0 /* ty=int64 */, meta[relay.Constant][150] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][90]) /* ty=Tensor[(256, 256, 3, 3), float32] */;
  %581 = fn (%p090: Tensor[(256, 256, 3, 3), float32], %p189: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 256, 3, 3), float32] {
    %579 = squeeze(%p189, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %580 = expand_dims(%579, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p090, %580) /* ty=Tensor[(256, 256, 3, 3), float32] */
  };
  %582 = (%model.backbone.body.layer3.1.conv2.weight, %x148);
  %583 = (%tensor_090,);
  let %v90: () = vm.invoke_tvm_op(%581, %582, %583) /* ty=() */;
  let %x149: Tensor[(256, 256, 3, 3), float32] = %tensor_090;
  let %x150: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.1.bn2.bias, meta[relay.Constant][151] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][58]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x151: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.1.bn2.running_mean, meta[relay.Constant][152] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][59]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_091: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][91]) /* ty=Storage[] */;
  let %tensor_091: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_091, 0 /* ty=int64 */, meta[relay.Constant][153] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][91]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %588 = fn (%p091: Tensor[(1, 256, 50, 50), float32], %p190: Tensor[(256, 256, 3, 3), float32], %p230: Tensor[(1, 256, 1, 1), float32], %p329: Tensor[(1, 256, 1, 1), float32], %p429: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %584 = nn.conv2d(%p091, %p190, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %585 = multiply(%p329, %p429) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %586 = subtract(%p230, %585) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %587 = add(%584, %586) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%587) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %589 = (%x147, %x149, %x150, %x151, %x148);
  %590 = (%tensor_091,);
  let %v91: () = vm.invoke_tvm_op(%588, %589, %590) /* ty=() */;
  let %x152: Tensor[(1, 256, 50, 50), float32] = %tensor_091;
  let %storage_092: Storage[] = memory.alloc_storage(4096 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][92]) /* ty=Storage[] */;
  let %tensor_092: Tensor[(1, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_092, 0 /* ty=int64 */, meta[relay.Constant][154] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][92]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  %595 = fn (%p092: Tensor[(1024), float32], %p191: Tensor[(1024), float32], Primitive=1) -> Tensor[(1, 1024, 1, 1), float32] {
    %591 = reshape(%p092, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %592 = reshape(%p191, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %593 = add(%592, 0f /* ty=float32 */) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %594 = rsqrt(%593) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    multiply(%591, %594) /* ty=Tensor[(1, 1024, 1, 1), float32] */
  };
  %596 = (%model.backbone.body.layer3.1.bn3.weight, %model.backbone.body.layer3.1.bn3.running_var);
  %597 = (%tensor_092,);
  let %v92: () = vm.invoke_tvm_op(%595, %596, %597) /* ty=() */;
  let %x153: Tensor[(1, 1024, 1, 1), float32] = %tensor_092;
  let %storage_093: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][93]) /* ty=Storage[] */;
  let %tensor_093: Tensor[(1024, 256, 1, 1), float32] = memory.alloc_tensor(%storage_093, 0 /* ty=int64 */, meta[relay.Constant][155] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][93]) /* ty=Tensor[(1024, 256, 1, 1), float32] */;
  %600 = fn (%p093: Tensor[(1024, 256, 1, 1), float32], %p192: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1024, 256, 1, 1), float32] {
    %598 = squeeze(%p192, axis=[0, 2, 3]) /* ty=Tensor[(1024), float32] */;
    %599 = expand_dims(%598, axis=1, num_newaxis=3) /* ty=Tensor[(1024, 1, 1, 1), float32] */;
    multiply(%p093, %599) /* ty=Tensor[(1024, 256, 1, 1), float32] */
  };
  %601 = (%model.backbone.body.layer3.1.conv3.weight, %x153);
  %602 = (%tensor_093,);
  let %v93: () = vm.invoke_tvm_op(%600, %601, %602) /* ty=() */;
  let %x154: Tensor[(1024, 256, 1, 1), float32] = %tensor_093;
  let %x155: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.1.bn3.bias, meta[relay.Constant][156] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][60]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %x156: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.1.bn3.running_mean, meta[relay.Constant][157] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][61]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %storage_094: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][94]) /* ty=Storage[] */;
  let %tensor_094: Tensor[(1, 1024, 50, 50), float32] = memory.alloc_tensor(%storage_094, 0 /* ty=int64 */, meta[relay.Constant][158] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][94]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
  %608 = fn (%p094: Tensor[(1, 256, 50, 50), float32], %p193: Tensor[(1024, 256, 1, 1), float32], %p231: Tensor[(1, 1024, 1, 1), float32], %p330: Tensor[(1, 1024, 1, 1), float32], %p430: Tensor[(1, 1024, 1, 1), float32], %p58: Tensor[(1, 1024, 50, 50), float32], Primitive=1) -> Tensor[(1, 1024, 50, 50), float32] {
    %603 = nn.conv2d(%p094, %p193, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %604 = multiply(%p330, %p430) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %605 = subtract(%p231, %604) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %606 = add(%603, %605) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %607 = add(%606, %p58) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    nn.relu(%607) /* ty=Tensor[(1, 1024, 50, 50), float32] */
  };
  %609 = (%x152, %x154, %x155, %x156, %x153, %x142);
  %610 = (%tensor_094,);
  let %v94: () = vm.invoke_tvm_op(%608, %609, %610) /* ty=() */;
  let %x157: Tensor[(1, 1024, 50, 50), float32] = %tensor_094;
  let %storage_095: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][95]) /* ty=Storage[] */;
  let %tensor_095: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_095, 0 /* ty=int64 */, meta[relay.Constant][159] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][95]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %615 = fn (%p095: Tensor[(256), float32], %p194: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %611 = reshape(%p095, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %612 = reshape(%p194, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %613 = add(%612, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %614 = rsqrt(%613) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%611, %614) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %616 = (%model.backbone.body.layer3.2.bn1.weight, %model.backbone.body.layer3.2.bn1.running_var);
  %617 = (%tensor_095,);
  let %v95: () = vm.invoke_tvm_op(%615, %616, %617) /* ty=() */;
  let %x158: Tensor[(1, 256, 1, 1), float32] = %tensor_095;
  let %storage_096: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][96]) /* ty=Storage[] */;
  let %tensor_096: Tensor[(256, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_096, 0 /* ty=int64 */, meta[relay.Constant][160] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][96]) /* ty=Tensor[(256, 1024, 1, 1), float32] */;
  %620 = fn (%p096: Tensor[(256, 1024, 1, 1), float32], %p195: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 1024, 1, 1), float32] {
    %618 = squeeze(%p195, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %619 = expand_dims(%618, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p096, %619) /* ty=Tensor[(256, 1024, 1, 1), float32] */
  };
  %621 = (%model.backbone.body.layer3.2.conv1.weight, %x158);
  %622 = (%tensor_096,);
  let %v96: () = vm.invoke_tvm_op(%620, %621, %622) /* ty=() */;
  let %x159: Tensor[(256, 1024, 1, 1), float32] = %tensor_096;
  let %x160: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.2.bn1.bias, meta[relay.Constant][161] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][62]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x161: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.2.bn1.running_mean, meta[relay.Constant][162] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][63]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_097: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][97]) /* ty=Storage[] */;
  let %tensor_097: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_097, 0 /* ty=int64 */, meta[relay.Constant][163] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][97]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %627 = fn (%p097: Tensor[(1, 1024, 50, 50), float32], %p196: Tensor[(256, 1024, 1, 1), float32], %p232: Tensor[(1, 256, 1, 1), float32], %p331: Tensor[(1, 256, 1, 1), float32], %p431: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %623 = nn.conv2d(%p097, %p196, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %624 = multiply(%p331, %p431) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %625 = subtract(%p232, %624) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %626 = add(%623, %625) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%626) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %628 = (%x157, %x159, %x160, %x161, %x158);
  %629 = (%tensor_097,);
  let %v97: () = vm.invoke_tvm_op(%627, %628, %629) /* ty=() */;
  let %x162: Tensor[(1, 256, 50, 50), float32] = %tensor_097;
  let %storage_098: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][98]) /* ty=Storage[] */;
  let %tensor_098: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_098, 0 /* ty=int64 */, meta[relay.Constant][164] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][98]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %634 = fn (%p098: Tensor[(256), float32], %p197: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %630 = reshape(%p098, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %631 = reshape(%p197, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %632 = add(%631, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %633 = rsqrt(%632) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%630, %633) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %635 = (%model.backbone.body.layer3.2.bn2.weight, %model.backbone.body.layer3.2.bn2.running_var);
  %636 = (%tensor_098,);
  let %v98: () = vm.invoke_tvm_op(%634, %635, %636) /* ty=() */;
  let %x163: Tensor[(1, 256, 1, 1), float32] = %tensor_098;
  let %storage_099: Storage[] = memory.alloc_storage(2359296 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][99]) /* ty=Storage[] */;
  let %tensor_099: Tensor[(256, 256, 3, 3), float32] = memory.alloc_tensor(%storage_099, 0 /* ty=int64 */, meta[relay.Constant][165] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][99]) /* ty=Tensor[(256, 256, 3, 3), float32] */;
  %639 = fn (%p099: Tensor[(256, 256, 3, 3), float32], %p198: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 256, 3, 3), float32] {
    %637 = squeeze(%p198, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %638 = expand_dims(%637, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p099, %638) /* ty=Tensor[(256, 256, 3, 3), float32] */
  };
  %640 = (%model.backbone.body.layer3.2.conv2.weight, %x163);
  %641 = (%tensor_099,);
  let %v99: () = vm.invoke_tvm_op(%639, %640, %641) /* ty=() */;
  let %x164: Tensor[(256, 256, 3, 3), float32] = %tensor_099;
  let %x165: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.2.bn2.bias, meta[relay.Constant][166] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][64]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x166: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.2.bn2.running_mean, meta[relay.Constant][167] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][65]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_0100: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][100]) /* ty=Storage[] */;
  let %tensor_0100: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0100, 0 /* ty=int64 */, meta[relay.Constant][168] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][100]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %646 = fn (%p0100: Tensor[(1, 256, 50, 50), float32], %p199: Tensor[(256, 256, 3, 3), float32], %p233: Tensor[(1, 256, 1, 1), float32], %p332: Tensor[(1, 256, 1, 1), float32], %p432: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %642 = nn.conv2d(%p0100, %p199, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %643 = multiply(%p332, %p432) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %644 = subtract(%p233, %643) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %645 = add(%642, %644) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%645) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %647 = (%x162, %x164, %x165, %x166, %x163);
  %648 = (%tensor_0100,);
  let %v100: () = vm.invoke_tvm_op(%646, %647, %648) /* ty=() */;
  let %x167: Tensor[(1, 256, 50, 50), float32] = %tensor_0100;
  let %storage_0101: Storage[] = memory.alloc_storage(4096 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][101]) /* ty=Storage[] */;
  let %tensor_0101: Tensor[(1, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0101, 0 /* ty=int64 */, meta[relay.Constant][169] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][101]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  %653 = fn (%p0101: Tensor[(1024), float32], %p1100: Tensor[(1024), float32], Primitive=1) -> Tensor[(1, 1024, 1, 1), float32] {
    %649 = reshape(%p0101, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %650 = reshape(%p1100, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %651 = add(%650, 0f /* ty=float32 */) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %652 = rsqrt(%651) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    multiply(%649, %652) /* ty=Tensor[(1, 1024, 1, 1), float32] */
  };
  %654 = (%model.backbone.body.layer3.2.bn3.weight, %model.backbone.body.layer3.2.bn3.running_var);
  %655 = (%tensor_0101,);
  let %v101: () = vm.invoke_tvm_op(%653, %654, %655) /* ty=() */;
  let %x168: Tensor[(1, 1024, 1, 1), float32] = %tensor_0101;
  let %storage_0102: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][102]) /* ty=Storage[] */;
  let %tensor_0102: Tensor[(1024, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0102, 0 /* ty=int64 */, meta[relay.Constant][170] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][102]) /* ty=Tensor[(1024, 256, 1, 1), float32] */;
  %658 = fn (%p0102: Tensor[(1024, 256, 1, 1), float32], %p1101: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1024, 256, 1, 1), float32] {
    %656 = squeeze(%p1101, axis=[0, 2, 3]) /* ty=Tensor[(1024), float32] */;
    %657 = expand_dims(%656, axis=1, num_newaxis=3) /* ty=Tensor[(1024, 1, 1, 1), float32] */;
    multiply(%p0102, %657) /* ty=Tensor[(1024, 256, 1, 1), float32] */
  };
  %659 = (%model.backbone.body.layer3.2.conv3.weight, %x168);
  %660 = (%tensor_0102,);
  let %v102: () = vm.invoke_tvm_op(%658, %659, %660) /* ty=() */;
  let %x169: Tensor[(1024, 256, 1, 1), float32] = %tensor_0102;
  let %x170: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.2.bn3.bias, meta[relay.Constant][171] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][66]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %x171: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.2.bn3.running_mean, meta[relay.Constant][172] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][67]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %storage_0103: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][103]) /* ty=Storage[] */;
  let %tensor_0103: Tensor[(1, 1024, 50, 50), float32] = memory.alloc_tensor(%storage_0103, 0 /* ty=int64 */, meta[relay.Constant][173] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][103]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
  %666 = fn (%p0103: Tensor[(1, 256, 50, 50), float32], %p1102: Tensor[(1024, 256, 1, 1), float32], %p234: Tensor[(1, 1024, 1, 1), float32], %p333: Tensor[(1, 1024, 1, 1), float32], %p433: Tensor[(1, 1024, 1, 1), float32], %p59: Tensor[(1, 1024, 50, 50), float32], Primitive=1) -> Tensor[(1, 1024, 50, 50), float32] {
    %661 = nn.conv2d(%p0103, %p1102, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %662 = multiply(%p333, %p433) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %663 = subtract(%p234, %662) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %664 = add(%661, %663) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %665 = add(%664, %p59) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    nn.relu(%665) /* ty=Tensor[(1, 1024, 50, 50), float32] */
  };
  %667 = (%x167, %x169, %x170, %x171, %x168, %x157);
  %668 = (%tensor_0103,);
  let %v103: () = vm.invoke_tvm_op(%666, %667, %668) /* ty=() */;
  let %x172: Tensor[(1, 1024, 50, 50), float32] = %tensor_0103;
  let %storage_0104: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][104]) /* ty=Storage[] */;
  let %tensor_0104: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0104, 0 /* ty=int64 */, meta[relay.Constant][174] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][104]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %673 = fn (%p0104: Tensor[(256), float32], %p1103: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %669 = reshape(%p0104, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %670 = reshape(%p1103, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %671 = add(%670, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %672 = rsqrt(%671) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%669, %672) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %674 = (%model.backbone.body.layer3.3.bn1.weight, %model.backbone.body.layer3.3.bn1.running_var);
  %675 = (%tensor_0104,);
  let %v104: () = vm.invoke_tvm_op(%673, %674, %675) /* ty=() */;
  let %x173: Tensor[(1, 256, 1, 1), float32] = %tensor_0104;
  let %storage_0105: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][105]) /* ty=Storage[] */;
  let %tensor_0105: Tensor[(256, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0105, 0 /* ty=int64 */, meta[relay.Constant][175] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][105]) /* ty=Tensor[(256, 1024, 1, 1), float32] */;
  %678 = fn (%p0105: Tensor[(256, 1024, 1, 1), float32], %p1104: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 1024, 1, 1), float32] {
    %676 = squeeze(%p1104, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %677 = expand_dims(%676, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p0105, %677) /* ty=Tensor[(256, 1024, 1, 1), float32] */
  };
  %679 = (%model.backbone.body.layer3.3.conv1.weight, %x173);
  %680 = (%tensor_0105,);
  let %v105: () = vm.invoke_tvm_op(%678, %679, %680) /* ty=() */;
  let %x174: Tensor[(256, 1024, 1, 1), float32] = %tensor_0105;
  let %x175: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.3.bn1.bias, meta[relay.Constant][176] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][68]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x176: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.3.bn1.running_mean, meta[relay.Constant][177] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][69]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_0106: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][106]) /* ty=Storage[] */;
  let %tensor_0106: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0106, 0 /* ty=int64 */, meta[relay.Constant][178] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][106]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %685 = fn (%p0106: Tensor[(1, 1024, 50, 50), float32], %p1105: Tensor[(256, 1024, 1, 1), float32], %p235: Tensor[(1, 256, 1, 1), float32], %p334: Tensor[(1, 256, 1, 1), float32], %p434: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %681 = nn.conv2d(%p0106, %p1105, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %682 = multiply(%p334, %p434) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %683 = subtract(%p235, %682) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %684 = add(%681, %683) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%684) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %686 = (%x172, %x174, %x175, %x176, %x173);
  %687 = (%tensor_0106,);
  let %v106: () = vm.invoke_tvm_op(%685, %686, %687) /* ty=() */;
  let %x177: Tensor[(1, 256, 50, 50), float32] = %tensor_0106;
  let %storage_0107: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][107]) /* ty=Storage[] */;
  let %tensor_0107: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0107, 0 /* ty=int64 */, meta[relay.Constant][179] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][107]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %692 = fn (%p0107: Tensor[(256), float32], %p1106: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %688 = reshape(%p0107, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %689 = reshape(%p1106, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %690 = add(%689, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %691 = rsqrt(%690) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%688, %691) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %693 = (%model.backbone.body.layer3.3.bn2.weight, %model.backbone.body.layer3.3.bn2.running_var);
  %694 = (%tensor_0107,);
  let %v107: () = vm.invoke_tvm_op(%692, %693, %694) /* ty=() */;
  let %x178: Tensor[(1, 256, 1, 1), float32] = %tensor_0107;
  let %storage_0108: Storage[] = memory.alloc_storage(2359296 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][108]) /* ty=Storage[] */;
  let %tensor_0108: Tensor[(256, 256, 3, 3), float32] = memory.alloc_tensor(%storage_0108, 0 /* ty=int64 */, meta[relay.Constant][180] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][108]) /* ty=Tensor[(256, 256, 3, 3), float32] */;
  %697 = fn (%p0108: Tensor[(256, 256, 3, 3), float32], %p1107: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 256, 3, 3), float32] {
    %695 = squeeze(%p1107, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %696 = expand_dims(%695, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p0108, %696) /* ty=Tensor[(256, 256, 3, 3), float32] */
  };
  %698 = (%model.backbone.body.layer3.3.conv2.weight, %x178);
  %699 = (%tensor_0108,);
  let %v108: () = vm.invoke_tvm_op(%697, %698, %699) /* ty=() */;
  let %x179: Tensor[(256, 256, 3, 3), float32] = %tensor_0108;
  let %x180: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.3.bn2.bias, meta[relay.Constant][181] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][70]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x181: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.3.bn2.running_mean, meta[relay.Constant][182] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][71]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_0109: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][109]) /* ty=Storage[] */;
  let %tensor_0109: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0109, 0 /* ty=int64 */, meta[relay.Constant][183] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][109]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %704 = fn (%p0109: Tensor[(1, 256, 50, 50), float32], %p1108: Tensor[(256, 256, 3, 3), float32], %p236: Tensor[(1, 256, 1, 1), float32], %p335: Tensor[(1, 256, 1, 1), float32], %p435: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %700 = nn.conv2d(%p0109, %p1108, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %701 = multiply(%p335, %p435) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %702 = subtract(%p236, %701) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %703 = add(%700, %702) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%703) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %705 = (%x177, %x179, %x180, %x181, %x178);
  %706 = (%tensor_0109,);
  let %v109: () = vm.invoke_tvm_op(%704, %705, %706) /* ty=() */;
  let %x182: Tensor[(1, 256, 50, 50), float32] = %tensor_0109;
  let %storage_0110: Storage[] = memory.alloc_storage(4096 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][110]) /* ty=Storage[] */;
  let %tensor_0110: Tensor[(1, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0110, 0 /* ty=int64 */, meta[relay.Constant][184] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][110]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  %711 = fn (%p0110: Tensor[(1024), float32], %p1109: Tensor[(1024), float32], Primitive=1) -> Tensor[(1, 1024, 1, 1), float32] {
    %707 = reshape(%p0110, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %708 = reshape(%p1109, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %709 = add(%708, 0f /* ty=float32 */) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %710 = rsqrt(%709) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    multiply(%707, %710) /* ty=Tensor[(1, 1024, 1, 1), float32] */
  };
  %712 = (%model.backbone.body.layer3.3.bn3.weight, %model.backbone.body.layer3.3.bn3.running_var);
  %713 = (%tensor_0110,);
  let %v110: () = vm.invoke_tvm_op(%711, %712, %713) /* ty=() */;
  let %x183: Tensor[(1, 1024, 1, 1), float32] = %tensor_0110;
  let %storage_0111: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][111]) /* ty=Storage[] */;
  let %tensor_0111: Tensor[(1024, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0111, 0 /* ty=int64 */, meta[relay.Constant][185] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][111]) /* ty=Tensor[(1024, 256, 1, 1), float32] */;
  %716 = fn (%p0111: Tensor[(1024, 256, 1, 1), float32], %p1110: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1024, 256, 1, 1), float32] {
    %714 = squeeze(%p1110, axis=[0, 2, 3]) /* ty=Tensor[(1024), float32] */;
    %715 = expand_dims(%714, axis=1, num_newaxis=3) /* ty=Tensor[(1024, 1, 1, 1), float32] */;
    multiply(%p0111, %715) /* ty=Tensor[(1024, 256, 1, 1), float32] */
  };
  %717 = (%model.backbone.body.layer3.3.conv3.weight, %x183);
  %718 = (%tensor_0111,);
  let %v111: () = vm.invoke_tvm_op(%716, %717, %718) /* ty=() */;
  let %x184: Tensor[(1024, 256, 1, 1), float32] = %tensor_0111;
  let %x185: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.3.bn3.bias, meta[relay.Constant][186] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][72]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %x186: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.3.bn3.running_mean, meta[relay.Constant][187] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][73]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %storage_0112: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][112]) /* ty=Storage[] */;
  let %tensor_0112: Tensor[(1, 1024, 50, 50), float32] = memory.alloc_tensor(%storage_0112, 0 /* ty=int64 */, meta[relay.Constant][188] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][112]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
  %724 = fn (%p0112: Tensor[(1, 256, 50, 50), float32], %p1111: Tensor[(1024, 256, 1, 1), float32], %p237: Tensor[(1, 1024, 1, 1), float32], %p336: Tensor[(1, 1024, 1, 1), float32], %p436: Tensor[(1, 1024, 1, 1), float32], %p510: Tensor[(1, 1024, 50, 50), float32], Primitive=1) -> Tensor[(1, 1024, 50, 50), float32] {
    %719 = nn.conv2d(%p0112, %p1111, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %720 = multiply(%p336, %p436) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %721 = subtract(%p237, %720) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %722 = add(%719, %721) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %723 = add(%722, %p510) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    nn.relu(%723) /* ty=Tensor[(1, 1024, 50, 50), float32] */
  };
  %725 = (%x182, %x184, %x185, %x186, %x183, %x172);
  %726 = (%tensor_0112,);
  let %v112: () = vm.invoke_tvm_op(%724, %725, %726) /* ty=() */;
  let %x187: Tensor[(1, 1024, 50, 50), float32] = %tensor_0112;
  let %storage_0113: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][113]) /* ty=Storage[] */;
  let %tensor_0113: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0113, 0 /* ty=int64 */, meta[relay.Constant][189] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][113]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %731 = fn (%p0113: Tensor[(256), float32], %p1112: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %727 = reshape(%p0113, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %728 = reshape(%p1112, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %729 = add(%728, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %730 = rsqrt(%729) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%727, %730) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %732 = (%model.backbone.body.layer3.4.bn1.weight, %model.backbone.body.layer3.4.bn1.running_var);
  %733 = (%tensor_0113,);
  let %v113: () = vm.invoke_tvm_op(%731, %732, %733) /* ty=() */;
  let %x188: Tensor[(1, 256, 1, 1), float32] = %tensor_0113;
  let %storage_0114: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][114]) /* ty=Storage[] */;
  let %tensor_0114: Tensor[(256, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0114, 0 /* ty=int64 */, meta[relay.Constant][190] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][114]) /* ty=Tensor[(256, 1024, 1, 1), float32] */;
  %736 = fn (%p0114: Tensor[(256, 1024, 1, 1), float32], %p1113: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 1024, 1, 1), float32] {
    %734 = squeeze(%p1113, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %735 = expand_dims(%734, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p0114, %735) /* ty=Tensor[(256, 1024, 1, 1), float32] */
  };
  %737 = (%model.backbone.body.layer3.4.conv1.weight, %x188);
  %738 = (%tensor_0114,);
  let %v114: () = vm.invoke_tvm_op(%736, %737, %738) /* ty=() */;
  let %x189: Tensor[(256, 1024, 1, 1), float32] = %tensor_0114;
  let %x190: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.4.bn1.bias, meta[relay.Constant][191] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][74]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x191: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.4.bn1.running_mean, meta[relay.Constant][192] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][75]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_0115: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][115]) /* ty=Storage[] */;
  let %tensor_0115: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0115, 0 /* ty=int64 */, meta[relay.Constant][193] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][115]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %743 = fn (%p0115: Tensor[(1, 1024, 50, 50), float32], %p1114: Tensor[(256, 1024, 1, 1), float32], %p238: Tensor[(1, 256, 1, 1), float32], %p337: Tensor[(1, 256, 1, 1), float32], %p437: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %739 = nn.conv2d(%p0115, %p1114, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %740 = multiply(%p337, %p437) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %741 = subtract(%p238, %740) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %742 = add(%739, %741) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%742) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %744 = (%x187, %x189, %x190, %x191, %x188);
  %745 = (%tensor_0115,);
  let %v115: () = vm.invoke_tvm_op(%743, %744, %745) /* ty=() */;
  let %x192: Tensor[(1, 256, 50, 50), float32] = %tensor_0115;
  let %storage_0116: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][116]) /* ty=Storage[] */;
  let %tensor_0116: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0116, 0 /* ty=int64 */, meta[relay.Constant][194] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][116]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %750 = fn (%p0116: Tensor[(256), float32], %p1115: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %746 = reshape(%p0116, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %747 = reshape(%p1115, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %748 = add(%747, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %749 = rsqrt(%748) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%746, %749) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %751 = (%model.backbone.body.layer3.4.bn2.weight, %model.backbone.body.layer3.4.bn2.running_var);
  %752 = (%tensor_0116,);
  let %v116: () = vm.invoke_tvm_op(%750, %751, %752) /* ty=() */;
  let %x193: Tensor[(1, 256, 1, 1), float32] = %tensor_0116;
  let %storage_0117: Storage[] = memory.alloc_storage(2359296 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][117]) /* ty=Storage[] */;
  let %tensor_0117: Tensor[(256, 256, 3, 3), float32] = memory.alloc_tensor(%storage_0117, 0 /* ty=int64 */, meta[relay.Constant][195] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][117]) /* ty=Tensor[(256, 256, 3, 3), float32] */;
  %755 = fn (%p0117: Tensor[(256, 256, 3, 3), float32], %p1116: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 256, 3, 3), float32] {
    %753 = squeeze(%p1116, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %754 = expand_dims(%753, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p0117, %754) /* ty=Tensor[(256, 256, 3, 3), float32] */
  };
  %756 = (%model.backbone.body.layer3.4.conv2.weight, %x193);
  %757 = (%tensor_0117,);
  let %v117: () = vm.invoke_tvm_op(%755, %756, %757) /* ty=() */;
  let %x194: Tensor[(256, 256, 3, 3), float32] = %tensor_0117;
  let %x195: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.4.bn2.bias, meta[relay.Constant][196] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][76]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x196: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.4.bn2.running_mean, meta[relay.Constant][197] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][77]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_0118: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][118]) /* ty=Storage[] */;
  let %tensor_0118: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0118, 0 /* ty=int64 */, meta[relay.Constant][198] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][118]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %762 = fn (%p0118: Tensor[(1, 256, 50, 50), float32], %p1117: Tensor[(256, 256, 3, 3), float32], %p239: Tensor[(1, 256, 1, 1), float32], %p338: Tensor[(1, 256, 1, 1), float32], %p438: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %758 = nn.conv2d(%p0118, %p1117, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %759 = multiply(%p338, %p438) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %760 = subtract(%p239, %759) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %761 = add(%758, %760) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%761) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %763 = (%x192, %x194, %x195, %x196, %x193);
  %764 = (%tensor_0118,);
  let %v118: () = vm.invoke_tvm_op(%762, %763, %764) /* ty=() */;
  let %x197: Tensor[(1, 256, 50, 50), float32] = %tensor_0118;
  let %storage_0119: Storage[] = memory.alloc_storage(4096 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][119]) /* ty=Storage[] */;
  let %tensor_0119: Tensor[(1, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0119, 0 /* ty=int64 */, meta[relay.Constant][199] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][119]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  %769 = fn (%p0119: Tensor[(1024), float32], %p1118: Tensor[(1024), float32], Primitive=1) -> Tensor[(1, 1024, 1, 1), float32] {
    %765 = reshape(%p0119, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %766 = reshape(%p1118, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %767 = add(%766, 0f /* ty=float32 */) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %768 = rsqrt(%767) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    multiply(%765, %768) /* ty=Tensor[(1, 1024, 1, 1), float32] */
  };
  %770 = (%model.backbone.body.layer3.4.bn3.weight, %model.backbone.body.layer3.4.bn3.running_var);
  %771 = (%tensor_0119,);
  let %v119: () = vm.invoke_tvm_op(%769, %770, %771) /* ty=() */;
  let %x198: Tensor[(1, 1024, 1, 1), float32] = %tensor_0119;
  let %storage_0120: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][120]) /* ty=Storage[] */;
  let %tensor_0120: Tensor[(1024, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0120, 0 /* ty=int64 */, meta[relay.Constant][200] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][120]) /* ty=Tensor[(1024, 256, 1, 1), float32] */;
  %774 = fn (%p0120: Tensor[(1024, 256, 1, 1), float32], %p1119: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1024, 256, 1, 1), float32] {
    %772 = squeeze(%p1119, axis=[0, 2, 3]) /* ty=Tensor[(1024), float32] */;
    %773 = expand_dims(%772, axis=1, num_newaxis=3) /* ty=Tensor[(1024, 1, 1, 1), float32] */;
    multiply(%p0120, %773) /* ty=Tensor[(1024, 256, 1, 1), float32] */
  };
  %775 = (%model.backbone.body.layer3.4.conv3.weight, %x198);
  %776 = (%tensor_0120,);
  let %v120: () = vm.invoke_tvm_op(%774, %775, %776) /* ty=() */;
  let %x199: Tensor[(1024, 256, 1, 1), float32] = %tensor_0120;
  let %x200: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.4.bn3.bias, meta[relay.Constant][201] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][78]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %x201: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.4.bn3.running_mean, meta[relay.Constant][202] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][79]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %storage_0121: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][121]) /* ty=Storage[] */;
  let %tensor_0121: Tensor[(1, 1024, 50, 50), float32] = memory.alloc_tensor(%storage_0121, 0 /* ty=int64 */, meta[relay.Constant][203] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][121]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
  %782 = fn (%p0121: Tensor[(1, 256, 50, 50), float32], %p1120: Tensor[(1024, 256, 1, 1), float32], %p240: Tensor[(1, 1024, 1, 1), float32], %p339: Tensor[(1, 1024, 1, 1), float32], %p439: Tensor[(1, 1024, 1, 1), float32], %p511: Tensor[(1, 1024, 50, 50), float32], Primitive=1) -> Tensor[(1, 1024, 50, 50), float32] {
    %777 = nn.conv2d(%p0121, %p1120, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %778 = multiply(%p339, %p439) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %779 = subtract(%p240, %778) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %780 = add(%777, %779) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %781 = add(%780, %p511) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    nn.relu(%781) /* ty=Tensor[(1, 1024, 50, 50), float32] */
  };
  %783 = (%x197, %x199, %x200, %x201, %x198, %x187);
  %784 = (%tensor_0121,);
  let %v121: () = vm.invoke_tvm_op(%782, %783, %784) /* ty=() */;
  let %x202: Tensor[(1, 1024, 50, 50), float32] = %tensor_0121;
  let %storage_0122: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][122]) /* ty=Storage[] */;
  let %tensor_0122: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0122, 0 /* ty=int64 */, meta[relay.Constant][204] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][122]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %789 = fn (%p0122: Tensor[(256), float32], %p1121: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %785 = reshape(%p0122, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %786 = reshape(%p1121, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %787 = add(%786, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %788 = rsqrt(%787) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%785, %788) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %790 = (%model.backbone.body.layer3.5.bn1.weight, %model.backbone.body.layer3.5.bn1.running_var);
  %791 = (%tensor_0122,);
  let %v122: () = vm.invoke_tvm_op(%789, %790, %791) /* ty=() */;
  let %x203: Tensor[(1, 256, 1, 1), float32] = %tensor_0122;
  let %storage_0123: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][123]) /* ty=Storage[] */;
  let %tensor_0123: Tensor[(256, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0123, 0 /* ty=int64 */, meta[relay.Constant][205] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][123]) /* ty=Tensor[(256, 1024, 1, 1), float32] */;
  %794 = fn (%p0123: Tensor[(256, 1024, 1, 1), float32], %p1122: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 1024, 1, 1), float32] {
    %792 = squeeze(%p1122, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %793 = expand_dims(%792, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p0123, %793) /* ty=Tensor[(256, 1024, 1, 1), float32] */
  };
  %795 = (%model.backbone.body.layer3.5.conv1.weight, %x203);
  %796 = (%tensor_0123,);
  let %v123: () = vm.invoke_tvm_op(%794, %795, %796) /* ty=() */;
  let %x204: Tensor[(256, 1024, 1, 1), float32] = %tensor_0123;
  let %x205: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.5.bn1.bias, meta[relay.Constant][206] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][80]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x206: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.5.bn1.running_mean, meta[relay.Constant][207] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][81]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_0124: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][124]) /* ty=Storage[] */;
  let %tensor_0124: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0124, 0 /* ty=int64 */, meta[relay.Constant][208] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][124]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %801 = fn (%p0124: Tensor[(1, 1024, 50, 50), float32], %p1123: Tensor[(256, 1024, 1, 1), float32], %p241: Tensor[(1, 256, 1, 1), float32], %p340: Tensor[(1, 256, 1, 1), float32], %p440: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %797 = nn.conv2d(%p0124, %p1123, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %798 = multiply(%p340, %p440) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %799 = subtract(%p241, %798) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %800 = add(%797, %799) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%800) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %802 = (%x202, %x204, %x205, %x206, %x203);
  %803 = (%tensor_0124,);
  let %v124: () = vm.invoke_tvm_op(%801, %802, %803) /* ty=() */;
  let %x207: Tensor[(1, 256, 50, 50), float32] = %tensor_0124;
  let %storage_0125: Storage[] = memory.alloc_storage(1024 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][125]) /* ty=Storage[] */;
  let %tensor_0125: Tensor[(1, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0125, 0 /* ty=int64 */, meta[relay.Constant][209] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][125]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  %808 = fn (%p0125: Tensor[(256), float32], %p1124: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 1, 1), float32] {
    %804 = reshape(%p0125, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %805 = reshape(%p1124, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %806 = add(%805, 0f /* ty=float32 */) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %807 = rsqrt(%806) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    multiply(%804, %807) /* ty=Tensor[(1, 256, 1, 1), float32] */
  };
  %809 = (%model.backbone.body.layer3.5.bn2.weight, %model.backbone.body.layer3.5.bn2.running_var);
  %810 = (%tensor_0125,);
  let %v125: () = vm.invoke_tvm_op(%808, %809, %810) /* ty=() */;
  let %x208: Tensor[(1, 256, 1, 1), float32] = %tensor_0125;
  let %storage_0126: Storage[] = memory.alloc_storage(2359296 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][126]) /* ty=Storage[] */;
  let %tensor_0126: Tensor[(256, 256, 3, 3), float32] = memory.alloc_tensor(%storage_0126, 0 /* ty=int64 */, meta[relay.Constant][210] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][126]) /* ty=Tensor[(256, 256, 3, 3), float32] */;
  %813 = fn (%p0126: Tensor[(256, 256, 3, 3), float32], %p1125: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(256, 256, 3, 3), float32] {
    %811 = squeeze(%p1125, axis=[0, 2, 3]) /* ty=Tensor[(256), float32] */;
    %812 = expand_dims(%811, axis=1, num_newaxis=3) /* ty=Tensor[(256, 1, 1, 1), float32] */;
    multiply(%p0126, %812) /* ty=Tensor[(256, 256, 3, 3), float32] */
  };
  %814 = (%model.backbone.body.layer3.5.conv2.weight, %x208);
  %815 = (%tensor_0126,);
  let %v126: () = vm.invoke_tvm_op(%813, %814, %815) /* ty=() */;
  let %x209: Tensor[(256, 256, 3, 3), float32] = %tensor_0126;
  let %x210: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.5.bn2.bias, meta[relay.Constant][211] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][82]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %x211: Tensor[(1, 256, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.5.bn2.running_mean, meta[relay.Constant][212] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][83]) /* ty=Tensor[(1, 256, 1, 1), float32] */;
  let %storage_0127: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][127]) /* ty=Storage[] */;
  let %tensor_0127: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0127, 0 /* ty=int64 */, meta[relay.Constant][213] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][127]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %820 = fn (%p0127: Tensor[(1, 256, 50, 50), float32], %p1126: Tensor[(256, 256, 3, 3), float32], %p242: Tensor[(1, 256, 1, 1), float32], %p341: Tensor[(1, 256, 1, 1), float32], %p441: Tensor[(1, 256, 1, 1), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %816 = nn.conv2d(%p0127, %p1126, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %817 = multiply(%p341, %p441) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %818 = subtract(%p242, %817) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %819 = add(%816, %818) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%819) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %821 = (%x207, %x209, %x210, %x211, %x208);
  %822 = (%tensor_0127,);
  let %v127: () = vm.invoke_tvm_op(%820, %821, %822) /* ty=() */;
  let %x212: Tensor[(1, 256, 50, 50), float32] = %tensor_0127;
  let %storage_0128: Storage[] = memory.alloc_storage(4096 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][128]) /* ty=Storage[] */;
  let %tensor_0128: Tensor[(1, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0128, 0 /* ty=int64 */, meta[relay.Constant][214] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][128]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  %827 = fn (%p0128: Tensor[(1024), float32], %p1127: Tensor[(1024), float32], Primitive=1) -> Tensor[(1, 1024, 1, 1), float32] {
    %823 = reshape(%p0128, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %824 = reshape(%p1127, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %825 = add(%824, 0f /* ty=float32 */) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %826 = rsqrt(%825) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    multiply(%823, %826) /* ty=Tensor[(1, 1024, 1, 1), float32] */
  };
  %828 = (%model.backbone.body.layer3.5.bn3.weight, %model.backbone.body.layer3.5.bn3.running_var);
  %829 = (%tensor_0128,);
  let %v128: () = vm.invoke_tvm_op(%827, %828, %829) /* ty=() */;
  let %x213: Tensor[(1, 1024, 1, 1), float32] = %tensor_0128;
  let %storage_0129: Storage[] = memory.alloc_storage(1048576 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][129]) /* ty=Storage[] */;
  let %tensor_0129: Tensor[(1024, 256, 1, 1), float32] = memory.alloc_tensor(%storage_0129, 0 /* ty=int64 */, meta[relay.Constant][215] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][129]) /* ty=Tensor[(1024, 256, 1, 1), float32] */;
  %832 = fn (%p0129: Tensor[(1024, 256, 1, 1), float32], %p1128: Tensor[(1, 1024, 1, 1), float32], Primitive=1) -> Tensor[(1024, 256, 1, 1), float32] {
    %830 = squeeze(%p1128, axis=[0, 2, 3]) /* ty=Tensor[(1024), float32] */;
    %831 = expand_dims(%830, axis=1, num_newaxis=3) /* ty=Tensor[(1024, 1, 1, 1), float32] */;
    multiply(%p0129, %831) /* ty=Tensor[(1024, 256, 1, 1), float32] */
  };
  %833 = (%model.backbone.body.layer3.5.conv3.weight, %x213);
  %834 = (%tensor_0129,);
  let %v129: () = vm.invoke_tvm_op(%832, %833, %834) /* ty=() */;
  let %x214: Tensor[(1024, 256, 1, 1), float32] = %tensor_0129;
  let %x215: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.5.bn3.bias, meta[relay.Constant][216] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][84]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %x216: Tensor[(1, 1024, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer3.5.bn3.running_mean, meta[relay.Constant][217] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][85]) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
  let %storage_0130: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][130]) /* ty=Storage[] */;
  let %tensor_0130: Tensor[(1, 1024, 50, 50), float32] = memory.alloc_tensor(%storage_0130, 0 /* ty=int64 */, meta[relay.Constant][218] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][130]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
  %840 = fn (%p0130: Tensor[(1, 256, 50, 50), float32], %p1129: Tensor[(1024, 256, 1, 1), float32], %p243: Tensor[(1, 1024, 1, 1), float32], %p342: Tensor[(1, 1024, 1, 1), float32], %p442: Tensor[(1, 1024, 1, 1), float32], %p512: Tensor[(1, 1024, 50, 50), float32], Primitive=1) -> Tensor[(1, 1024, 50, 50), float32] {
    %835 = nn.conv2d(%p0130, %p1129, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %836 = multiply(%p342, %p442) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %837 = subtract(%p243, %836) /* ty=Tensor[(1, 1024, 1, 1), float32] */;
    %838 = add(%835, %837) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    %839 = add(%838, %p512) /* ty=Tensor[(1, 1024, 50, 50), float32] */;
    nn.relu(%839) /* ty=Tensor[(1, 1024, 50, 50), float32] */
  };
  %841 = (%x212, %x214, %x215, %x216, %x213, %x202);
  %842 = (%tensor_0130,);
  let %v130: () = vm.invoke_tvm_op(%840, %841, %842) /* ty=() */;
  let %x217: Tensor[(1, 1024, 50, 50), float32] = %tensor_0130;
  let %storage_0131: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][131]) /* ty=Storage[] */;
  let %tensor_0131: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0131, 0 /* ty=int64 */, meta[relay.Constant][219] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][131]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %847 = fn (%p0131: Tensor[(512), float32], %p1130: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %843 = reshape(%p0131, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %844 = reshape(%p1130, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %845 = add(%844, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %846 = rsqrt(%845) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%843, %846) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %848 = (%model.backbone.body.layer4.0.bn1.weight, %model.backbone.body.layer4.0.bn1.running_var);
  %849 = (%tensor_0131,);
  let %v131: () = vm.invoke_tvm_op(%847, %848, %849) /* ty=() */;
  let %x218: Tensor[(1, 512, 1, 1), float32] = %tensor_0131;
  let %storage_0132: Storage[] = memory.alloc_storage(2097152 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][132]) /* ty=Storage[] */;
  let %tensor_0132: Tensor[(512, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0132, 0 /* ty=int64 */, meta[relay.Constant][220] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][132]) /* ty=Tensor[(512, 1024, 1, 1), float32] */;
  %852 = fn (%p0132: Tensor[(512, 1024, 1, 1), float32], %p1131: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 1024, 1, 1), float32] {
    %850 = squeeze(%p1131, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %851 = expand_dims(%850, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p0132, %851) /* ty=Tensor[(512, 1024, 1, 1), float32] */
  };
  %853 = (%model.backbone.body.layer4.0.conv1.weight, %x218);
  %854 = (%tensor_0132,);
  let %v132: () = vm.invoke_tvm_op(%852, %853, %854) /* ty=() */;
  let %x219: Tensor[(512, 1024, 1, 1), float32] = %tensor_0132;
  let %x220: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.bn1.bias, meta[relay.Constant][221] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][86]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x221: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.bn1.running_mean, meta[relay.Constant][222] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][87]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_0133: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][133]) /* ty=Storage[] */;
  let %tensor_0133: Tensor[(1, 512, 50, 50), float32] = memory.alloc_tensor(%storage_0133, 0 /* ty=int64 */, meta[relay.Constant][223] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][133]) /* ty=Tensor[(1, 512, 50, 50), float32] */;
  %859 = fn (%p0133: Tensor[(1, 1024, 50, 50), float32], %p1132: Tensor[(512, 1024, 1, 1), float32], %p244: Tensor[(1, 512, 1, 1), float32], %p343: Tensor[(1, 512, 1, 1), float32], %p443: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(1, 512, 50, 50), float32] {
    %855 = nn.conv2d(%p0133, %p1132, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 50, 50), float32] */;
    %856 = multiply(%p343, %p443) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %857 = subtract(%p244, %856) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %858 = add(%855, %857) /* ty=Tensor[(1, 512, 50, 50), float32] */;
    nn.relu(%858) /* ty=Tensor[(1, 512, 50, 50), float32] */
  };
  %860 = (%x217, %x219, %x220, %x221, %x218);
  %861 = (%tensor_0133,);
  let %v133: () = vm.invoke_tvm_op(%859, %860, %861) /* ty=() */;
  let %x222: Tensor[(1, 512, 50, 50), float32] = %tensor_0133;
  let %storage_0134: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][134]) /* ty=Storage[] */;
  let %tensor_0134: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0134, 0 /* ty=int64 */, meta[relay.Constant][224] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][134]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %866 = fn (%p0134: Tensor[(512), float32], %p1133: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %862 = reshape(%p0134, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %863 = reshape(%p1133, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %864 = add(%863, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %865 = rsqrt(%864) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%862, %865) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %867 = (%model.backbone.body.layer4.0.bn2.weight, %model.backbone.body.layer4.0.bn2.running_var);
  %868 = (%tensor_0134,);
  let %v134: () = vm.invoke_tvm_op(%866, %867, %868) /* ty=() */;
  let %x223: Tensor[(1, 512, 1, 1), float32] = %tensor_0134;
  let %storage_0135: Storage[] = memory.alloc_storage(9437184 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][135]) /* ty=Storage[] */;
  let %tensor_0135: Tensor[(512, 512, 3, 3), float32] = memory.alloc_tensor(%storage_0135, 0 /* ty=int64 */, meta[relay.Constant][225] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][135]) /* ty=Tensor[(512, 512, 3, 3), float32] */;
  %871 = fn (%p0135: Tensor[(512, 512, 3, 3), float32], %p1134: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 512, 3, 3), float32] {
    %869 = squeeze(%p1134, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %870 = expand_dims(%869, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p0135, %870) /* ty=Tensor[(512, 512, 3, 3), float32] */
  };
  %872 = (%model.backbone.body.layer4.0.conv2.weight, %x223);
  %873 = (%tensor_0135,);
  let %v135: () = vm.invoke_tvm_op(%871, %872, %873) /* ty=() */;
  let %x224: Tensor[(512, 512, 3, 3), float32] = %tensor_0135;
  let %x225: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.bn2.bias, meta[relay.Constant][226] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][88]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x226: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.bn2.running_mean, meta[relay.Constant][227] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][89]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_0136: Storage[] = memory.alloc_storage(1280000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][136]) /* ty=Storage[] */;
  let %tensor_0136: Tensor[(1, 512, 25, 25), float32] = memory.alloc_tensor(%storage_0136, 0 /* ty=int64 */, meta[relay.Constant][228] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][136]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
  %878 = fn (%p0136: Tensor[(1, 512, 50, 50), float32], %p1135: Tensor[(512, 512, 3, 3), float32], %p245: Tensor[(1, 512, 1, 1), float32], %p344: Tensor[(1, 512, 1, 1), float32], %p444: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(1, 512, 25, 25), float32] {
    %874 = nn.conv2d(%p0136, %p1135, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    %875 = multiply(%p344, %p444) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %876 = subtract(%p245, %875) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %877 = add(%874, %876) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    nn.relu(%877) /* ty=Tensor[(1, 512, 25, 25), float32] */
  };
  %879 = (%x222, %x224, %x225, %x226, %x223);
  %880 = (%tensor_0136,);
  let %v136: () = vm.invoke_tvm_op(%878, %879, %880) /* ty=() */;
  let %x227: Tensor[(1, 512, 25, 25), float32] = %tensor_0136;
  let %storage_0137: Storage[] = memory.alloc_storage(8192 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][137]) /* ty=Storage[] */;
  let %tensor_0137: Tensor[(1, 2048, 1, 1), float32] = memory.alloc_tensor(%storage_0137, 0 /* ty=int64 */, meta[relay.Constant][229] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][137]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  %885 = fn (%p0137: Tensor[(2048), float32], %p1136: Tensor[(2048), float32], Primitive=1) -> Tensor[(1, 2048, 1, 1), float32] {
    %881 = reshape(%p0137, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %882 = reshape(%p1136, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %883 = add(%882, 0f /* ty=float32 */) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %884 = rsqrt(%883) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    multiply(%881, %884) /* ty=Tensor[(1, 2048, 1, 1), float32] */
  };
  %886 = (%model.backbone.body.layer4.0.bn3.weight, %model.backbone.body.layer4.0.bn3.running_var);
  %887 = (%tensor_0137,);
  let %v137: () = vm.invoke_tvm_op(%885, %886, %887) /* ty=() */;
  let %x228: Tensor[(1, 2048, 1, 1), float32] = %tensor_0137;
  let %storage_0138: Storage[] = memory.alloc_storage(4194304 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][138]) /* ty=Storage[] */;
  let %tensor_0138: Tensor[(2048, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0138, 0 /* ty=int64 */, meta[relay.Constant][230] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][138]) /* ty=Tensor[(2048, 512, 1, 1), float32] */;
  %890 = fn (%p0138: Tensor[(2048, 512, 1, 1), float32], %p1137: Tensor[(1, 2048, 1, 1), float32], Primitive=1) -> Tensor[(2048, 512, 1, 1), float32] {
    %888 = squeeze(%p1137, axis=[0, 2, 3]) /* ty=Tensor[(2048), float32] */;
    %889 = expand_dims(%888, axis=1, num_newaxis=3) /* ty=Tensor[(2048, 1, 1, 1), float32] */;
    multiply(%p0138, %889) /* ty=Tensor[(2048, 512, 1, 1), float32] */
  };
  %891 = (%model.backbone.body.layer4.0.conv3.weight, %x228);
  %892 = (%tensor_0138,);
  let %v138: () = vm.invoke_tvm_op(%890, %891, %892) /* ty=() */;
  let %x229: Tensor[(2048, 512, 1, 1), float32] = %tensor_0138;
  let %x230: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.bn3.bias, meta[relay.Constant][231] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][90]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %x231: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.bn3.running_mean, meta[relay.Constant][232] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][91]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %storage_0139: Storage[] = memory.alloc_storage(8192 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][139]) /* ty=Storage[] */;
  let %tensor_0139: Tensor[(1, 2048, 1, 1), float32] = memory.alloc_tensor(%storage_0139, 0 /* ty=int64 */, meta[relay.Constant][233] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][139]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  %897 = fn (%p0139: Tensor[(2048), float32], %p1138: Tensor[(2048), float32], Primitive=1) -> Tensor[(1, 2048, 1, 1), float32] {
    %893 = reshape(%p0139, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %894 = reshape(%p1138, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %895 = add(%894, 0f /* ty=float32 */) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %896 = rsqrt(%895) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    multiply(%893, %896) /* ty=Tensor[(1, 2048, 1, 1), float32] */
  };
  %898 = (%model.backbone.body.layer4.0.downsample.1.weight, %model.backbone.body.layer4.0.downsample.1.running_var);
  %899 = (%tensor_0139,);
  let %v139: () = vm.invoke_tvm_op(%897, %898, %899) /* ty=() */;
  let %x232: Tensor[(1, 2048, 1, 1), float32] = %tensor_0139;
  let %storage_0140: Storage[] = memory.alloc_storage(8388608 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][140]) /* ty=Storage[] */;
  let %tensor_0140: Tensor[(2048, 1024, 1, 1), float32] = memory.alloc_tensor(%storage_0140, 0 /* ty=int64 */, meta[relay.Constant][234] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][140]) /* ty=Tensor[(2048, 1024, 1, 1), float32] */;
  %902 = fn (%p0140: Tensor[(2048, 1024, 1, 1), float32], %p1139: Tensor[(1, 2048, 1, 1), float32], Primitive=1) -> Tensor[(2048, 1024, 1, 1), float32] {
    %900 = squeeze(%p1139, axis=[0, 2, 3]) /* ty=Tensor[(2048), float32] */;
    %901 = expand_dims(%900, axis=1, num_newaxis=3) /* ty=Tensor[(2048, 1, 1, 1), float32] */;
    multiply(%p0140, %901) /* ty=Tensor[(2048, 1024, 1, 1), float32] */
  };
  %903 = (%model.backbone.body.layer4.0.downsample.0.weight, %x232);
  %904 = (%tensor_0140,);
  let %v140: () = vm.invoke_tvm_op(%902, %903, %904) /* ty=() */;
  let %x233: Tensor[(2048, 1024, 1, 1), float32] = %tensor_0140;
  let %x234: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.downsample.1.bias, meta[relay.Constant][235] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][92]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %x235: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.0.downsample.1.running_mean, meta[relay.Constant][236] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][93]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %storage_0141: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][141]) /* ty=Storage[] */;
  let %tensor_0141: Tensor[(1, 2048, 25, 25), float32] = memory.alloc_tensor(%storage_0141, 0 /* ty=int64 */, meta[relay.Constant][237] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][141]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
  %908 = fn (%p0141: Tensor[(1, 1024, 50, 50), float32], %p1140: Tensor[(2048, 1024, 1, 1), float32], %p246: Tensor[(1, 2048, 1, 1), float32], %p345: Tensor[(1, 2048, 1, 1), float32], %p445: Tensor[(1, 2048, 1, 1), float32], Primitive=1) -> Tensor[(1, 2048, 25, 25), float32] {
    %905 = nn.conv2d(%p0141, %p1140, strides=[2, 2], padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    %906 = multiply(%p345, %p445) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %907 = subtract(%p246, %906) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    add(%905, %907) /* ty=Tensor[(1, 2048, 25, 25), float32] */
  };
  %909 = (%x217, %x233, %x234, %x235, %x232);
  %910 = (%tensor_0141,);
  let %v141: () = vm.invoke_tvm_op(%908, %909, %910) /* ty=() */;
  let %x236: Tensor[(1, 2048, 25, 25), float32] = %tensor_0141;
  let %storage_0142: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][142]) /* ty=Storage[] */;
  let %tensor_0142: Tensor[(1, 2048, 25, 25), float32] = memory.alloc_tensor(%storage_0142, 0 /* ty=int64 */, meta[relay.Constant][238] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][142]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
  %916 = fn (%p0142: Tensor[(1, 512, 25, 25), float32], %p1141: Tensor[(2048, 512, 1, 1), float32], %p247: Tensor[(1, 2048, 1, 1), float32], %p346: Tensor[(1, 2048, 1, 1), float32], %p446: Tensor[(1, 2048, 1, 1), float32], %p513: Tensor[(1, 2048, 25, 25), float32], Primitive=1) -> Tensor[(1, 2048, 25, 25), float32] {
    %911 = nn.conv2d(%p0142, %p1141, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    %912 = multiply(%p346, %p446) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %913 = subtract(%p247, %912) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %914 = add(%911, %913) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    %915 = add(%914, %p513) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    nn.relu(%915) /* ty=Tensor[(1, 2048, 25, 25), float32] */
  };
  %917 = (%x227, %x229, %x230, %x231, %x228, %x236);
  %918 = (%tensor_0142,);
  let %v142: () = vm.invoke_tvm_op(%916, %917, %918) /* ty=() */;
  let %x237: Tensor[(1, 2048, 25, 25), float32] = %tensor_0142;
  let %storage_0143: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][143]) /* ty=Storage[] */;
  let %tensor_0143: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0143, 0 /* ty=int64 */, meta[relay.Constant][239] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][143]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %923 = fn (%p0143: Tensor[(512), float32], %p1142: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %919 = reshape(%p0143, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %920 = reshape(%p1142, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %921 = add(%920, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %922 = rsqrt(%921) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%919, %922) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %924 = (%model.backbone.body.layer4.1.bn1.weight, %model.backbone.body.layer4.1.bn1.running_var);
  %925 = (%tensor_0143,);
  let %v143: () = vm.invoke_tvm_op(%923, %924, %925) /* ty=() */;
  let %x238: Tensor[(1, 512, 1, 1), float32] = %tensor_0143;
  let %storage_0144: Storage[] = memory.alloc_storage(4194304 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][144]) /* ty=Storage[] */;
  let %tensor_0144: Tensor[(512, 2048, 1, 1), float32] = memory.alloc_tensor(%storage_0144, 0 /* ty=int64 */, meta[relay.Constant][240] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][144]) /* ty=Tensor[(512, 2048, 1, 1), float32] */;
  %928 = fn (%p0144: Tensor[(512, 2048, 1, 1), float32], %p1143: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 2048, 1, 1), float32] {
    %926 = squeeze(%p1143, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %927 = expand_dims(%926, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p0144, %927) /* ty=Tensor[(512, 2048, 1, 1), float32] */
  };
  %929 = (%model.backbone.body.layer4.1.conv1.weight, %x238);
  %930 = (%tensor_0144,);
  let %v144: () = vm.invoke_tvm_op(%928, %929, %930) /* ty=() */;
  let %x239: Tensor[(512, 2048, 1, 1), float32] = %tensor_0144;
  let %x240: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.1.bn1.bias, meta[relay.Constant][241] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][94]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x241: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.1.bn1.running_mean, meta[relay.Constant][242] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][95]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_0145: Storage[] = memory.alloc_storage(1280000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][145]) /* ty=Storage[] */;
  let %tensor_0145: Tensor[(1, 512, 25, 25), float32] = memory.alloc_tensor(%storage_0145, 0 /* ty=int64 */, meta[relay.Constant][243] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][145]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
  %935 = fn (%p0145: Tensor[(1, 2048, 25, 25), float32], %p1144: Tensor[(512, 2048, 1, 1), float32], %p248: Tensor[(1, 512, 1, 1), float32], %p347: Tensor[(1, 512, 1, 1), float32], %p447: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(1, 512, 25, 25), float32] {
    %931 = nn.conv2d(%p0145, %p1144, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    %932 = multiply(%p347, %p447) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %933 = subtract(%p248, %932) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %934 = add(%931, %933) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    nn.relu(%934) /* ty=Tensor[(1, 512, 25, 25), float32] */
  };
  %936 = (%x237, %x239, %x240, %x241, %x238);
  %937 = (%tensor_0145,);
  let %v145: () = vm.invoke_tvm_op(%935, %936, %937) /* ty=() */;
  let %x242: Tensor[(1, 512, 25, 25), float32] = %tensor_0145;
  let %storage_0146: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][146]) /* ty=Storage[] */;
  let %tensor_0146: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0146, 0 /* ty=int64 */, meta[relay.Constant][244] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][146]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %942 = fn (%p0146: Tensor[(512), float32], %p1145: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %938 = reshape(%p0146, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %939 = reshape(%p1145, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %940 = add(%939, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %941 = rsqrt(%940) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%938, %941) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %943 = (%model.backbone.body.layer4.1.bn2.weight, %model.backbone.body.layer4.1.bn2.running_var);
  %944 = (%tensor_0146,);
  let %v146: () = vm.invoke_tvm_op(%942, %943, %944) /* ty=() */;
  let %x243: Tensor[(1, 512, 1, 1), float32] = %tensor_0146;
  let %storage_0147: Storage[] = memory.alloc_storage(9437184 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][147]) /* ty=Storage[] */;
  let %tensor_0147: Tensor[(512, 512, 3, 3), float32] = memory.alloc_tensor(%storage_0147, 0 /* ty=int64 */, meta[relay.Constant][245] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][147]) /* ty=Tensor[(512, 512, 3, 3), float32] */;
  %947 = fn (%p0147: Tensor[(512, 512, 3, 3), float32], %p1146: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 512, 3, 3), float32] {
    %945 = squeeze(%p1146, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %946 = expand_dims(%945, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p0147, %946) /* ty=Tensor[(512, 512, 3, 3), float32] */
  };
  %948 = (%model.backbone.body.layer4.1.conv2.weight, %x243);
  %949 = (%tensor_0147,);
  let %v147: () = vm.invoke_tvm_op(%947, %948, %949) /* ty=() */;
  let %x244: Tensor[(512, 512, 3, 3), float32] = %tensor_0147;
  let %x245: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.1.bn2.bias, meta[relay.Constant][246] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][96]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x246: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.1.bn2.running_mean, meta[relay.Constant][247] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][97]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_0148: Storage[] = memory.alloc_storage(1280000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][148]) /* ty=Storage[] */;
  let %tensor_0148: Tensor[(1, 512, 25, 25), float32] = memory.alloc_tensor(%storage_0148, 0 /* ty=int64 */, meta[relay.Constant][248] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][148]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
  %954 = fn (%p0148: Tensor[(1, 512, 25, 25), float32], %p1147: Tensor[(512, 512, 3, 3), float32], %p249: Tensor[(1, 512, 1, 1), float32], %p348: Tensor[(1, 512, 1, 1), float32], %p448: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(1, 512, 25, 25), float32] {
    %950 = nn.conv2d(%p0148, %p1147, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    %951 = multiply(%p348, %p448) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %952 = subtract(%p249, %951) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %953 = add(%950, %952) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    nn.relu(%953) /* ty=Tensor[(1, 512, 25, 25), float32] */
  };
  %955 = (%x242, %x244, %x245, %x246, %x243);
  %956 = (%tensor_0148,);
  let %v148: () = vm.invoke_tvm_op(%954, %955, %956) /* ty=() */;
  let %x247: Tensor[(1, 512, 25, 25), float32] = %tensor_0148;
  let %storage_0149: Storage[] = memory.alloc_storage(8192 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][149]) /* ty=Storage[] */;
  let %tensor_0149: Tensor[(1, 2048, 1, 1), float32] = memory.alloc_tensor(%storage_0149, 0 /* ty=int64 */, meta[relay.Constant][249] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][149]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  %961 = fn (%p0149: Tensor[(2048), float32], %p1148: Tensor[(2048), float32], Primitive=1) -> Tensor[(1, 2048, 1, 1), float32] {
    %957 = reshape(%p0149, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %958 = reshape(%p1148, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %959 = add(%958, 0f /* ty=float32 */) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %960 = rsqrt(%959) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    multiply(%957, %960) /* ty=Tensor[(1, 2048, 1, 1), float32] */
  };
  %962 = (%model.backbone.body.layer4.1.bn3.weight, %model.backbone.body.layer4.1.bn3.running_var);
  %963 = (%tensor_0149,);
  let %v149: () = vm.invoke_tvm_op(%961, %962, %963) /* ty=() */;
  let %x248: Tensor[(1, 2048, 1, 1), float32] = %tensor_0149;
  let %storage_0150: Storage[] = memory.alloc_storage(4194304 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][150]) /* ty=Storage[] */;
  let %tensor_0150: Tensor[(2048, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0150, 0 /* ty=int64 */, meta[relay.Constant][250] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][150]) /* ty=Tensor[(2048, 512, 1, 1), float32] */;
  %966 = fn (%p0150: Tensor[(2048, 512, 1, 1), float32], %p1149: Tensor[(1, 2048, 1, 1), float32], Primitive=1) -> Tensor[(2048, 512, 1, 1), float32] {
    %964 = squeeze(%p1149, axis=[0, 2, 3]) /* ty=Tensor[(2048), float32] */;
    %965 = expand_dims(%964, axis=1, num_newaxis=3) /* ty=Tensor[(2048, 1, 1, 1), float32] */;
    multiply(%p0150, %965) /* ty=Tensor[(2048, 512, 1, 1), float32] */
  };
  %967 = (%model.backbone.body.layer4.1.conv3.weight, %x248);
  %968 = (%tensor_0150,);
  let %v150: () = vm.invoke_tvm_op(%966, %967, %968) /* ty=() */;
  let %x249: Tensor[(2048, 512, 1, 1), float32] = %tensor_0150;
  let %x250: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.1.bn3.bias, meta[relay.Constant][251] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][98]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %x251: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.1.bn3.running_mean, meta[relay.Constant][252] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][99]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %storage_0151: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][151]) /* ty=Storage[] */;
  let %tensor_0151: Tensor[(1, 2048, 25, 25), float32] = memory.alloc_tensor(%storage_0151, 0 /* ty=int64 */, meta[relay.Constant][253] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][151]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
  %974 = fn (%p0151: Tensor[(1, 512, 25, 25), float32], %p1150: Tensor[(2048, 512, 1, 1), float32], %p250: Tensor[(1, 2048, 1, 1), float32], %p349: Tensor[(1, 2048, 1, 1), float32], %p449: Tensor[(1, 2048, 1, 1), float32], %p514: Tensor[(1, 2048, 25, 25), float32], Primitive=1) -> Tensor[(1, 2048, 25, 25), float32] {
    %969 = nn.conv2d(%p0151, %p1150, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    %970 = multiply(%p349, %p449) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %971 = subtract(%p250, %970) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %972 = add(%969, %971) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    %973 = add(%972, %p514) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    nn.relu(%973) /* ty=Tensor[(1, 2048, 25, 25), float32] */
  };
  %975 = (%x247, %x249, %x250, %x251, %x248, %x237);
  %976 = (%tensor_0151,);
  let %v151: () = vm.invoke_tvm_op(%974, %975, %976) /* ty=() */;
  let %x252: Tensor[(1, 2048, 25, 25), float32] = %tensor_0151;
  let %storage_0152: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][152]) /* ty=Storage[] */;
  let %tensor_0152: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0152, 0 /* ty=int64 */, meta[relay.Constant][254] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][152]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %981 = fn (%p0152: Tensor[(512), float32], %p1151: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %977 = reshape(%p0152, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %978 = reshape(%p1151, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %979 = add(%978, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %980 = rsqrt(%979) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%977, %980) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %982 = (%model.backbone.body.layer4.2.bn1.weight, %model.backbone.body.layer4.2.bn1.running_var);
  %983 = (%tensor_0152,);
  let %v152: () = vm.invoke_tvm_op(%981, %982, %983) /* ty=() */;
  let %x253: Tensor[(1, 512, 1, 1), float32] = %tensor_0152;
  let %storage_0153: Storage[] = memory.alloc_storage(4194304 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][153]) /* ty=Storage[] */;
  let %tensor_0153: Tensor[(512, 2048, 1, 1), float32] = memory.alloc_tensor(%storage_0153, 0 /* ty=int64 */, meta[relay.Constant][255] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][153]) /* ty=Tensor[(512, 2048, 1, 1), float32] */;
  %986 = fn (%p0153: Tensor[(512, 2048, 1, 1), float32], %p1152: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 2048, 1, 1), float32] {
    %984 = squeeze(%p1152, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %985 = expand_dims(%984, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p0153, %985) /* ty=Tensor[(512, 2048, 1, 1), float32] */
  };
  %987 = (%model.backbone.body.layer4.2.conv1.weight, %x253);
  %988 = (%tensor_0153,);
  let %v153: () = vm.invoke_tvm_op(%986, %987, %988) /* ty=() */;
  let %x254: Tensor[(512, 2048, 1, 1), float32] = %tensor_0153;
  let %x255: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.2.bn1.bias, meta[relay.Constant][256] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][100]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x256: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.2.bn1.running_mean, meta[relay.Constant][257] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][101]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_0154: Storage[] = memory.alloc_storage(1280000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][154]) /* ty=Storage[] */;
  let %tensor_0154: Tensor[(1, 512, 25, 25), float32] = memory.alloc_tensor(%storage_0154, 0 /* ty=int64 */, meta[relay.Constant][258] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][154]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
  %993 = fn (%p0154: Tensor[(1, 2048, 25, 25), float32], %p1153: Tensor[(512, 2048, 1, 1), float32], %p251: Tensor[(1, 512, 1, 1), float32], %p350: Tensor[(1, 512, 1, 1), float32], %p450: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(1, 512, 25, 25), float32] {
    %989 = nn.conv2d(%p0154, %p1153, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    %990 = multiply(%p350, %p450) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %991 = subtract(%p251, %990) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %992 = add(%989, %991) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    nn.relu(%992) /* ty=Tensor[(1, 512, 25, 25), float32] */
  };
  %994 = (%x252, %x254, %x255, %x256, %x253);
  %995 = (%tensor_0154,);
  let %v154: () = vm.invoke_tvm_op(%993, %994, %995) /* ty=() */;
  let %x257: Tensor[(1, 512, 25, 25), float32] = %tensor_0154;
  let %storage_0155: Storage[] = memory.alloc_storage(2048 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][155]) /* ty=Storage[] */;
  let %tensor_0155: Tensor[(1, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0155, 0 /* ty=int64 */, meta[relay.Constant][259] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][155]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  %1000 = fn (%p0155: Tensor[(512), float32], %p1154: Tensor[(512), float32], Primitive=1) -> Tensor[(1, 512, 1, 1), float32] {
    %996 = reshape(%p0155, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %997 = reshape(%p1154, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %998 = add(%997, 0f /* ty=float32 */) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %999 = rsqrt(%998) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    multiply(%996, %999) /* ty=Tensor[(1, 512, 1, 1), float32] */
  };
  %1001 = (%model.backbone.body.layer4.2.bn2.weight, %model.backbone.body.layer4.2.bn2.running_var);
  %1002 = (%tensor_0155,);
  let %v155: () = vm.invoke_tvm_op(%1000, %1001, %1002) /* ty=() */;
  let %x258: Tensor[(1, 512, 1, 1), float32] = %tensor_0155;
  let %storage_0156: Storage[] = memory.alloc_storage(9437184 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][156]) /* ty=Storage[] */;
  let %tensor_0156: Tensor[(512, 512, 3, 3), float32] = memory.alloc_tensor(%storage_0156, 0 /* ty=int64 */, meta[relay.Constant][260] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][156]) /* ty=Tensor[(512, 512, 3, 3), float32] */;
  %1005 = fn (%p0156: Tensor[(512, 512, 3, 3), float32], %p1155: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(512, 512, 3, 3), float32] {
    %1003 = squeeze(%p1155, axis=[0, 2, 3]) /* ty=Tensor[(512), float32] */;
    %1004 = expand_dims(%1003, axis=1, num_newaxis=3) /* ty=Tensor[(512, 1, 1, 1), float32] */;
    multiply(%p0156, %1004) /* ty=Tensor[(512, 512, 3, 3), float32] */
  };
  %1006 = (%model.backbone.body.layer4.2.conv2.weight, %x258);
  %1007 = (%tensor_0156,);
  let %v156: () = vm.invoke_tvm_op(%1005, %1006, %1007) /* ty=() */;
  let %x259: Tensor[(512, 512, 3, 3), float32] = %tensor_0156;
  let %x260: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.2.bn2.bias, meta[relay.Constant][261] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][102]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %x261: Tensor[(1, 512, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.2.bn2.running_mean, meta[relay.Constant][262] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][103]) /* ty=Tensor[(1, 512, 1, 1), float32] */;
  let %storage_0157: Storage[] = memory.alloc_storage(1280000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][157]) /* ty=Storage[] */;
  let %tensor_0157: Tensor[(1, 512, 25, 25), float32] = memory.alloc_tensor(%storage_0157, 0 /* ty=int64 */, meta[relay.Constant][263] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][157]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
  %1012 = fn (%p0157: Tensor[(1, 512, 25, 25), float32], %p1156: Tensor[(512, 512, 3, 3), float32], %p252: Tensor[(1, 512, 1, 1), float32], %p351: Tensor[(1, 512, 1, 1), float32], %p451: Tensor[(1, 512, 1, 1), float32], Primitive=1) -> Tensor[(1, 512, 25, 25), float32] {
    %1008 = nn.conv2d(%p0157, %p1156, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    %1009 = multiply(%p351, %p451) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %1010 = subtract(%p252, %1009) /* ty=Tensor[(1, 512, 1, 1), float32] */;
    %1011 = add(%1008, %1010) /* ty=Tensor[(1, 512, 25, 25), float32] */;
    nn.relu(%1011) /* ty=Tensor[(1, 512, 25, 25), float32] */
  };
  %1013 = (%x257, %x259, %x260, %x261, %x258);
  %1014 = (%tensor_0157,);
  let %v157: () = vm.invoke_tvm_op(%1012, %1013, %1014) /* ty=() */;
  let %x262: Tensor[(1, 512, 25, 25), float32] = %tensor_0157;
  let %storage_0158: Storage[] = memory.alloc_storage(8192 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][158]) /* ty=Storage[] */;
  let %tensor_0158: Tensor[(1, 2048, 1, 1), float32] = memory.alloc_tensor(%storage_0158, 0 /* ty=int64 */, meta[relay.Constant][264] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][158]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  %1019 = fn (%p0158: Tensor[(2048), float32], %p1157: Tensor[(2048), float32], Primitive=1) -> Tensor[(1, 2048, 1, 1), float32] {
    %1015 = reshape(%p0158, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %1016 = reshape(%p1157, newshape=[1, -1, 1, 1]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %1017 = add(%1016, 0f /* ty=float32 */) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %1018 = rsqrt(%1017) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    multiply(%1015, %1018) /* ty=Tensor[(1, 2048, 1, 1), float32] */
  };
  %1020 = (%model.backbone.body.layer4.2.bn3.weight, %model.backbone.body.layer4.2.bn3.running_var);
  %1021 = (%tensor_0158,);
  let %v158: () = vm.invoke_tvm_op(%1019, %1020, %1021) /* ty=() */;
  let %x263: Tensor[(1, 2048, 1, 1), float32] = %tensor_0158;
  let %storage_0159: Storage[] = memory.alloc_storage(4194304 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][159]) /* ty=Storage[] */;
  let %tensor_0159: Tensor[(2048, 512, 1, 1), float32] = memory.alloc_tensor(%storage_0159, 0 /* ty=int64 */, meta[relay.Constant][265] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][159]) /* ty=Tensor[(2048, 512, 1, 1), float32] */;
  %1024 = fn (%p0159: Tensor[(2048, 512, 1, 1), float32], %p1158: Tensor[(1, 2048, 1, 1), float32], Primitive=1) -> Tensor[(2048, 512, 1, 1), float32] {
    %1022 = squeeze(%p1158, axis=[0, 2, 3]) /* ty=Tensor[(2048), float32] */;
    %1023 = expand_dims(%1022, axis=1, num_newaxis=3) /* ty=Tensor[(2048, 1, 1, 1), float32] */;
    multiply(%p0159, %1023) /* ty=Tensor[(2048, 512, 1, 1), float32] */
  };
  %1025 = (%model.backbone.body.layer4.2.conv3.weight, %x263);
  %1026 = (%tensor_0159,);
  let %v159: () = vm.invoke_tvm_op(%1024, %1025, %1026) /* ty=() */;
  let %x264: Tensor[(2048, 512, 1, 1), float32] = %tensor_0159;
  let %x265: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.2.bn3.bias, meta[relay.Constant][266] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][104]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %x266: Tensor[(1, 2048, 1, 1), float32] = vm.reshape_tensor(%model.backbone.body.layer4.2.bn3.running_mean, meta[relay.Constant][267] /* ty=Tensor[(4), int64] */, meta[relay.attrs.ReshapeTensorAttrs][105]) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
  let %storage_0160: Storage[] = memory.alloc_storage(5120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][160]) /* ty=Storage[] */;
  let %tensor_0160: Tensor[(1, 2048, 25, 25), float32] = memory.alloc_tensor(%storage_0160, 0 /* ty=int64 */, meta[relay.Constant][268] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][160]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
  %1032 = fn (%p0160: Tensor[(1, 512, 25, 25), float32], %p1159: Tensor[(2048, 512, 1, 1), float32], %p253: Tensor[(1, 2048, 1, 1), float32], %p352: Tensor[(1, 2048, 1, 1), float32], %p452: Tensor[(1, 2048, 1, 1), float32], %p515: Tensor[(1, 2048, 25, 25), float32], Primitive=1) -> Tensor[(1, 2048, 25, 25), float32] {
    %1027 = nn.conv2d(%p0160, %p1159, padding=[0, 0, 0, 0], channels=2048, kernel_size=[1, 1]) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    %1028 = multiply(%p352, %p452) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %1029 = subtract(%p253, %1028) /* ty=Tensor[(1, 2048, 1, 1), float32] */;
    %1030 = add(%1027, %1029) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    %1031 = add(%1030, %p515) /* ty=Tensor[(1, 2048, 25, 25), float32] */;
    nn.relu(%1031) /* ty=Tensor[(1, 2048, 25, 25), float32] */
  };
  %1033 = (%x262, %x264, %x265, %x266, %x263, %x252);
  %1034 = (%tensor_0160,);
  let %v160: () = vm.invoke_tvm_op(%1032, %1033, %1034) /* ty=() */;
  let %x267: Tensor[(1, 2048, 25, 25), float32] = %tensor_0160;
  let %storage_0161: Storage[] = memory.alloc_storage(640000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][161]) /* ty=Storage[] */;
  let %tensor_0161: Tensor[(1, 256, 25, 25), float32] = memory.alloc_tensor(%storage_0161, 0 /* ty=int64 */, meta[relay.Constant][269] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][161]) /* ty=Tensor[(1, 256, 25, 25), float32] */;
  %1038 = fn (%p0161: Tensor[(1, 2048, 25, 25), float32], %p1160: Tensor[(256, 2048, 1, 1), float32], %p254: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 25, 25), float32] {
    %1035 = nn.conv2d(%p0161, %p1160, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 25, 25), float32] */;
    %1036 = expand_dims(%p254, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1037 = expand_dims(%1036, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    add(%1035, %1037) /* ty=Tensor[(1, 256, 25, 25), float32] */
  };
  %1039 = (%x267, %model.backbone.fpn.inner_blocks.3.weight, %model.backbone.fpn.inner_blocks.3.bias);
  %1040 = (%tensor_0161,);
  let %v161: () = vm.invoke_tvm_op(%1038, %1039, %1040) /* ty=() */;
  let %x268: Tensor[(1, 256, 25, 25), float32] = %tensor_0161;
  let %storage_0162: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][162]) /* ty=Storage[] */;
  let %tensor_0162: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0162, 0 /* ty=int64 */, meta[relay.Constant][270] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][162]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %1041 = fn (%p0162: Tensor[(1, 256, 25, 25), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    image.resize(%p0162, size=[50, 50], method="nearest_neighbor", coordinate_transformation_mode="asymmetric") /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %1042 = (%x268,);
  %1043 = (%tensor_0162,);
  let %v162: () = vm.invoke_tvm_op(%1041, %1042, %1043) /* ty=() */;
  let %x269: Tensor[(1, 256, 50, 50), float32] = %tensor_0162;
  let %storage_0163: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][163]) /* ty=Storage[] */;
  let %tensor_0163: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0163, 0 /* ty=int64 */, meta[relay.Constant][271] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][163]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %1048 = fn (%p0163: Tensor[(1, 1024, 50, 50), float32], %p1161: Tensor[(256, 1024, 1, 1), float32], %p255: Tensor[(256), float32], %p353: Tensor[(1, 256, 50, 50), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %1044 = nn.conv2d(%p0163, %p1161, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %1045 = expand_dims(%p255, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1046 = expand_dims(%1045, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1047 = add(%1044, %1046) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    add(%1047, %p353) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %1049 = (%x217, %model.backbone.fpn.inner_blocks.2.weight, %model.backbone.fpn.inner_blocks.2.bias, %x269);
  %1050 = (%tensor_0163,);
  let %v163: () = vm.invoke_tvm_op(%1048, %1049, %1050) /* ty=() */;
  let %x270: Tensor[(1, 256, 50, 50), float32] = %tensor_0163;
  let %storage_0164: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][164]) /* ty=Storage[] */;
  let %tensor_0164: Tensor[(1, 256, 100, 100), float32] = memory.alloc_tensor(%storage_0164, 0 /* ty=int64 */, meta[relay.Constant][272] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][164]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
  %1051 = fn (%p0164: Tensor[(1, 256, 50, 50), float32], Primitive=1) -> Tensor[(1, 256, 100, 100), float32] {
    image.resize(%p0164, size=[100, 100], method="nearest_neighbor", coordinate_transformation_mode="asymmetric") /* ty=Tensor[(1, 256, 100, 100), float32] */
  };
  %1052 = (%x270,);
  %1053 = (%tensor_0164,);
  let %v164: () = vm.invoke_tvm_op(%1051, %1052, %1053) /* ty=() */;
  let %x271: Tensor[(1, 256, 100, 100), float32] = %tensor_0164;
  let %storage_0165: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][165]) /* ty=Storage[] */;
  let %tensor_0165: Tensor[(1, 256, 100, 100), float32] = memory.alloc_tensor(%storage_0165, 0 /* ty=int64 */, meta[relay.Constant][273] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][165]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
  %1058 = fn (%p0165: Tensor[(1, 512, 100, 100), float32], %p1162: Tensor[(256, 512, 1, 1), float32], %p256: Tensor[(256), float32], %p354: Tensor[(1, 256, 100, 100), float32], Primitive=1) -> Tensor[(1, 256, 100, 100), float32] {
    %1054 = nn.conv2d(%p0165, %p1162, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
    %1055 = expand_dims(%p256, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1056 = expand_dims(%1055, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1057 = add(%1054, %1056) /* ty=Tensor[(1, 256, 100, 100), float32] */;
    add(%1057, %p354) /* ty=Tensor[(1, 256, 100, 100), float32] */
  };
  %1059 = (%x122, %model.backbone.fpn.inner_blocks.1.weight, %model.backbone.fpn.inner_blocks.1.bias, %x271);
  %1060 = (%tensor_0165,);
  let %v165: () = vm.invoke_tvm_op(%1058, %1059, %1060) /* ty=() */;
  let %x272: Tensor[(1, 256, 100, 100), float32] = %tensor_0165;
  let %storage_0166: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][166]) /* ty=Storage[] */;
  let %tensor_0166: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_0166, 0 /* ty=int64 */, meta[relay.Constant][274] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][166]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %1061 = fn (%p0166: Tensor[(1, 256, 100, 100), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    image.resize(%p0166, size=[200, 200], method="nearest_neighbor", coordinate_transformation_mode="asymmetric") /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %1062 = (%x272,);
  %1063 = (%tensor_0166,);
  let %v166: () = vm.invoke_tvm_op(%1061, %1062, %1063) /* ty=() */;
  let %x273: Tensor[(1, 256, 200, 200), float32] = %tensor_0166;
  let %storage_0167: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][167]) /* ty=Storage[] */;
  let %tensor_0167: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_0167, 0 /* ty=int64 */, meta[relay.Constant][275] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][167]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %1068 = fn (%p0167: Tensor[(1, 256, 200, 200), float32], %p1163: Tensor[(256, 256, 1, 1), float32], %p257: Tensor[(256), float32], %p355: Tensor[(1, 256, 200, 200), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    %1064 = nn.conv2d(%p0167, %p1163, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %1065 = expand_dims(%p257, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1066 = expand_dims(%1065, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1067 = add(%1064, %1066) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    add(%1067, %p355) /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %1069 = (%x57, %model.backbone.fpn.inner_blocks.0.weight, %model.backbone.fpn.inner_blocks.0.bias, %x273);
  %1070 = (%tensor_0167,);
  let %v167: () = vm.invoke_tvm_op(%1068, %1069, %1070) /* ty=() */;
  let %x274: Tensor[(1, 256, 200, 200), float32] = %tensor_0167;
  let %storage_0168: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][168]) /* ty=Storage[] */;
  let %tensor_0168: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_0168, 0 /* ty=int64 */, meta[relay.Constant][276] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][168]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %1074 = fn (%p0168: Tensor[(1, 256, 200, 200), float32], %p1164: Tensor[(256, 256, 3, 3), float32], %p258: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    %1071 = nn.conv2d(%p0168, %p1164, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %1072 = expand_dims(%p258, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1073 = expand_dims(%1072, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    add(%1071, %1073) /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %1075 = (%x274, %model.backbone.fpn.layer_blocks.0.weight, %model.backbone.fpn.layer_blocks.0.bias);
  %1076 = (%tensor_0168,);
  let %v168: () = vm.invoke_tvm_op(%1074, %1075, %1076) /* ty=() */;
  let %x275: Tensor[(1, 256, 200, 200), float32] = %tensor_0168;
  let %storage_0169: Storage[] = memory.alloc_storage(40960000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][169]) /* ty=Storage[] */;
  let %tensor_0169: Tensor[(1, 256, 200, 200), float32] = memory.alloc_tensor(%storage_0169, 0 /* ty=int64 */, meta[relay.Constant][277] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][169]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
  %1081 = fn (%p0169: Tensor[(1, 256, 200, 200), float32], %p1165: Tensor[(256, 256, 3, 3), float32], %p259: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 200, 200), float32] {
    %1077 = nn.conv2d(%p0169, %p1165, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    %1078 = expand_dims(%p259, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1079 = expand_dims(%1078, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1080 = add(%1077, %1079) /* ty=Tensor[(1, 256, 200, 200), float32] */;
    nn.relu(%1080) /* ty=Tensor[(1, 256, 200, 200), float32] */
  };
  %1082 = (%x275, %model.rpn.head.conv.weight, %model.rpn.head.conv.bias);
  %1083 = (%tensor_0169,);
  let %v169: () = vm.invoke_tvm_op(%1081, %1082, %1083) /* ty=() */;
  let %x276: Tensor[(1, 256, 200, 200), float32] = %tensor_0169;
  let %storage_0170: Storage[] = memory.alloc_storage(1920000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][170]) /* ty=Storage[] */;
  let %tensor_0170: Tensor[(1, 12, 200, 200), float32] = memory.alloc_tensor(%storage_0170, 0 /* ty=int64 */, meta[relay.Constant][278] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][170]) /* ty=Tensor[(1, 12, 200, 200), float32] */;
  %1087 = fn (%p0170: Tensor[(1, 256, 200, 200), float32], %p1166: Tensor[(12, 256, 1, 1), float32], %p260: Tensor[(12), float32], Primitive=1) -> Tensor[(1, 12, 200, 200), float32] {
    %1084 = nn.conv2d(%p0170, %p1166, padding=[0, 0, 0, 0], channels=12, kernel_size=[1, 1]) /* ty=Tensor[(1, 12, 200, 200), float32] */;
    %1085 = expand_dims(%p260, axis=1, num_newaxis=2) /* ty=Tensor[(12, 1, 1), float32] */;
    %1086 = expand_dims(%1085, axis=0) /* ty=Tensor[(1, 12, 1, 1), float32] */;
    add(%1084, %1086) /* ty=Tensor[(1, 12, 200, 200), float32] */
  };
  %1088 = (%x276, %model.rpn.head.bbox_pred.weight, %model.rpn.head.bbox_pred.bias);
  %1089 = (%tensor_0170,);
  let %v170: () = vm.invoke_tvm_op(%1087, %1088, %1089) /* ty=() */;
  let %x277: Tensor[(1, 12, 200, 200), float32] = %tensor_0170;
  let %storage_0171: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][171]) /* ty=Storage[] */;
  let %tensor_0171: Tensor[(1, 256, 100, 100), float32] = memory.alloc_tensor(%storage_0171, 0 /* ty=int64 */, meta[relay.Constant][279] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][171]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
  %1093 = fn (%p0171: Tensor[(1, 256, 100, 100), float32], %p1167: Tensor[(256, 256, 3, 3), float32], %p261: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 100, 100), float32] {
    %1090 = nn.conv2d(%p0171, %p1167, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
    %1091 = expand_dims(%p261, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1092 = expand_dims(%1091, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    add(%1090, %1092) /* ty=Tensor[(1, 256, 100, 100), float32] */
  };
  %1094 = (%x272, %model.backbone.fpn.layer_blocks.1.weight, %model.backbone.fpn.layer_blocks.1.bias);
  %1095 = (%tensor_0171,);
  let %v171: () = vm.invoke_tvm_op(%1093, %1094, %1095) /* ty=() */;
  let %x278: Tensor[(1, 256, 100, 100), float32] = %tensor_0171;
  let %storage_0172: Storage[] = memory.alloc_storage(10240000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][172]) /* ty=Storage[] */;
  let %tensor_0172: Tensor[(1, 256, 100, 100), float32] = memory.alloc_tensor(%storage_0172, 0 /* ty=int64 */, meta[relay.Constant][280] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][172]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
  %1100 = fn (%p0172: Tensor[(1, 256, 100, 100), float32], %p1168: Tensor[(256, 256, 3, 3), float32], %p262: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 100, 100), float32] {
    %1096 = nn.conv2d(%p0172, %p1168, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 100, 100), float32] */;
    %1097 = expand_dims(%p262, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1098 = expand_dims(%1097, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1099 = add(%1096, %1098) /* ty=Tensor[(1, 256, 100, 100), float32] */;
    nn.relu(%1099) /* ty=Tensor[(1, 256, 100, 100), float32] */
  };
  %1101 = (%x278, %model.rpn.head.conv.weight, %model.rpn.head.conv.bias);
  %1102 = (%tensor_0172,);
  let %v172: () = vm.invoke_tvm_op(%1100, %1101, %1102) /* ty=() */;
  let %x279: Tensor[(1, 256, 100, 100), float32] = %tensor_0172;
  let %storage_0173: Storage[] = memory.alloc_storage(480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][173]) /* ty=Storage[] */;
  let %tensor_0173: Tensor[(1, 12, 100, 100), float32] = memory.alloc_tensor(%storage_0173, 0 /* ty=int64 */, meta[relay.Constant][281] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][173]) /* ty=Tensor[(1, 12, 100, 100), float32] */;
  %1106 = fn (%p0173: Tensor[(1, 256, 100, 100), float32], %p1169: Tensor[(12, 256, 1, 1), float32], %p263: Tensor[(12), float32], Primitive=1) -> Tensor[(1, 12, 100, 100), float32] {
    %1103 = nn.conv2d(%p0173, %p1169, padding=[0, 0, 0, 0], channels=12, kernel_size=[1, 1]) /* ty=Tensor[(1, 12, 100, 100), float32] */;
    %1104 = expand_dims(%p263, axis=1, num_newaxis=2) /* ty=Tensor[(12, 1, 1), float32] */;
    %1105 = expand_dims(%1104, axis=0) /* ty=Tensor[(1, 12, 1, 1), float32] */;
    add(%1103, %1105) /* ty=Tensor[(1, 12, 100, 100), float32] */
  };
  %1107 = (%x279, %model.rpn.head.bbox_pred.weight, %model.rpn.head.bbox_pred.bias);
  %1108 = (%tensor_0173,);
  let %v173: () = vm.invoke_tvm_op(%1106, %1107, %1108) /* ty=() */;
  let %x280: Tensor[(1, 12, 100, 100), float32] = %tensor_0173;
  let %storage_0174: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][174]) /* ty=Storage[] */;
  let %tensor_0174: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0174, 0 /* ty=int64 */, meta[relay.Constant][282] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][174]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %1112 = fn (%p0174: Tensor[(1, 256, 50, 50), float32], %p1170: Tensor[(256, 256, 3, 3), float32], %p264: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %1109 = nn.conv2d(%p0174, %p1170, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %1110 = expand_dims(%p264, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1111 = expand_dims(%1110, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    add(%1109, %1111) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %1113 = (%x270, %model.backbone.fpn.layer_blocks.2.weight, %model.backbone.fpn.layer_blocks.2.bias);
  %1114 = (%tensor_0174,);
  let %v174: () = vm.invoke_tvm_op(%1112, %1113, %1114) /* ty=() */;
  let %x281: Tensor[(1, 256, 50, 50), float32] = %tensor_0174;
  let %storage_0175: Storage[] = memory.alloc_storage(2560000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][175]) /* ty=Storage[] */;
  let %tensor_0175: Tensor[(1, 256, 50, 50), float32] = memory.alloc_tensor(%storage_0175, 0 /* ty=int64 */, meta[relay.Constant][283] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][175]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
  %1119 = fn (%p0175: Tensor[(1, 256, 50, 50), float32], %p1171: Tensor[(256, 256, 3, 3), float32], %p265: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 50, 50), float32] {
    %1115 = nn.conv2d(%p0175, %p1171, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    %1116 = expand_dims(%p265, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1117 = expand_dims(%1116, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1118 = add(%1115, %1117) /* ty=Tensor[(1, 256, 50, 50), float32] */;
    nn.relu(%1118) /* ty=Tensor[(1, 256, 50, 50), float32] */
  };
  %1120 = (%x281, %model.rpn.head.conv.weight, %model.rpn.head.conv.bias);
  %1121 = (%tensor_0175,);
  let %v175: () = vm.invoke_tvm_op(%1119, %1120, %1121) /* ty=() */;
  let %x282: Tensor[(1, 256, 50, 50), float32] = %tensor_0175;
  let %storage_0176: Storage[] = memory.alloc_storage(120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][176]) /* ty=Storage[] */;
  let %tensor_0176: Tensor[(1, 12, 50, 50), float32] = memory.alloc_tensor(%storage_0176, 0 /* ty=int64 */, meta[relay.Constant][284] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][176]) /* ty=Tensor[(1, 12, 50, 50), float32] */;
  %1125 = fn (%p0176: Tensor[(1, 256, 50, 50), float32], %p1172: Tensor[(12, 256, 1, 1), float32], %p266: Tensor[(12), float32], Primitive=1) -> Tensor[(1, 12, 50, 50), float32] {
    %1122 = nn.conv2d(%p0176, %p1172, padding=[0, 0, 0, 0], channels=12, kernel_size=[1, 1]) /* ty=Tensor[(1, 12, 50, 50), float32] */;
    %1123 = expand_dims(%p266, axis=1, num_newaxis=2) /* ty=Tensor[(12, 1, 1), float32] */;
    %1124 = expand_dims(%1123, axis=0) /* ty=Tensor[(1, 12, 1, 1), float32] */;
    add(%1122, %1124) /* ty=Tensor[(1, 12, 50, 50), float32] */
  };
  %1126 = (%x282, %model.rpn.head.bbox_pred.weight, %model.rpn.head.bbox_pred.bias);
  %1127 = (%tensor_0176,);
  let %v176: () = vm.invoke_tvm_op(%1125, %1126, %1127) /* ty=() */;
  let %x283: Tensor[(1, 12, 50, 50), float32] = %tensor_0176;
  let %storage_0177: Storage[] = memory.alloc_storage(640000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][177]) /* ty=Storage[] */;
  let %tensor_0177: Tensor[(1, 256, 25, 25), float32] = memory.alloc_tensor(%storage_0177, 0 /* ty=int64 */, meta[relay.Constant][285] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][177]) /* ty=Tensor[(1, 256, 25, 25), float32] */;
  %1131 = fn (%p0177: Tensor[(1, 256, 25, 25), float32], %p1173: Tensor[(256, 256, 3, 3), float32], %p267: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 25, 25), float32] {
    %1128 = nn.conv2d(%p0177, %p1173, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 25, 25), float32] */;
    %1129 = expand_dims(%p267, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1130 = expand_dims(%1129, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    add(%1128, %1130) /* ty=Tensor[(1, 256, 25, 25), float32] */
  };
  %1132 = (%x268, %model.backbone.fpn.layer_blocks.3.weight, %model.backbone.fpn.layer_blocks.3.bias);
  %1133 = (%tensor_0177,);
  let %v177: () = vm.invoke_tvm_op(%1131, %1132, %1133) /* ty=() */;
  let %x284: Tensor[(1, 256, 25, 25), float32] = %tensor_0177;
  let %storage_0178: Storage[] = memory.alloc_storage(640000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][178]) /* ty=Storage[] */;
  let %tensor_0178: Tensor[(1, 256, 25, 25), float32] = memory.alloc_tensor(%storage_0178, 0 /* ty=int64 */, meta[relay.Constant][286] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][178]) /* ty=Tensor[(1, 256, 25, 25), float32] */;
  %1138 = fn (%p0178: Tensor[(1, 256, 25, 25), float32], %p1174: Tensor[(256, 256, 3, 3), float32], %p268: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 25, 25), float32] {
    %1134 = nn.conv2d(%p0178, %p1174, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 25, 25), float32] */;
    %1135 = expand_dims(%p268, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1136 = expand_dims(%1135, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1137 = add(%1134, %1136) /* ty=Tensor[(1, 256, 25, 25), float32] */;
    nn.relu(%1137) /* ty=Tensor[(1, 256, 25, 25), float32] */
  };
  %1139 = (%x284, %model.rpn.head.conv.weight, %model.rpn.head.conv.bias);
  %1140 = (%tensor_0178,);
  let %v178: () = vm.invoke_tvm_op(%1138, %1139, %1140) /* ty=() */;
  let %x285: Tensor[(1, 256, 25, 25), float32] = %tensor_0178;
  let %storage_0179: Storage[] = memory.alloc_storage(30000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][179]) /* ty=Storage[] */;
  let %tensor_0179: Tensor[(1, 12, 25, 25), float32] = memory.alloc_tensor(%storage_0179, 0 /* ty=int64 */, meta[relay.Constant][287] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][179]) /* ty=Tensor[(1, 12, 25, 25), float32] */;
  %1144 = fn (%p0179: Tensor[(1, 256, 25, 25), float32], %p1175: Tensor[(12, 256, 1, 1), float32], %p269: Tensor[(12), float32], Primitive=1) -> Tensor[(1, 12, 25, 25), float32] {
    %1141 = nn.conv2d(%p0179, %p1175, padding=[0, 0, 0, 0], channels=12, kernel_size=[1, 1]) /* ty=Tensor[(1, 12, 25, 25), float32] */;
    %1142 = expand_dims(%p269, axis=1, num_newaxis=2) /* ty=Tensor[(12, 1, 1), float32] */;
    %1143 = expand_dims(%1142, axis=0) /* ty=Tensor[(1, 12, 1, 1), float32] */;
    add(%1141, %1143) /* ty=Tensor[(1, 12, 25, 25), float32] */
  };
  %1145 = (%x285, %model.rpn.head.bbox_pred.weight, %model.rpn.head.bbox_pred.bias);
  %1146 = (%tensor_0179,);
  let %v179: () = vm.invoke_tvm_op(%1144, %1145, %1146) /* ty=() */;
  let %x286: Tensor[(1, 12, 25, 25), float32] = %tensor_0179;
  let %storage_0180: Storage[] = memory.alloc_storage(173056 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][180]) /* ty=Storage[] */;
  let %tensor_0180: Tensor[(1, 256, 13, 13), float32] = memory.alloc_tensor(%storage_0180, 0 /* ty=int64 */, meta[relay.Constant][288] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][180]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %1147 = fn (%p0180: Tensor[(1, 256, 25, 25), float32], Primitive=1) -> Tensor[(1, 256, 13, 13), float32] {
    nn.max_pool2d(%p0180, pool_size=[1, 1], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 13, 13), float32] */
  };
  %1148 = (%x284,);
  %1149 = (%tensor_0180,);
  let %v180: () = vm.invoke_tvm_op(%1147, %1148, %1149) /* ty=() */;
  let %x287: Tensor[(1, 256, 13, 13), float32] = %tensor_0180;
  let %storage_0181: Storage[] = memory.alloc_storage(173056 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][181]) /* ty=Storage[] */;
  let %tensor_0181: Tensor[(1, 256, 13, 13), float32] = memory.alloc_tensor(%storage_0181, 0 /* ty=int64 */, meta[relay.Constant][289] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][181]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %1154 = fn (%p0181: Tensor[(1, 256, 13, 13), float32], %p1176: Tensor[(256, 256, 3, 3), float32], %p270: Tensor[(256), float32], Primitive=1) -> Tensor[(1, 256, 13, 13), float32] {
    %1150 = nn.conv2d(%p0181, %p1176, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
    %1151 = expand_dims(%p270, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %1152 = expand_dims(%1151, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %1153 = add(%1150, %1152) /* ty=Tensor[(1, 256, 13, 13), float32] */;
    nn.relu(%1153) /* ty=Tensor[(1, 256, 13, 13), float32] */
  };
  %1155 = (%x287, %model.rpn.head.conv.weight, %model.rpn.head.conv.bias);
  %1156 = (%tensor_0181,);
  let %v181: () = vm.invoke_tvm_op(%1154, %1155, %1156) /* ty=() */;
  let %x288: Tensor[(1, 256, 13, 13), float32] = %tensor_0181;
  let %storage_0182: Storage[] = memory.alloc_storage(8112 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][182]) /* ty=Storage[] */;
  let %tensor_0182: Tensor[(1, 12, 13, 13), float32] = memory.alloc_tensor(%storage_0182, 0 /* ty=int64 */, meta[relay.Constant][290] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][182]) /* ty=Tensor[(1, 12, 13, 13), float32] */;
  %1160 = fn (%p0182: Tensor[(1, 256, 13, 13), float32], %p1177: Tensor[(12, 256, 1, 1), float32], %p271: Tensor[(12), float32], Primitive=1) -> Tensor[(1, 12, 13, 13), float32] {
    %1157 = nn.conv2d(%p0182, %p1177, padding=[0, 0, 0, 0], channels=12, kernel_size=[1, 1]) /* ty=Tensor[(1, 12, 13, 13), float32] */;
    %1158 = expand_dims(%p271, axis=1, num_newaxis=2) /* ty=Tensor[(12, 1, 1), float32] */;
    %1159 = expand_dims(%1158, axis=0) /* ty=Tensor[(1, 12, 1, 1), float32] */;
    add(%1157, %1159) /* ty=Tensor[(1, 12, 13, 13), float32] */
  };
  %1161 = (%x288, %model.rpn.head.bbox_pred.weight, %model.rpn.head.bbox_pred.bias);
  %1162 = (%tensor_0182,);
  let %v182: () = vm.invoke_tvm_op(%1160, %1161, %1162) /* ty=() */;
  let %x289: Tensor[(1, 12, 13, 13), float32] = %tensor_0182;
  let %storage_0183: Storage[] = memory.alloc_storage(480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][183]) /* ty=Storage[] */;
  let %tensor_0183: Tensor[(1, 3, 200, 200), float32] = memory.alloc_tensor(%storage_0183, 0 /* ty=int64 */, meta[relay.Constant][291] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][183]) /* ty=Tensor[(1, 3, 200, 200), float32] */;
  %1166 = fn (%p0183: Tensor[(1, 256, 200, 200), float32], %p1178: Tensor[(3, 256, 1, 1), float32], %p272: Tensor[(3), float32], Primitive=1) -> Tensor[(1, 3, 200, 200), float32] {
    %1163 = nn.conv2d(%p0183, %p1178, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]) /* ty=Tensor[(1, 3, 200, 200), float32] */;
    %1164 = expand_dims(%p272, axis=1, num_newaxis=2) /* ty=Tensor[(3, 1, 1), float32] */;
    %1165 = expand_dims(%1164, axis=0) /* ty=Tensor[(1, 3, 1, 1), float32] */;
    add(%1163, %1165) /* ty=Tensor[(1, 3, 200, 200), float32] */
  };
  %1167 = (%x276, %model.rpn.head.cls_logits.weight, %model.rpn.head.cls_logits.bias);
  %1168 = (%tensor_0183,);
  let %v183: () = vm.invoke_tvm_op(%1166, %1167, %1168) /* ty=() */;
  let %x290: Tensor[(1, 3, 200, 200), float32] = %tensor_0183;
  let %storage_0184: Storage[] = memory.alloc_storage(120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][184]) /* ty=Storage[] */;
  let %tensor_0184: Tensor[(1, 3, 100, 100), float32] = memory.alloc_tensor(%storage_0184, 0 /* ty=int64 */, meta[relay.Constant][292] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][184]) /* ty=Tensor[(1, 3, 100, 100), float32] */;
  %1172 = fn (%p0184: Tensor[(1, 256, 100, 100), float32], %p1179: Tensor[(3, 256, 1, 1), float32], %p273: Tensor[(3), float32], Primitive=1) -> Tensor[(1, 3, 100, 100), float32] {
    %1169 = nn.conv2d(%p0184, %p1179, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]) /* ty=Tensor[(1, 3, 100, 100), float32] */;
    %1170 = expand_dims(%p273, axis=1, num_newaxis=2) /* ty=Tensor[(3, 1, 1), float32] */;
    %1171 = expand_dims(%1170, axis=0) /* ty=Tensor[(1, 3, 1, 1), float32] */;
    add(%1169, %1171) /* ty=Tensor[(1, 3, 100, 100), float32] */
  };
  %1173 = (%x279, %model.rpn.head.cls_logits.weight, %model.rpn.head.cls_logits.bias);
  %1174 = (%tensor_0184,);
  let %v184: () = vm.invoke_tvm_op(%1172, %1173, %1174) /* ty=() */;
  let %x291: Tensor[(1, 3, 100, 100), float32] = %tensor_0184;
  let %storage_0185: Storage[] = memory.alloc_storage(30000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][185]) /* ty=Storage[] */;
  let %tensor_0185: Tensor[(1, 3, 50, 50), float32] = memory.alloc_tensor(%storage_0185, 0 /* ty=int64 */, meta[relay.Constant][293] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][185]) /* ty=Tensor[(1, 3, 50, 50), float32] */;
  %1178 = fn (%p0185: Tensor[(1, 256, 50, 50), float32], %p1180: Tensor[(3, 256, 1, 1), float32], %p274: Tensor[(3), float32], Primitive=1) -> Tensor[(1, 3, 50, 50), float32] {
    %1175 = nn.conv2d(%p0185, %p1180, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]) /* ty=Tensor[(1, 3, 50, 50), float32] */;
    %1176 = expand_dims(%p274, axis=1, num_newaxis=2) /* ty=Tensor[(3, 1, 1), float32] */;
    %1177 = expand_dims(%1176, axis=0) /* ty=Tensor[(1, 3, 1, 1), float32] */;
    add(%1175, %1177) /* ty=Tensor[(1, 3, 50, 50), float32] */
  };
  %1179 = (%x282, %model.rpn.head.cls_logits.weight, %model.rpn.head.cls_logits.bias);
  %1180 = (%tensor_0185,);
  let %v185: () = vm.invoke_tvm_op(%1178, %1179, %1180) /* ty=() */;
  let %x292: Tensor[(1, 3, 50, 50), float32] = %tensor_0185;
  let %storage_0186: Storage[] = memory.alloc_storage(7500 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][186]) /* ty=Storage[] */;
  let %tensor_0186: Tensor[(1, 3, 25, 25), float32] = memory.alloc_tensor(%storage_0186, 0 /* ty=int64 */, meta[relay.Constant][294] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][186]) /* ty=Tensor[(1, 3, 25, 25), float32] */;
  %1184 = fn (%p0186: Tensor[(1, 256, 25, 25), float32], %p1181: Tensor[(3, 256, 1, 1), float32], %p275: Tensor[(3), float32], Primitive=1) -> Tensor[(1, 3, 25, 25), float32] {
    %1181 = nn.conv2d(%p0186, %p1181, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]) /* ty=Tensor[(1, 3, 25, 25), float32] */;
    %1182 = expand_dims(%p275, axis=1, num_newaxis=2) /* ty=Tensor[(3, 1, 1), float32] */;
    %1183 = expand_dims(%1182, axis=0) /* ty=Tensor[(1, 3, 1, 1), float32] */;
    add(%1181, %1183) /* ty=Tensor[(1, 3, 25, 25), float32] */
  };
  %1185 = (%x285, %model.rpn.head.cls_logits.weight, %model.rpn.head.cls_logits.bias);
  %1186 = (%tensor_0186,);
  let %v186: () = vm.invoke_tvm_op(%1184, %1185, %1186) /* ty=() */;
  let %x293: Tensor[(1, 3, 25, 25), float32] = %tensor_0186;
  let %storage_0187: Storage[] = memory.alloc_storage(2028 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][187]) /* ty=Storage[] */;
  let %tensor_0187: Tensor[(1, 3, 13, 13), float32] = memory.alloc_tensor(%storage_0187, 0 /* ty=int64 */, meta[relay.Constant][295] /* ty=Tensor[(4), int64] */, meta[relay.attrs.AllocTensorAttrs][187]) /* ty=Tensor[(1, 3, 13, 13), float32] */;
  %1190 = fn (%p0187: Tensor[(1, 256, 13, 13), float32], %p1182: Tensor[(3, 256, 1, 1), float32], %p276: Tensor[(3), float32], Primitive=1) -> Tensor[(1, 3, 13, 13), float32] {
    %1187 = nn.conv2d(%p0187, %p1182, padding=[0, 0, 0, 0], channels=3, kernel_size=[1, 1]) /* ty=Tensor[(1, 3, 13, 13), float32] */;
    %1188 = expand_dims(%p276, axis=1, num_newaxis=2) /* ty=Tensor[(3, 1, 1), float32] */;
    %1189 = expand_dims(%1188, axis=0) /* ty=Tensor[(1, 3, 1, 1), float32] */;
    add(%1187, %1189) /* ty=Tensor[(1, 3, 13, 13), float32] */
  };
  %1191 = (%x288, %model.rpn.head.cls_logits.weight, %model.rpn.head.cls_logits.bias);
  %1192 = (%tensor_0187,);
  let %v187: () = vm.invoke_tvm_op(%1190, %1191, %1192) /* ty=() */;
  let %x294: Tensor[(1, 3, 13, 13), float32] = %tensor_0187;
  let %storage_0188: Storage[] = memory.alloc_storage(639528 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][188]) /* ty=Storage[] */;
  let %tensor_0188: Tensor[(1, 159882), float32] = memory.alloc_tensor(%storage_0188, 0 /* ty=int64 */, meta[relay.Constant][296] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][188]) /* ty=Tensor[(1, 159882), float32] */;
  %1212 = fn (%p0188: Tensor[(1, 3, 200, 200), float32], %p1183: Tensor[(1, 3, 100, 100), float32], %p277: Tensor[(1, 3, 50, 50), float32], %p356: Tensor[(1, 3, 25, 25), float32], %p453: Tensor[(1, 3, 13, 13), float32], Primitive=1) -> Tensor[(1, 159882), float32] {
    %1193 = reshape(%p0188, newshape=[1, -1, 1, 200, 200]) /* ty=Tensor[(1, 3, 1, 200, 200), float32] */;
    %1194 = transpose(%1193, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 200, 200, 3, 1), float32] */;
    %1195 = reshape(%1194, newshape=[1, -1, 1]) /* ty=Tensor[(1, 120000, 1), float32] */;
    %1196 = reshape(%p1183, newshape=[1, -1, 1, 100, 100]) /* ty=Tensor[(1, 3, 1, 100, 100), float32] */;
    %1197 = transpose(%1196, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 100, 100, 3, 1), float32] */;
    %1198 = reshape(%1197, newshape=[1, -1, 1]) /* ty=Tensor[(1, 30000, 1), float32] */;
    %1199 = reshape(%p277, newshape=[1, -1, 1, 50, 50]) /* ty=Tensor[(1, 3, 1, 50, 50), float32] */;
    %1200 = transpose(%1199, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 50, 50, 3, 1), float32] */;
    %1201 = reshape(%1200, newshape=[1, -1, 1]) /* ty=Tensor[(1, 7500, 1), float32] */;
    %1202 = reshape(%p356, newshape=[1, -1, 1, 25, 25]) /* ty=Tensor[(1, 3, 1, 25, 25), float32] */;
    %1203 = transpose(%1202, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 25, 25, 3, 1), float32] */;
    %1204 = reshape(%1203, newshape=[1, -1, 1]) /* ty=Tensor[(1, 1875, 1), float32] */;
    %1205 = reshape(%p453, newshape=[1, -1, 1, 13, 13]) /* ty=Tensor[(1, 3, 1, 13, 13), float32] */;
    %1206 = transpose(%1205, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 13, 13, 3, 1), float32] */;
    %1207 = reshape(%1206, newshape=[1, -1, 1]) /* ty=Tensor[(1, 507, 1), float32] */;
    %1208 = (%1195, %1198, %1201, %1204, %1207);
    %1209 = concatenate(%1208, axis=1) /* ty=Tensor[(1, 159882, 1), float32] */;
    %1210 = reshape(%1209, newshape=[-1, 1, 0]) /* ty=Tensor[(159882, 1, 1), float32] */;
    %1211 = squeeze(%1210, axis=[1]) /* ty=Tensor[(159882, 1), float32] */;
    reshape(%1211, newshape=[1, -1]) /* ty=Tensor[(1, 159882), float32] */
  };
  %1213 = (%x290, %x291, %x292, %x293, %x294);
  %1214 = (%tensor_0188,);
  let %v188: () = vm.invoke_tvm_op(%1212, %1213, %1214) /* ty=() */;
  let %x295: Tensor[(1, 159882), float32] = %tensor_0188;
  let %storage_0189: Storage[] = memory.alloc_storage(480000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][189]) /* ty=Storage[] */;
  let %tensor_0189: Tensor[(1, 120000), float32] = memory.alloc_tensor(%storage_0189, 0 /* ty=int64 */, meta[relay.Constant][297] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][189]) /* ty=Tensor[(1, 120000), float32] */;
  let %storage_1: Storage[] = memory.alloc_storage(120000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][190]) /* ty=Storage[] */;
  let %tensor_1: Tensor[(1, 30000), float32] = memory.alloc_tensor(%storage_1, 0 /* ty=int64 */, meta[relay.Constant][298] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][190]) /* ty=Tensor[(1, 30000), float32] */;
  let %storage_2: Storage[] = memory.alloc_storage(30000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][191]) /* ty=Storage[] */;
  let %tensor_2: Tensor[(1, 7500), float32] = memory.alloc_tensor(%storage_2, 0 /* ty=int64 */, meta[relay.Constant][299] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][191]) /* ty=Tensor[(1, 7500), float32] */;
  let %storage_3: Storage[] = memory.alloc_storage(7500 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][192]) /* ty=Storage[] */;
  let %tensor_3: Tensor[(1, 1875), float32] = memory.alloc_tensor(%storage_3, 0 /* ty=int64 */, meta[relay.Constant][300] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][192]) /* ty=Tensor[(1, 1875), float32] */;
  let %storage_4: Storage[] = memory.alloc_storage(2028 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][193]) /* ty=Storage[] */;
  let %tensor_4: Tensor[(1, 507), float32] = memory.alloc_tensor(%storage_4, 0 /* ty=int64 */, meta[relay.Constant][301] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][193]) /* ty=Tensor[(1, 507), float32] */;
  %1215 = fn (%p0189: Tensor[(1, 159882), float32], Primitive=1) -> (Tensor[(1, 120000), float32], Tensor[(1, 30000), float32], Tensor[(1, 7500), float32], Tensor[(1, 1875), float32], Tensor[(1, 507), float32]) {
    split(%p0189, indices_or_sections=[120000, 150000, 157500, 159375], axis=1) /* ty=(Tensor[(1, 120000), float32], Tensor[(1, 30000), float32], Tensor[(1, 7500), float32], Tensor[(1, 1875), float32], Tensor[(1, 507), float32]) */
  };
  %1216 = (%x295,);
  %1217 = (%tensor_0189, %tensor_1, %tensor_2, %tensor_3, %tensor_4);
  let %v189: () = vm.invoke_tvm_op(%1215, %1216, %1217) /* ty=() */;
  let %x296: (Tensor[(1, 120000), float32], Tensor[(1, 30000), float32], Tensor[(1, 7500), float32], Tensor[(1, 1875), float32], Tensor[(1, 507), float32]) = (%tensor_0189, %tensor_1, %tensor_2, %tensor_3, %tensor_4);
  let %x297: Tensor[(1, 120000), float32] = %x296.0;
  let %storage_0190: Storage[] = memory.alloc_storage(4000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][194]) /* ty=Storage[] */;
  let %tensor_0190: Tensor[(1, 1000), float32] = memory.alloc_tensor(%storage_0190, 0 /* ty=int64 */, meta[relay.Constant][302] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][194]) /* ty=Tensor[(1, 1000), float32] */;
  let %storage_11: Storage[] = memory.alloc_storage(8000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][195]) /* ty=Storage[] */;
  let %tensor_11: Tensor[(1, 1000), int64] = memory.alloc_tensor(%storage_11, 0 /* ty=int64 */, meta[relay.Constant][303] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][195]) /* ty=Tensor[(1, 1000), int64] */;
  %1218 = fn (%p0190: Tensor[(1, 120000), float32], Primitive=1) -> (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) {
    topk(%p0190, k=1000, axis=1, dtype="int64") /* ty=(Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) */
  };
  %1219 = (%x297,);
  %1220 = (%tensor_0190, %tensor_11);
  let %v190: () = vm.invoke_tvm_op(%1218, %1219, %1220) /* ty=() */;
  let %x298: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) = (%tensor_0190, %tensor_11);
  let %x299: Tensor[(1, 30000), float32] = %x296.1;
  let %storage_0191: Storage[] = memory.alloc_storage(4000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][196]) /* ty=Storage[] */;
  let %tensor_0191: Tensor[(1, 1000), float32] = memory.alloc_tensor(%storage_0191, 0 /* ty=int64 */, meta[relay.Constant][304] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][196]) /* ty=Tensor[(1, 1000), float32] */;
  let %storage_12: Storage[] = memory.alloc_storage(8000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][197]) /* ty=Storage[] */;
  let %tensor_12: Tensor[(1, 1000), int64] = memory.alloc_tensor(%storage_12, 0 /* ty=int64 */, meta[relay.Constant][305] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][197]) /* ty=Tensor[(1, 1000), int64] */;
  %1221 = fn (%p0191: Tensor[(1, 30000), float32], Primitive=1) -> (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) {
    topk(%p0191, k=1000, axis=1, dtype="int64") /* ty=(Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) */
  };
  %1222 = (%x299,);
  %1223 = (%tensor_0191, %tensor_12);
  let %v191: () = vm.invoke_tvm_op(%1221, %1222, %1223) /* ty=() */;
  let %x300: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) = (%tensor_0191, %tensor_12);
  let %x301: Tensor[(1, 7500), float32] = %x296.2;
  let %storage_0192: Storage[] = memory.alloc_storage(4000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][198]) /* ty=Storage[] */;
  let %tensor_0192: Tensor[(1, 1000), float32] = memory.alloc_tensor(%storage_0192, 0 /* ty=int64 */, meta[relay.Constant][306] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][198]) /* ty=Tensor[(1, 1000), float32] */;
  let %storage_13: Storage[] = memory.alloc_storage(8000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][199]) /* ty=Storage[] */;
  let %tensor_13: Tensor[(1, 1000), int64] = memory.alloc_tensor(%storage_13, 0 /* ty=int64 */, meta[relay.Constant][307] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][199]) /* ty=Tensor[(1, 1000), int64] */;
  %1224 = fn (%p0192: Tensor[(1, 7500), float32], Primitive=1) -> (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) {
    topk(%p0192, k=1000, axis=1, dtype="int64") /* ty=(Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) */
  };
  %1225 = (%x301,);
  %1226 = (%tensor_0192, %tensor_13);
  let %v192: () = vm.invoke_tvm_op(%1224, %1225, %1226) /* ty=() */;
  let %x302: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) = (%tensor_0192, %tensor_13);
  let %x303: Tensor[(1, 1875), float32] = %x296.3;
  let %storage_0193: Storage[] = memory.alloc_storage(4000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][200]) /* ty=Storage[] */;
  let %tensor_0193: Tensor[(1, 1000), float32] = memory.alloc_tensor(%storage_0193, 0 /* ty=int64 */, meta[relay.Constant][308] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][200]) /* ty=Tensor[(1, 1000), float32] */;
  let %storage_14: Storage[] = memory.alloc_storage(8000 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][201]) /* ty=Storage[] */;
  let %tensor_14: Tensor[(1, 1000), int64] = memory.alloc_tensor(%storage_14, 0 /* ty=int64 */, meta[relay.Constant][309] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][201]) /* ty=Tensor[(1, 1000), int64] */;
  %1227 = fn (%p0193: Tensor[(1, 1875), float32], Primitive=1) -> (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) {
    topk(%p0193, k=1000, axis=1, dtype="int64") /* ty=(Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) */
  };
  %1228 = (%x303,);
  %1229 = (%tensor_0193, %tensor_14);
  let %v193: () = vm.invoke_tvm_op(%1227, %1228, %1229) /* ty=() */;
  let %x304: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]) = (%tensor_0193, %tensor_14);
  let %x305: Tensor[(1, 507), float32] = %x296.4;
  let %storage_0194: Storage[] = memory.alloc_storage(2028 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][202]) /* ty=Storage[] */;
  let %tensor_0194: Tensor[(1, 507), float32] = memory.alloc_tensor(%storage_0194, 0 /* ty=int64 */, meta[relay.Constant][310] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][202]) /* ty=Tensor[(1, 507), float32] */;
  let %storage_15: Storage[] = memory.alloc_storage(4056 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][203]) /* ty=Storage[] */;
  let %tensor_15: Tensor[(1, 507), int64] = memory.alloc_tensor(%storage_15, 0 /* ty=int64 */, meta[relay.Constant][311] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][203]) /* ty=Tensor[(1, 507), int64] */;
  %1230 = fn (%p0194: Tensor[(1, 507), float32], Primitive=1) -> (Tensor[(1, 507), float32], Tensor[(1, 507), int64]) {
    topk(%p0194, k=507, axis=1, dtype="int64") /* ty=(Tensor[(1, 507), float32], Tensor[(1, 507), int64]) */
  };
  %1231 = (%x305,);
  %1232 = (%tensor_0194, %tensor_15);
  let %v194: () = vm.invoke_tvm_op(%1230, %1231, %1232) /* ty=() */;
  let %x306: (Tensor[(1, 507), float32], Tensor[(1, 507), int64]) = (%tensor_0194, %tensor_15);
  let %storage_0195: Storage[] = memory.alloc_storage(36056 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][204]) /* ty=Storage[] */;
  let %tensor_0195: Tensor[(1, 4507), int64] = memory.alloc_tensor(%storage_0195, 0 /* ty=int64 */, meta[relay.Constant][312] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][204]) /* ty=Tensor[(1, 4507), int64] */;
  %1244 = fn (%p0195: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]), %p1184: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]), %p278: Tensor[(1), int64], %p357: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]), %p454: Tensor[(1), int64], %p516: (Tensor[(1, 1000), float32], Tensor[(1, 1000), int64]), %p6: Tensor[(1), int64], %p7: (Tensor[(1, 507), float32], Tensor[(1, 507), int64]), %p8: Tensor[(1), int64], Primitive=1) -> Tensor[(1, 4507), int64] {
    %1233 = %p0195.1;
    %1234 = add(%1233, 0 /* ty=int64 */) /* ty=Tensor[(1, 1000), int64] */;
    %1235 = %p1184.1;
    %1236 = add(%1235, %p278) /* ty=Tensor[(1, 1000), int64] */;
    %1237 = %p357.1;
    %1238 = add(%1237, %p454) /* ty=Tensor[(1, 1000), int64] */;
    %1239 = %p516.1;
    %1240 = add(%1239, %p6) /* ty=Tensor[(1, 1000), int64] */;
    %1241 = %p7.1;
    %1242 = add(%1241, %p8) /* ty=Tensor[(1, 507), int64] */;
    %1243 = (%1234, %1236, %1238, %1240, %1242);
    concatenate(%1243, axis=1) /* ty=Tensor[(1, 4507), int64] */
  };
  %1245 = (%x298, %x300, meta[relay.Constant][313] /* ty=Tensor[(1), int64] */, %x302, meta[relay.Constant][314] /* ty=Tensor[(1), int64] */, %x304, meta[relay.Constant][315] /* ty=Tensor[(1), int64] */, %x306, meta[relay.Constant][316] /* ty=Tensor[(1), int64] */);
  %1246 = (%tensor_0195,);
  let %v195: () = vm.invoke_tvm_op(%1244, %1245, %1246) /* ty=() */;
  let %x307: Tensor[(1, 4507), int64] = %tensor_0195;
  let %storage_0196: Storage[] = memory.alloc_storage(72112 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][205]) /* ty=Storage[] */;
  let %tensor_0196: Tensor[(4507, 4), float32] = memory.alloc_tensor(%storage_0196, 0 /* ty=int64 */, meta[relay.Constant][317] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][205]) /* ty=Tensor[(4507, 4), float32] */;
  %1308 = fn (%p0196: Tensor[(1, 12, 200, 200), float32], %p1185: Tensor[(1, 12, 100, 100), float32], %p279: Tensor[(1, 12, 50, 50), float32], %p358: Tensor[(1, 12, 25, 25), float32], %p455: Tensor[(1, 12, 13, 13), float32], %p517: Tensor[(159882, 1), float32], %p61: Tensor[(159882, 1), float32], %p71: Tensor[(159882, 1), float32], %p81: Tensor[(159882, 1), float32], %p9: Tensor[(1, 1), int64], %p10: Tensor[(1, 4507), int64], %p1186: float32, %p1210: float32, Primitive=1) -> Tensor[(4507, 4), float32] {
    %1247 = reshape(%p0196, newshape=[1, -1, 4, 200, 200]) /* ty=Tensor[(1, 3, 4, 200, 200), float32] */;
    %1248 = transpose(%1247, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 200, 200, 3, 4), float32] */;
    %1249 = reshape(%1248, newshape=[1, -1, 4]) /* ty=Tensor[(1, 120000, 4), float32] */;
    %1250 = reshape(%p1185, newshape=[1, -1, 4, 100, 100]) /* ty=Tensor[(1, 3, 4, 100, 100), float32] */;
    %1251 = transpose(%1250, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 100, 100, 3, 4), float32] */;
    %1252 = reshape(%1251, newshape=[1, -1, 4]) /* ty=Tensor[(1, 30000, 4), float32] */;
    %1253 = reshape(%p279, newshape=[1, -1, 4, 50, 50]) /* ty=Tensor[(1, 3, 4, 50, 50), float32] */;
    %1254 = transpose(%1253, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 50, 50, 3, 4), float32] */;
    %1255 = reshape(%1254, newshape=[1, -1, 4]) /* ty=Tensor[(1, 7500, 4), float32] */;
    %1256 = reshape(%p358, newshape=[1, -1, 4, 25, 25]) /* ty=Tensor[(1, 3, 4, 25, 25), float32] */;
    %1257 = transpose(%1256, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 25, 25, 3, 4), float32] */;
    %1258 = reshape(%1257, newshape=[1, -1, 4]) /* ty=Tensor[(1, 1875, 4), float32] */;
    %1259 = reshape(%p455, newshape=[1, -1, 4, 13, 13]) /* ty=Tensor[(1, 3, 4, 13, 13), float32] */;
    %1260 = transpose(%1259, axes=[0, 3, 4, 1, 2]) /* ty=Tensor[(1, 13, 13, 3, 4), float32] */;
    %1261 = reshape(%1260, newshape=[1, -1, 4]) /* ty=Tensor[(1, 507, 4), float32] */;
    %1262 = (%1249, %1252, %1255, %1258, %1261);
    %1263 = concatenate(%1262, axis=1) /* ty=Tensor[(1, 159882, 4), float32] */;
    %1264 = reshape(%1263, newshape=[159882, 4]) /* ty=Tensor[(159882, 4), float32] */;
    %1265 = strided_slice(%1264, begin=[0, 0], end=[159882, 4], strides=[1, 1]) /* ty=Tensor[(159882, 4), float32] */;
    %1266 = strided_slice(%1265, begin=[0, 0], end=[159882, 4], strides=[1, 4]) /* ty=Tensor[(159882, 1), float32] */;
    %1267 = divide(%1266, 1f /* ty=float32 */) /* ty=Tensor[(159882, 1), float32] */;
    %1268 = multiply(%1267, %p517) /* ty=Tensor[(159882, 1), float32] */;
    %1269 = add(%1268, %p61) /* ty=Tensor[(159882, 1), float32] */;
    %1270 = strided_slice(%1265, begin=[0, 2], end=[159882, 4], strides=[1, 4]) /* ty=Tensor[(159882, 1), float32] */;
    %1271 = divide(%1270, 1f /* ty=float32 */) /* ty=Tensor[(159882, 1), float32] */;
    %1272 = clip(%1271, a_min=-3.40282e+38f, a_max=4.13517f) /* ty=Tensor[(159882, 1), float32] */;
    %1273 = exp(%1272) /* ty=Tensor[(159882, 1), float32] */;
    %1274 = multiply(%1273, %p517) /* ty=Tensor[(159882, 1), float32] */;
    %1275 = multiply(0.5f /* ty=float32 */, %1274) /* ty=Tensor[(159882, 1), float32] */;
    %1276 = subtract(%1269, %1275) /* ty=Tensor[(159882, 1), float32] */;
    %1277 = strided_slice(%1265, begin=[0, 1], end=[159882, 4], strides=[1, 4]) /* ty=Tensor[(159882, 1), float32] */;
    %1278 = divide(%1277, 1f /* ty=float32 */) /* ty=Tensor[(159882, 1), float32] */;
    %1279 = multiply(%1278, %p71) /* ty=Tensor[(159882, 1), float32] */;
    %1280 = add(%1279, %p81) /* ty=Tensor[(159882, 1), float32] */;
    %1281 = strided_slice(%1265, begin=[0, 3], end=[159882, 4], strides=[1, 4]) /* ty=Tensor[(159882, 1), float32] */;
    %1282 = divide(%1281, 1f /* ty=float32 */) /* ty=Tensor[(159882, 1), float32] */;
    %1283 = clip(%1282, a_min=-3.40282e+38f, a_max=4.13517f) /* ty=Tensor[(159882, 1), float32] */;
    %1284 = exp(%1283) /* ty=Tensor[(159882, 1), float32] */;
    %1285 = multiply(%1284, %p71) /* ty=Tensor[(159882, 1), float32] */;
    %1286 = multiply(0.5f /* ty=float32 */, %1285) /* ty=Tensor[(159882, 1), float32] */;
    %1287 = subtract(%1280, %1286) /* ty=Tensor[(159882, 1), float32] */;
    %1288 = add(%1269, %1275) /* ty=Tensor[(159882, 1), float32] */;
    %1289 = add(%1280, %1286) /* ty=Tensor[(159882, 1), float32] */;
    %1290 = (%1276, %1287, %1288, %1289);
    %1291 = stack(%1290, axis=2) /* ty=Tensor[(159882, 1, 4), float32] */;
    %1292 = reshape(%1291, newshape=[0, -1, 1]) /* ty=Tensor[(159882, 4, 1), float32] */;
    %1293 = squeeze(%1292, axis=[2]) /* ty=Tensor[(159882, 4), float32] */;
    %1294 = reshape(%1293, newshape=[1, 159882, 4]) /* ty=Tensor[(1, 159882, 4), float32] */;
    %1295 = (%1294, %p9, %p10);
    %1296 = adv_index(%1295) /* ty=Tensor[(1, 4507, 4), float32] */;
    %1297 = split(%1296, indices_or_sections=1) /* ty=(Tensor[(1, 4507, 4), float32],) */;
    %1298 = %1297.0;
    %1299 = squeeze(%1298, axis=[0]) /* ty=Tensor[(4507, 4), float32] */;
    %1300 = strided_slice(%1299, begin=[0, 0], end=[4507, 4], strides=[1, 2]) /* ty=Tensor[(4507, 2), float32] */;
    %1301 = maximum(%1300, 0f /* ty=float32 */) /* ty=Tensor[(4507, 2), float32] */;
    %1302 = minimum(%1301, %p1186) /* ty=Tensor[(4507, 2), float32] */;
    %1303 = strided_slice(%1299, begin=[0, 1], end=[4507, 4], strides=[1, 2]) /* ty=Tensor[(4507, 2), float32] */;
    %1304 = maximum(%1303, 0f /* ty=float32 */) /* ty=Tensor[(4507, 2), float32] */;
    %1305 = minimum(%1304, %p1210) /* ty=Tensor[(4507, 2), float32] */;
    %1306 = (%1302, %1305);
    %1307 = stack(%1306, axis=2) /* ty=Tensor[(4507, 2, 2), float32] */;
    reshape(%1307, newshape=[4507, 4]) /* ty=Tensor[(4507, 4), float32] */
  };
  %1309 = (%x277, %x280, %x283, %x286, %x289, meta[relay.Constant][318] /* ty=Tensor[(159882, 1), float32] */, meta[relay.Constant][319] /* ty=Tensor[(159882, 1), float32] */, meta[relay.Constant][320] /* ty=Tensor[(159882, 1), float32] */, meta[relay.Constant][321] /* ty=Tensor[(159882, 1), float32] */, meta[relay.Constant][322] /* ty=Tensor[(1, 1), int64] */, %x307, 800f /* ty=float32 */, 800f /* ty=float32 */);
  %1310 = (%tensor_0196,);
  let %v196: () = vm.invoke_tvm_op(%1308, %1309, %1310) /* ty=() */;
  let %x308: Tensor[(4507, 4), float32] = %tensor_0196;
  let %storage_0197: Storage[] = memory.alloc_storage(4507 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][206]) /* ty=Storage[] */;
  let %tensor_0197: Tensor[(4507), bool] = memory.alloc_tensor(%storage_0197, 0 /* ty=int64 */, meta[relay.Constant][323] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][206]) /* ty=Tensor[(4507), bool] */;
  %1322 = fn (%p0197: Tensor[(4507, 4), float32], Primitive=1) -> Tensor[(4507), bool] {
    %1311 = strided_slice(%p0197, begin=[0, 0], end=[4507, 4], strides=[1, 1]) /* ty=Tensor[(4507, 4), float32] */;
    %1312 = take(%1311, 2 /* ty=int32 */, axis=1) /* ty=Tensor[(4507), float32] */;
    %1313 = take(%1311, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(4507), float32] */;
    %1314 = subtract(%1312, %1313) /* ty=Tensor[(4507), float32] */;
    %1315 = greater_equal(%1314, 0.001f /* ty=float32 */) /* ty=Tensor[(4507), bool] */;
    %1316 = cast(%1315, dtype="bool") /* ty=Tensor[(4507), bool] */;
    %1317 = take(%1311, 3 /* ty=int32 */, axis=1) /* ty=Tensor[(4507), float32] */;
    %1318 = take(%1311, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(4507), float32] */;
    %1319 = subtract(%1317, %1318) /* ty=Tensor[(4507), float32] */;
    %1320 = greater_equal(%1319, 0.001f /* ty=float32 */) /* ty=Tensor[(4507), bool] */;
    %1321 = cast(%1320, dtype="bool") /* ty=Tensor[(4507), bool] */;
    logical_and(%1316, %1321) /* ty=Tensor[(4507), bool] */
  };
  %1323 = (%x308,);
  %1324 = (%tensor_0197,);
  let %v197: () = vm.invoke_tvm_op(%1322, %1323, %1324) /* ty=() */;
  let %x309: Tensor[(4507), bool] = %tensor_0197;
  let %in_shape_0: Tensor[(4507), bool] = device_copy(%x309, meta[relay.attrs.DeviceCopyAttrs][0]) /* ty=Tensor[(4507), bool] */;
  let %storage_0198: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][207]) /* ty=Storage[] */;
  let %tensor_0198: Tensor[(2), int64] = memory.alloc_tensor(%storage_0198, 0 /* ty=int64 */, meta[relay.Constant][324] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][207]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0: Tensor[(2), int64] = %tensor_0198;
  %1325 = fn (%p0198: Tensor[(4507), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0198) /* ty=Tensor[(?, 1), int32] */
  };
  %1326 = (%in_shape_0,);
  %1327 = (%shape_func_out_0,);
  let %shape_func: () = vm.shape_func(%1325, %1326, %1327, meta[relay.attrs.ShapeFuncAttrs][0]) /* ty=() */;
  let %storage_0199: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][208]) /* ty=Storage[] */;
  let %tensor_0199: int64 = memory.alloc_tensor(%storage_0199, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][208]) /* ty=int64 */;
  %1328 = fn (%p0199: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0199) /* ty=int64 */
  };
  %1329 = (%shape_func_out_0,);
  %1330 = (%tensor_0199,);
  let %v198: () = vm.invoke_tvm_op(%1328, %1329, %1330) /* ty=() */;
  let %storage_0200: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][209]) /* ty=Storage[] */;
  let %tensor_0200: int64 = memory.alloc_tensor(%storage_0200, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][209]) /* ty=int64 */;
  %1331 = fn (%p0200: int64, Primitive=1) -> int64 {
    multiply(%p0200, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1332 = (%tensor_0199,);
  %1333 = (%tensor_0200,);
  let %v199: () = vm.invoke_tvm_op(%1331, %1332, %1333) /* ty=() */;
  let %storage_0201: Storage[] = memory.alloc_storage(%tensor_0200, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][210]) /* ty=Storage[] */;
  let %out_0: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0201, 0 /* ty=int64 */, %shape_func_out_0, meta[relay.attrs.AllocTensorAttrs][210]) /* ty=Tensor[(?, 1), int32] */;
  %1334 = (%x309,);
  %1335 = (%out_0,);
  let %v200: () = vm.invoke_tvm_op(%1325, %1334, %1335) /* ty=() */;
  let %x310: Tensor[(?, 1), int32] = %out_0;
  let %in_shape_01: Tensor[(2), int64] = vm.shape_of(%x310, meta[relay.attrs.ShapeOfAttrs][0]) /* ty=Tensor[(2), int64] */;
  let %storage_0202: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][211]) /* ty=Storage[] */;
  let %tensor_0201: Tensor[(1), int64] = memory.alloc_tensor(%storage_0202, 0 /* ty=int64 */, meta[relay.Constant][325] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][211]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_01: Tensor[(1), int64] = %tensor_0201;
  %1339 = fn (%p0201: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int64] {
    %1336 = split(%p0201, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %1337 = %1336.0;
    %1338 = squeeze(%1337, axis=[1]) /* ty=Tensor[(?), int32] */;
    cast(%1338, dtype="int64") /* ty=Tensor[(?), int64] */
  };
  %1340 = (%in_shape_01,);
  %1341 = (%shape_func_out_01,);
  let %shape_func1: () = vm.shape_func(%1339, %1340, %1341, meta[relay.attrs.ShapeFuncAttrs][1]) /* ty=() */;
  let %storage_0203: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][212]) /* ty=Storage[] */;
  let %tensor_0202: int64 = memory.alloc_tensor(%storage_0203, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][212]) /* ty=int64 */;
  %1342 = fn (%p0202: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0202) /* ty=int64 */
  };
  %1343 = (%shape_func_out_01,);
  %1344 = (%tensor_0202,);
  let %v201: () = vm.invoke_tvm_op(%1342, %1343, %1344) /* ty=() */;
  let %storage_0204: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][213]) /* ty=Storage[] */;
  let %tensor_0203: int64 = memory.alloc_tensor(%storage_0204, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][213]) /* ty=int64 */;
  %1345 = fn (%p0203: int64, Primitive=1) -> int64 {
    multiply(%p0203, 8 /* ty=int64 */) /* ty=int64 */
  };
  %1346 = (%tensor_0202,);
  %1347 = (%tensor_0203,);
  let %v202: () = vm.invoke_tvm_op(%1345, %1346, %1347) /* ty=() */;
  let %storage_0205: Storage[] = memory.alloc_storage(%tensor_0203, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][214]) /* ty=Storage[] */;
  let %out_01: Tensor[(?), int64] = memory.alloc_tensor(%storage_0205, 0 /* ty=int64 */, %shape_func_out_01, meta[relay.attrs.AllocTensorAttrs][214]) /* ty=Tensor[(?), int64] */;
  %1348 = (%x310,);
  %1349 = (%out_01,);
  let %v203: () = vm.invoke_tvm_op(%1339, %1348, %1349) /* ty=() */;
  let %x311: Tensor[(?), int64] = %out_01;
  let %in_shape_1: Tensor[(1), int64] = vm.shape_of(%x311, meta[relay.attrs.ShapeOfAttrs][1]) /* ty=Tensor[(1), int64] */;
  let %storage_0206: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][215]) /* ty=Storage[] */;
  let %tensor_0204: Tensor[(2), int64] = memory.alloc_tensor(%storage_0206, 0 /* ty=int64 */, meta[relay.Constant][326] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][215]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_02: Tensor[(2), int64] = %tensor_0204;
  %1351 = fn (%p0204: Tensor[(4507, 4), float32], %p1187: Tensor[(?), int64], Primitive=1) -> Tensor[(?, 4), float32] {
    %1350 = (%p0204, %p1187);
    adv_index(%1350) /* ty=Tensor[(?, 4), float32] */
  };
  %1352 = (meta[relay.Constant][327] /* ty=Tensor[(2), int64] */, %in_shape_1);
  %1353 = (%shape_func_out_02,);
  let %shape_func2: () = vm.shape_func(%1351, %1352, %1353, meta[relay.attrs.ShapeFuncAttrs][2]) /* ty=() */;
  let %storage_0207: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][216]) /* ty=Storage[] */;
  let %tensor_0205: int64 = memory.alloc_tensor(%storage_0207, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][216]) /* ty=int64 */;
  %1354 = fn (%p0205: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0205) /* ty=int64 */
  };
  %1355 = (%shape_func_out_02,);
  %1356 = (%tensor_0205,);
  let %v204: () = vm.invoke_tvm_op(%1354, %1355, %1356) /* ty=() */;
  let %storage_0208: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][217]) /* ty=Storage[] */;
  let %tensor_0206: int64 = memory.alloc_tensor(%storage_0208, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][217]) /* ty=int64 */;
  %1357 = fn (%p0206: int64, Primitive=1) -> int64 {
    multiply(%p0206, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1358 = (%tensor_0205,);
  %1359 = (%tensor_0206,);
  let %v205: () = vm.invoke_tvm_op(%1357, %1358, %1359) /* ty=() */;
  let %storage_0209: Storage[] = memory.alloc_storage(%tensor_0206, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][218]) /* ty=Storage[] */;
  let %out_02: Tensor[(?, 4), float32] = memory.alloc_tensor(%storage_0209, 0 /* ty=int64 */, %shape_func_out_02, meta[relay.attrs.AllocTensorAttrs][218]) /* ty=Tensor[(?, 4), float32] */;
  %1360 = (%x308, %x311);
  %1361 = (%out_02,);
  let %v206: () = vm.invoke_tvm_op(%1351, %1360, %1361) /* ty=() */;
  let %x312: Tensor[(?, 4), float32] = %out_02;
  let %storage_0210: Storage[] = memory.alloc_storage(1 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][219]) /* ty=Storage[] */;
  let %tensor_0207: bool = memory.alloc_tensor(%storage_0210, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][219]) /* ty=bool */;
  %1363 = fn (%p0207: Tensor[(?, 4), float32], Primitive=1) -> bool {
    %1362 = ndarray_size(%p0207, dtype="int32") /* ty=int32 */;
    equal(%1362, 0 /* ty=int32 */) /* ty=bool */
  };
  %1364 = (%x312,);
  %1365 = (%tensor_0207,);
  let %v207: () = vm.invoke_tvm_op(%1363, %1364, %1365) /* ty=() */;
  let %x313: bool = %tensor_0207;
  let %x314: Tensor[(?), int64] = if (%x313) {
    let %storage_0211: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][220]) /* ty=Storage[] */;
    let %tensor_0208: Tensor[(1), int64] = memory.alloc_tensor(%storage_0211, 0 /* ty=int64 */, meta[relay.Constant][328] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][220]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_03: Tensor[(1), int64] = %tensor_0208;
    %1366 = fn (Primitive=1) -> Tensor[(?), int64] {
      zeros(shape=[0], dtype="int64") /* ty=Tensor[(?), int64] */
    };
    %1367 = ();
    %1368 = (%shape_func_out_03,);
    let %shape_func3: () = vm.shape_func(%1366, %1367, %1368, meta[relay.attrs.ShapeFuncAttrs][3]) /* ty=() */;
    let %storage_0212: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][221]) /* ty=Storage[] */;
    let %tensor_0209: int64 = memory.alloc_tensor(%storage_0212, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][221]) /* ty=int64 */;
    %1369 = fn (%p0208: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0208) /* ty=int64 */
    };
    %1370 = (%shape_func_out_03,);
    %1371 = (%tensor_0209,);
    let %v208: () = vm.invoke_tvm_op(%1369, %1370, %1371) /* ty=() */;
    let %storage_0213: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][222]) /* ty=Storage[] */;
    let %tensor_0210: int64 = memory.alloc_tensor(%storage_0213, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][222]) /* ty=int64 */;
    %1372 = fn (%p0209: int64, Primitive=1) -> int64 {
      multiply(%p0209, 8 /* ty=int64 */) /* ty=int64 */
    };
    %1373 = (%tensor_0209,);
    %1374 = (%tensor_0210,);
    let %v209: () = vm.invoke_tvm_op(%1372, %1373, %1374) /* ty=() */;
    let %storage_0214: Storage[] = memory.alloc_storage(%tensor_0210, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][223]) /* ty=Storage[] */;
    let %out_03: Tensor[(?), int64] = memory.alloc_tensor(%storage_0214, 0 /* ty=int64 */, %shape_func_out_03, meta[relay.attrs.AllocTensorAttrs][223]) /* ty=Tensor[(?), int64] */;
    %1375 = ();
    %1376 = (%out_03,);
    let %v210: () = vm.invoke_tvm_op(%1366, %1375, %1376) /* ty=() */;
    let %x315: Tensor[(?), int64] = %out_03;
    %x315
  } else {
    let %in_shape_3: Tensor[(1), int64] = vm.shape_of(%x311, meta[relay.attrs.ShapeOfAttrs][2]) /* ty=Tensor[(1), int64] */;
    let %storage_0215: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][224]) /* ty=Storage[] */;
    let %tensor_0211: Tensor[(1), int64] = memory.alloc_tensor(%storage_0215, 0 /* ty=int64 */, meta[relay.Constant][329] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][224]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_04: Tensor[(1), int64] = %tensor_0211;
    %1383 = fn (%p0210: Tensor[(1, 159882), float32], %p1188: Tensor[(1, 1), int64], %p280: Tensor[(1, 4507), int64], %p359: Tensor[(?), int64], Primitive=1) -> Tensor[(?), float32] {
      %1377 = (%p0210, %p1188, %p280);
      %1378 = adv_index(%1377) /* ty=Tensor[(1, 4507), float32] */;
      %1379 = split(%1378, indices_or_sections=1) /* ty=(Tensor[(1, 4507), float32],) */;
      %1380 = %1379.0;
      %1381 = squeeze(%1380, axis=[0]) /* ty=Tensor[(4507), float32] */;
      %1382 = (%1381, %p359);
      adv_index(%1382) /* ty=Tensor[(?), float32] */
    };
    %1384 = (meta[relay.Constant][330] /* ty=Tensor[(2), int64] */, meta[relay.Constant][331] /* ty=Tensor[(2), int64] */, meta[relay.Constant][332] /* ty=Tensor[(2), int64] */, %in_shape_3);
    %1385 = (%shape_func_out_04,);
    let %shape_func4: () = vm.shape_func(%1383, %1384, %1385, meta[relay.attrs.ShapeFuncAttrs][4]) /* ty=() */;
    let %storage_0216: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][225]) /* ty=Storage[] */;
    let %tensor_0212: int64 = memory.alloc_tensor(%storage_0216, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][225]) /* ty=int64 */;
    %1386 = fn (%p0211: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0211) /* ty=int64 */
    };
    %1387 = (%shape_func_out_04,);
    %1388 = (%tensor_0212,);
    let %v211: () = vm.invoke_tvm_op(%1386, %1387, %1388) /* ty=() */;
    let %storage_0217: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][226]) /* ty=Storage[] */;
    let %tensor_0213: int64 = memory.alloc_tensor(%storage_0217, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][226]) /* ty=int64 */;
    %1389 = fn (%p0212: int64, Primitive=1) -> int64 {
      multiply(%p0212, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1390 = (%tensor_0212,);
    %1391 = (%tensor_0213,);
    let %v212: () = vm.invoke_tvm_op(%1389, %1390, %1391) /* ty=() */;
    let %storage_0218: Storage[] = memory.alloc_storage(%tensor_0213, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][227]) /* ty=Storage[] */;
    let %out_04: Tensor[(?), float32] = memory.alloc_tensor(%storage_0218, 0 /* ty=int64 */, %shape_func_out_04, meta[relay.attrs.AllocTensorAttrs][227]) /* ty=Tensor[(?), float32] */;
    %1392 = (%x295, meta[relay.Constant][322] /* ty=Tensor[(1, 1), int64] */, %x307, %x311);
    %1393 = (%out_04,);
    let %v213: () = vm.invoke_tvm_op(%1383, %1392, %1393) /* ty=() */;
    let %x316: Tensor[(?), float32] = %out_04;
    let %storage_0219: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][228]) /* ty=Storage[] */;
    let %tensor_0214: float32 = memory.alloc_tensor(%storage_0219, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][228]) /* ty=float32 */;
    %1394 = fn (%p0213: Tensor[(?), float32], Primitive=1) -> float32 {
      min(%p0213) /* ty=float32 */
    };
    %1395 = (%x316,);
    %1396 = (%tensor_0214,);
    let %v214: () = vm.invoke_tvm_op(%1394, %1395, %1396) /* ty=() */;
    let %x317: float32 = %tensor_0214;
    let %in_shape_02: Tensor[(1), int64] = vm.shape_of(%x316, meta[relay.attrs.ShapeOfAttrs][3]) /* ty=Tensor[(1), int64] */;
    let %storage_0220: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][229]) /* ty=Storage[] */;
    let %tensor_0215: Tensor[(1), int64] = memory.alloc_tensor(%storage_0220, 0 /* ty=int64 */, meta[relay.Constant][333] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][229]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_05: Tensor[(1), int64] = %tensor_0215;
    %1398 = fn (%p0214: Tensor[(?), float32], %p1189: float32, Primitive=1) -> Tensor[(?), float32] {
      %1397 = subtract(%p0214, %p1189) /* ty=Tensor[(?), float32] */;
      add(%1397, 1f /* ty=float32 */) /* ty=Tensor[(?), float32] */
    };
    %1399 = (%in_shape_02, 1683439200 /* ty=int64 */);
    %1400 = (%shape_func_out_05,);
    let %shape_func5: () = vm.shape_func(%1398, %1399, %1400, meta[relay.attrs.ShapeFuncAttrs][5]) /* ty=() */;
    let %storage_0221: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][230]) /* ty=Storage[] */;
    let %tensor_0216: int64 = memory.alloc_tensor(%storage_0221, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][230]) /* ty=int64 */;
    %1401 = fn (%p0215: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0215) /* ty=int64 */
    };
    %1402 = (%shape_func_out_05,);
    %1403 = (%tensor_0216,);
    let %v215: () = vm.invoke_tvm_op(%1401, %1402, %1403) /* ty=() */;
    let %storage_0222: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][231]) /* ty=Storage[] */;
    let %tensor_0217: int64 = memory.alloc_tensor(%storage_0222, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][231]) /* ty=int64 */;
    %1404 = fn (%p0216: int64, Primitive=1) -> int64 {
      multiply(%p0216, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1405 = (%tensor_0216,);
    %1406 = (%tensor_0217,);
    let %v216: () = vm.invoke_tvm_op(%1404, %1405, %1406) /* ty=() */;
    let %storage_0223: Storage[] = memory.alloc_storage(%tensor_0217, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][232]) /* ty=Storage[] */;
    let %out_05: Tensor[(?), float32] = memory.alloc_tensor(%storage_0223, 0 /* ty=int64 */, %shape_func_out_05, meta[relay.attrs.AllocTensorAttrs][232]) /* ty=Tensor[(?), float32] */;
    %1407 = (%x316, %x317);
    %1408 = (%out_05,);
    let %v217: () = vm.invoke_tvm_op(%1398, %1407, %1408) /* ty=() */;
    let %x318: Tensor[(?), float32] = %out_05;
    let %in_shape_31: Tensor[(1), int64] = vm.shape_of(%x311, meta[relay.attrs.ShapeOfAttrs][4]) /* ty=Tensor[(1), int64] */;
    let %in_shape_4: Tensor[(1), int64] = vm.shape_of(%x318, meta[relay.attrs.ShapeOfAttrs][5]) /* ty=Tensor[(1), int64] */;
    let %in_shape_5: Tensor[(2), int64] = vm.shape_of(%x312, meta[relay.attrs.ShapeOfAttrs][6]) /* ty=Tensor[(2), int64] */;
    let %storage_0224: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][233]) /* ty=Storage[] */;
    let %tensor_0218: Tensor[(3), int64] = memory.alloc_tensor(%storage_0224, 0 /* ty=int64 */, meta[relay.Constant][334] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][233]) /* ty=Tensor[(3), int64] */;
    let %shape_func_out_06: Tensor[(3), int64] = %tensor_0218;
    %1431 = fn (%p0217: Tensor[(1, 159882), float32], %p1190: Tensor[(1, 1), int64], %p281: Tensor[(1, 4507), int64], %p360: Tensor[(?), int64], %p456: Tensor[(?), float32], %p518: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(1, ?, 6), float32] {
      %1409 = full(0 /* ty=int32 */, shape=[120000], dtype="int64") /* ty=Tensor[(120000), int64] */;
      %1410 = full(1 /* ty=int32 */, shape=[30000], dtype="int64") /* ty=Tensor[(30000), int64] */;
      %1411 = full(2 /* ty=int32 */, shape=[7500], dtype="int64") /* ty=Tensor[(7500), int64] */;
      %1412 = full(3 /* ty=int32 */, shape=[1875], dtype="int64") /* ty=Tensor[(1875), int64] */;
      %1413 = full(4 /* ty=int32 */, shape=[507], dtype="int64") /* ty=Tensor[(507), int64] */;
      %1414 = (%1409, %1410, %1411, %1412, %1413);
      %1415 = concatenate(%1414) /* ty=Tensor[(159882), int64] */;
      %1416 = reshape(%1415, newshape=[1, -1]) /* ty=Tensor[(1, 159882), int64] */;
      %1417 = cast(%p0217, dtype="int64") /* ty=Tensor[(1, 159882), int64] */;
      %1418 = broadcast_to_like(%1416, %1417) /* ty=Tensor[(1, 159882), int64] */;
      %1419 = (%1418, %p1190, %p281);
      %1420 = adv_index(%1419) /* ty=Tensor[(1, 4507), int64] */;
      %1421 = split(%1420, indices_or_sections=1) /* ty=(Tensor[(1, 4507), int64],) */;
      %1422 = %1421.0;
      %1423 = squeeze(%1422, axis=[0]) /* ty=Tensor[(4507), int64] */;
      %1424 = (%1423, %p360);
      %1425 = adv_index(%1424) /* ty=Tensor[(?), int64] */;
      %1426 = expand_dims(%1425, axis=-1) /* ty=Tensor[(?, 1), int64] */;
      %1427 = cast(%1426, dtype="float32") /* ty=Tensor[(?, 1), float32] */;
      %1428 = expand_dims(%p456, axis=-1) /* ty=Tensor[(?, 1), float32] */;
      %1429 = (%1427, %1428, %p518);
      %1430 = concatenate(%1429, axis=-1) /* ty=Tensor[(?, 6), float32] */;
      expand_dims(%1430, axis=0) /* ty=Tensor[(1, ?, 6), float32] */
    };
    %1432 = (meta[relay.Constant][335] /* ty=Tensor[(2), int64] */, meta[relay.Constant][336] /* ty=Tensor[(2), int64] */, meta[relay.Constant][337] /* ty=Tensor[(2), int64] */, %in_shape_31, %in_shape_4, %in_shape_5);
    %1433 = (%shape_func_out_06,);
    let %shape_func6: () = vm.shape_func(%1431, %1432, %1433, meta[relay.attrs.ShapeFuncAttrs][6]) /* ty=() */;
    let %storage_0225: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][234]) /* ty=Storage[] */;
    let %tensor_0219: int64 = memory.alloc_tensor(%storage_0225, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][234]) /* ty=int64 */;
    %1434 = fn (%p0218: Tensor[(3), int64], Primitive=1) -> int64 {
      prod(%p0218) /* ty=int64 */
    };
    %1435 = (%shape_func_out_06,);
    %1436 = (%tensor_0219,);
    let %v218: () = vm.invoke_tvm_op(%1434, %1435, %1436) /* ty=() */;
    let %storage_0226: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][235]) /* ty=Storage[] */;
    let %tensor_0220: int64 = memory.alloc_tensor(%storage_0226, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][235]) /* ty=int64 */;
    %1437 = fn (%p0219: int64, Primitive=1) -> int64 {
      multiply(%p0219, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1438 = (%tensor_0219,);
    %1439 = (%tensor_0220,);
    let %v219: () = vm.invoke_tvm_op(%1437, %1438, %1439) /* ty=() */;
    let %storage_0227: Storage[] = memory.alloc_storage(%tensor_0220, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][236]) /* ty=Storage[] */;
    let %out_06: Tensor[(1, ?, 6), float32] = memory.alloc_tensor(%storage_0227, 0 /* ty=int64 */, %shape_func_out_06, meta[relay.attrs.AllocTensorAttrs][236]) /* ty=Tensor[(1, ?, 6), float32] */;
    %1440 = (%x295, meta[relay.Constant][322] /* ty=Tensor[(1, 1), int64] */, %x307, %x311, %x318, %x312);
    %1441 = (%out_06,);
    let %v220: () = vm.invoke_tvm_op(%1431, %1440, %1441) /* ty=() */;
    let %x319: Tensor[(1, ?, 6), float32] = %out_06;
    let %storage_0228: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][237]) /* ty=Storage[] */;
    let %tensor_0221: Tensor[(1), int32] = memory.alloc_tensor(%storage_0228, 0 /* ty=int64 */, meta[relay.Constant][338] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][237]) /* ty=Tensor[(1), int32] */;
    %1442 = fn (%p0220: Tensor[(?), float32], Primitive=1) -> Tensor[(1), int32] {
      shape_of(%p0220, dtype="int32") /* ty=Tensor[(1), int32] */
    };
    %1443 = (%x318,);
    %1444 = (%tensor_0221,);
    let %v221: () = vm.invoke_tvm_op(%1442, %1443, %1444) /* ty=() */;
    let %x320: Tensor[(1), int32] = %tensor_0221;
    let %storage_0229: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][238]) /* ty=Storage[] */;
    let %tensor_0222: int32 = memory.alloc_tensor(%storage_0229, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][238]) /* ty=int32 */;
    %1445 = fn (%p0221: Tensor[(1), int32], Primitive=1) -> int32 {
      squeeze(%p0221) /* ty=int32 */
    };
    %1446 = (%x320,);
    %1447 = (%tensor_0222,);
    let %v222: () = vm.invoke_tvm_op(%1445, %1446, %1447) /* ty=() */;
    let %x321: int32 = %tensor_0222;
    let %in_shape_03: int32 = device_copy(0 /* ty=int32 */, meta[relay.attrs.DeviceCopyAttrs][1]) /* ty=int32 */;
    let %in_shape_11: int32 = device_copy(%x321, meta[relay.attrs.DeviceCopyAttrs][2]) /* ty=int32 */;
    let %in_shape_2: int32 = device_copy(1 /* ty=int32 */, meta[relay.attrs.DeviceCopyAttrs][3]) /* ty=int32 */;
    let %storage_0230: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][239]) /* ty=Storage[] */;
    let %tensor_0223: Tensor[(1), int64] = memory.alloc_tensor(%storage_0230, 0 /* ty=int64 */, meta[relay.Constant][339] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][239]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_07: Tensor[(1), int64] = %tensor_0223;
    %1448 = fn (%p0222: int32, %p1191: int32, %p282: int32, Primitive=1) -> Tensor[(?), int32] {
      arange(%p0222, %p1191, %p282, start=meta[relay.Constant][340], stop=meta[relay.Call][0], step=meta[relay.Constant][341], dtype="int32") /* ty=Tensor[(?), int32] */
    };
    %1449 = (%in_shape_03, %in_shape_11, %in_shape_2);
    %1450 = (%shape_func_out_07,);
    let %shape_func7: () = vm.shape_func(%1448, %1449, %1450, meta[relay.attrs.ShapeFuncAttrs][7]) /* ty=() */;
    let %storage_0231: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][240]) /* ty=Storage[] */;
    let %tensor_0224: int64 = memory.alloc_tensor(%storage_0231, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][240]) /* ty=int64 */;
    %1451 = fn (%p0223: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0223) /* ty=int64 */
    };
    %1452 = (%shape_func_out_07,);
    %1453 = (%tensor_0224,);
    let %v223: () = vm.invoke_tvm_op(%1451, %1452, %1453) /* ty=() */;
    let %storage_0232: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][241]) /* ty=Storage[] */;
    let %tensor_0225: int64 = memory.alloc_tensor(%storage_0232, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][241]) /* ty=int64 */;
    %1454 = fn (%p0224: int64, Primitive=1) -> int64 {
      multiply(%p0224, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1455 = (%tensor_0224,);
    %1456 = (%tensor_0225,);
    let %v224: () = vm.invoke_tvm_op(%1454, %1455, %1456) /* ty=() */;
    let %storage_0233: Storage[] = memory.alloc_storage(%tensor_0225, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][242]) /* ty=Storage[] */;
    let %out_07: Tensor[(?), int32] = memory.alloc_tensor(%storage_0233, 0 /* ty=int64 */, %shape_func_out_07, meta[relay.attrs.AllocTensorAttrs][242]) /* ty=Tensor[(?), int32] */;
    %1457 = (0 /* ty=int32 */, %x321, 1 /* ty=int32 */);
    %1458 = (%out_07,);
    let %v225: () = vm.invoke_tvm_op(%1448, %1457, %1458) /* ty=() */;
    let %x322: Tensor[(?), int32] = %out_07;
    let %in_shape_04: Tensor[(1), int64] = vm.shape_of(%x322, meta[relay.attrs.ShapeOfAttrs][7]) /* ty=Tensor[(1), int64] */;
    let %storage_0234: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][243]) /* ty=Storage[] */;
    let %tensor_0226: Tensor[(2), int64] = memory.alloc_tensor(%storage_0234, 0 /* ty=int64 */, meta[relay.Constant][342] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][243]) /* ty=Tensor[(2), int64] */;
    let %shape_func_out_08: Tensor[(2), int64] = %tensor_0226;
    %1459 = fn (%p0225: Tensor[(?), int32], Primitive=1) -> Tensor[(1, ?), int32] {
      expand_dims(%p0225, axis=0) /* ty=Tensor[(1, ?), int32] */
    };
    %1460 = (%in_shape_04,);
    %1461 = (%shape_func_out_08,);
    let %shape_func8: () = vm.shape_func(%1459, %1460, %1461, meta[relay.attrs.ShapeFuncAttrs][8]) /* ty=() */;
    let %storage_0235: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][244]) /* ty=Storage[] */;
    let %tensor_0227: int64 = memory.alloc_tensor(%storage_0235, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][244]) /* ty=int64 */;
    %1462 = fn (%p0226: Tensor[(2), int64], Primitive=1) -> int64 {
      prod(%p0226) /* ty=int64 */
    };
    %1463 = (%shape_func_out_08,);
    %1464 = (%tensor_0227,);
    let %v226: () = vm.invoke_tvm_op(%1462, %1463, %1464) /* ty=() */;
    let %storage_0236: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][245]) /* ty=Storage[] */;
    let %tensor_0228: int64 = memory.alloc_tensor(%storage_0236, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][245]) /* ty=int64 */;
    %1465 = fn (%p0227: int64, Primitive=1) -> int64 {
      multiply(%p0227, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1466 = (%tensor_0227,);
    %1467 = (%tensor_0228,);
    let %v227: () = vm.invoke_tvm_op(%1465, %1466, %1467) /* ty=() */;
    let %storage_0237: Storage[] = memory.alloc_storage(%tensor_0228, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][246]) /* ty=Storage[] */;
    let %out_08: Tensor[(1, ?), int32] = memory.alloc_tensor(%storage_0237, 0 /* ty=int64 */, %shape_func_out_08, meta[relay.attrs.AllocTensorAttrs][246]) /* ty=Tensor[(1, ?), int32] */;
    %1468 = (%x322,);
    %1469 = (%out_08,);
    let %v228: () = vm.invoke_tvm_op(%1459, %1468, %1469) /* ty=() */;
    let %x323: Tensor[(1, ?), int32] = %out_08;
    let %in_shape_05: Tensor[(3), int64] = vm.shape_of(%x319, meta[relay.attrs.ShapeOfAttrs][8]) /* ty=Tensor[(3), int64] */;
    let %in_shape_21: Tensor[(2), int64] = vm.shape_of(%x323, meta[relay.attrs.ShapeOfAttrs][9]) /* ty=Tensor[(2), int64] */;
    let %storage_0238: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][247]) /* ty=Storage[] */;
    let %tensor_0229: Tensor[(2), int64] = memory.alloc_tensor(%storage_0238, 0 /* ty=int64 */, meta[relay.Constant][343] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][247]) /* ty=Tensor[(2), int64] */;
    let %shape_func_out_09: Tensor[(2), int64] = %tensor_0229;
    let %storage_16: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][248]) /* ty=Storage[] */;
    let %tensor_16: Tensor[(2), int64] = memory.alloc_tensor(%storage_16, 0 /* ty=int64 */, meta[relay.Constant][344] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][248]) /* ty=Tensor[(2), int64] */;
    let %shape_func_out_1: Tensor[(2), int64] = %tensor_16;
    %1470 = fn (%p0228: Tensor[(1, ?, 6), float32], %p1192: Tensor[(1), int32], %p283: Tensor[(1, ?), int32], %p361: int32, %p457: float32, Primitive=1) -> (Tensor[(1, ?), int32], Tensor[(1, 1), int32]) {
      vision.non_max_suppression(%p0228, %p1192, %p283, %p361, %p457, meta[relay.attrs.NonMaximumSuppressionAttrs][0]) /* ty=(Tensor[(1, ?), int32], Tensor[(1, 1), int32]) */
    };
    %1471 = (%in_shape_05, meta[relay.Constant][345] /* ty=Tensor[(1), int64] */, %in_shape_21, 1498088592 /* ty=int64 */, 931749024 /* ty=int64 */);
    %1472 = (%shape_func_out_09, %shape_func_out_1);
    let %shape_func9: () = vm.shape_func(%1470, %1471, %1472, meta[relay.attrs.ShapeFuncAttrs][9]) /* ty=() */;
    let %storage_0239: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][249]) /* ty=Storage[] */;
    let %tensor_0230: int64 = memory.alloc_tensor(%storage_0239, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][249]) /* ty=int64 */;
    %1473 = fn (%p0229: Tensor[(2), int64], Primitive=1) -> int64 {
      prod(%p0229) /* ty=int64 */
    };
    %1474 = (%shape_func_out_09,);
    %1475 = (%tensor_0230,);
    let %v229: () = vm.invoke_tvm_op(%1473, %1474, %1475) /* ty=() */;
    let %storage_0240: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][250]) /* ty=Storage[] */;
    let %tensor_0231: int64 = memory.alloc_tensor(%storage_0240, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][250]) /* ty=int64 */;
    %1476 = fn (%p0230: int64, Primitive=1) -> int64 {
      multiply(%p0230, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1477 = (%tensor_0230,);
    %1478 = (%tensor_0231,);
    let %v230: () = vm.invoke_tvm_op(%1476, %1477, %1478) /* ty=() */;
    let %storage_0241: Storage[] = memory.alloc_storage(%tensor_0231, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][251]) /* ty=Storage[] */;
    let %storage_0242: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][252]) /* ty=Storage[] */;
    let %tensor_0232: int64 = memory.alloc_tensor(%storage_0242, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][251]) /* ty=int64 */;
    %1479 = fn (%p0231: Tensor[(2), int64], Primitive=1) -> int64 {
      prod(%p0231) /* ty=int64 */
    };
    %1480 = (%shape_func_out_1,);
    %1481 = (%tensor_0232,);
    let %v231: () = vm.invoke_tvm_op(%1479, %1480, %1481) /* ty=() */;
    let %storage_0243: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][253]) /* ty=Storage[] */;
    let %tensor_0233: int64 = memory.alloc_tensor(%storage_0243, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][252]) /* ty=int64 */;
    %1482 = fn (%p0232: int64, Primitive=1) -> int64 {
      multiply(%p0232, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1483 = (%tensor_0232,);
    %1484 = (%tensor_0233,);
    let %v232: () = vm.invoke_tvm_op(%1482, %1483, %1484) /* ty=() */;
    let %storage_17: Storage[] = memory.alloc_storage(%tensor_0233, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][254]) /* ty=Storage[] */;
    let %out_09: Tensor[(1, ?), int32] = memory.alloc_tensor(%storage_0241, 0 /* ty=int64 */, %shape_func_out_09, meta[relay.attrs.AllocTensorAttrs][253]) /* ty=Tensor[(1, ?), int32] */;
    let %out_1: Tensor[(1, 1), int32] = memory.alloc_tensor(%storage_17, 0 /* ty=int64 */, %shape_func_out_1, meta[relay.attrs.AllocTensorAttrs][254]) /* ty=Tensor[(1, 1), int32] */;
    %1485 = (%x319, %x320, %x323, 1000 /* ty=int32 */, 0.7f /* ty=float32 */);
    %1486 = (%out_09, %out_1);
    let %v233: () = vm.invoke_tvm_op(%1470, %1485, %1486) /* ty=() */;
    let %x324: (Tensor[(1, ?), int32], Tensor[(1, 1), int32]) = (%out_09, %out_1);
    %1487 = %x324.0;
    let %in_shape_06: Tensor[(2), int64] = vm.shape_of(%1487, meta[relay.attrs.ShapeOfAttrs][10]) /* ty=Tensor[(2), int64] */;
    let %storage_0244: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][255]) /* ty=Storage[] */;
    let %tensor_0234: Tensor[(1), int64] = memory.alloc_tensor(%storage_0244, 0 /* ty=int64 */, meta[relay.Constant][346] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][255]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_010: Tensor[(1), int64] = %tensor_0234;
    %1489 = fn (%p0233: (Tensor[(1, ?), int32], Tensor[(1, 1), int32]), Primitive=1) -> Tensor[(?), int32] {
      %1488 = %p0233.0;
      squeeze(%1488, axis=[0]) /* ty=Tensor[(?), int32] */
    };
    %1490 = (%in_shape_06, meta[relay.Constant][347] /* ty=Tensor[(2), int64] */);
    %1491 = (%shape_func_out_010,);
    let %shape_func10: () = vm.shape_func(%1489, %1490, %1491, meta[relay.attrs.ShapeFuncAttrs][10]) /* ty=() */;
    let %storage_0245: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][256]) /* ty=Storage[] */;
    let %tensor_0235: int64 = memory.alloc_tensor(%storage_0245, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][256]) /* ty=int64 */;
    %1492 = fn (%p0234: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0234) /* ty=int64 */
    };
    %1493 = (%shape_func_out_010,);
    %1494 = (%tensor_0235,);
    let %v234: () = vm.invoke_tvm_op(%1492, %1493, %1494) /* ty=() */;
    let %storage_0246: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][257]) /* ty=Storage[] */;
    let %tensor_0236: int64 = memory.alloc_tensor(%storage_0246, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][257]) /* ty=int64 */;
    %1495 = fn (%p0235: int64, Primitive=1) -> int64 {
      multiply(%p0235, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1496 = (%tensor_0235,);
    %1497 = (%tensor_0236,);
    let %v235: () = vm.invoke_tvm_op(%1495, %1496, %1497) /* ty=() */;
    let %storage_0247: Storage[] = memory.alloc_storage(%tensor_0236, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][258]) /* ty=Storage[] */;
    let %out_010: Tensor[(?), int32] = memory.alloc_tensor(%storage_0247, 0 /* ty=int64 */, %shape_func_out_010, meta[relay.attrs.AllocTensorAttrs][258]) /* ty=Tensor[(?), int32] */;
    %1498 = (%x324,);
    %1499 = (%out_010,);
    let %v236: () = vm.invoke_tvm_op(%1489, %1498, %1499) /* ty=() */;
    let %x325: Tensor[(?), int32] = %out_010;
    let %storage_0248: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][259]) /* ty=Storage[] */;
    let %tensor_0237: Tensor[(1), int32] = memory.alloc_tensor(%storage_0248, 0 /* ty=int64 */, meta[relay.Constant][348] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][259]) /* ty=Tensor[(1), int32] */;
    %1500 = fn (%p0236: Tensor[(?), int32], Primitive=1) -> Tensor[(1), int32] {
      shape_of(%p0236, dtype="int32") /* ty=Tensor[(1), int32] */
    };
    %1501 = (%x325,);
    %1502 = (%tensor_0237,);
    let %v237: () = vm.invoke_tvm_op(%1500, %1501, %1502) /* ty=() */;
    let %x326: Tensor[(1), int32] = %tensor_0237;
    let %storage_0249: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][260]) /* ty=Storage[] */;
    let %tensor_0238: Tensor[(1), int32] = memory.alloc_tensor(%storage_0249, 0 /* ty=int64 */, meta[relay.Constant][349] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][260]) /* ty=Tensor[(1), int32] */;
    %1505 = fn (%p0237: Tensor[(1), bool], %p1193: Tensor[(1), int32], %p284: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
      %1503 = cast_like(%p284, %p1193) /* ty=Tensor[(1), int32] */;
      %1504 = add(%p1193, %1503) /* ty=Tensor[(1), int32] */;
      where(%p0237, %1504, %p1193) /* ty=Tensor[(1), int32] */
    };
    %1506 = (meta[relay.Constant][350] /* ty=Tensor[(1), bool] */, meta[relay.Constant][351] /* ty=Tensor[(1), int32] */, %x326);
    %1507 = (%tensor_0238,);
    let %v238: () = vm.invoke_tvm_op(%1505, %1506, %1507) /* ty=() */;
    let %x327: Tensor[(1), int32] = %tensor_0238;
    let %storage_0250: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][261]) /* ty=Storage[] */;
    let %tensor_0239: Tensor[(1), int32] = memory.alloc_tensor(%storage_0250, 0 /* ty=int64 */, meta[relay.Constant][352] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][261]) /* ty=Tensor[(1), int32] */;
    %1509 = fn (%p0238: (Tensor[(1, ?), int32], Tensor[(1, 1), int32]), Primitive=1) -> Tensor[(1), int32] {
      %1508 = %p0238.1;
      squeeze(%1508, axis=[1]) /* ty=Tensor[(1), int32] */
    };
    %1510 = (%x324,);
    %1511 = (%tensor_0239,);
    let %v239: () = vm.invoke_tvm_op(%1509, %1510, %1511) /* ty=() */;
    let %x328: Tensor[(1), int32] = %tensor_0239;
    let %in_shape_07: Tensor[(?), int32] = device_copy(%x325, meta[relay.attrs.DeviceCopyAttrs][4]) /* ty=Tensor[(?), int32] */;
    let %in_shape_12: Tensor[(1), int32] = device_copy(%x327, meta[relay.attrs.DeviceCopyAttrs][5]) /* ty=Tensor[(1), int32] */;
    let %in_shape_22: Tensor[(1), int32] = device_copy(%x328, meta[relay.attrs.DeviceCopyAttrs][6]) /* ty=Tensor[(1), int32] */;
    let %in_shape_32: Tensor[(1), int32] = device_copy(meta[relay.Constant][353] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][7]) /* ty=Tensor[(1), int32] */;
    let %storage_0251: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][262]) /* ty=Storage[] */;
    let %tensor_0240: Tensor[(1), int64] = memory.alloc_tensor(%storage_0251, 0 /* ty=int64 */, meta[relay.Constant][354] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][262]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_011: Tensor[(1), int64] = %tensor_0240;
    %1512 = fn (%p0239: Tensor[(?), int32], %p1194: Tensor[(1), int32], %p285: Tensor[(1), int32], %p362: Tensor[(1), int32], Primitive=1) -> Tensor[(?), int32] {
      dyn.strided_slice(%p0239, %p1194, %p285, %p362, begin=None, end=None, strides=None, slice_mode="size") /* ty=Tensor[(?), int32] */
    };
    %1513 = (%in_shape_07, %in_shape_12, %in_shape_22, %in_shape_32);
    %1514 = (%shape_func_out_011,);
    let %shape_func11: () = vm.shape_func(%1512, %1513, %1514, meta[relay.attrs.ShapeFuncAttrs][11]) /* ty=() */;
    let %storage_0252: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][263]) /* ty=Storage[] */;
    let %tensor_0241: int64 = memory.alloc_tensor(%storage_0252, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][263]) /* ty=int64 */;
    %1515 = fn (%p0240: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0240) /* ty=int64 */
    };
    %1516 = (%shape_func_out_011,);
    %1517 = (%tensor_0241,);
    let %v240: () = vm.invoke_tvm_op(%1515, %1516, %1517) /* ty=() */;
    let %storage_0253: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][264]) /* ty=Storage[] */;
    let %tensor_0242: int64 = memory.alloc_tensor(%storage_0253, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][264]) /* ty=int64 */;
    %1518 = fn (%p0241: int64, Primitive=1) -> int64 {
      multiply(%p0241, 4 /* ty=int64 */) /* ty=int64 */
    };
    %1519 = (%tensor_0241,);
    %1520 = (%tensor_0242,);
    let %v241: () = vm.invoke_tvm_op(%1518, %1519, %1520) /* ty=() */;
    let %storage_0254: Storage[] = memory.alloc_storage(%tensor_0242, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][265]) /* ty=Storage[] */;
    let %out_011: Tensor[(?), int32] = memory.alloc_tensor(%storage_0254, 0 /* ty=int64 */, %shape_func_out_011, meta[relay.attrs.AllocTensorAttrs][265]) /* ty=Tensor[(?), int32] */;
    %1521 = (%x325, %x327, %x328, meta[relay.Constant][353] /* ty=Tensor[(1), int32] */);
    %1522 = (%out_011,);
    let %v242: () = vm.invoke_tvm_op(%1512, %1521, %1522) /* ty=() */;
    let %x329: Tensor[(?), int32] = %out_011;
    let %in_shape_08: Tensor[(1), int64] = vm.shape_of(%x329, meta[relay.attrs.ShapeOfAttrs][11]) /* ty=Tensor[(1), int64] */;
    let %storage_0255: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][266]) /* ty=Storage[] */;
    let %tensor_0243: Tensor[(1), int64] = memory.alloc_tensor(%storage_0255, 0 /* ty=int64 */, meta[relay.Constant][355] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][266]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_012: Tensor[(1), int64] = %tensor_0243;
    %1523 = fn (%p0242: Tensor[(?), int32], Primitive=1) -> Tensor[(?), int64] {
      cast(%p0242, dtype="int64") /* ty=Tensor[(?), int64] */
    };
    %1524 = (%in_shape_08,);
    %1525 = (%shape_func_out_012,);
    let %shape_func12: () = vm.shape_func(%1523, %1524, %1525, meta[relay.attrs.ShapeFuncAttrs][12]) /* ty=() */;
    let %storage_0256: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][267]) /* ty=Storage[] */;
    let %tensor_0244: int64 = memory.alloc_tensor(%storage_0256, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][267]) /* ty=int64 */;
    %1526 = fn (%p0243: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0243) /* ty=int64 */
    };
    %1527 = (%shape_func_out_012,);
    %1528 = (%tensor_0244,);
    let %v243: () = vm.invoke_tvm_op(%1526, %1527, %1528) /* ty=() */;
    let %storage_0257: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][268]) /* ty=Storage[] */;
    let %tensor_0245: int64 = memory.alloc_tensor(%storage_0257, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][268]) /* ty=int64 */;
    %1529 = fn (%p0244: int64, Primitive=1) -> int64 {
      multiply(%p0244, 8 /* ty=int64 */) /* ty=int64 */
    };
    %1530 = (%tensor_0244,);
    %1531 = (%tensor_0245,);
    let %v244: () = vm.invoke_tvm_op(%1529, %1530, %1531) /* ty=() */;
    let %storage_0258: Storage[] = memory.alloc_storage(%tensor_0245, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][269]) /* ty=Storage[] */;
    let %out_012: Tensor[(?), int64] = memory.alloc_tensor(%storage_0258, 0 /* ty=int64 */, %shape_func_out_012, meta[relay.attrs.AllocTensorAttrs][269]) /* ty=Tensor[(?), int64] */;
    %1532 = (%x329,);
    %1533 = (%out_012,);
    let %v245: () = vm.invoke_tvm_op(%1523, %1532, %1533) /* ty=() */;
    let %x330: Tensor[(?), int64] = %out_012;
    %x330
  };
  let %in_shape_09: Tensor[(2), int64] = vm.shape_of(%x312, meta[relay.attrs.ShapeOfAttrs][12]) /* ty=Tensor[(2), int64] */;
  let %in_shape_13: Tensor[(1), int64] = vm.shape_of(%x314, meta[relay.attrs.ShapeOfAttrs][13]) /* ty=Tensor[(1), int64] */;
  let %storage_0259: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][270]) /* ty=Storage[] */;
  let %tensor_0246: Tensor[(2), int64] = memory.alloc_tensor(%storage_0259, 0 /* ty=int64 */, meta[relay.Constant][356] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][270]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_013: Tensor[(2), int64] = %tensor_0246;
  %1535 = fn (%p0245: Tensor[(?, 4), float32], %p1195: Tensor[(?), int64], Primitive=1) -> Tensor[(?, 4), float32] {
    %1534 = (%p0245, %p1195);
    adv_index(%1534) /* ty=Tensor[(?, 4), float32] */
  };
  %1536 = (%in_shape_09, %in_shape_13);
  %1537 = (%shape_func_out_013,);
  let %shape_func13: () = vm.shape_func(%1535, %1536, %1537, meta[relay.attrs.ShapeFuncAttrs][13]) /* ty=() */;
  let %storage_0260: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][271]) /* ty=Storage[] */;
  let %tensor_0247: int64 = memory.alloc_tensor(%storage_0260, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][271]) /* ty=int64 */;
  %1538 = fn (%p0246: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0246) /* ty=int64 */
  };
  %1539 = (%shape_func_out_013,);
  %1540 = (%tensor_0247,);
  let %v246: () = vm.invoke_tvm_op(%1538, %1539, %1540) /* ty=() */;
  let %storage_0261: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][272]) /* ty=Storage[] */;
  let %tensor_0248: int64 = memory.alloc_tensor(%storage_0261, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][272]) /* ty=int64 */;
  %1541 = fn (%p0247: int64, Primitive=1) -> int64 {
    multiply(%p0247, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1542 = (%tensor_0247,);
  %1543 = (%tensor_0248,);
  let %v247: () = vm.invoke_tvm_op(%1541, %1542, %1543) /* ty=() */;
  let %storage_0262: Storage[] = memory.alloc_storage(%tensor_0248, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][273]) /* ty=Storage[] */;
  let %out_013: Tensor[(?, 4), float32] = memory.alloc_tensor(%storage_0262, 0 /* ty=int64 */, %shape_func_out_013, meta[relay.attrs.AllocTensorAttrs][273]) /* ty=Tensor[(?, 4), float32] */;
  %1544 = (%x312, %x314);
  %1545 = (%out_013,);
  let %v248: () = vm.invoke_tvm_op(%1535, %1544, %1545) /* ty=() */;
  let %x331: Tensor[(?, 4), float32] = %out_013;
  let %storage_0263: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][274]) /* ty=Storage[] */;
  let %tensor_0249: Tensor[(2), int32] = memory.alloc_tensor(%storage_0263, 0 /* ty=int64 */, meta[relay.Constant][357] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][274]) /* ty=Tensor[(2), int32] */;
  %1546 = fn (%p0248: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0248, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %1547 = (%x331,);
  %1548 = (%tensor_0249,);
  let %v249: () = vm.invoke_tvm_op(%1546, %1547, %1548) /* ty=() */;
  let %x332: Tensor[(2), int32] = %tensor_0249;
  let %storage_0264: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][275]) /* ty=Storage[] */;
  let %tensor_0250: Tensor[(2), int32] = memory.alloc_tensor(%storage_0264, 0 /* ty=int64 */, meta[relay.Constant][358] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][275]) /* ty=Tensor[(2), int32] */;
  %1551 = fn (%p0249: Tensor[(2), bool], %p1196: Tensor[(2), int32], %p286: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %1549 = cast_like(%p286, %p1196) /* ty=Tensor[(2), int32] */;
    %1550 = add(%p1196, %1549) /* ty=Tensor[(2), int32] */;
    where(%p0249, %1550, %p1196) /* ty=Tensor[(2), int32] */
  };
  %1552 = (meta[relay.Constant][359] /* ty=Tensor[(2), bool] */, meta[relay.Constant][360] /* ty=Tensor[(2), int32] */, %x332);
  %1553 = (%tensor_0250,);
  let %v250: () = vm.invoke_tvm_op(%1551, %1552, %1553) /* ty=() */;
  let %x333: Tensor[(2), int32] = %tensor_0250;
  let %storage_0265: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][276]) /* ty=Storage[] */;
  let %tensor_0251: Tensor[(2), int64] = memory.alloc_tensor(%storage_0265, 0 /* ty=int64 */, meta[relay.Constant][361] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][276]) /* ty=Tensor[(2), int64] */;
  %1554 = fn (%p0250: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0250, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %1555 = (%x332,);
  %1556 = (%tensor_0251,);
  let %v251: () = vm.invoke_tvm_op(%1554, %1555, %1556) /* ty=() */;
  let %x334: Tensor[(2), int64] = %tensor_0251;
  let %in_shape_010: Tensor[(?, 4), float32] = device_copy(%x331, meta[relay.attrs.DeviceCopyAttrs][8]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_14: Tensor[(2), int32] = device_copy(%x333, meta[relay.attrs.DeviceCopyAttrs][9]) /* ty=Tensor[(2), int32] */;
  let %in_shape_23: Tensor[(2), int64] = device_copy(%x334, meta[relay.attrs.DeviceCopyAttrs][10]) /* ty=Tensor[(2), int64] */;
  let %in_shape_33: Tensor[(2), int32] = device_copy(meta[relay.Constant][362] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][11]) /* ty=Tensor[(2), int32] */;
  let %storage_0266: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][277]) /* ty=Storage[] */;
  let %tensor_0252: Tensor[(2), int64] = memory.alloc_tensor(%storage_0266, 0 /* ty=int64 */, meta[relay.Constant][363] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][277]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_014: Tensor[(2), int64] = %tensor_0252;
  %1557 = fn (%p0251: Tensor[(?, 4), float32], %p1197: Tensor[(2), int32], %p287: Tensor[(2), int64], %p363: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0251, %p1197, %p287, %p363, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %1558 = (%in_shape_010, %in_shape_14, %in_shape_23, %in_shape_33);
  %1559 = (%shape_func_out_014,);
  let %shape_func14: () = vm.shape_func(%1557, %1558, %1559, meta[relay.attrs.ShapeFuncAttrs][14]) /* ty=() */;
  let %storage_0267: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][278]) /* ty=Storage[] */;
  let %tensor_0253: int64 = memory.alloc_tensor(%storage_0267, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][278]) /* ty=int64 */;
  %1560 = fn (%p0252: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0252) /* ty=int64 */
  };
  %1561 = (%shape_func_out_014,);
  %1562 = (%tensor_0253,);
  let %v252: () = vm.invoke_tvm_op(%1560, %1561, %1562) /* ty=() */;
  let %storage_0268: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][279]) /* ty=Storage[] */;
  let %tensor_0254: int64 = memory.alloc_tensor(%storage_0268, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][279]) /* ty=int64 */;
  %1563 = fn (%p0253: int64, Primitive=1) -> int64 {
    multiply(%p0253, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1564 = (%tensor_0253,);
  %1565 = (%tensor_0254,);
  let %v253: () = vm.invoke_tvm_op(%1563, %1564, %1565) /* ty=() */;
  let %storage_0269: Storage[] = memory.alloc_storage(%tensor_0254, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][280]) /* ty=Storage[] */;
  let %out_014: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0269, 0 /* ty=int64 */, %shape_func_out_014, meta[relay.attrs.AllocTensorAttrs][280]) /* ty=Tensor[(?, ?), float32] */;
  %1566 = (%x331, %x333, %x334, meta[relay.Constant][362] /* ty=Tensor[(2), int32] */);
  %1567 = (%out_014,);
  let %v254: () = vm.invoke_tvm_op(%1557, %1566, %1567) /* ty=() */;
  let %x335: Tensor[(?, ?), float32] = %out_014;
  let %storage_0270: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][281]) /* ty=Storage[] */;
  let %tensor_0255: Tensor[(2), int32] = memory.alloc_tensor(%storage_0270, 0 /* ty=int64 */, meta[relay.Constant][364] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][281]) /* ty=Tensor[(2), int32] */;
  %1570 = fn (%p0254: Tensor[(2), bool], %p1198: Tensor[(2), int32], %p288: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %1568 = cast_like(%p288, %p1198) /* ty=Tensor[(2), int32] */;
    %1569 = add(%p1198, %1568) /* ty=Tensor[(2), int32] */;
    where(%p0254, %1569, %p1198) /* ty=Tensor[(2), int32] */
  };
  %1571 = (meta[relay.Constant][365] /* ty=Tensor[(2), bool] */, meta[relay.Constant][366] /* ty=Tensor[(2), int32] */, %x332);
  %1572 = (%tensor_0255,);
  let %v255: () = vm.invoke_tvm_op(%1570, %1571, %1572) /* ty=() */;
  let %x336: Tensor[(2), int32] = %tensor_0255;
  let %in_shape_011: Tensor[(?, 4), float32] = device_copy(%x331, meta[relay.attrs.DeviceCopyAttrs][12]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_15: Tensor[(2), int32] = device_copy(%x336, meta[relay.attrs.DeviceCopyAttrs][13]) /* ty=Tensor[(2), int32] */;
  let %in_shape_24: Tensor[(2), int64] = device_copy(%x334, meta[relay.attrs.DeviceCopyAttrs][14]) /* ty=Tensor[(2), int64] */;
  let %in_shape_34: Tensor[(2), int32] = device_copy(meta[relay.Constant][367] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][15]) /* ty=Tensor[(2), int32] */;
  let %storage_0271: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][282]) /* ty=Storage[] */;
  let %tensor_0256: Tensor[(2), int64] = memory.alloc_tensor(%storage_0271, 0 /* ty=int64 */, meta[relay.Constant][368] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][282]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_015: Tensor[(2), int64] = %tensor_0256;
  %1573 = fn (%p0255: Tensor[(?, 4), float32], %p1199: Tensor[(2), int32], %p289: Tensor[(2), int64], %p364: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0255, %p1199, %p289, %p364, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %1574 = (%in_shape_011, %in_shape_15, %in_shape_24, %in_shape_34);
  %1575 = (%shape_func_out_015,);
  let %shape_func15: () = vm.shape_func(%1573, %1574, %1575, meta[relay.attrs.ShapeFuncAttrs][15]) /* ty=() */;
  let %storage_0272: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][283]) /* ty=Storage[] */;
  let %tensor_0257: int64 = memory.alloc_tensor(%storage_0272, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][283]) /* ty=int64 */;
  %1576 = fn (%p0256: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0256) /* ty=int64 */
  };
  %1577 = (%shape_func_out_015,);
  %1578 = (%tensor_0257,);
  let %v256: () = vm.invoke_tvm_op(%1576, %1577, %1578) /* ty=() */;
  let %storage_0273: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][284]) /* ty=Storage[] */;
  let %tensor_0258: int64 = memory.alloc_tensor(%storage_0273, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][284]) /* ty=int64 */;
  %1579 = fn (%p0257: int64, Primitive=1) -> int64 {
    multiply(%p0257, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1580 = (%tensor_0257,);
  %1581 = (%tensor_0258,);
  let %v257: () = vm.invoke_tvm_op(%1579, %1580, %1581) /* ty=() */;
  let %storage_0274: Storage[] = memory.alloc_storage(%tensor_0258, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][285]) /* ty=Storage[] */;
  let %out_015: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0274, 0 /* ty=int64 */, %shape_func_out_015, meta[relay.attrs.AllocTensorAttrs][285]) /* ty=Tensor[(?, ?), float32] */;
  %1582 = (%x331, %x336, %x334, meta[relay.Constant][367] /* ty=Tensor[(2), int32] */);
  %1583 = (%out_015,);
  let %v258: () = vm.invoke_tvm_op(%1573, %1582, %1583) /* ty=() */;
  let %x337: Tensor[(?, ?), float32] = %out_015;
  let %storage_0275: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][286]) /* ty=Storage[] */;
  let %tensor_0259: Tensor[(2), int32] = memory.alloc_tensor(%storage_0275, 0 /* ty=int64 */, meta[relay.Constant][369] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][286]) /* ty=Tensor[(2), int32] */;
  %1586 = fn (%p0258: Tensor[(2), bool], %p1200: Tensor[(2), int32], %p290: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %1584 = cast_like(%p290, %p1200) /* ty=Tensor[(2), int32] */;
    %1585 = add(%p1200, %1584) /* ty=Tensor[(2), int32] */;
    where(%p0258, %1585, %p1200) /* ty=Tensor[(2), int32] */
  };
  %1587 = (meta[relay.Constant][370] /* ty=Tensor[(2), bool] */, meta[relay.Constant][371] /* ty=Tensor[(2), int32] */, %x332);
  %1588 = (%tensor_0259,);
  let %v259: () = vm.invoke_tvm_op(%1586, %1587, %1588) /* ty=() */;
  let %x338: Tensor[(2), int32] = %tensor_0259;
  let %in_shape_012: Tensor[(?, 4), float32] = device_copy(%x331, meta[relay.attrs.DeviceCopyAttrs][16]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_16: Tensor[(2), int32] = device_copy(%x338, meta[relay.attrs.DeviceCopyAttrs][17]) /* ty=Tensor[(2), int32] */;
  let %in_shape_25: Tensor[(2), int64] = device_copy(%x334, meta[relay.attrs.DeviceCopyAttrs][18]) /* ty=Tensor[(2), int64] */;
  let %in_shape_35: Tensor[(2), int32] = device_copy(meta[relay.Constant][372] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][19]) /* ty=Tensor[(2), int32] */;
  let %storage_0276: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][287]) /* ty=Storage[] */;
  let %tensor_0260: Tensor[(2), int64] = memory.alloc_tensor(%storage_0276, 0 /* ty=int64 */, meta[relay.Constant][373] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][287]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_016: Tensor[(2), int64] = %tensor_0260;
  %1589 = fn (%p0259: Tensor[(?, 4), float32], %p1201: Tensor[(2), int32], %p291: Tensor[(2), int64], %p365: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0259, %p1201, %p291, %p365, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %1590 = (%in_shape_012, %in_shape_16, %in_shape_25, %in_shape_35);
  %1591 = (%shape_func_out_016,);
  let %shape_func16: () = vm.shape_func(%1589, %1590, %1591, meta[relay.attrs.ShapeFuncAttrs][16]) /* ty=() */;
  let %storage_0277: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][288]) /* ty=Storage[] */;
  let %tensor_0261: int64 = memory.alloc_tensor(%storage_0277, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][288]) /* ty=int64 */;
  %1592 = fn (%p0260: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0260) /* ty=int64 */
  };
  %1593 = (%shape_func_out_016,);
  %1594 = (%tensor_0261,);
  let %v260: () = vm.invoke_tvm_op(%1592, %1593, %1594) /* ty=() */;
  let %storage_0278: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][289]) /* ty=Storage[] */;
  let %tensor_0262: int64 = memory.alloc_tensor(%storage_0278, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][289]) /* ty=int64 */;
  %1595 = fn (%p0261: int64, Primitive=1) -> int64 {
    multiply(%p0261, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1596 = (%tensor_0261,);
  %1597 = (%tensor_0262,);
  let %v261: () = vm.invoke_tvm_op(%1595, %1596, %1597) /* ty=() */;
  let %storage_0279: Storage[] = memory.alloc_storage(%tensor_0262, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][290]) /* ty=Storage[] */;
  let %out_016: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0279, 0 /* ty=int64 */, %shape_func_out_016, meta[relay.attrs.AllocTensorAttrs][290]) /* ty=Tensor[(?, ?), float32] */;
  %1598 = (%x331, %x338, %x334, meta[relay.Constant][372] /* ty=Tensor[(2), int32] */);
  %1599 = (%out_016,);
  let %v262: () = vm.invoke_tvm_op(%1589, %1598, %1599) /* ty=() */;
  let %x339: Tensor[(?, ?), float32] = %out_016;
  let %storage_0280: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][291]) /* ty=Storage[] */;
  let %tensor_0263: Tensor[(2), int32] = memory.alloc_tensor(%storage_0280, 0 /* ty=int64 */, meta[relay.Constant][374] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][291]) /* ty=Tensor[(2), int32] */;
  %1602 = fn (%p0262: Tensor[(2), bool], %p1202: Tensor[(2), int32], %p292: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %1600 = cast_like(%p292, %p1202) /* ty=Tensor[(2), int32] */;
    %1601 = add(%p1202, %1600) /* ty=Tensor[(2), int32] */;
    where(%p0262, %1601, %p1202) /* ty=Tensor[(2), int32] */
  };
  %1603 = (meta[relay.Constant][375] /* ty=Tensor[(2), bool] */, meta[relay.Constant][376] /* ty=Tensor[(2), int32] */, %x332);
  %1604 = (%tensor_0263,);
  let %v263: () = vm.invoke_tvm_op(%1602, %1603, %1604) /* ty=() */;
  let %x340: Tensor[(2), int32] = %tensor_0263;
  let %in_shape_013: Tensor[(?, 4), float32] = device_copy(%x331, meta[relay.attrs.DeviceCopyAttrs][20]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_17: Tensor[(2), int32] = device_copy(%x340, meta[relay.attrs.DeviceCopyAttrs][21]) /* ty=Tensor[(2), int32] */;
  let %in_shape_26: Tensor[(2), int64] = device_copy(%x334, meta[relay.attrs.DeviceCopyAttrs][22]) /* ty=Tensor[(2), int64] */;
  let %in_shape_36: Tensor[(2), int32] = device_copy(meta[relay.Constant][377] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][23]) /* ty=Tensor[(2), int32] */;
  let %storage_0281: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][292]) /* ty=Storage[] */;
  let %tensor_0264: Tensor[(2), int64] = memory.alloc_tensor(%storage_0281, 0 /* ty=int64 */, meta[relay.Constant][378] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][292]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_017: Tensor[(2), int64] = %tensor_0264;
  %1605 = fn (%p0263: Tensor[(?, 4), float32], %p1203: Tensor[(2), int32], %p293: Tensor[(2), int64], %p366: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0263, %p1203, %p293, %p366, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %1606 = (%in_shape_013, %in_shape_17, %in_shape_26, %in_shape_36);
  %1607 = (%shape_func_out_017,);
  let %shape_func17: () = vm.shape_func(%1605, %1606, %1607, meta[relay.attrs.ShapeFuncAttrs][17]) /* ty=() */;
  let %storage_0282: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][293]) /* ty=Storage[] */;
  let %tensor_0265: int64 = memory.alloc_tensor(%storage_0282, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][293]) /* ty=int64 */;
  %1608 = fn (%p0264: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0264) /* ty=int64 */
  };
  %1609 = (%shape_func_out_017,);
  %1610 = (%tensor_0265,);
  let %v264: () = vm.invoke_tvm_op(%1608, %1609, %1610) /* ty=() */;
  let %storage_0283: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][294]) /* ty=Storage[] */;
  let %tensor_0266: int64 = memory.alloc_tensor(%storage_0283, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][294]) /* ty=int64 */;
  %1611 = fn (%p0265: int64, Primitive=1) -> int64 {
    multiply(%p0265, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1612 = (%tensor_0265,);
  %1613 = (%tensor_0266,);
  let %v265: () = vm.invoke_tvm_op(%1611, %1612, %1613) /* ty=() */;
  let %storage_0284: Storage[] = memory.alloc_storage(%tensor_0266, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][295]) /* ty=Storage[] */;
  let %out_017: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0284, 0 /* ty=int64 */, %shape_func_out_017, meta[relay.attrs.AllocTensorAttrs][295]) /* ty=Tensor[(?, ?), float32] */;
  %1614 = (%x331, %x340, %x334, meta[relay.Constant][377] /* ty=Tensor[(2), int32] */);
  %1615 = (%out_017,);
  let %v266: () = vm.invoke_tvm_op(%1605, %1614, %1615) /* ty=() */;
  let %x341: Tensor[(?, ?), float32] = %out_017;
  let %in_shape_014: Tensor[(2), int64] = vm.shape_of(%x335, meta[relay.attrs.ShapeOfAttrs][14]) /* ty=Tensor[(2), int64] */;
  let %in_shape_18: Tensor[(2), int64] = vm.shape_of(%x337, meta[relay.attrs.ShapeOfAttrs][15]) /* ty=Tensor[(2), int64] */;
  let %in_shape_27: Tensor[(2), int64] = vm.shape_of(%x339, meta[relay.attrs.ShapeOfAttrs][16]) /* ty=Tensor[(2), int64] */;
  let %in_shape_37: Tensor[(2), int64] = vm.shape_of(%x341, meta[relay.attrs.ShapeOfAttrs][17]) /* ty=Tensor[(2), int64] */;
  let %storage_0285: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][296]) /* ty=Storage[] */;
  let %tensor_0267: Tensor[(1), int64] = memory.alloc_tensor(%storage_0285, 0 /* ty=int64 */, meta[relay.Constant][379] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][296]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_018: Tensor[(1), int64] = %tensor_0267;
  %1633 = fn (%p0266: Tensor[(?, ?), float32], %p1204: Tensor[(?, ?), float32], %p294: Tensor[(?, ?), float32], %p367: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?), int64] {
    %1616 = take(%p0266, 2 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %1617 = take(%p1204, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %1618 = subtract(%1616, %1617) /* ty=Tensor[(?), float32] */;
    %1619 = take(%p294, 3 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %1620 = take(%p367, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %1621 = subtract(%1619, %1620) /* ty=Tensor[(?), float32] */;
    %1622 = multiply(%1618, %1621) /* ty=Tensor[(?), float32] */;
    %1623 = (%1622,);
    %1624 = concatenate(%1623) /* ty=Tensor[(?), float32] */;
    %1625 = sqrt(%1624) /* ty=Tensor[(?), float32] */;
    %1626 = divide(%1625, 224f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %1627 = log2(%1626) /* ty=Tensor[(?), float32] */;
    %1628 = add(%1627, 4f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %1629 = add(%1628, 1e-06f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %1630 = floor(%1629) /* ty=Tensor[(?), float32] */;
    %1631 = clip(%1630, a_min=2f, a_max=5f) /* ty=Tensor[(?), float32] */;
    %1632 = cast(%1631, dtype="int64") /* ty=Tensor[(?), int64] */;
    subtract(%1632, 2 /* ty=int64 */) /* ty=Tensor[(?), int64] */
  };
  %1634 = (%in_shape_014, %in_shape_18, %in_shape_27, %in_shape_37);
  %1635 = (%shape_func_out_018,);
  let %shape_func18: () = vm.shape_func(%1633, %1634, %1635, meta[relay.attrs.ShapeFuncAttrs][18]) /* ty=() */;
  let %storage_0286: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][297]) /* ty=Storage[] */;
  let %tensor_0268: int64 = memory.alloc_tensor(%storage_0286, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][297]) /* ty=int64 */;
  %1636 = fn (%p0267: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0267) /* ty=int64 */
  };
  %1637 = (%shape_func_out_018,);
  %1638 = (%tensor_0268,);
  let %v267: () = vm.invoke_tvm_op(%1636, %1637, %1638) /* ty=() */;
  let %storage_0287: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][298]) /* ty=Storage[] */;
  let %tensor_0269: int64 = memory.alloc_tensor(%storage_0287, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][298]) /* ty=int64 */;
  %1639 = fn (%p0268: int64, Primitive=1) -> int64 {
    multiply(%p0268, 8 /* ty=int64 */) /* ty=int64 */
  };
  %1640 = (%tensor_0268,);
  %1641 = (%tensor_0269,);
  let %v268: () = vm.invoke_tvm_op(%1639, %1640, %1641) /* ty=() */;
  let %storage_0288: Storage[] = memory.alloc_storage(%tensor_0269, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][299]) /* ty=Storage[] */;
  let %out_018: Tensor[(?), int64] = memory.alloc_tensor(%storage_0288, 0 /* ty=int64 */, %shape_func_out_018, meta[relay.attrs.AllocTensorAttrs][299]) /* ty=Tensor[(?), int64] */;
  %1642 = (%x335, %x337, %x339, %x341);
  %1643 = (%out_018,);
  let %v269: () = vm.invoke_tvm_op(%1633, %1642, %1643) /* ty=() */;
  let %x342: Tensor[(?), int64] = %out_018;
  let %storage_0289: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][300]) /* ty=Storage[] */;
  let %tensor_0270: Tensor[(1), int32] = memory.alloc_tensor(%storage_0289, 0 /* ty=int64 */, meta[relay.Constant][380] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][300]) /* ty=Tensor[(1), int32] */;
  %1644 = fn (%p0269: Tensor[(?), int64], Primitive=1) -> Tensor[(1), int32] {
    shape_of(%p0269, dtype="int32") /* ty=Tensor[(1), int32] */
  };
  %1645 = (%x342,);
  %1646 = (%tensor_0270,);
  let %v270: () = vm.invoke_tvm_op(%1644, %1645, %1646) /* ty=() */;
  let %x343: Tensor[(1), int32] = %tensor_0270;
  let %storage_0290: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][301]) /* ty=Storage[] */;
  let %tensor_0271: Tensor[(4), int64] = memory.alloc_tensor(%storage_0290, 0 /* ty=int64 */, meta[relay.Constant][381] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][301]) /* ty=Tensor[(4), int64] */;
  %1651 = fn (%p0270: Tensor[(1), int32], %p1205: Tensor[(1), int64], %p295: Tensor[(1), int64], Primitive=1) -> Tensor[(4), int64] {
    %1647 = take(%p0270, 0 /* ty=int32 */, axis=0) /* ty=int32 */;
    %1648 = expand_dims(%1647, axis=0) /* ty=Tensor[(1), int32] */;
    %1649 = cast(%1648, dtype="int64") /* ty=Tensor[(1), int64] */;
    %1650 = (%1649, %p1205, %p295, %p295);
    concatenate(%1650) /* ty=Tensor[(4), int64] */
  };
  %1652 = (%x343, meta[relay.Constant][382] /* ty=Tensor[(1), int64] */, meta[relay.Constant][383] /* ty=Tensor[(1), int64] */);
  %1653 = (%tensor_0271,);
  let %v271: () = vm.invoke_tvm_op(%1651, %1652, %1653) /* ty=() */;
  let %x344: Tensor[(4), int64] = %tensor_0271;
  let %in_shape_015: int32 = device_copy(0 /* ty=int32 */, meta[relay.attrs.DeviceCopyAttrs][24]) /* ty=int32 */;
  let %in_shape_19: Tensor[(4), int64] = device_copy(%x344, meta[relay.attrs.DeviceCopyAttrs][25]) /* ty=Tensor[(4), int64] */;
  let %storage_0291: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][302]) /* ty=Storage[] */;
  let %tensor_0272: Tensor[(4), int64] = memory.alloc_tensor(%storage_0291, 0 /* ty=int64 */, meta[relay.Constant][384] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][302]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_019: Tensor[(4), int64] = %tensor_0272;
  %1654 = fn (%p0271: int32, %p1206: Tensor[(4), int64], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    dyn.full(%p0271, %p1206, shape=None, dtype="float32") /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %1655 = (%in_shape_015, %in_shape_19);
  %1656 = (%shape_func_out_019,);
  let %shape_func19: () = vm.shape_func(%1654, %1655, %1656, meta[relay.attrs.ShapeFuncAttrs][19]) /* ty=() */;
  let %storage_0292: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][303]) /* ty=Storage[] */;
  let %tensor_0273: int64 = memory.alloc_tensor(%storage_0292, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][303]) /* ty=int64 */;
  %1657 = fn (%p0272: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0272) /* ty=int64 */
  };
  %1658 = (%shape_func_out_019,);
  %1659 = (%tensor_0273,);
  let %v272: () = vm.invoke_tvm_op(%1657, %1658, %1659) /* ty=() */;
  let %storage_0293: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][304]) /* ty=Storage[] */;
  let %tensor_0274: int64 = memory.alloc_tensor(%storage_0293, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][304]) /* ty=int64 */;
  %1660 = fn (%p0273: int64, Primitive=1) -> int64 {
    multiply(%p0273, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1661 = (%tensor_0273,);
  %1662 = (%tensor_0274,);
  let %v273: () = vm.invoke_tvm_op(%1660, %1661, %1662) /* ty=() */;
  let %storage_0294: Storage[] = memory.alloc_storage(%tensor_0274, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][305]) /* ty=Storage[] */;
  let %out_019: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_0294, 0 /* ty=int64 */, %shape_func_out_019, meta[relay.attrs.AllocTensorAttrs][305]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %1663 = (0 /* ty=int32 */, %x344);
  %1664 = (%out_019,);
  let %v274: () = vm.invoke_tvm_op(%1654, %1663, %1664) /* ty=() */;
  let %x345: Tensor[(?, ?, ?, ?), float32] = %out_019;
  let %in_shape_016: Tensor[(4), int64] = vm.shape_of(%x345, meta[relay.attrs.ShapeOfAttrs][18]) /* ty=Tensor[(4), int64] */;
  let %storage_0295: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][306]) /* ty=Storage[] */;
  let %tensor_0275: Tensor[(4), int64] = memory.alloc_tensor(%storage_0295, 0 /* ty=int64 */, meta[relay.Constant][385] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][306]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_020: Tensor[(4), int64] = %tensor_0275;
  %1665 = fn (%p0274: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    reshape(%p0274, newshape=[0, 256, 7, 7]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %1666 = (%in_shape_016,);
  %1667 = (%shape_func_out_020,);
  let %shape_func20: () = vm.shape_func(%1665, %1666, %1667, meta[relay.attrs.ShapeFuncAttrs][20]) /* ty=() */;
  let %x346: Tensor[(?, 256, 7, 7), float32] = vm.reshape_tensor(%x345, %shape_func_out_020, meta[relay.attrs.ReshapeTensorAttrs][106]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  let %in_shape_017: Tensor[(1), int64] = vm.shape_of(%x342, meta[relay.attrs.ShapeOfAttrs][19]) /* ty=Tensor[(1), int64] */;
  let %storage_0296: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][307]) /* ty=Storage[] */;
  let %tensor_0276: Tensor[(1), int64] = memory.alloc_tensor(%storage_0296, 0 /* ty=int64 */, meta[relay.Constant][386] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][307]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_021: Tensor[(1), int64] = %tensor_0276;
  %1668 = fn (%p0275: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0275, 0 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %1669 = (%in_shape_017,);
  %1670 = (%shape_func_out_021,);
  let %shape_func21: () = vm.shape_func(%1668, %1669, %1670, meta[relay.attrs.ShapeFuncAttrs][21]) /* ty=() */;
  let %storage_0297: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][308]) /* ty=Storage[] */;
  let %tensor_0277: int64 = memory.alloc_tensor(%storage_0297, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][308]) /* ty=int64 */;
  %1671 = fn (%p0276: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0276) /* ty=int64 */
  };
  %1672 = (%shape_func_out_021,);
  %1673 = (%tensor_0277,);
  let %v275: () = vm.invoke_tvm_op(%1671, %1672, %1673) /* ty=() */;
  let %storage_0298: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][309]) /* ty=Storage[] */;
  let %tensor_0278: int64 = memory.alloc_tensor(%storage_0298, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][309]) /* ty=int64 */;
  %1674 = fn (%p0277: int64, Primitive=1) -> int64 {
    multiply(%p0277, 1 /* ty=int64 */) /* ty=int64 */
  };
  %1675 = (%tensor_0277,);
  %1676 = (%tensor_0278,);
  let %v276: () = vm.invoke_tvm_op(%1674, %1675, %1676) /* ty=() */;
  let %storage_0299: Storage[] = memory.alloc_storage(%tensor_0278, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][310]) /* ty=Storage[] */;
  let %out_020: Tensor[(?), bool] = memory.alloc_tensor(%storage_0299, 0 /* ty=int64 */, %shape_func_out_021, meta[relay.attrs.AllocTensorAttrs][310]) /* ty=Tensor[(?), bool] */;
  %1677 = (%x342,);
  %1678 = (%out_020,);
  let %v277: () = vm.invoke_tvm_op(%1668, %1677, %1678) /* ty=() */;
  let %x347: Tensor[(?), bool] = %out_020;
  let %in_shape_018: Tensor[(?), bool] = device_copy(%x347, meta[relay.attrs.DeviceCopyAttrs][26]) /* ty=Tensor[(?), bool] */;
  let %storage_0300: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][311]) /* ty=Storage[] */;
  let %tensor_0279: Tensor[(2), int64] = memory.alloc_tensor(%storage_0300, 0 /* ty=int64 */, meta[relay.Constant][387] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][311]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_022: Tensor[(2), int64] = %tensor_0279;
  %1679 = fn (%p0278: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0278) /* ty=Tensor[(?, 1), int32] */
  };
  %1680 = (%in_shape_018,);
  %1681 = (%shape_func_out_022,);
  let %shape_func22: () = vm.shape_func(%1679, %1680, %1681, meta[relay.attrs.ShapeFuncAttrs][22]) /* ty=() */;
  let %storage_0301: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][312]) /* ty=Storage[] */;
  let %tensor_0280: int64 = memory.alloc_tensor(%storage_0301, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][312]) /* ty=int64 */;
  %1682 = fn (%p0279: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0279) /* ty=int64 */
  };
  %1683 = (%shape_func_out_022,);
  %1684 = (%tensor_0280,);
  let %v278: () = vm.invoke_tvm_op(%1682, %1683, %1684) /* ty=() */;
  let %storage_0302: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][313]) /* ty=Storage[] */;
  let %tensor_0281: int64 = memory.alloc_tensor(%storage_0302, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][313]) /* ty=int64 */;
  %1685 = fn (%p0280: int64, Primitive=1) -> int64 {
    multiply(%p0280, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1686 = (%tensor_0280,);
  %1687 = (%tensor_0281,);
  let %v279: () = vm.invoke_tvm_op(%1685, %1686, %1687) /* ty=() */;
  let %storage_0303: Storage[] = memory.alloc_storage(%tensor_0281, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][314]) /* ty=Storage[] */;
  let %out_021: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0303, 0 /* ty=int64 */, %shape_func_out_022, meta[relay.attrs.AllocTensorAttrs][314]) /* ty=Tensor[(?, 1), int32] */;
  %1688 = (%x347,);
  %1689 = (%out_021,);
  let %v280: () = vm.invoke_tvm_op(%1679, %1688, %1689) /* ty=() */;
  let %x348: Tensor[(?, 1), int32] = %out_021;
  let %in_shape_019: Tensor[(2), int64] = vm.shape_of(%x348, meta[relay.attrs.ShapeOfAttrs][20]) /* ty=Tensor[(2), int64] */;
  let %storage_0304: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][315]) /* ty=Storage[] */;
  let %tensor_0282: Tensor[(1), int64] = memory.alloc_tensor(%storage_0304, 0 /* ty=int64 */, meta[relay.Constant][388] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][315]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_023: Tensor[(1), int64] = %tensor_0282;
  %1692 = fn (%p0281: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %1690 = split(%p0281, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %1691 = %1690.0;
    squeeze(%1691, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %1693 = (%in_shape_019,);
  %1694 = (%shape_func_out_023,);
  let %shape_func23: () = vm.shape_func(%1692, %1693, %1694, meta[relay.attrs.ShapeFuncAttrs][23]) /* ty=() */;
  let %storage_0305: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][316]) /* ty=Storage[] */;
  let %tensor_0283: int64 = memory.alloc_tensor(%storage_0305, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][316]) /* ty=int64 */;
  %1695 = fn (%p0282: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0282) /* ty=int64 */
  };
  %1696 = (%shape_func_out_023,);
  %1697 = (%tensor_0283,);
  let %v281: () = vm.invoke_tvm_op(%1695, %1696, %1697) /* ty=() */;
  let %storage_0306: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][317]) /* ty=Storage[] */;
  let %tensor_0284: int64 = memory.alloc_tensor(%storage_0306, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][317]) /* ty=int64 */;
  %1698 = fn (%p0283: int64, Primitive=1) -> int64 {
    multiply(%p0283, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1699 = (%tensor_0283,);
  %1700 = (%tensor_0284,);
  let %v282: () = vm.invoke_tvm_op(%1698, %1699, %1700) /* ty=() */;
  let %storage_0307: Storage[] = memory.alloc_storage(%tensor_0284, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][318]) /* ty=Storage[] */;
  let %out_022: Tensor[(?), int32] = memory.alloc_tensor(%storage_0307, 0 /* ty=int64 */, %shape_func_out_023, meta[relay.attrs.AllocTensorAttrs][318]) /* ty=Tensor[(?), int32] */;
  %1701 = (%x348,);
  %1702 = (%out_022,);
  let %v283: () = vm.invoke_tvm_op(%1692, %1701, %1702) /* ty=() */;
  let %x349: Tensor[(?), int32] = %out_022;
  let %in_shape_020: Tensor[(1), int64] = vm.shape_of(%x349, meta[relay.attrs.ShapeOfAttrs][21]) /* ty=Tensor[(1), int64] */;
  let %storage_0308: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][319]) /* ty=Storage[] */;
  let %tensor_0285: Tensor[(4), int64] = memory.alloc_tensor(%storage_0308, 0 /* ty=int64 */, meta[relay.Constant][389] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][319]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_024: Tensor[(4), int64] = %tensor_0285;
  %1706 = fn (%p0284: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 7, 7), int32] {
    %1703 = reshape(%p0284, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %1704 = repeat(%1703, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %1705 = repeat(%1704, repeats=7, axis=2) /* ty=Tensor[(?, 256, 7, 1), int32] */;
    repeat(%1705, repeats=7, axis=3) /* ty=Tensor[(?, 256, 7, 7), int32] */
  };
  %1707 = (%in_shape_020,);
  %1708 = (%shape_func_out_024,);
  let %shape_func24: () = vm.shape_func(%1706, %1707, %1708, meta[relay.attrs.ShapeFuncAttrs][24]) /* ty=() */;
  let %storage_0309: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][320]) /* ty=Storage[] */;
  let %tensor_0286: int64 = memory.alloc_tensor(%storage_0309, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][320]) /* ty=int64 */;
  %1709 = fn (%p0285: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0285) /* ty=int64 */
  };
  %1710 = (%shape_func_out_024,);
  %1711 = (%tensor_0286,);
  let %v284: () = vm.invoke_tvm_op(%1709, %1710, %1711) /* ty=() */;
  let %storage_0310: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][321]) /* ty=Storage[] */;
  let %tensor_0287: int64 = memory.alloc_tensor(%storage_0310, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][321]) /* ty=int64 */;
  %1712 = fn (%p0286: int64, Primitive=1) -> int64 {
    multiply(%p0286, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1713 = (%tensor_0286,);
  %1714 = (%tensor_0287,);
  let %v285: () = vm.invoke_tvm_op(%1712, %1713, %1714) /* ty=() */;
  let %storage_0311: Storage[] = memory.alloc_storage(%tensor_0287, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][322]) /* ty=Storage[] */;
  let %out_023: Tensor[(?, 256, 7, 7), int32] = memory.alloc_tensor(%storage_0311, 0 /* ty=int64 */, %shape_func_out_024, meta[relay.attrs.AllocTensorAttrs][322]) /* ty=Tensor[(?, 256, 7, 7), int32] */;
  %1715 = (%x349,);
  %1716 = (%out_023,);
  let %v286: () = vm.invoke_tvm_op(%1706, %1715, %1716) /* ty=() */;
  let %x350: Tensor[(?, 256, 7, 7), int32] = %out_023;
  let %storage_0312: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][323]) /* ty=Storage[] */;
  let %tensor_0288: Tensor[(2), int32] = memory.alloc_tensor(%storage_0312, 0 /* ty=int64 */, meta[relay.Constant][390] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][323]) /* ty=Tensor[(2), int32] */;
  %1719 = fn (%p0287: Tensor[(2), bool], %p1207: Tensor[(2), int32], %p296: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %1717 = cast_like(%p296, %p1207) /* ty=Tensor[(2), int32] */;
    %1718 = add(%p1207, %1717) /* ty=Tensor[(2), int32] */;
    where(%p0287, %1718, %p1207) /* ty=Tensor[(2), int32] */
  };
  %1720 = (meta[relay.Constant][391] /* ty=Tensor[(2), bool] */, meta[relay.Constant][392] /* ty=Tensor[(2), int32] */, %x332);
  %1721 = (%tensor_0288,);
  let %v287: () = vm.invoke_tvm_op(%1719, %1720, %1721) /* ty=() */;
  let %x351: Tensor[(2), int32] = %tensor_0288;
  let %in_shape_021: Tensor[(?, 4), float32] = device_copy(%x331, meta[relay.attrs.DeviceCopyAttrs][27]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_110: Tensor[(2), int32] = device_copy(%x351, meta[relay.attrs.DeviceCopyAttrs][28]) /* ty=Tensor[(2), int32] */;
  let %in_shape_28: Tensor[(2), int64] = device_copy(%x334, meta[relay.attrs.DeviceCopyAttrs][29]) /* ty=Tensor[(2), int64] */;
  let %in_shape_38: Tensor[(2), int32] = device_copy(meta[relay.Constant][393] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][30]) /* ty=Tensor[(2), int32] */;
  let %storage_0313: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][324]) /* ty=Storage[] */;
  let %tensor_0289: Tensor[(2), int64] = memory.alloc_tensor(%storage_0313, 0 /* ty=int64 */, meta[relay.Constant][394] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][324]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_025: Tensor[(2), int64] = %tensor_0289;
  %1722 = fn (%p0288: Tensor[(?, 4), float32], %p1208: Tensor[(2), int32], %p297: Tensor[(2), int64], %p368: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0288, %p1208, %p297, %p368, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %1723 = (%in_shape_021, %in_shape_110, %in_shape_28, %in_shape_38);
  %1724 = (%shape_func_out_025,);
  let %shape_func25: () = vm.shape_func(%1722, %1723, %1724, meta[relay.attrs.ShapeFuncAttrs][25]) /* ty=() */;
  let %storage_0314: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][325]) /* ty=Storage[] */;
  let %tensor_0290: int64 = memory.alloc_tensor(%storage_0314, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][325]) /* ty=int64 */;
  %1725 = fn (%p0289: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0289) /* ty=int64 */
  };
  %1726 = (%shape_func_out_025,);
  %1727 = (%tensor_0290,);
  let %v288: () = vm.invoke_tvm_op(%1725, %1726, %1727) /* ty=() */;
  let %storage_0315: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][326]) /* ty=Storage[] */;
  let %tensor_0291: int64 = memory.alloc_tensor(%storage_0315, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][326]) /* ty=int64 */;
  %1728 = fn (%p0290: int64, Primitive=1) -> int64 {
    multiply(%p0290, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1729 = (%tensor_0290,);
  %1730 = (%tensor_0291,);
  let %v289: () = vm.invoke_tvm_op(%1728, %1729, %1730) /* ty=() */;
  let %storage_0316: Storage[] = memory.alloc_storage(%tensor_0291, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][327]) /* ty=Storage[] */;
  let %out_024: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0316, 0 /* ty=int64 */, %shape_func_out_025, meta[relay.attrs.AllocTensorAttrs][327]) /* ty=Tensor[(?, ?), float32] */;
  %1731 = (%x331, %x351, %x334, meta[relay.Constant][393] /* ty=Tensor[(2), int32] */);
  %1732 = (%out_024,);
  let %v290: () = vm.invoke_tvm_op(%1722, %1731, %1732) /* ty=() */;
  let %x352: Tensor[(?, ?), float32] = %out_024;
  let %storage_0317: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][328]) /* ty=Storage[] */;
  let %tensor_0292: Tensor[(2), int32] = memory.alloc_tensor(%storage_0317, 0 /* ty=int64 */, meta[relay.Constant][395] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][328]) /* ty=Tensor[(2), int32] */;
  %1733 = fn (%p0291: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0291, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %1734 = (%x352,);
  %1735 = (%tensor_0292,);
  let %v291: () = vm.invoke_tvm_op(%1733, %1734, %1735) /* ty=() */;
  let %x353: Tensor[(2), int32] = %tensor_0292;
  let %storage_0318: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][329]) /* ty=Storage[] */;
  let %tensor_0293: Tensor[(2), int32] = memory.alloc_tensor(%storage_0318, 0 /* ty=int64 */, meta[relay.Constant][396] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][329]) /* ty=Tensor[(2), int32] */;
  %1738 = fn (%p0292: Tensor[(2), bool], %p1209: Tensor[(2), int32], %p298: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %1736 = cast_like(%p298, %p1209) /* ty=Tensor[(2), int32] */;
    %1737 = add(%p1209, %1736) /* ty=Tensor[(2), int32] */;
    where(%p0292, %1737, %p1209) /* ty=Tensor[(2), int32] */
  };
  %1739 = (meta[relay.Constant][397] /* ty=Tensor[(2), bool] */, meta[relay.Constant][398] /* ty=Tensor[(2), int32] */, %x353);
  %1740 = (%tensor_0293,);
  let %v292: () = vm.invoke_tvm_op(%1738, %1739, %1740) /* ty=() */;
  let %x354: Tensor[(2), int32] = %tensor_0293;
  let %storage_0319: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][330]) /* ty=Storage[] */;
  let %tensor_0294: Tensor[(2), int32] = memory.alloc_tensor(%storage_0319, 0 /* ty=int64 */, meta[relay.Constant][399] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][330]) /* ty=Tensor[(2), int32] */;
  %1741 = fn (%p0293: Tensor[(2), int32], %p1211: Tensor[(1), int32], Primitive=1) -> Tensor[(2), int32] {
    scatter(%p0293, %p1211, %p1211, meta[relay.attrs.ScatterAttrs][0]) /* ty=Tensor[(2), int32] */
  };
  %1742 = (%x353, meta[relay.Constant][400] /* ty=Tensor[(1), int32] */);
  %1743 = (%tensor_0294,);
  let %v293: () = vm.invoke_tvm_op(%1741, %1742, %1743) /* ty=() */;
  let %x355: Tensor[(2), int32] = %tensor_0294;
  let %storage_0320: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][331]) /* ty=Storage[] */;
  let %tensor_0295: Tensor[(2), int64] = memory.alloc_tensor(%storage_0320, 0 /* ty=int64 */, meta[relay.Constant][401] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][331]) /* ty=Tensor[(2), int64] */;
  %1744 = fn (%p0294: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0294, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %1745 = (%x355,);
  %1746 = (%tensor_0295,);
  let %v294: () = vm.invoke_tvm_op(%1744, %1745, %1746) /* ty=() */;
  let %x356: Tensor[(2), int64] = %tensor_0295;
  let %in_shape_022: Tensor[(?, ?), float32] = device_copy(%x352, meta[relay.attrs.DeviceCopyAttrs][31]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_111: Tensor[(2), int32] = device_copy(%x354, meta[relay.attrs.DeviceCopyAttrs][32]) /* ty=Tensor[(2), int32] */;
  let %in_shape_29: Tensor[(2), int64] = device_copy(%x356, meta[relay.attrs.DeviceCopyAttrs][33]) /* ty=Tensor[(2), int64] */;
  let %in_shape_39: Tensor[(2), int32] = device_copy(meta[relay.Constant][402] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][34]) /* ty=Tensor[(2), int32] */;
  let %storage_0321: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][332]) /* ty=Storage[] */;
  let %tensor_0296: Tensor[(2), int64] = memory.alloc_tensor(%storage_0321, 0 /* ty=int64 */, meta[relay.Constant][403] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][332]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_026: Tensor[(2), int64] = %tensor_0296;
  %1747 = fn (%p0295: Tensor[(?, ?), float32], %p1212: Tensor[(2), int32], %p299: Tensor[(2), int64], %p369: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0295, %p1212, %p299, %p369, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %1748 = (%in_shape_022, %in_shape_111, %in_shape_29, %in_shape_39);
  %1749 = (%shape_func_out_026,);
  let %shape_func26: () = vm.shape_func(%1747, %1748, %1749, meta[relay.attrs.ShapeFuncAttrs][26]) /* ty=() */;
  let %storage_0322: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][333]) /* ty=Storage[] */;
  let %tensor_0297: int64 = memory.alloc_tensor(%storage_0322, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][333]) /* ty=int64 */;
  %1750 = fn (%p0296: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0296) /* ty=int64 */
  };
  %1751 = (%shape_func_out_026,);
  %1752 = (%tensor_0297,);
  let %v295: () = vm.invoke_tvm_op(%1750, %1751, %1752) /* ty=() */;
  let %storage_0323: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][334]) /* ty=Storage[] */;
  let %tensor_0298: int64 = memory.alloc_tensor(%storage_0323, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][334]) /* ty=int64 */;
  %1753 = fn (%p0297: int64, Primitive=1) -> int64 {
    multiply(%p0297, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1754 = (%tensor_0297,);
  %1755 = (%tensor_0298,);
  let %v296: () = vm.invoke_tvm_op(%1753, %1754, %1755) /* ty=() */;
  let %storage_0324: Storage[] = memory.alloc_storage(%tensor_0298, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][335]) /* ty=Storage[] */;
  let %out_025: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0324, 0 /* ty=int64 */, %shape_func_out_026, meta[relay.attrs.AllocTensorAttrs][335]) /* ty=Tensor[(?, ?), float32] */;
  %1756 = (%x352, %x354, %x356, meta[relay.Constant][402] /* ty=Tensor[(2), int32] */);
  %1757 = (%out_025,);
  let %v297: () = vm.invoke_tvm_op(%1747, %1756, %1757) /* ty=() */;
  let %x357: Tensor[(?, ?), float32] = %out_025;
  let %in_shape_023: Tensor[(2), int64] = vm.shape_of(%x357, meta[relay.attrs.ShapeOfAttrs][22]) /* ty=Tensor[(2), int64] */;
  let %in_shape_112: Tensor[(2), int64] = vm.shape_of(%x331, meta[relay.attrs.ShapeOfAttrs][23]) /* ty=Tensor[(2), int64] */;
  let %storage_0325: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][336]) /* ty=Storage[] */;
  let %tensor_0299: Tensor[(2), int64] = memory.alloc_tensor(%storage_0325, 0 /* ty=int64 */, meta[relay.Constant][404] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][336]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_027: Tensor[(2), int64] = %tensor_0299;
  %1764 = fn (%p0298: Tensor[(?, ?), float32], %p1213: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(?, ?), float32] {
    %1758 = full_like(%p0298, 0 /* ty=int32 */) /* ty=Tensor[(?, ?), float32] */;
    %1759 = (%1758,);
    %1760 = concatenate(%1759) /* ty=Tensor[(?, ?), float32] */;
    %1761 = (%p1213,);
    %1762 = concatenate(%1761) /* ty=Tensor[(?, 4), float32] */;
    %1763 = (%1760, %1762);
    concatenate(%1763, axis=1) /* ty=Tensor[(?, ?), float32] */
  };
  %1765 = (%in_shape_023, %in_shape_112);
  %1766 = (%shape_func_out_027,);
  let %shape_func27: () = vm.shape_func(%1764, %1765, %1766, meta[relay.attrs.ShapeFuncAttrs][27]) /* ty=() */;
  let %storage_0326: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][337]) /* ty=Storage[] */;
  let %tensor_0300: int64 = memory.alloc_tensor(%storage_0326, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][337]) /* ty=int64 */;
  %1767 = fn (%p0299: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0299) /* ty=int64 */
  };
  %1768 = (%shape_func_out_027,);
  %1769 = (%tensor_0300,);
  let %v298: () = vm.invoke_tvm_op(%1767, %1768, %1769) /* ty=() */;
  let %storage_0327: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][338]) /* ty=Storage[] */;
  let %tensor_0301: int64 = memory.alloc_tensor(%storage_0327, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][338]) /* ty=int64 */;
  %1770 = fn (%p0300: int64, Primitive=1) -> int64 {
    multiply(%p0300, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1771 = (%tensor_0300,);
  %1772 = (%tensor_0301,);
  let %v299: () = vm.invoke_tvm_op(%1770, %1771, %1772) /* ty=() */;
  let %storage_0328: Storage[] = memory.alloc_storage(%tensor_0301, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][339]) /* ty=Storage[] */;
  let %out_026: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0328, 0 /* ty=int64 */, %shape_func_out_027, meta[relay.attrs.AllocTensorAttrs][339]) /* ty=Tensor[(?, ?), float32] */;
  %1773 = (%x357, %x331);
  %1774 = (%out_026,);
  let %v300: () = vm.invoke_tvm_op(%1764, %1773, %1774) /* ty=() */;
  let %x358: Tensor[(?, ?), float32] = %out_026;
  let %in_shape_024: Tensor[(2), int64] = vm.shape_of(%x358, meta[relay.attrs.ShapeOfAttrs][24]) /* ty=Tensor[(2), int64] */;
  let %in_shape_113: Tensor[(1), int64] = vm.shape_of(%x349, meta[relay.attrs.ShapeOfAttrs][25]) /* ty=Tensor[(1), int64] */;
  let %storage_0329: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][340]) /* ty=Storage[] */;
  let %tensor_0302: Tensor[(2), int64] = memory.alloc_tensor(%storage_0329, 0 /* ty=int64 */, meta[relay.Constant][405] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][340]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_028: Tensor[(2), int64] = %tensor_0302;
  %1777 = fn (%p0301: Tensor[(?, ?), float32], %p1214: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %1775 = cast(%p1214, dtype="int64") /* ty=Tensor[(?), int64] */;
    %1776 = (%p0301, %1775);
    adv_index(%1776) /* ty=Tensor[(?, ?), float32] */
  };
  %1778 = (%in_shape_024, %in_shape_113);
  %1779 = (%shape_func_out_028,);
  let %shape_func28: () = vm.shape_func(%1777, %1778, %1779, meta[relay.attrs.ShapeFuncAttrs][28]) /* ty=() */;
  let %storage_0330: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][341]) /* ty=Storage[] */;
  let %tensor_0303: int64 = memory.alloc_tensor(%storage_0330, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][341]) /* ty=int64 */;
  %1780 = fn (%p0302: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0302) /* ty=int64 */
  };
  %1781 = (%shape_func_out_028,);
  %1782 = (%tensor_0303,);
  let %v301: () = vm.invoke_tvm_op(%1780, %1781, %1782) /* ty=() */;
  let %storage_0331: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][342]) /* ty=Storage[] */;
  let %tensor_0304: int64 = memory.alloc_tensor(%storage_0331, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][342]) /* ty=int64 */;
  %1783 = fn (%p0303: int64, Primitive=1) -> int64 {
    multiply(%p0303, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1784 = (%tensor_0303,);
  %1785 = (%tensor_0304,);
  let %v302: () = vm.invoke_tvm_op(%1783, %1784, %1785) /* ty=() */;
  let %storage_0332: Storage[] = memory.alloc_storage(%tensor_0304, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][343]) /* ty=Storage[] */;
  let %out_027: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0332, 0 /* ty=int64 */, %shape_func_out_028, meta[relay.attrs.AllocTensorAttrs][343]) /* ty=Tensor[(?, ?), float32] */;
  %1786 = (%x358, %x349);
  %1787 = (%out_027,);
  let %v303: () = vm.invoke_tvm_op(%1777, %1786, %1787) /* ty=() */;
  let %x359: Tensor[(?, ?), float32] = %out_027;
  let %in_shape_114: Tensor[(2), int64] = vm.shape_of(%x359, meta[relay.attrs.ShapeOfAttrs][26]) /* ty=Tensor[(2), int64] */;
  let %storage_0333: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][344]) /* ty=Storage[] */;
  let %tensor_0305: Tensor[(4), int64] = memory.alloc_tensor(%storage_0333, 0 /* ty=int64 */, meta[relay.Constant][406] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][344]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_029: Tensor[(4), int64] = %tensor_0305;
  %1788 = fn (%p0304: Tensor[(1, 256, 200, 200), float32], %p1215: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    vision.roi_align(%p0304, %p1215, meta[relay.attrs.ROIAlignAttrs][0]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %1789 = (meta[relay.Constant][407] /* ty=Tensor[(4), int64] */, %in_shape_114);
  %1790 = (%shape_func_out_029,);
  let %shape_func29: () = vm.shape_func(%1788, %1789, %1790, meta[relay.attrs.ShapeFuncAttrs][29]) /* ty=() */;
  let %storage_0334: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][345]) /* ty=Storage[] */;
  let %tensor_0306: int64 = memory.alloc_tensor(%storage_0334, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][345]) /* ty=int64 */;
  %1791 = fn (%p0305: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0305) /* ty=int64 */
  };
  %1792 = (%shape_func_out_029,);
  %1793 = (%tensor_0306,);
  let %v304: () = vm.invoke_tvm_op(%1791, %1792, %1793) /* ty=() */;
  let %storage_0335: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][346]) /* ty=Storage[] */;
  let %tensor_0307: int64 = memory.alloc_tensor(%storage_0335, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][346]) /* ty=int64 */;
  %1794 = fn (%p0306: int64, Primitive=1) -> int64 {
    multiply(%p0306, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1795 = (%tensor_0306,);
  %1796 = (%tensor_0307,);
  let %v305: () = vm.invoke_tvm_op(%1794, %1795, %1796) /* ty=() */;
  let %storage_0336: Storage[] = memory.alloc_storage(%tensor_0307, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][347]) /* ty=Storage[] */;
  let %out_028: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0336, 0 /* ty=int64 */, %shape_func_out_029, meta[relay.attrs.AllocTensorAttrs][347]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %1797 = (%x275, %x359);
  %1798 = (%out_028,);
  let %v306: () = vm.invoke_tvm_op(%1788, %1797, %1798) /* ty=() */;
  let %x360: Tensor[(?, 256, 7, 7), float32] = %out_028;
  let %in_shape_025: Tensor[(4), int64] = vm.shape_of(%x346, meta[relay.attrs.ShapeOfAttrs][27]) /* ty=Tensor[(4), int64] */;
  let %in_shape_115: Tensor[(4), int64] = vm.shape_of(%x350, meta[relay.attrs.ShapeOfAttrs][28]) /* ty=Tensor[(4), int64] */;
  let %in_shape_210: Tensor[(4), int64] = vm.shape_of(%x360, meta[relay.attrs.ShapeOfAttrs][29]) /* ty=Tensor[(4), int64] */;
  let %storage_0337: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][348]) /* ty=Storage[] */;
  let %tensor_0308: Tensor[(4), int64] = memory.alloc_tensor(%storage_0337, 0 /* ty=int64 */, meta[relay.Constant][408] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][348]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_030: Tensor[(4), int64] = %tensor_0308;
  %1799 = fn (%p0307: Tensor[(?, 256, 7, 7), float32], %p1216: Tensor[(?, 256, 7, 7), int32], %p2100: Tensor[(?, 256, 7, 7), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    scatter(%p0307, %p1216, %p2100, meta[relay.attrs.ScatterAttrs][1]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %1800 = (%in_shape_025, %in_shape_115, %in_shape_210);
  %1801 = (%shape_func_out_030,);
  let %shape_func30: () = vm.shape_func(%1799, %1800, %1801, meta[relay.attrs.ShapeFuncAttrs][30]) /* ty=() */;
  let %storage_0338: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][349]) /* ty=Storage[] */;
  let %tensor_0309: int64 = memory.alloc_tensor(%storage_0338, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][349]) /* ty=int64 */;
  %1802 = fn (%p0308: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0308) /* ty=int64 */
  };
  %1803 = (%shape_func_out_030,);
  %1804 = (%tensor_0309,);
  let %v307: () = vm.invoke_tvm_op(%1802, %1803, %1804) /* ty=() */;
  let %storage_0339: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][350]) /* ty=Storage[] */;
  let %tensor_0310: int64 = memory.alloc_tensor(%storage_0339, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][350]) /* ty=int64 */;
  %1805 = fn (%p0309: int64, Primitive=1) -> int64 {
    multiply(%p0309, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1806 = (%tensor_0309,);
  %1807 = (%tensor_0310,);
  let %v308: () = vm.invoke_tvm_op(%1805, %1806, %1807) /* ty=() */;
  let %storage_0340: Storage[] = memory.alloc_storage(%tensor_0310, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][351]) /* ty=Storage[] */;
  let %out_029: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0340, 0 /* ty=int64 */, %shape_func_out_030, meta[relay.attrs.AllocTensorAttrs][351]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %1808 = (%x346, %x350, %x360);
  %1809 = (%out_029,);
  let %v309: () = vm.invoke_tvm_op(%1799, %1808, %1809) /* ty=() */;
  let %x361: Tensor[(?, 256, 7, 7), float32] = %out_029;
  let %in_shape_026: Tensor[(1), int64] = vm.shape_of(%x342, meta[relay.attrs.ShapeOfAttrs][30]) /* ty=Tensor[(1), int64] */;
  let %storage_0341: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][352]) /* ty=Storage[] */;
  let %tensor_0311: Tensor[(1), int64] = memory.alloc_tensor(%storage_0341, 0 /* ty=int64 */, meta[relay.Constant][409] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][352]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_031: Tensor[(1), int64] = %tensor_0311;
  %1810 = fn (%p0310: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0310, 1 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %1811 = (%in_shape_026,);
  %1812 = (%shape_func_out_031,);
  let %shape_func31: () = vm.shape_func(%1810, %1811, %1812, meta[relay.attrs.ShapeFuncAttrs][31]) /* ty=() */;
  let %storage_0342: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][353]) /* ty=Storage[] */;
  let %tensor_0312: int64 = memory.alloc_tensor(%storage_0342, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][353]) /* ty=int64 */;
  %1813 = fn (%p0311: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0311) /* ty=int64 */
  };
  %1814 = (%shape_func_out_031,);
  %1815 = (%tensor_0312,);
  let %v310: () = vm.invoke_tvm_op(%1813, %1814, %1815) /* ty=() */;
  let %storage_0343: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][354]) /* ty=Storage[] */;
  let %tensor_0313: int64 = memory.alloc_tensor(%storage_0343, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][354]) /* ty=int64 */;
  %1816 = fn (%p0312: int64, Primitive=1) -> int64 {
    multiply(%p0312, 1 /* ty=int64 */) /* ty=int64 */
  };
  %1817 = (%tensor_0312,);
  %1818 = (%tensor_0313,);
  let %v311: () = vm.invoke_tvm_op(%1816, %1817, %1818) /* ty=() */;
  let %storage_0344: Storage[] = memory.alloc_storage(%tensor_0313, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][355]) /* ty=Storage[] */;
  let %out_030: Tensor[(?), bool] = memory.alloc_tensor(%storage_0344, 0 /* ty=int64 */, %shape_func_out_031, meta[relay.attrs.AllocTensorAttrs][355]) /* ty=Tensor[(?), bool] */;
  %1819 = (%x342,);
  %1820 = (%out_030,);
  let %v312: () = vm.invoke_tvm_op(%1810, %1819, %1820) /* ty=() */;
  let %x362: Tensor[(?), bool] = %out_030;
  let %in_shape_027: Tensor[(?), bool] = device_copy(%x362, meta[relay.attrs.DeviceCopyAttrs][35]) /* ty=Tensor[(?), bool] */;
  let %storage_0345: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][356]) /* ty=Storage[] */;
  let %tensor_0314: Tensor[(2), int64] = memory.alloc_tensor(%storage_0345, 0 /* ty=int64 */, meta[relay.Constant][410] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][356]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_032: Tensor[(2), int64] = %tensor_0314;
  %1821 = fn (%p0313: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0313) /* ty=Tensor[(?, 1), int32] */
  };
  %1822 = (%in_shape_027,);
  %1823 = (%shape_func_out_032,);
  let %shape_func32: () = vm.shape_func(%1821, %1822, %1823, meta[relay.attrs.ShapeFuncAttrs][32]) /* ty=() */;
  let %storage_0346: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][357]) /* ty=Storage[] */;
  let %tensor_0315: int64 = memory.alloc_tensor(%storage_0346, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][357]) /* ty=int64 */;
  %1824 = fn (%p0314: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0314) /* ty=int64 */
  };
  %1825 = (%shape_func_out_032,);
  %1826 = (%tensor_0315,);
  let %v313: () = vm.invoke_tvm_op(%1824, %1825, %1826) /* ty=() */;
  let %storage_0347: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][358]) /* ty=Storage[] */;
  let %tensor_0316: int64 = memory.alloc_tensor(%storage_0347, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][358]) /* ty=int64 */;
  %1827 = fn (%p0315: int64, Primitive=1) -> int64 {
    multiply(%p0315, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1828 = (%tensor_0315,);
  %1829 = (%tensor_0316,);
  let %v314: () = vm.invoke_tvm_op(%1827, %1828, %1829) /* ty=() */;
  let %storage_0348: Storage[] = memory.alloc_storage(%tensor_0316, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][359]) /* ty=Storage[] */;
  let %out_031: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0348, 0 /* ty=int64 */, %shape_func_out_032, meta[relay.attrs.AllocTensorAttrs][359]) /* ty=Tensor[(?, 1), int32] */;
  %1830 = (%x362,);
  %1831 = (%out_031,);
  let %v315: () = vm.invoke_tvm_op(%1821, %1830, %1831) /* ty=() */;
  let %x363: Tensor[(?, 1), int32] = %out_031;
  let %in_shape_028: Tensor[(2), int64] = vm.shape_of(%x363, meta[relay.attrs.ShapeOfAttrs][31]) /* ty=Tensor[(2), int64] */;
  let %storage_0349: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][360]) /* ty=Storage[] */;
  let %tensor_0317: Tensor[(1), int64] = memory.alloc_tensor(%storage_0349, 0 /* ty=int64 */, meta[relay.Constant][411] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][360]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_033: Tensor[(1), int64] = %tensor_0317;
  %1834 = fn (%p0316: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %1832 = split(%p0316, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %1833 = %1832.0;
    squeeze(%1833, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %1835 = (%in_shape_028,);
  %1836 = (%shape_func_out_033,);
  let %shape_func33: () = vm.shape_func(%1834, %1835, %1836, meta[relay.attrs.ShapeFuncAttrs][33]) /* ty=() */;
  let %storage_0350: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][361]) /* ty=Storage[] */;
  let %tensor_0318: int64 = memory.alloc_tensor(%storage_0350, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][361]) /* ty=int64 */;
  %1837 = fn (%p0317: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0317) /* ty=int64 */
  };
  %1838 = (%shape_func_out_033,);
  %1839 = (%tensor_0318,);
  let %v316: () = vm.invoke_tvm_op(%1837, %1838, %1839) /* ty=() */;
  let %storage_0351: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][362]) /* ty=Storage[] */;
  let %tensor_0319: int64 = memory.alloc_tensor(%storage_0351, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][362]) /* ty=int64 */;
  %1840 = fn (%p0318: int64, Primitive=1) -> int64 {
    multiply(%p0318, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1841 = (%tensor_0318,);
  %1842 = (%tensor_0319,);
  let %v317: () = vm.invoke_tvm_op(%1840, %1841, %1842) /* ty=() */;
  let %storage_0352: Storage[] = memory.alloc_storage(%tensor_0319, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][363]) /* ty=Storage[] */;
  let %out_032: Tensor[(?), int32] = memory.alloc_tensor(%storage_0352, 0 /* ty=int64 */, %shape_func_out_033, meta[relay.attrs.AllocTensorAttrs][363]) /* ty=Tensor[(?), int32] */;
  %1843 = (%x363,);
  %1844 = (%out_032,);
  let %v318: () = vm.invoke_tvm_op(%1834, %1843, %1844) /* ty=() */;
  let %x364: Tensor[(?), int32] = %out_032;
  let %in_shape_029: Tensor[(1), int64] = vm.shape_of(%x364, meta[relay.attrs.ShapeOfAttrs][32]) /* ty=Tensor[(1), int64] */;
  let %storage_0353: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][364]) /* ty=Storage[] */;
  let %tensor_0320: Tensor[(4), int64] = memory.alloc_tensor(%storage_0353, 0 /* ty=int64 */, meta[relay.Constant][412] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][364]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_034: Tensor[(4), int64] = %tensor_0320;
  %1848 = fn (%p0319: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 7, 7), int32] {
    %1845 = reshape(%p0319, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %1846 = repeat(%1845, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %1847 = repeat(%1846, repeats=7, axis=2) /* ty=Tensor[(?, 256, 7, 1), int32] */;
    repeat(%1847, repeats=7, axis=3) /* ty=Tensor[(?, 256, 7, 7), int32] */
  };
  %1849 = (%in_shape_029,);
  %1850 = (%shape_func_out_034,);
  let %shape_func34: () = vm.shape_func(%1848, %1849, %1850, meta[relay.attrs.ShapeFuncAttrs][34]) /* ty=() */;
  let %storage_0354: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][365]) /* ty=Storage[] */;
  let %tensor_0321: int64 = memory.alloc_tensor(%storage_0354, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][365]) /* ty=int64 */;
  %1851 = fn (%p0320: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0320) /* ty=int64 */
  };
  %1852 = (%shape_func_out_034,);
  %1853 = (%tensor_0321,);
  let %v319: () = vm.invoke_tvm_op(%1851, %1852, %1853) /* ty=() */;
  let %storage_0355: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][366]) /* ty=Storage[] */;
  let %tensor_0322: int64 = memory.alloc_tensor(%storage_0355, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][366]) /* ty=int64 */;
  %1854 = fn (%p0321: int64, Primitive=1) -> int64 {
    multiply(%p0321, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1855 = (%tensor_0321,);
  %1856 = (%tensor_0322,);
  let %v320: () = vm.invoke_tvm_op(%1854, %1855, %1856) /* ty=() */;
  let %storage_0356: Storage[] = memory.alloc_storage(%tensor_0322, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][367]) /* ty=Storage[] */;
  let %out_033: Tensor[(?, 256, 7, 7), int32] = memory.alloc_tensor(%storage_0356, 0 /* ty=int64 */, %shape_func_out_034, meta[relay.attrs.AllocTensorAttrs][367]) /* ty=Tensor[(?, 256, 7, 7), int32] */;
  %1857 = (%x364,);
  %1858 = (%out_033,);
  let %v321: () = vm.invoke_tvm_op(%1848, %1857, %1858) /* ty=() */;
  let %x365: Tensor[(?, 256, 7, 7), int32] = %out_033;
  let %in_shape_030: Tensor[(2), int64] = vm.shape_of(%x358, meta[relay.attrs.ShapeOfAttrs][33]) /* ty=Tensor[(2), int64] */;
  let %in_shape_116: Tensor[(1), int64] = vm.shape_of(%x364, meta[relay.attrs.ShapeOfAttrs][34]) /* ty=Tensor[(1), int64] */;
  let %storage_0357: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][368]) /* ty=Storage[] */;
  let %tensor_0323: Tensor[(2), int64] = memory.alloc_tensor(%storage_0357, 0 /* ty=int64 */, meta[relay.Constant][413] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][368]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_035: Tensor[(2), int64] = %tensor_0323;
  %1861 = fn (%p0322: Tensor[(?, ?), float32], %p1217: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %1859 = cast(%p1217, dtype="int64") /* ty=Tensor[(?), int64] */;
    %1860 = (%p0322, %1859);
    adv_index(%1860) /* ty=Tensor[(?, ?), float32] */
  };
  %1862 = (%in_shape_030, %in_shape_116);
  %1863 = (%shape_func_out_035,);
  let %shape_func35: () = vm.shape_func(%1861, %1862, %1863, meta[relay.attrs.ShapeFuncAttrs][35]) /* ty=() */;
  let %storage_0358: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][369]) /* ty=Storage[] */;
  let %tensor_0324: int64 = memory.alloc_tensor(%storage_0358, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][369]) /* ty=int64 */;
  %1864 = fn (%p0323: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0323) /* ty=int64 */
  };
  %1865 = (%shape_func_out_035,);
  %1866 = (%tensor_0324,);
  let %v322: () = vm.invoke_tvm_op(%1864, %1865, %1866) /* ty=() */;
  let %storage_0359: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][370]) /* ty=Storage[] */;
  let %tensor_0325: int64 = memory.alloc_tensor(%storage_0359, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][370]) /* ty=int64 */;
  %1867 = fn (%p0324: int64, Primitive=1) -> int64 {
    multiply(%p0324, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1868 = (%tensor_0324,);
  %1869 = (%tensor_0325,);
  let %v323: () = vm.invoke_tvm_op(%1867, %1868, %1869) /* ty=() */;
  let %storage_0360: Storage[] = memory.alloc_storage(%tensor_0325, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][371]) /* ty=Storage[] */;
  let %out_034: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0360, 0 /* ty=int64 */, %shape_func_out_035, meta[relay.attrs.AllocTensorAttrs][371]) /* ty=Tensor[(?, ?), float32] */;
  %1870 = (%x358, %x364);
  %1871 = (%out_034,);
  let %v324: () = vm.invoke_tvm_op(%1861, %1870, %1871) /* ty=() */;
  let %x366: Tensor[(?, ?), float32] = %out_034;
  let %in_shape_117: Tensor[(2), int64] = vm.shape_of(%x366, meta[relay.attrs.ShapeOfAttrs][35]) /* ty=Tensor[(2), int64] */;
  let %storage_0361: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][372]) /* ty=Storage[] */;
  let %tensor_0326: Tensor[(4), int64] = memory.alloc_tensor(%storage_0361, 0 /* ty=int64 */, meta[relay.Constant][414] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][372]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_036: Tensor[(4), int64] = %tensor_0326;
  %1872 = fn (%p0325: Tensor[(1, 256, 100, 100), float32], %p1218: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    vision.roi_align(%p0325, %p1218, meta[relay.attrs.ROIAlignAttrs][1]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %1873 = (meta[relay.Constant][415] /* ty=Tensor[(4), int64] */, %in_shape_117);
  %1874 = (%shape_func_out_036,);
  let %shape_func36: () = vm.shape_func(%1872, %1873, %1874, meta[relay.attrs.ShapeFuncAttrs][36]) /* ty=() */;
  let %storage_0362: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][373]) /* ty=Storage[] */;
  let %tensor_0327: int64 = memory.alloc_tensor(%storage_0362, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][373]) /* ty=int64 */;
  %1875 = fn (%p0326: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0326) /* ty=int64 */
  };
  %1876 = (%shape_func_out_036,);
  %1877 = (%tensor_0327,);
  let %v325: () = vm.invoke_tvm_op(%1875, %1876, %1877) /* ty=() */;
  let %storage_0363: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][374]) /* ty=Storage[] */;
  let %tensor_0328: int64 = memory.alloc_tensor(%storage_0363, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][374]) /* ty=int64 */;
  %1878 = fn (%p0327: int64, Primitive=1) -> int64 {
    multiply(%p0327, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1879 = (%tensor_0327,);
  %1880 = (%tensor_0328,);
  let %v326: () = vm.invoke_tvm_op(%1878, %1879, %1880) /* ty=() */;
  let %storage_0364: Storage[] = memory.alloc_storage(%tensor_0328, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][375]) /* ty=Storage[] */;
  let %out_035: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0364, 0 /* ty=int64 */, %shape_func_out_036, meta[relay.attrs.AllocTensorAttrs][375]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %1881 = (%x278, %x366);
  %1882 = (%out_035,);
  let %v327: () = vm.invoke_tvm_op(%1872, %1881, %1882) /* ty=() */;
  let %x367: Tensor[(?, 256, 7, 7), float32] = %out_035;
  let %in_shape_031: Tensor[(4), int64] = vm.shape_of(%x361, meta[relay.attrs.ShapeOfAttrs][36]) /* ty=Tensor[(4), int64] */;
  let %in_shape_118: Tensor[(4), int64] = vm.shape_of(%x365, meta[relay.attrs.ShapeOfAttrs][37]) /* ty=Tensor[(4), int64] */;
  let %in_shape_211: Tensor[(4), int64] = vm.shape_of(%x367, meta[relay.attrs.ShapeOfAttrs][38]) /* ty=Tensor[(4), int64] */;
  let %storage_0365: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][376]) /* ty=Storage[] */;
  let %tensor_0329: Tensor[(4), int64] = memory.alloc_tensor(%storage_0365, 0 /* ty=int64 */, meta[relay.Constant][416] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][376]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_037: Tensor[(4), int64] = %tensor_0329;
  %1883 = fn (%p0328: Tensor[(?, 256, 7, 7), float32], %p1219: Tensor[(?, 256, 7, 7), int32], %p2101: Tensor[(?, 256, 7, 7), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    scatter(%p0328, %p1219, %p2101, meta[relay.attrs.ScatterAttrs][2]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %1884 = (%in_shape_031, %in_shape_118, %in_shape_211);
  %1885 = (%shape_func_out_037,);
  let %shape_func37: () = vm.shape_func(%1883, %1884, %1885, meta[relay.attrs.ShapeFuncAttrs][37]) /* ty=() */;
  let %storage_0366: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][377]) /* ty=Storage[] */;
  let %tensor_0330: int64 = memory.alloc_tensor(%storage_0366, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][377]) /* ty=int64 */;
  %1886 = fn (%p0329: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0329) /* ty=int64 */
  };
  %1887 = (%shape_func_out_037,);
  %1888 = (%tensor_0330,);
  let %v328: () = vm.invoke_tvm_op(%1886, %1887, %1888) /* ty=() */;
  let %storage_0367: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][378]) /* ty=Storage[] */;
  let %tensor_0331: int64 = memory.alloc_tensor(%storage_0367, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][378]) /* ty=int64 */;
  %1889 = fn (%p0330: int64, Primitive=1) -> int64 {
    multiply(%p0330, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1890 = (%tensor_0330,);
  %1891 = (%tensor_0331,);
  let %v329: () = vm.invoke_tvm_op(%1889, %1890, %1891) /* ty=() */;
  let %storage_0368: Storage[] = memory.alloc_storage(%tensor_0331, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][379]) /* ty=Storage[] */;
  let %out_036: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0368, 0 /* ty=int64 */, %shape_func_out_037, meta[relay.attrs.AllocTensorAttrs][379]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %1892 = (%x361, %x365, %x367);
  %1893 = (%out_036,);
  let %v330: () = vm.invoke_tvm_op(%1883, %1892, %1893) /* ty=() */;
  let %x368: Tensor[(?, 256, 7, 7), float32] = %out_036;
  let %in_shape_032: Tensor[(1), int64] = vm.shape_of(%x342, meta[relay.attrs.ShapeOfAttrs][39]) /* ty=Tensor[(1), int64] */;
  let %storage_0369: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][380]) /* ty=Storage[] */;
  let %tensor_0332: Tensor[(1), int64] = memory.alloc_tensor(%storage_0369, 0 /* ty=int64 */, meta[relay.Constant][417] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][380]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_038: Tensor[(1), int64] = %tensor_0332;
  %1894 = fn (%p0331: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0331, 2 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %1895 = (%in_shape_032,);
  %1896 = (%shape_func_out_038,);
  let %shape_func38: () = vm.shape_func(%1894, %1895, %1896, meta[relay.attrs.ShapeFuncAttrs][38]) /* ty=() */;
  let %storage_0370: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][381]) /* ty=Storage[] */;
  let %tensor_0333: int64 = memory.alloc_tensor(%storage_0370, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][381]) /* ty=int64 */;
  %1897 = fn (%p0332: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0332) /* ty=int64 */
  };
  %1898 = (%shape_func_out_038,);
  %1899 = (%tensor_0333,);
  let %v331: () = vm.invoke_tvm_op(%1897, %1898, %1899) /* ty=() */;
  let %storage_0371: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][382]) /* ty=Storage[] */;
  let %tensor_0334: int64 = memory.alloc_tensor(%storage_0371, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][382]) /* ty=int64 */;
  %1900 = fn (%p0333: int64, Primitive=1) -> int64 {
    multiply(%p0333, 1 /* ty=int64 */) /* ty=int64 */
  };
  %1901 = (%tensor_0333,);
  %1902 = (%tensor_0334,);
  let %v332: () = vm.invoke_tvm_op(%1900, %1901, %1902) /* ty=() */;
  let %storage_0372: Storage[] = memory.alloc_storage(%tensor_0334, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][383]) /* ty=Storage[] */;
  let %out_037: Tensor[(?), bool] = memory.alloc_tensor(%storage_0372, 0 /* ty=int64 */, %shape_func_out_038, meta[relay.attrs.AllocTensorAttrs][383]) /* ty=Tensor[(?), bool] */;
  %1903 = (%x342,);
  %1904 = (%out_037,);
  let %v333: () = vm.invoke_tvm_op(%1894, %1903, %1904) /* ty=() */;
  let %x369: Tensor[(?), bool] = %out_037;
  let %in_shape_033: Tensor[(?), bool] = device_copy(%x369, meta[relay.attrs.DeviceCopyAttrs][36]) /* ty=Tensor[(?), bool] */;
  let %storage_0373: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][384]) /* ty=Storage[] */;
  let %tensor_0335: Tensor[(2), int64] = memory.alloc_tensor(%storage_0373, 0 /* ty=int64 */, meta[relay.Constant][418] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][384]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_039: Tensor[(2), int64] = %tensor_0335;
  %1905 = fn (%p0334: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0334) /* ty=Tensor[(?, 1), int32] */
  };
  %1906 = (%in_shape_033,);
  %1907 = (%shape_func_out_039,);
  let %shape_func39: () = vm.shape_func(%1905, %1906, %1907, meta[relay.attrs.ShapeFuncAttrs][39]) /* ty=() */;
  let %storage_0374: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][385]) /* ty=Storage[] */;
  let %tensor_0336: int64 = memory.alloc_tensor(%storage_0374, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][385]) /* ty=int64 */;
  %1908 = fn (%p0335: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0335) /* ty=int64 */
  };
  %1909 = (%shape_func_out_039,);
  %1910 = (%tensor_0336,);
  let %v334: () = vm.invoke_tvm_op(%1908, %1909, %1910) /* ty=() */;
  let %storage_0375: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][386]) /* ty=Storage[] */;
  let %tensor_0337: int64 = memory.alloc_tensor(%storage_0375, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][386]) /* ty=int64 */;
  %1911 = fn (%p0336: int64, Primitive=1) -> int64 {
    multiply(%p0336, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1912 = (%tensor_0336,);
  %1913 = (%tensor_0337,);
  let %v335: () = vm.invoke_tvm_op(%1911, %1912, %1913) /* ty=() */;
  let %storage_0376: Storage[] = memory.alloc_storage(%tensor_0337, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][387]) /* ty=Storage[] */;
  let %out_038: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0376, 0 /* ty=int64 */, %shape_func_out_039, meta[relay.attrs.AllocTensorAttrs][387]) /* ty=Tensor[(?, 1), int32] */;
  %1914 = (%x369,);
  %1915 = (%out_038,);
  let %v336: () = vm.invoke_tvm_op(%1905, %1914, %1915) /* ty=() */;
  let %x370: Tensor[(?, 1), int32] = %out_038;
  let %in_shape_034: Tensor[(2), int64] = vm.shape_of(%x370, meta[relay.attrs.ShapeOfAttrs][40]) /* ty=Tensor[(2), int64] */;
  let %storage_0377: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][388]) /* ty=Storage[] */;
  let %tensor_0338: Tensor[(1), int64] = memory.alloc_tensor(%storage_0377, 0 /* ty=int64 */, meta[relay.Constant][419] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][388]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_040: Tensor[(1), int64] = %tensor_0338;
  %1918 = fn (%p0337: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %1916 = split(%p0337, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %1917 = %1916.0;
    squeeze(%1917, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %1919 = (%in_shape_034,);
  %1920 = (%shape_func_out_040,);
  let %shape_func40: () = vm.shape_func(%1918, %1919, %1920, meta[relay.attrs.ShapeFuncAttrs][40]) /* ty=() */;
  let %storage_0378: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][389]) /* ty=Storage[] */;
  let %tensor_0339: int64 = memory.alloc_tensor(%storage_0378, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][389]) /* ty=int64 */;
  %1921 = fn (%p0338: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0338) /* ty=int64 */
  };
  %1922 = (%shape_func_out_040,);
  %1923 = (%tensor_0339,);
  let %v337: () = vm.invoke_tvm_op(%1921, %1922, %1923) /* ty=() */;
  let %storage_0379: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][390]) /* ty=Storage[] */;
  let %tensor_0340: int64 = memory.alloc_tensor(%storage_0379, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][390]) /* ty=int64 */;
  %1924 = fn (%p0339: int64, Primitive=1) -> int64 {
    multiply(%p0339, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1925 = (%tensor_0339,);
  %1926 = (%tensor_0340,);
  let %v338: () = vm.invoke_tvm_op(%1924, %1925, %1926) /* ty=() */;
  let %storage_0380: Storage[] = memory.alloc_storage(%tensor_0340, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][391]) /* ty=Storage[] */;
  let %out_039: Tensor[(?), int32] = memory.alloc_tensor(%storage_0380, 0 /* ty=int64 */, %shape_func_out_040, meta[relay.attrs.AllocTensorAttrs][391]) /* ty=Tensor[(?), int32] */;
  %1927 = (%x370,);
  %1928 = (%out_039,);
  let %v339: () = vm.invoke_tvm_op(%1918, %1927, %1928) /* ty=() */;
  let %x371: Tensor[(?), int32] = %out_039;
  let %in_shape_035: Tensor[(1), int64] = vm.shape_of(%x371, meta[relay.attrs.ShapeOfAttrs][41]) /* ty=Tensor[(1), int64] */;
  let %storage_0381: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][392]) /* ty=Storage[] */;
  let %tensor_0341: Tensor[(4), int64] = memory.alloc_tensor(%storage_0381, 0 /* ty=int64 */, meta[relay.Constant][420] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][392]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_041: Tensor[(4), int64] = %tensor_0341;
  %1932 = fn (%p0340: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 7, 7), int32] {
    %1929 = reshape(%p0340, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %1930 = repeat(%1929, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %1931 = repeat(%1930, repeats=7, axis=2) /* ty=Tensor[(?, 256, 7, 1), int32] */;
    repeat(%1931, repeats=7, axis=3) /* ty=Tensor[(?, 256, 7, 7), int32] */
  };
  %1933 = (%in_shape_035,);
  %1934 = (%shape_func_out_041,);
  let %shape_func41: () = vm.shape_func(%1932, %1933, %1934, meta[relay.attrs.ShapeFuncAttrs][41]) /* ty=() */;
  let %storage_0382: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][393]) /* ty=Storage[] */;
  let %tensor_0342: int64 = memory.alloc_tensor(%storage_0382, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][393]) /* ty=int64 */;
  %1935 = fn (%p0341: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0341) /* ty=int64 */
  };
  %1936 = (%shape_func_out_041,);
  %1937 = (%tensor_0342,);
  let %v340: () = vm.invoke_tvm_op(%1935, %1936, %1937) /* ty=() */;
  let %storage_0383: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][394]) /* ty=Storage[] */;
  let %tensor_0343: int64 = memory.alloc_tensor(%storage_0383, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][394]) /* ty=int64 */;
  %1938 = fn (%p0342: int64, Primitive=1) -> int64 {
    multiply(%p0342, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1939 = (%tensor_0342,);
  %1940 = (%tensor_0343,);
  let %v341: () = vm.invoke_tvm_op(%1938, %1939, %1940) /* ty=() */;
  let %storage_0384: Storage[] = memory.alloc_storage(%tensor_0343, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][395]) /* ty=Storage[] */;
  let %out_040: Tensor[(?, 256, 7, 7), int32] = memory.alloc_tensor(%storage_0384, 0 /* ty=int64 */, %shape_func_out_041, meta[relay.attrs.AllocTensorAttrs][395]) /* ty=Tensor[(?, 256, 7, 7), int32] */;
  %1941 = (%x371,);
  %1942 = (%out_040,);
  let %v342: () = vm.invoke_tvm_op(%1932, %1941, %1942) /* ty=() */;
  let %x372: Tensor[(?, 256, 7, 7), int32] = %out_040;
  let %in_shape_036: Tensor[(2), int64] = vm.shape_of(%x358, meta[relay.attrs.ShapeOfAttrs][42]) /* ty=Tensor[(2), int64] */;
  let %in_shape_119: Tensor[(1), int64] = vm.shape_of(%x371, meta[relay.attrs.ShapeOfAttrs][43]) /* ty=Tensor[(1), int64] */;
  let %storage_0385: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][396]) /* ty=Storage[] */;
  let %tensor_0344: Tensor[(2), int64] = memory.alloc_tensor(%storage_0385, 0 /* ty=int64 */, meta[relay.Constant][421] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][396]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_042: Tensor[(2), int64] = %tensor_0344;
  %1945 = fn (%p0343: Tensor[(?, ?), float32], %p1220: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %1943 = cast(%p1220, dtype="int64") /* ty=Tensor[(?), int64] */;
    %1944 = (%p0343, %1943);
    adv_index(%1944) /* ty=Tensor[(?, ?), float32] */
  };
  %1946 = (%in_shape_036, %in_shape_119);
  %1947 = (%shape_func_out_042,);
  let %shape_func42: () = vm.shape_func(%1945, %1946, %1947, meta[relay.attrs.ShapeFuncAttrs][42]) /* ty=() */;
  let %storage_0386: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][397]) /* ty=Storage[] */;
  let %tensor_0345: int64 = memory.alloc_tensor(%storage_0386, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][397]) /* ty=int64 */;
  %1948 = fn (%p0344: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0344) /* ty=int64 */
  };
  %1949 = (%shape_func_out_042,);
  %1950 = (%tensor_0345,);
  let %v343: () = vm.invoke_tvm_op(%1948, %1949, %1950) /* ty=() */;
  let %storage_0387: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][398]) /* ty=Storage[] */;
  let %tensor_0346: int64 = memory.alloc_tensor(%storage_0387, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][398]) /* ty=int64 */;
  %1951 = fn (%p0345: int64, Primitive=1) -> int64 {
    multiply(%p0345, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1952 = (%tensor_0345,);
  %1953 = (%tensor_0346,);
  let %v344: () = vm.invoke_tvm_op(%1951, %1952, %1953) /* ty=() */;
  let %storage_0388: Storage[] = memory.alloc_storage(%tensor_0346, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][399]) /* ty=Storage[] */;
  let %out_041: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0388, 0 /* ty=int64 */, %shape_func_out_042, meta[relay.attrs.AllocTensorAttrs][399]) /* ty=Tensor[(?, ?), float32] */;
  %1954 = (%x358, %x371);
  %1955 = (%out_041,);
  let %v345: () = vm.invoke_tvm_op(%1945, %1954, %1955) /* ty=() */;
  let %x373: Tensor[(?, ?), float32] = %out_041;
  let %in_shape_120: Tensor[(2), int64] = vm.shape_of(%x373, meta[relay.attrs.ShapeOfAttrs][44]) /* ty=Tensor[(2), int64] */;
  let %storage_0389: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][400]) /* ty=Storage[] */;
  let %tensor_0347: Tensor[(4), int64] = memory.alloc_tensor(%storage_0389, 0 /* ty=int64 */, meta[relay.Constant][422] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][400]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_043: Tensor[(4), int64] = %tensor_0347;
  %1956 = fn (%p0346: Tensor[(1, 256, 50, 50), float32], %p1221: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    vision.roi_align(%p0346, %p1221, meta[relay.attrs.ROIAlignAttrs][2]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %1957 = (meta[relay.Constant][423] /* ty=Tensor[(4), int64] */, %in_shape_120);
  %1958 = (%shape_func_out_043,);
  let %shape_func43: () = vm.shape_func(%1956, %1957, %1958, meta[relay.attrs.ShapeFuncAttrs][43]) /* ty=() */;
  let %storage_0390: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][401]) /* ty=Storage[] */;
  let %tensor_0348: int64 = memory.alloc_tensor(%storage_0390, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][401]) /* ty=int64 */;
  %1959 = fn (%p0347: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0347) /* ty=int64 */
  };
  %1960 = (%shape_func_out_043,);
  %1961 = (%tensor_0348,);
  let %v346: () = vm.invoke_tvm_op(%1959, %1960, %1961) /* ty=() */;
  let %storage_0391: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][402]) /* ty=Storage[] */;
  let %tensor_0349: int64 = memory.alloc_tensor(%storage_0391, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][402]) /* ty=int64 */;
  %1962 = fn (%p0348: int64, Primitive=1) -> int64 {
    multiply(%p0348, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1963 = (%tensor_0348,);
  %1964 = (%tensor_0349,);
  let %v347: () = vm.invoke_tvm_op(%1962, %1963, %1964) /* ty=() */;
  let %storage_0392: Storage[] = memory.alloc_storage(%tensor_0349, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][403]) /* ty=Storage[] */;
  let %out_042: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0392, 0 /* ty=int64 */, %shape_func_out_043, meta[relay.attrs.AllocTensorAttrs][403]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %1965 = (%x281, %x373);
  %1966 = (%out_042,);
  let %v348: () = vm.invoke_tvm_op(%1956, %1965, %1966) /* ty=() */;
  let %x374: Tensor[(?, 256, 7, 7), float32] = %out_042;
  let %in_shape_037: Tensor[(4), int64] = vm.shape_of(%x368, meta[relay.attrs.ShapeOfAttrs][45]) /* ty=Tensor[(4), int64] */;
  let %in_shape_121: Tensor[(4), int64] = vm.shape_of(%x372, meta[relay.attrs.ShapeOfAttrs][46]) /* ty=Tensor[(4), int64] */;
  let %in_shape_212: Tensor[(4), int64] = vm.shape_of(%x374, meta[relay.attrs.ShapeOfAttrs][47]) /* ty=Tensor[(4), int64] */;
  let %storage_0393: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][404]) /* ty=Storage[] */;
  let %tensor_0350: Tensor[(4), int64] = memory.alloc_tensor(%storage_0393, 0 /* ty=int64 */, meta[relay.Constant][424] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][404]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_044: Tensor[(4), int64] = %tensor_0350;
  %1967 = fn (%p0349: Tensor[(?, 256, 7, 7), float32], %p1222: Tensor[(?, 256, 7, 7), int32], %p2102: Tensor[(?, 256, 7, 7), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    scatter(%p0349, %p1222, %p2102, meta[relay.attrs.ScatterAttrs][3]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %1968 = (%in_shape_037, %in_shape_121, %in_shape_212);
  %1969 = (%shape_func_out_044,);
  let %shape_func44: () = vm.shape_func(%1967, %1968, %1969, meta[relay.attrs.ShapeFuncAttrs][44]) /* ty=() */;
  let %storage_0394: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][405]) /* ty=Storage[] */;
  let %tensor_0351: int64 = memory.alloc_tensor(%storage_0394, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][405]) /* ty=int64 */;
  %1970 = fn (%p0350: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0350) /* ty=int64 */
  };
  %1971 = (%shape_func_out_044,);
  %1972 = (%tensor_0351,);
  let %v349: () = vm.invoke_tvm_op(%1970, %1971, %1972) /* ty=() */;
  let %storage_0395: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][406]) /* ty=Storage[] */;
  let %tensor_0352: int64 = memory.alloc_tensor(%storage_0395, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][406]) /* ty=int64 */;
  %1973 = fn (%p0351: int64, Primitive=1) -> int64 {
    multiply(%p0351, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1974 = (%tensor_0351,);
  %1975 = (%tensor_0352,);
  let %v350: () = vm.invoke_tvm_op(%1973, %1974, %1975) /* ty=() */;
  let %storage_0396: Storage[] = memory.alloc_storage(%tensor_0352, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][407]) /* ty=Storage[] */;
  let %out_043: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0396, 0 /* ty=int64 */, %shape_func_out_044, meta[relay.attrs.AllocTensorAttrs][407]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %1976 = (%x368, %x372, %x374);
  %1977 = (%out_043,);
  let %v351: () = vm.invoke_tvm_op(%1967, %1976, %1977) /* ty=() */;
  let %x375: Tensor[(?, 256, 7, 7), float32] = %out_043;
  let %in_shape_038: Tensor[(1), int64] = vm.shape_of(%x342, meta[relay.attrs.ShapeOfAttrs][48]) /* ty=Tensor[(1), int64] */;
  let %storage_0397: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][408]) /* ty=Storage[] */;
  let %tensor_0353: Tensor[(1), int64] = memory.alloc_tensor(%storage_0397, 0 /* ty=int64 */, meta[relay.Constant][425] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][408]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_045: Tensor[(1), int64] = %tensor_0353;
  %1978 = fn (%p0352: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0352, 3 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %1979 = (%in_shape_038,);
  %1980 = (%shape_func_out_045,);
  let %shape_func45: () = vm.shape_func(%1978, %1979, %1980, meta[relay.attrs.ShapeFuncAttrs][45]) /* ty=() */;
  let %storage_0398: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][409]) /* ty=Storage[] */;
  let %tensor_0354: int64 = memory.alloc_tensor(%storage_0398, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][409]) /* ty=int64 */;
  %1981 = fn (%p0353: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0353) /* ty=int64 */
  };
  %1982 = (%shape_func_out_045,);
  %1983 = (%tensor_0354,);
  let %v352: () = vm.invoke_tvm_op(%1981, %1982, %1983) /* ty=() */;
  let %storage_0399: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][410]) /* ty=Storage[] */;
  let %tensor_0355: int64 = memory.alloc_tensor(%storage_0399, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][410]) /* ty=int64 */;
  %1984 = fn (%p0354: int64, Primitive=1) -> int64 {
    multiply(%p0354, 1 /* ty=int64 */) /* ty=int64 */
  };
  %1985 = (%tensor_0354,);
  %1986 = (%tensor_0355,);
  let %v353: () = vm.invoke_tvm_op(%1984, %1985, %1986) /* ty=() */;
  let %storage_0400: Storage[] = memory.alloc_storage(%tensor_0355, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][411]) /* ty=Storage[] */;
  let %out_044: Tensor[(?), bool] = memory.alloc_tensor(%storage_0400, 0 /* ty=int64 */, %shape_func_out_045, meta[relay.attrs.AllocTensorAttrs][411]) /* ty=Tensor[(?), bool] */;
  %1987 = (%x342,);
  %1988 = (%out_044,);
  let %v354: () = vm.invoke_tvm_op(%1978, %1987, %1988) /* ty=() */;
  let %x376: Tensor[(?), bool] = %out_044;
  let %in_shape_039: Tensor[(?), bool] = device_copy(%x376, meta[relay.attrs.DeviceCopyAttrs][37]) /* ty=Tensor[(?), bool] */;
  let %storage_0401: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][412]) /* ty=Storage[] */;
  let %tensor_0356: Tensor[(2), int64] = memory.alloc_tensor(%storage_0401, 0 /* ty=int64 */, meta[relay.Constant][426] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][412]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_046: Tensor[(2), int64] = %tensor_0356;
  %1989 = fn (%p0355: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0355) /* ty=Tensor[(?, 1), int32] */
  };
  %1990 = (%in_shape_039,);
  %1991 = (%shape_func_out_046,);
  let %shape_func46: () = vm.shape_func(%1989, %1990, %1991, meta[relay.attrs.ShapeFuncAttrs][46]) /* ty=() */;
  let %storage_0402: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][413]) /* ty=Storage[] */;
  let %tensor_0357: int64 = memory.alloc_tensor(%storage_0402, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][413]) /* ty=int64 */;
  %1992 = fn (%p0356: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0356) /* ty=int64 */
  };
  %1993 = (%shape_func_out_046,);
  %1994 = (%tensor_0357,);
  let %v355: () = vm.invoke_tvm_op(%1992, %1993, %1994) /* ty=() */;
  let %storage_0403: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][414]) /* ty=Storage[] */;
  let %tensor_0358: int64 = memory.alloc_tensor(%storage_0403, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][414]) /* ty=int64 */;
  %1995 = fn (%p0357: int64, Primitive=1) -> int64 {
    multiply(%p0357, 4 /* ty=int64 */) /* ty=int64 */
  };
  %1996 = (%tensor_0357,);
  %1997 = (%tensor_0358,);
  let %v356: () = vm.invoke_tvm_op(%1995, %1996, %1997) /* ty=() */;
  let %storage_0404: Storage[] = memory.alloc_storage(%tensor_0358, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][415]) /* ty=Storage[] */;
  let %out_045: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0404, 0 /* ty=int64 */, %shape_func_out_046, meta[relay.attrs.AllocTensorAttrs][415]) /* ty=Tensor[(?, 1), int32] */;
  %1998 = (%x376,);
  %1999 = (%out_045,);
  let %v357: () = vm.invoke_tvm_op(%1989, %1998, %1999) /* ty=() */;
  let %x377: Tensor[(?, 1), int32] = %out_045;
  let %in_shape_040: Tensor[(2), int64] = vm.shape_of(%x377, meta[relay.attrs.ShapeOfAttrs][49]) /* ty=Tensor[(2), int64] */;
  let %storage_0405: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][416]) /* ty=Storage[] */;
  let %tensor_0359: Tensor[(1), int64] = memory.alloc_tensor(%storage_0405, 0 /* ty=int64 */, meta[relay.Constant][427] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][416]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_047: Tensor[(1), int64] = %tensor_0359;
  %2002 = fn (%p0358: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %2000 = split(%p0358, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %2001 = %2000.0;
    squeeze(%2001, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %2003 = (%in_shape_040,);
  %2004 = (%shape_func_out_047,);
  let %shape_func47: () = vm.shape_func(%2002, %2003, %2004, meta[relay.attrs.ShapeFuncAttrs][47]) /* ty=() */;
  let %storage_0406: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][417]) /* ty=Storage[] */;
  let %tensor_0360: int64 = memory.alloc_tensor(%storage_0406, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][417]) /* ty=int64 */;
  %2005 = fn (%p0359: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0359) /* ty=int64 */
  };
  %2006 = (%shape_func_out_047,);
  %2007 = (%tensor_0360,);
  let %v358: () = vm.invoke_tvm_op(%2005, %2006, %2007) /* ty=() */;
  let %storage_0407: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][418]) /* ty=Storage[] */;
  let %tensor_0361: int64 = memory.alloc_tensor(%storage_0407, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][418]) /* ty=int64 */;
  %2008 = fn (%p0360: int64, Primitive=1) -> int64 {
    multiply(%p0360, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2009 = (%tensor_0360,);
  %2010 = (%tensor_0361,);
  let %v359: () = vm.invoke_tvm_op(%2008, %2009, %2010) /* ty=() */;
  let %storage_0408: Storage[] = memory.alloc_storage(%tensor_0361, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][419]) /* ty=Storage[] */;
  let %out_046: Tensor[(?), int32] = memory.alloc_tensor(%storage_0408, 0 /* ty=int64 */, %shape_func_out_047, meta[relay.attrs.AllocTensorAttrs][419]) /* ty=Tensor[(?), int32] */;
  %2011 = (%x377,);
  %2012 = (%out_046,);
  let %v360: () = vm.invoke_tvm_op(%2002, %2011, %2012) /* ty=() */;
  let %x378: Tensor[(?), int32] = %out_046;
  let %in_shape_041: Tensor[(1), int64] = vm.shape_of(%x378, meta[relay.attrs.ShapeOfAttrs][50]) /* ty=Tensor[(1), int64] */;
  let %storage_0409: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][420]) /* ty=Storage[] */;
  let %tensor_0362: Tensor[(4), int64] = memory.alloc_tensor(%storage_0409, 0 /* ty=int64 */, meta[relay.Constant][428] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][420]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_048: Tensor[(4), int64] = %tensor_0362;
  %2016 = fn (%p0361: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 7, 7), int32] {
    %2013 = reshape(%p0361, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %2014 = repeat(%2013, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %2015 = repeat(%2014, repeats=7, axis=2) /* ty=Tensor[(?, 256, 7, 1), int32] */;
    repeat(%2015, repeats=7, axis=3) /* ty=Tensor[(?, 256, 7, 7), int32] */
  };
  %2017 = (%in_shape_041,);
  %2018 = (%shape_func_out_048,);
  let %shape_func48: () = vm.shape_func(%2016, %2017, %2018, meta[relay.attrs.ShapeFuncAttrs][48]) /* ty=() */;
  let %storage_0410: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][421]) /* ty=Storage[] */;
  let %tensor_0363: int64 = memory.alloc_tensor(%storage_0410, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][421]) /* ty=int64 */;
  %2019 = fn (%p0362: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0362) /* ty=int64 */
  };
  %2020 = (%shape_func_out_048,);
  %2021 = (%tensor_0363,);
  let %v361: () = vm.invoke_tvm_op(%2019, %2020, %2021) /* ty=() */;
  let %storage_0411: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][422]) /* ty=Storage[] */;
  let %tensor_0364: int64 = memory.alloc_tensor(%storage_0411, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][422]) /* ty=int64 */;
  %2022 = fn (%p0363: int64, Primitive=1) -> int64 {
    multiply(%p0363, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2023 = (%tensor_0363,);
  %2024 = (%tensor_0364,);
  let %v362: () = vm.invoke_tvm_op(%2022, %2023, %2024) /* ty=() */;
  let %storage_0412: Storage[] = memory.alloc_storage(%tensor_0364, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][423]) /* ty=Storage[] */;
  let %out_047: Tensor[(?, 256, 7, 7), int32] = memory.alloc_tensor(%storage_0412, 0 /* ty=int64 */, %shape_func_out_048, meta[relay.attrs.AllocTensorAttrs][423]) /* ty=Tensor[(?, 256, 7, 7), int32] */;
  %2025 = (%x378,);
  %2026 = (%out_047,);
  let %v363: () = vm.invoke_tvm_op(%2016, %2025, %2026) /* ty=() */;
  let %x379: Tensor[(?, 256, 7, 7), int32] = %out_047;
  let %in_shape_042: Tensor[(2), int64] = vm.shape_of(%x358, meta[relay.attrs.ShapeOfAttrs][51]) /* ty=Tensor[(2), int64] */;
  let %in_shape_122: Tensor[(1), int64] = vm.shape_of(%x378, meta[relay.attrs.ShapeOfAttrs][52]) /* ty=Tensor[(1), int64] */;
  let %storage_0413: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][424]) /* ty=Storage[] */;
  let %tensor_0365: Tensor[(2), int64] = memory.alloc_tensor(%storage_0413, 0 /* ty=int64 */, meta[relay.Constant][429] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][424]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_049: Tensor[(2), int64] = %tensor_0365;
  %2029 = fn (%p0364: Tensor[(?, ?), float32], %p1223: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %2027 = cast(%p1223, dtype="int64") /* ty=Tensor[(?), int64] */;
    %2028 = (%p0364, %2027);
    adv_index(%2028) /* ty=Tensor[(?, ?), float32] */
  };
  %2030 = (%in_shape_042, %in_shape_122);
  %2031 = (%shape_func_out_049,);
  let %shape_func49: () = vm.shape_func(%2029, %2030, %2031, meta[relay.attrs.ShapeFuncAttrs][49]) /* ty=() */;
  let %storage_0414: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][425]) /* ty=Storage[] */;
  let %tensor_0366: int64 = memory.alloc_tensor(%storage_0414, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][425]) /* ty=int64 */;
  %2032 = fn (%p0365: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0365) /* ty=int64 */
  };
  %2033 = (%shape_func_out_049,);
  %2034 = (%tensor_0366,);
  let %v364: () = vm.invoke_tvm_op(%2032, %2033, %2034) /* ty=() */;
  let %storage_0415: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][426]) /* ty=Storage[] */;
  let %tensor_0367: int64 = memory.alloc_tensor(%storage_0415, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][426]) /* ty=int64 */;
  %2035 = fn (%p0366: int64, Primitive=1) -> int64 {
    multiply(%p0366, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2036 = (%tensor_0366,);
  %2037 = (%tensor_0367,);
  let %v365: () = vm.invoke_tvm_op(%2035, %2036, %2037) /* ty=() */;
  let %storage_0416: Storage[] = memory.alloc_storage(%tensor_0367, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][427]) /* ty=Storage[] */;
  let %out_048: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0416, 0 /* ty=int64 */, %shape_func_out_049, meta[relay.attrs.AllocTensorAttrs][427]) /* ty=Tensor[(?, ?), float32] */;
  %2038 = (%x358, %x378);
  %2039 = (%out_048,);
  let %v366: () = vm.invoke_tvm_op(%2029, %2038, %2039) /* ty=() */;
  let %x380: Tensor[(?, ?), float32] = %out_048;
  let %in_shape_123: Tensor[(2), int64] = vm.shape_of(%x380, meta[relay.attrs.ShapeOfAttrs][53]) /* ty=Tensor[(2), int64] */;
  let %storage_0417: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][428]) /* ty=Storage[] */;
  let %tensor_0368: Tensor[(4), int64] = memory.alloc_tensor(%storage_0417, 0 /* ty=int64 */, meta[relay.Constant][430] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][428]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_050: Tensor[(4), int64] = %tensor_0368;
  %2040 = fn (%p0367: Tensor[(1, 256, 25, 25), float32], %p1224: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    vision.roi_align(%p0367, %p1224, meta[relay.attrs.ROIAlignAttrs][3]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %2041 = (meta[relay.Constant][431] /* ty=Tensor[(4), int64] */, %in_shape_123);
  %2042 = (%shape_func_out_050,);
  let %shape_func50: () = vm.shape_func(%2040, %2041, %2042, meta[relay.attrs.ShapeFuncAttrs][50]) /* ty=() */;
  let %storage_0418: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][429]) /* ty=Storage[] */;
  let %tensor_0369: int64 = memory.alloc_tensor(%storage_0418, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][429]) /* ty=int64 */;
  %2043 = fn (%p0368: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0368) /* ty=int64 */
  };
  %2044 = (%shape_func_out_050,);
  %2045 = (%tensor_0369,);
  let %v367: () = vm.invoke_tvm_op(%2043, %2044, %2045) /* ty=() */;
  let %storage_0419: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][430]) /* ty=Storage[] */;
  let %tensor_0370: int64 = memory.alloc_tensor(%storage_0419, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][430]) /* ty=int64 */;
  %2046 = fn (%p0369: int64, Primitive=1) -> int64 {
    multiply(%p0369, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2047 = (%tensor_0369,);
  %2048 = (%tensor_0370,);
  let %v368: () = vm.invoke_tvm_op(%2046, %2047, %2048) /* ty=() */;
  let %storage_0420: Storage[] = memory.alloc_storage(%tensor_0370, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][431]) /* ty=Storage[] */;
  let %out_049: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0420, 0 /* ty=int64 */, %shape_func_out_050, meta[relay.attrs.AllocTensorAttrs][431]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %2049 = (%x284, %x380);
  %2050 = (%out_049,);
  let %v369: () = vm.invoke_tvm_op(%2040, %2049, %2050) /* ty=() */;
  let %x381: Tensor[(?, 256, 7, 7), float32] = %out_049;
  let %in_shape_043: Tensor[(4), int64] = vm.shape_of(%x375, meta[relay.attrs.ShapeOfAttrs][54]) /* ty=Tensor[(4), int64] */;
  let %in_shape_124: Tensor[(4), int64] = vm.shape_of(%x379, meta[relay.attrs.ShapeOfAttrs][55]) /* ty=Tensor[(4), int64] */;
  let %in_shape_213: Tensor[(4), int64] = vm.shape_of(%x381, meta[relay.attrs.ShapeOfAttrs][56]) /* ty=Tensor[(4), int64] */;
  let %storage_0421: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][432]) /* ty=Storage[] */;
  let %tensor_0371: Tensor[(4), int64] = memory.alloc_tensor(%storage_0421, 0 /* ty=int64 */, meta[relay.Constant][432] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][432]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_051: Tensor[(4), int64] = %tensor_0371;
  %2051 = fn (%p0370: Tensor[(?, 256, 7, 7), float32], %p1225: Tensor[(?, 256, 7, 7), int32], %p2103: Tensor[(?, 256, 7, 7), float32], Primitive=1) -> Tensor[(?, 256, 7, 7), float32] {
    scatter(%p0370, %p1225, %p2103, meta[relay.attrs.ScatterAttrs][4]) /* ty=Tensor[(?, 256, 7, 7), float32] */
  };
  %2052 = (%in_shape_043, %in_shape_124, %in_shape_213);
  %2053 = (%shape_func_out_051,);
  let %shape_func51: () = vm.shape_func(%2051, %2052, %2053, meta[relay.attrs.ShapeFuncAttrs][51]) /* ty=() */;
  let %storage_0422: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][433]) /* ty=Storage[] */;
  let %tensor_0372: int64 = memory.alloc_tensor(%storage_0422, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][433]) /* ty=int64 */;
  %2054 = fn (%p0371: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0371) /* ty=int64 */
  };
  %2055 = (%shape_func_out_051,);
  %2056 = (%tensor_0372,);
  let %v370: () = vm.invoke_tvm_op(%2054, %2055, %2056) /* ty=() */;
  let %storage_0423: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][434]) /* ty=Storage[] */;
  let %tensor_0373: int64 = memory.alloc_tensor(%storage_0423, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][434]) /* ty=int64 */;
  %2057 = fn (%p0372: int64, Primitive=1) -> int64 {
    multiply(%p0372, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2058 = (%tensor_0372,);
  %2059 = (%tensor_0373,);
  let %v371: () = vm.invoke_tvm_op(%2057, %2058, %2059) /* ty=() */;
  let %storage_0424: Storage[] = memory.alloc_storage(%tensor_0373, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][435]) /* ty=Storage[] */;
  let %out_050: Tensor[(?, 256, 7, 7), float32] = memory.alloc_tensor(%storage_0424, 0 /* ty=int64 */, %shape_func_out_051, meta[relay.attrs.AllocTensorAttrs][435]) /* ty=Tensor[(?, 256, 7, 7), float32] */;
  %2060 = (%x375, %x379, %x381);
  %2061 = (%out_050,);
  let %v372: () = vm.invoke_tvm_op(%2051, %2060, %2061) /* ty=() */;
  let %x382: Tensor[(?, 256, 7, 7), float32] = %out_050;
  let %in_shape_044: Tensor[(4), int64] = vm.shape_of(%x382, meta[relay.attrs.ShapeOfAttrs][57]) /* ty=Tensor[(4), int64] */;
  let %storage_0425: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][436]) /* ty=Storage[] */;
  let %tensor_0374: Tensor[(2), int64] = memory.alloc_tensor(%storage_0425, 0 /* ty=int64 */, meta[relay.Constant][433] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][436]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_052: Tensor[(2), int64] = %tensor_0374;
  %2063 = fn (%p0373: Tensor[(?, 256, 7, 7), float32], Primitive=1) -> Tensor[(?, 12544), float32] {
    %2062 = reshape(%p0373, newshape=[0, -1, 1, 1]) /* ty=Tensor[(?, 12544, 1, 1), float32] */;
    squeeze(%2062, axis=[2, 3]) /* ty=Tensor[(?, 12544), float32] */
  };
  %2064 = (%in_shape_044,);
  %2065 = (%shape_func_out_052,);
  let %shape_func52: () = vm.shape_func(%2063, %2064, %2065, meta[relay.attrs.ShapeFuncAttrs][52]) /* ty=() */;
  let %storage_0426: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][437]) /* ty=Storage[] */;
  let %tensor_0375: int64 = memory.alloc_tensor(%storage_0426, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][437]) /* ty=int64 */;
  %2066 = fn (%p0374: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0374) /* ty=int64 */
  };
  %2067 = (%shape_func_out_052,);
  %2068 = (%tensor_0375,);
  let %v373: () = vm.invoke_tvm_op(%2066, %2067, %2068) /* ty=() */;
  let %storage_0427: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][438]) /* ty=Storage[] */;
  let %tensor_0376: int64 = memory.alloc_tensor(%storage_0427, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][438]) /* ty=int64 */;
  %2069 = fn (%p0375: int64, Primitive=1) -> int64 {
    multiply(%p0375, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2070 = (%tensor_0375,);
  %2071 = (%tensor_0376,);
  let %v374: () = vm.invoke_tvm_op(%2069, %2070, %2071) /* ty=() */;
  let %storage_0428: Storage[] = memory.alloc_storage(%tensor_0376, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][439]) /* ty=Storage[] */;
  let %out_051: Tensor[(?, 12544), float32] = memory.alloc_tensor(%storage_0428, 0 /* ty=int64 */, %shape_func_out_052, meta[relay.attrs.AllocTensorAttrs][439]) /* ty=Tensor[(?, 12544), float32] */;
  %2072 = (%x382,);
  %2073 = (%out_051,);
  let %v375: () = vm.invoke_tvm_op(%2063, %2072, %2073) /* ty=() */;
  let %x383: Tensor[(?, 12544), float32] = %out_051;
  let %storage_0429: Storage[] = memory.alloc_storage(51380224 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][440]) /* ty=Storage[] */;
  let %tensor_0377: Tensor[(1024, 12544), float32] = memory.alloc_tensor(%storage_0429, 0 /* ty=int64 */, meta[relay.Constant][434] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][440]) /* ty=Tensor[(1024, 12544), float32] */;
  %2075 = fn (%p0376: Tensor[(1024, 12544), float32], Primitive=1) -> Tensor[(1024, 12544), float32] {
    %2074 = transpose(%p0376, axes=[1, 0]) /* ty=Tensor[(12544, 1024), float32] */;
    transpose(%2074, axes=[1, 0]) /* ty=Tensor[(1024, 12544), float32] */
  };
  %2076 = (%model.roi_heads.box_head.fc6.weight,);
  %2077 = (%tensor_0377,);
  let %v376: () = vm.invoke_tvm_op(%2075, %2076, %2077) /* ty=() */;
  let %x384: Tensor[(1024, 12544), float32] = %tensor_0377;
  let %in_shape_045: Tensor[(2), int64] = vm.shape_of(%x383, meta[relay.attrs.ShapeOfAttrs][58]) /* ty=Tensor[(2), int64] */;
  let %storage_0430: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][441]) /* ty=Storage[] */;
  let %tensor_0378: Tensor[(2), int64] = memory.alloc_tensor(%storage_0430, 0 /* ty=int64 */, meta[relay.Constant][435] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][441]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_053: Tensor[(2), int64] = %tensor_0378;
  %2080 = fn (%p0377: Tensor[(?, 12544), float32], %p1226: Tensor[(1024, 12544), float32], %p2104: Tensor[(1024), float32], Primitive=1) -> Tensor[(?, 1024), float32] {
    %2078 = nn.dense(%p0377, %p1226, units=1024) /* ty=Tensor[(?, 1024), float32] */;
    %2079 = add(%2078, %p2104) /* ty=Tensor[(?, 1024), float32] */;
    nn.relu(%2079) /* ty=Tensor[(?, 1024), float32] */
  };
  %2081 = (%in_shape_045, meta[relay.Constant][436] /* ty=Tensor[(2), int64] */, meta[relay.Constant][437] /* ty=Tensor[(1), int64] */);
  %2082 = (%shape_func_out_053,);
  let %shape_func53: () = vm.shape_func(%2080, %2081, %2082, meta[relay.attrs.ShapeFuncAttrs][53]) /* ty=() */;
  let %storage_0431: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][442]) /* ty=Storage[] */;
  let %tensor_0379: int64 = memory.alloc_tensor(%storage_0431, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][442]) /* ty=int64 */;
  %2083 = fn (%p0378: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0378) /* ty=int64 */
  };
  %2084 = (%shape_func_out_053,);
  %2085 = (%tensor_0379,);
  let %v377: () = vm.invoke_tvm_op(%2083, %2084, %2085) /* ty=() */;
  let %storage_0432: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][443]) /* ty=Storage[] */;
  let %tensor_0380: int64 = memory.alloc_tensor(%storage_0432, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][443]) /* ty=int64 */;
  %2086 = fn (%p0379: int64, Primitive=1) -> int64 {
    multiply(%p0379, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2087 = (%tensor_0379,);
  %2088 = (%tensor_0380,);
  let %v378: () = vm.invoke_tvm_op(%2086, %2087, %2088) /* ty=() */;
  let %storage_0433: Storage[] = memory.alloc_storage(%tensor_0380, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][444]) /* ty=Storage[] */;
  let %out_052: Tensor[(?, 1024), float32] = memory.alloc_tensor(%storage_0433, 0 /* ty=int64 */, %shape_func_out_053, meta[relay.attrs.AllocTensorAttrs][444]) /* ty=Tensor[(?, 1024), float32] */;
  %2089 = (%x383, %x384, %model.roi_heads.box_head.fc6.bias);
  %2090 = (%out_052,);
  let %v379: () = vm.invoke_tvm_op(%2080, %2089, %2090) /* ty=() */;
  let %x385: Tensor[(?, 1024), float32] = %out_052;
  let %storage_0434: Storage[] = memory.alloc_storage(4194304 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][445]) /* ty=Storage[] */;
  let %tensor_0381: Tensor[(1024, 1024), float32] = memory.alloc_tensor(%storage_0434, 0 /* ty=int64 */, meta[relay.Constant][438] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][445]) /* ty=Tensor[(1024, 1024), float32] */;
  %2092 = fn (%p0380: Tensor[(1024, 1024), float32], Primitive=1) -> Tensor[(1024, 1024), float32] {
    %2091 = transpose(%p0380, axes=[1, 0]) /* ty=Tensor[(1024, 1024), float32] */;
    transpose(%2091, axes=[1, 0]) /* ty=Tensor[(1024, 1024), float32] */
  };
  %2093 = (%model.roi_heads.box_head.fc7.weight,);
  %2094 = (%tensor_0381,);
  let %v380: () = vm.invoke_tvm_op(%2092, %2093, %2094) /* ty=() */;
  let %x386: Tensor[(1024, 1024), float32] = %tensor_0381;
  let %in_shape_046: Tensor[(2), int64] = vm.shape_of(%x385, meta[relay.attrs.ShapeOfAttrs][59]) /* ty=Tensor[(2), int64] */;
  let %storage_0435: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][446]) /* ty=Storage[] */;
  let %tensor_0382: Tensor[(2), int64] = memory.alloc_tensor(%storage_0435, 0 /* ty=int64 */, meta[relay.Constant][439] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][446]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_054: Tensor[(2), int64] = %tensor_0382;
  %2097 = fn (%p0381: Tensor[(?, 1024), float32], %p1227: Tensor[(1024, 1024), float32], %p2105: Tensor[(1024), float32], Primitive=1) -> Tensor[(?, 1024), float32] {
    %2095 = nn.dense(%p0381, %p1227, units=1024) /* ty=Tensor[(?, 1024), float32] */;
    %2096 = add(%2095, %p2105) /* ty=Tensor[(?, 1024), float32] */;
    nn.relu(%2096) /* ty=Tensor[(?, 1024), float32] */
  };
  %2098 = (%in_shape_046, meta[relay.Constant][440] /* ty=Tensor[(2), int64] */, meta[relay.Constant][441] /* ty=Tensor[(1), int64] */);
  %2099 = (%shape_func_out_054,);
  let %shape_func54: () = vm.shape_func(%2097, %2098, %2099, meta[relay.attrs.ShapeFuncAttrs][54]) /* ty=() */;
  let %storage_0436: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][447]) /* ty=Storage[] */;
  let %tensor_0383: int64 = memory.alloc_tensor(%storage_0436, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][447]) /* ty=int64 */;
  %2100 = fn (%p0382: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0382) /* ty=int64 */
  };
  %2101 = (%shape_func_out_054,);
  %2102 = (%tensor_0383,);
  let %v381: () = vm.invoke_tvm_op(%2100, %2101, %2102) /* ty=() */;
  let %storage_0437: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][448]) /* ty=Storage[] */;
  let %tensor_0384: int64 = memory.alloc_tensor(%storage_0437, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][448]) /* ty=int64 */;
  %2103 = fn (%p0383: int64, Primitive=1) -> int64 {
    multiply(%p0383, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2104 = (%tensor_0383,);
  %2105 = (%tensor_0384,);
  let %v382: () = vm.invoke_tvm_op(%2103, %2104, %2105) /* ty=() */;
  let %storage_0438: Storage[] = memory.alloc_storage(%tensor_0384, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][449]) /* ty=Storage[] */;
  let %out_053: Tensor[(?, 1024), float32] = memory.alloc_tensor(%storage_0438, 0 /* ty=int64 */, %shape_func_out_054, meta[relay.attrs.AllocTensorAttrs][449]) /* ty=Tensor[(?, 1024), float32] */;
  %2106 = (%x385, %x386, %model.roi_heads.box_head.fc7.bias);
  %2107 = (%out_053,);
  let %v383: () = vm.invoke_tvm_op(%2097, %2106, %2107) /* ty=() */;
  let %x387: Tensor[(?, 1024), float32] = %out_053;
  let %in_shape_047: Tensor[(2), int64] = vm.shape_of(%x387, meta[relay.attrs.ShapeOfAttrs][60]) /* ty=Tensor[(2), int64] */;
  let %storage_0439: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][450]) /* ty=Storage[] */;
  let %tensor_0385: Tensor[(2), int64] = memory.alloc_tensor(%storage_0439, 0 /* ty=int64 */, meta[relay.Constant][442] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][450]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_055: Tensor[(2), int64] = %tensor_0385;
  %2108 = fn (%p0384: Tensor[(?, 1024), float32], Primitive=1) -> Tensor[(?, 1024), float32] {
    reshape(%p0384, newshape=[0, -1]) /* ty=Tensor[(?, 1024), float32] */
  };
  %2109 = (%in_shape_047,);
  %2110 = (%shape_func_out_055,);
  let %shape_func55: () = vm.shape_func(%2108, %2109, %2110, meta[relay.attrs.ShapeFuncAttrs][55]) /* ty=() */;
  let %x388: Tensor[(?, 1024), float32] = vm.reshape_tensor(%x387, %shape_func_out_055, meta[relay.attrs.ReshapeTensorAttrs][107]) /* ty=Tensor[(?, 1024), float32] */;
  let %storage_0440: Storage[] = memory.alloc_storage(372736 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][451]) /* ty=Storage[] */;
  let %tensor_0386: Tensor[(91, 1024), float32] = memory.alloc_tensor(%storage_0440, 0 /* ty=int64 */, meta[relay.Constant][443] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][451]) /* ty=Tensor[(91, 1024), float32] */;
  %2112 = fn (%p0385: Tensor[(91, 1024), float32], Primitive=1) -> Tensor[(91, 1024), float32] {
    %2111 = transpose(%p0385, axes=[1, 0]) /* ty=Tensor[(1024, 91), float32] */;
    transpose(%2111, axes=[1, 0]) /* ty=Tensor[(91, 1024), float32] */
  };
  %2113 = (%model.roi_heads.box_predictor.cls_score.weight,);
  %2114 = (%tensor_0386,);
  let %v384: () = vm.invoke_tvm_op(%2112, %2113, %2114) /* ty=() */;
  let %x389: Tensor[(91, 1024), float32] = %tensor_0386;
  let %in_shape_048: Tensor[(2), int64] = vm.shape_of(%x388, meta[relay.attrs.ShapeOfAttrs][61]) /* ty=Tensor[(2), int64] */;
  let %storage_0441: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][452]) /* ty=Storage[] */;
  let %tensor_0387: Tensor[(2), int64] = memory.alloc_tensor(%storage_0441, 0 /* ty=int64 */, meta[relay.Constant][444] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][452]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_056: Tensor[(2), int64] = %tensor_0387;
  %2116 = fn (%p0386: Tensor[(?, 1024), float32], %p1228: Tensor[(91, 1024), float32], %p2106: Tensor[(91), float32], Primitive=1) -> Tensor[(?, 91), float32] {
    %2115 = nn.dense(%p0386, %p1228, units=91) /* ty=Tensor[(?, 91), float32] */;
    add(%2115, %p2106) /* ty=Tensor[(?, 91), float32] */
  };
  %2117 = (%in_shape_048, meta[relay.Constant][445] /* ty=Tensor[(2), int64] */, meta[relay.Constant][446] /* ty=Tensor[(1), int64] */);
  %2118 = (%shape_func_out_056,);
  let %shape_func56: () = vm.shape_func(%2116, %2117, %2118, meta[relay.attrs.ShapeFuncAttrs][56]) /* ty=() */;
  let %storage_0442: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][453]) /* ty=Storage[] */;
  let %tensor_0388: int64 = memory.alloc_tensor(%storage_0442, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][453]) /* ty=int64 */;
  %2119 = fn (%p0387: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0387) /* ty=int64 */
  };
  %2120 = (%shape_func_out_056,);
  %2121 = (%tensor_0388,);
  let %v385: () = vm.invoke_tvm_op(%2119, %2120, %2121) /* ty=() */;
  let %storage_0443: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][454]) /* ty=Storage[] */;
  let %tensor_0389: int64 = memory.alloc_tensor(%storage_0443, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][454]) /* ty=int64 */;
  %2122 = fn (%p0388: int64, Primitive=1) -> int64 {
    multiply(%p0388, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2123 = (%tensor_0388,);
  %2124 = (%tensor_0389,);
  let %v386: () = vm.invoke_tvm_op(%2122, %2123, %2124) /* ty=() */;
  let %storage_0444: Storage[] = memory.alloc_storage(%tensor_0389, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][455]) /* ty=Storage[] */;
  let %out_054: Tensor[(?, 91), float32] = memory.alloc_tensor(%storage_0444, 0 /* ty=int64 */, %shape_func_out_056, meta[relay.attrs.AllocTensorAttrs][455]) /* ty=Tensor[(?, 91), float32] */;
  %2125 = (%x388, %x389, %model.roi_heads.box_predictor.cls_score.bias);
  %2126 = (%out_054,);
  let %v387: () = vm.invoke_tvm_op(%2116, %2125, %2126) /* ty=() */;
  let %x390: Tensor[(?, 91), float32] = %out_054;
  let %in_shape_049: Tensor[(2), int64] = vm.shape_of(%x390, meta[relay.attrs.ShapeOfAttrs][62]) /* ty=Tensor[(2), int64] */;
  let %storage_0445: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][456]) /* ty=Storage[] */;
  let %tensor_0390: Tensor[(2), int64] = memory.alloc_tensor(%storage_0445, 0 /* ty=int64 */, meta[relay.Constant][447] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][456]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_057: Tensor[(2), int64] = %tensor_0390;
  %2127 = fn (%p0389: Tensor[(?, 91), float32], Primitive=1) -> Tensor[(?, 91), float32] {
    nn.softmax(%p0389) /* ty=Tensor[(?, 91), float32] */
  };
  %2128 = (%in_shape_049,);
  %2129 = (%shape_func_out_057,);
  let %shape_func57: () = vm.shape_func(%2127, %2128, %2129, meta[relay.attrs.ShapeFuncAttrs][57]) /* ty=() */;
  let %storage_0446: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][457]) /* ty=Storage[] */;
  let %tensor_0391: int64 = memory.alloc_tensor(%storage_0446, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][457]) /* ty=int64 */;
  %2130 = fn (%p0390: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0390) /* ty=int64 */
  };
  %2131 = (%shape_func_out_057,);
  %2132 = (%tensor_0391,);
  let %v388: () = vm.invoke_tvm_op(%2130, %2131, %2132) /* ty=() */;
  let %storage_0447: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][458]) /* ty=Storage[] */;
  let %tensor_0392: int64 = memory.alloc_tensor(%storage_0447, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][458]) /* ty=int64 */;
  %2133 = fn (%p0391: int64, Primitive=1) -> int64 {
    multiply(%p0391, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2134 = (%tensor_0391,);
  %2135 = (%tensor_0392,);
  let %v389: () = vm.invoke_tvm_op(%2133, %2134, %2135) /* ty=() */;
  let %storage_0448: Storage[] = memory.alloc_storage(%tensor_0392, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][459]) /* ty=Storage[] */;
  let %out_055: Tensor[(?, 91), float32] = memory.alloc_tensor(%storage_0448, 0 /* ty=int64 */, %shape_func_out_057, meta[relay.attrs.AllocTensorAttrs][459]) /* ty=Tensor[(?, 91), float32] */;
  %2136 = (%x390,);
  %2137 = (%out_055,);
  let %v390: () = vm.invoke_tvm_op(%2127, %2136, %2137) /* ty=() */;
  let %x391: Tensor[(?, 91), float32] = %out_055;
  let %in_shape_125: Tensor[(2), int64] = vm.shape_of(%x391, meta[relay.attrs.ShapeOfAttrs][63]) /* ty=Tensor[(2), int64] */;
  let %storage_0449: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][460]) /* ty=Storage[] */;
  let %tensor_0393: Tensor[(2), int64] = memory.alloc_tensor(%storage_0449, 0 /* ty=int64 */, meta[relay.Constant][448] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][460]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_058: Tensor[(2), int64] = %tensor_0393;
  %2139 = fn (%p0392: Tensor[(1, 91), int64], %p1229: Tensor[(?, 91), float32], Primitive=1) -> Tensor[(?, 91), int64] {
    %2138 = cast(%p1229, dtype="int64") /* ty=Tensor[(?, 91), int64] */;
    broadcast_to_like(%p0392, %2138) /* ty=Tensor[(?, 91), int64] */
  };
  %2140 = (meta[relay.Constant][449] /* ty=Tensor[(2), int64] */, %in_shape_125);
  %2141 = (%shape_func_out_058,);
  let %shape_func58: () = vm.shape_func(%2139, %2140, %2141, meta[relay.attrs.ShapeFuncAttrs][58]) /* ty=() */;
  let %storage_0450: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][461]) /* ty=Storage[] */;
  let %tensor_0394: int64 = memory.alloc_tensor(%storage_0450, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][461]) /* ty=int64 */;
  %2142 = fn (%p0393: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0393) /* ty=int64 */
  };
  %2143 = (%shape_func_out_058,);
  %2144 = (%tensor_0394,);
  let %v391: () = vm.invoke_tvm_op(%2142, %2143, %2144) /* ty=() */;
  let %storage_0451: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][462]) /* ty=Storage[] */;
  let %tensor_0395: int64 = memory.alloc_tensor(%storage_0451, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][462]) /* ty=int64 */;
  %2145 = fn (%p0394: int64, Primitive=1) -> int64 {
    multiply(%p0394, 8 /* ty=int64 */) /* ty=int64 */
  };
  %2146 = (%tensor_0394,);
  %2147 = (%tensor_0395,);
  let %v392: () = vm.invoke_tvm_op(%2145, %2146, %2147) /* ty=() */;
  let %storage_0452: Storage[] = memory.alloc_storage(%tensor_0395, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][463]) /* ty=Storage[] */;
  let %out_056: Tensor[(?, 91), int64] = memory.alloc_tensor(%storage_0452, 0 /* ty=int64 */, %shape_func_out_058, meta[relay.attrs.AllocTensorAttrs][463]) /* ty=Tensor[(?, 91), int64] */;
  %2148 = (meta[relay.Constant][450] /* ty=Tensor[(1, 91), int64] */, %x391);
  %2149 = (%out_056,);
  let %v393: () = vm.invoke_tvm_op(%2139, %2148, %2149) /* ty=() */;
  let %x392: Tensor[(?, 91), int64] = %out_056;
  let %storage_0453: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][464]) /* ty=Storage[] */;
  let %tensor_0396: Tensor[(2), int32] = memory.alloc_tensor(%storage_0453, 0 /* ty=int64 */, meta[relay.Constant][451] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][464]) /* ty=Tensor[(2), int32] */;
  %2150 = fn (%p0395: Tensor[(?, 91), int64], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0395, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2151 = (%x392,);
  %2152 = (%tensor_0396,);
  let %v394: () = vm.invoke_tvm_op(%2150, %2151, %2152) /* ty=() */;
  let %x393: Tensor[(2), int32] = %tensor_0396;
  let %storage_0454: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][465]) /* ty=Storage[] */;
  let %tensor_0397: Tensor[(2), int32] = memory.alloc_tensor(%storage_0454, 0 /* ty=int64 */, meta[relay.Constant][452] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][465]) /* ty=Tensor[(2), int32] */;
  %2155 = fn (%p0396: Tensor[(2), bool], %p1230: Tensor[(2), int32], %p2107: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2153 = cast_like(%p2107, %p1230) /* ty=Tensor[(2), int32] */;
    %2154 = add(%p1230, %2153) /* ty=Tensor[(2), int32] */;
    where(%p0396, %2154, %p1230) /* ty=Tensor[(2), int32] */
  };
  %2156 = (meta[relay.Constant][453] /* ty=Tensor[(2), bool] */, meta[relay.Constant][454] /* ty=Tensor[(2), int32] */, %x393);
  %2157 = (%tensor_0397,);
  let %v395: () = vm.invoke_tvm_op(%2155, %2156, %2157) /* ty=() */;
  let %x394: Tensor[(2), int32] = %tensor_0397;
  let %storage_0455: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][466]) /* ty=Storage[] */;
  let %tensor_0398: Tensor[(2), int64] = memory.alloc_tensor(%storage_0455, 0 /* ty=int64 */, meta[relay.Constant][455] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][466]) /* ty=Tensor[(2), int64] */;
  %2158 = fn (%p0397: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0397, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2159 = (%x393,);
  %2160 = (%tensor_0398,);
  let %v396: () = vm.invoke_tvm_op(%2158, %2159, %2160) /* ty=() */;
  let %x395: Tensor[(2), int64] = %tensor_0398;
  let %in_shape_050: Tensor[(?, 91), int64] = device_copy(%x392, meta[relay.attrs.DeviceCopyAttrs][38]) /* ty=Tensor[(?, 91), int64] */;
  let %in_shape_126: Tensor[(2), int32] = device_copy(%x394, meta[relay.attrs.DeviceCopyAttrs][39]) /* ty=Tensor[(2), int32] */;
  let %in_shape_214: Tensor[(2), int64] = device_copy(%x395, meta[relay.attrs.DeviceCopyAttrs][40]) /* ty=Tensor[(2), int64] */;
  let %in_shape_310: Tensor[(2), int32] = device_copy(meta[relay.Constant][456] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][41]) /* ty=Tensor[(2), int32] */;
  let %storage_0456: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][467]) /* ty=Storage[] */;
  let %tensor_0399: Tensor[(2), int64] = memory.alloc_tensor(%storage_0456, 0 /* ty=int64 */, meta[relay.Constant][457] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][467]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_059: Tensor[(2), int64] = %tensor_0399;
  %2161 = fn (%p0398: Tensor[(?, 91), int64], %p1231: Tensor[(2), int32], %p2108: Tensor[(2), int64], %p370: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), int64] {
    dyn.strided_slice(%p0398, %p1231, %p2108, %p370, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), int64] */
  };
  %2162 = (%in_shape_050, %in_shape_126, %in_shape_214, %in_shape_310);
  %2163 = (%shape_func_out_059,);
  let %shape_func59: () = vm.shape_func(%2161, %2162, %2163, meta[relay.attrs.ShapeFuncAttrs][59]) /* ty=() */;
  let %storage_0457: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][468]) /* ty=Storage[] */;
  let %tensor_0400: int64 = memory.alloc_tensor(%storage_0457, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][468]) /* ty=int64 */;
  %2164 = fn (%p0399: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0399) /* ty=int64 */
  };
  %2165 = (%shape_func_out_059,);
  %2166 = (%tensor_0400,);
  let %v397: () = vm.invoke_tvm_op(%2164, %2165, %2166) /* ty=() */;
  let %storage_0458: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][469]) /* ty=Storage[] */;
  let %tensor_0401: int64 = memory.alloc_tensor(%storage_0458, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][469]) /* ty=int64 */;
  %2167 = fn (%p0400: int64, Primitive=1) -> int64 {
    multiply(%p0400, 8 /* ty=int64 */) /* ty=int64 */
  };
  %2168 = (%tensor_0400,);
  %2169 = (%tensor_0401,);
  let %v398: () = vm.invoke_tvm_op(%2167, %2168, %2169) /* ty=() */;
  let %storage_0459: Storage[] = memory.alloc_storage(%tensor_0401, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][470]) /* ty=Storage[] */;
  let %out_057: Tensor[(?, ?), int64] = memory.alloc_tensor(%storage_0459, 0 /* ty=int64 */, %shape_func_out_059, meta[relay.attrs.AllocTensorAttrs][470]) /* ty=Tensor[(?, ?), int64] */;
  %2170 = (%x392, %x394, %x395, meta[relay.Constant][456] /* ty=Tensor[(2), int32] */);
  %2171 = (%out_057,);
  let %v399: () = vm.invoke_tvm_op(%2161, %2170, %2171) /* ty=() */;
  let %x396: Tensor[(?, ?), int64] = %out_057;
  let %storage_0460: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][471]) /* ty=Storage[] */;
  let %tensor_0402: Tensor[(2), int32] = memory.alloc_tensor(%storage_0460, 0 /* ty=int64 */, meta[relay.Constant][458] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][471]) /* ty=Tensor[(2), int32] */;
  %2172 = fn (%p0401: Tensor[(?, ?), int64], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0401, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2173 = (%x396,);
  %2174 = (%tensor_0402,);
  let %v400: () = vm.invoke_tvm_op(%2172, %2173, %2174) /* ty=() */;
  let %x397: Tensor[(2), int32] = %tensor_0402;
  let %storage_0461: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][472]) /* ty=Storage[] */;
  let %tensor_0403: Tensor[(2), int32] = memory.alloc_tensor(%storage_0461, 0 /* ty=int64 */, meta[relay.Constant][459] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][472]) /* ty=Tensor[(2), int32] */;
  %2177 = fn (%p0402: Tensor[(2), bool], %p1232: Tensor[(2), int32], %p2109: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2175 = cast_like(%p2109, %p1232) /* ty=Tensor[(2), int32] */;
    %2176 = add(%p1232, %2175) /* ty=Tensor[(2), int32] */;
    where(%p0402, %2176, %p1232) /* ty=Tensor[(2), int32] */
  };
  %2178 = (meta[relay.Constant][460] /* ty=Tensor[(2), bool] */, meta[relay.Constant][461] /* ty=Tensor[(2), int32] */, %x397);
  %2179 = (%tensor_0403,);
  let %v401: () = vm.invoke_tvm_op(%2177, %2178, %2179) /* ty=() */;
  let %x398: Tensor[(2), int32] = %tensor_0403;
  let %storage_0462: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][473]) /* ty=Storage[] */;
  let %tensor_0404: Tensor[(2), int64] = memory.alloc_tensor(%storage_0462, 0 /* ty=int64 */, meta[relay.Constant][462] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][473]) /* ty=Tensor[(2), int64] */;
  %2180 = fn (%p0403: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0403, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2181 = (%x397,);
  %2182 = (%tensor_0404,);
  let %v402: () = vm.invoke_tvm_op(%2180, %2181, %2182) /* ty=() */;
  let %x399: Tensor[(2), int64] = %tensor_0404;
  let %in_shape_051: Tensor[(?, ?), int64] = device_copy(%x396, meta[relay.attrs.DeviceCopyAttrs][42]) /* ty=Tensor[(?, ?), int64] */;
  let %in_shape_127: Tensor[(2), int32] = device_copy(%x398, meta[relay.attrs.DeviceCopyAttrs][43]) /* ty=Tensor[(2), int32] */;
  let %in_shape_215: Tensor[(2), int64] = device_copy(%x399, meta[relay.attrs.DeviceCopyAttrs][44]) /* ty=Tensor[(2), int64] */;
  let %in_shape_311: Tensor[(2), int32] = device_copy(meta[relay.Constant][463] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][45]) /* ty=Tensor[(2), int32] */;
  let %storage_0463: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][474]) /* ty=Storage[] */;
  let %tensor_0405: Tensor[(2), int64] = memory.alloc_tensor(%storage_0463, 0 /* ty=int64 */, meta[relay.Constant][464] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][474]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_060: Tensor[(2), int64] = %tensor_0405;
  %2183 = fn (%p0404: Tensor[(?, ?), int64], %p1233: Tensor[(2), int32], %p2110: Tensor[(2), int64], %p371: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), int64] {
    dyn.strided_slice(%p0404, %p1233, %p2110, %p371, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), int64] */
  };
  %2184 = (%in_shape_051, %in_shape_127, %in_shape_215, %in_shape_311);
  %2185 = (%shape_func_out_060,);
  let %shape_func60: () = vm.shape_func(%2183, %2184, %2185, meta[relay.attrs.ShapeFuncAttrs][60]) /* ty=() */;
  let %storage_0464: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][475]) /* ty=Storage[] */;
  let %tensor_0406: int64 = memory.alloc_tensor(%storage_0464, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][475]) /* ty=int64 */;
  %2186 = fn (%p0405: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0405) /* ty=int64 */
  };
  %2187 = (%shape_func_out_060,);
  %2188 = (%tensor_0406,);
  let %v403: () = vm.invoke_tvm_op(%2186, %2187, %2188) /* ty=() */;
  let %storage_0465: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][476]) /* ty=Storage[] */;
  let %tensor_0407: int64 = memory.alloc_tensor(%storage_0465, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][476]) /* ty=int64 */;
  %2189 = fn (%p0406: int64, Primitive=1) -> int64 {
    multiply(%p0406, 8 /* ty=int64 */) /* ty=int64 */
  };
  %2190 = (%tensor_0406,);
  %2191 = (%tensor_0407,);
  let %v404: () = vm.invoke_tvm_op(%2189, %2190, %2191) /* ty=() */;
  let %storage_0466: Storage[] = memory.alloc_storage(%tensor_0407, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][477]) /* ty=Storage[] */;
  let %out_058: Tensor[(?, ?), int64] = memory.alloc_tensor(%storage_0466, 0 /* ty=int64 */, %shape_func_out_060, meta[relay.attrs.AllocTensorAttrs][477]) /* ty=Tensor[(?, ?), int64] */;
  %2192 = (%x396, %x398, %x399, meta[relay.Constant][463] /* ty=Tensor[(2), int32] */);
  %2193 = (%out_058,);
  let %v405: () = vm.invoke_tvm_op(%2183, %2192, %2193) /* ty=() */;
  let %x400: Tensor[(?, ?), int64] = %out_058;
  let %storage_0467: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][478]) /* ty=Storage[] */;
  let %tensor_0408: Tensor[(2), int32] = memory.alloc_tensor(%storage_0467, 0 /* ty=int64 */, meta[relay.Constant][465] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][478]) /* ty=Tensor[(2), int32] */;
  %2194 = fn (%p0407: Tensor[(?, 91), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0407, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2195 = (%x391,);
  %2196 = (%tensor_0408,);
  let %v406: () = vm.invoke_tvm_op(%2194, %2195, %2196) /* ty=() */;
  let %x401: Tensor[(2), int32] = %tensor_0408;
  let %storage_0468: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][479]) /* ty=Storage[] */;
  let %tensor_0409: Tensor[(2), int32] = memory.alloc_tensor(%storage_0468, 0 /* ty=int64 */, meta[relay.Constant][466] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][479]) /* ty=Tensor[(2), int32] */;
  %2199 = fn (%p0408: Tensor[(2), bool], %p1234: Tensor[(2), int32], %p2111: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2197 = cast_like(%p2111, %p1234) /* ty=Tensor[(2), int32] */;
    %2198 = add(%p1234, %2197) /* ty=Tensor[(2), int32] */;
    where(%p0408, %2198, %p1234) /* ty=Tensor[(2), int32] */
  };
  %2200 = (meta[relay.Constant][467] /* ty=Tensor[(2), bool] */, meta[relay.Constant][468] /* ty=Tensor[(2), int32] */, %x401);
  %2201 = (%tensor_0409,);
  let %v407: () = vm.invoke_tvm_op(%2199, %2200, %2201) /* ty=() */;
  let %x402: Tensor[(2), int32] = %tensor_0409;
  let %storage_0469: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][480]) /* ty=Storage[] */;
  let %tensor_0410: Tensor[(2), int64] = memory.alloc_tensor(%storage_0469, 0 /* ty=int64 */, meta[relay.Constant][469] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][480]) /* ty=Tensor[(2), int64] */;
  %2202 = fn (%p0409: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0409, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2203 = (%x401,);
  %2204 = (%tensor_0410,);
  let %v408: () = vm.invoke_tvm_op(%2202, %2203, %2204) /* ty=() */;
  let %x403: Tensor[(2), int64] = %tensor_0410;
  let %in_shape_052: Tensor[(?, 91), float32] = device_copy(%x391, meta[relay.attrs.DeviceCopyAttrs][46]) /* ty=Tensor[(?, 91), float32] */;
  let %in_shape_128: Tensor[(2), int32] = device_copy(%x402, meta[relay.attrs.DeviceCopyAttrs][47]) /* ty=Tensor[(2), int32] */;
  let %in_shape_216: Tensor[(2), int64] = device_copy(%x403, meta[relay.attrs.DeviceCopyAttrs][48]) /* ty=Tensor[(2), int64] */;
  let %in_shape_312: Tensor[(2), int32] = device_copy(meta[relay.Constant][470] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][49]) /* ty=Tensor[(2), int32] */;
  let %storage_0470: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][481]) /* ty=Storage[] */;
  let %tensor_0411: Tensor[(2), int64] = memory.alloc_tensor(%storage_0470, 0 /* ty=int64 */, meta[relay.Constant][471] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][481]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_061: Tensor[(2), int64] = %tensor_0411;
  %2205 = fn (%p0410: Tensor[(?, 91), float32], %p1235: Tensor[(2), int32], %p2112: Tensor[(2), int64], %p372: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0410, %p1235, %p2112, %p372, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2206 = (%in_shape_052, %in_shape_128, %in_shape_216, %in_shape_312);
  %2207 = (%shape_func_out_061,);
  let %shape_func61: () = vm.shape_func(%2205, %2206, %2207, meta[relay.attrs.ShapeFuncAttrs][61]) /* ty=() */;
  let %storage_0471: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][482]) /* ty=Storage[] */;
  let %tensor_0412: int64 = memory.alloc_tensor(%storage_0471, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][482]) /* ty=int64 */;
  %2208 = fn (%p0411: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0411) /* ty=int64 */
  };
  %2209 = (%shape_func_out_061,);
  %2210 = (%tensor_0412,);
  let %v409: () = vm.invoke_tvm_op(%2208, %2209, %2210) /* ty=() */;
  let %storage_0472: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][483]) /* ty=Storage[] */;
  let %tensor_0413: int64 = memory.alloc_tensor(%storage_0472, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][483]) /* ty=int64 */;
  %2211 = fn (%p0412: int64, Primitive=1) -> int64 {
    multiply(%p0412, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2212 = (%tensor_0412,);
  %2213 = (%tensor_0413,);
  let %v410: () = vm.invoke_tvm_op(%2211, %2212, %2213) /* ty=() */;
  let %storage_0473: Storage[] = memory.alloc_storage(%tensor_0413, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][484]) /* ty=Storage[] */;
  let %out_059: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0473, 0 /* ty=int64 */, %shape_func_out_061, meta[relay.attrs.AllocTensorAttrs][484]) /* ty=Tensor[(?, ?), float32] */;
  %2214 = (%x391, %x402, %x403, meta[relay.Constant][470] /* ty=Tensor[(2), int32] */);
  %2215 = (%out_059,);
  let %v411: () = vm.invoke_tvm_op(%2205, %2214, %2215) /* ty=() */;
  let %x404: Tensor[(?, ?), float32] = %out_059;
  let %storage_0474: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][485]) /* ty=Storage[] */;
  let %tensor_0414: Tensor[(2), int32] = memory.alloc_tensor(%storage_0474, 0 /* ty=int64 */, meta[relay.Constant][472] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][485]) /* ty=Tensor[(2), int32] */;
  %2216 = fn (%p0413: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0413, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2217 = (%x404,);
  %2218 = (%tensor_0414,);
  let %v412: () = vm.invoke_tvm_op(%2216, %2217, %2218) /* ty=() */;
  let %x405: Tensor[(2), int32] = %tensor_0414;
  let %storage_0475: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][486]) /* ty=Storage[] */;
  let %tensor_0415: Tensor[(2), int32] = memory.alloc_tensor(%storage_0475, 0 /* ty=int64 */, meta[relay.Constant][473] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][486]) /* ty=Tensor[(2), int32] */;
  %2221 = fn (%p0414: Tensor[(2), bool], %p1236: Tensor[(2), int32], %p2113: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2219 = cast_like(%p2113, %p1236) /* ty=Tensor[(2), int32] */;
    %2220 = add(%p1236, %2219) /* ty=Tensor[(2), int32] */;
    where(%p0414, %2220, %p1236) /* ty=Tensor[(2), int32] */
  };
  %2222 = (meta[relay.Constant][474] /* ty=Tensor[(2), bool] */, meta[relay.Constant][475] /* ty=Tensor[(2), int32] */, %x405);
  %2223 = (%tensor_0415,);
  let %v413: () = vm.invoke_tvm_op(%2221, %2222, %2223) /* ty=() */;
  let %x406: Tensor[(2), int32] = %tensor_0415;
  let %storage_0476: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][487]) /* ty=Storage[] */;
  let %tensor_0416: Tensor[(2), int64] = memory.alloc_tensor(%storage_0476, 0 /* ty=int64 */, meta[relay.Constant][476] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][487]) /* ty=Tensor[(2), int64] */;
  %2224 = fn (%p0415: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0415, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2225 = (%x405,);
  %2226 = (%tensor_0416,);
  let %v414: () = vm.invoke_tvm_op(%2224, %2225, %2226) /* ty=() */;
  let %x407: Tensor[(2), int64] = %tensor_0416;
  let %in_shape_053: Tensor[(?, ?), float32] = device_copy(%x404, meta[relay.attrs.DeviceCopyAttrs][50]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_129: Tensor[(2), int32] = device_copy(%x406, meta[relay.attrs.DeviceCopyAttrs][51]) /* ty=Tensor[(2), int32] */;
  let %in_shape_217: Tensor[(2), int64] = device_copy(%x407, meta[relay.attrs.DeviceCopyAttrs][52]) /* ty=Tensor[(2), int64] */;
  let %in_shape_313: Tensor[(2), int32] = device_copy(meta[relay.Constant][477] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][53]) /* ty=Tensor[(2), int32] */;
  let %storage_0477: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][488]) /* ty=Storage[] */;
  let %tensor_0417: Tensor[(2), int64] = memory.alloc_tensor(%storage_0477, 0 /* ty=int64 */, meta[relay.Constant][478] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][488]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_062: Tensor[(2), int64] = %tensor_0417;
  %2227 = fn (%p0416: Tensor[(?, ?), float32], %p1237: Tensor[(2), int32], %p2114: Tensor[(2), int64], %p373: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0416, %p1237, %p2114, %p373, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2228 = (%in_shape_053, %in_shape_129, %in_shape_217, %in_shape_313);
  %2229 = (%shape_func_out_062,);
  let %shape_func62: () = vm.shape_func(%2227, %2228, %2229, meta[relay.attrs.ShapeFuncAttrs][62]) /* ty=() */;
  let %storage_0478: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][489]) /* ty=Storage[] */;
  let %tensor_0418: int64 = memory.alloc_tensor(%storage_0478, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][489]) /* ty=int64 */;
  %2230 = fn (%p0417: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0417) /* ty=int64 */
  };
  %2231 = (%shape_func_out_062,);
  %2232 = (%tensor_0418,);
  let %v415: () = vm.invoke_tvm_op(%2230, %2231, %2232) /* ty=() */;
  let %storage_0479: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][490]) /* ty=Storage[] */;
  let %tensor_0419: int64 = memory.alloc_tensor(%storage_0479, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][490]) /* ty=int64 */;
  %2233 = fn (%p0418: int64, Primitive=1) -> int64 {
    multiply(%p0418, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2234 = (%tensor_0418,);
  %2235 = (%tensor_0419,);
  let %v416: () = vm.invoke_tvm_op(%2233, %2234, %2235) /* ty=() */;
  let %storage_0480: Storage[] = memory.alloc_storage(%tensor_0419, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][491]) /* ty=Storage[] */;
  let %out_060: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0480, 0 /* ty=int64 */, %shape_func_out_062, meta[relay.attrs.AllocTensorAttrs][491]) /* ty=Tensor[(?, ?), float32] */;
  %2236 = (%x404, %x406, %x407, meta[relay.Constant][477] /* ty=Tensor[(2), int32] */);
  %2237 = (%out_060,);
  let %v417: () = vm.invoke_tvm_op(%2227, %2236, %2237) /* ty=() */;
  let %x408: Tensor[(?, ?), float32] = %out_060;
  let %in_shape_054: Tensor[(2), int64] = vm.shape_of(%x408, meta[relay.attrs.ShapeOfAttrs][64]) /* ty=Tensor[(2), int64] */;
  let %storage_0481: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][492]) /* ty=Storage[] */;
  let %tensor_0420: Tensor[(1), int64] = memory.alloc_tensor(%storage_0481, 0 /* ty=int64 */, meta[relay.Constant][479] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][492]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_063: Tensor[(1), int64] = %tensor_0420;
  %2238 = fn (%p0419: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?), float32] {
    reshape(%p0419, newshape=[-1]) /* ty=Tensor[(?), float32] */
  };
  %2239 = (%in_shape_054,);
  %2240 = (%shape_func_out_063,);
  let %shape_func63: () = vm.shape_func(%2238, %2239, %2240, meta[relay.attrs.ShapeFuncAttrs][63]) /* ty=() */;
  let %x409: Tensor[(?), float32] = vm.reshape_tensor(%x408, %shape_func_out_063, meta[relay.attrs.ReshapeTensorAttrs][108]) /* ty=Tensor[(?), float32] */;
  let %in_shape_055: Tensor[(1), int64] = vm.shape_of(%x409, meta[relay.attrs.ShapeOfAttrs][65]) /* ty=Tensor[(1), int64] */;
  let %storage_0482: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][493]) /* ty=Storage[] */;
  let %tensor_0421: Tensor[(1), int64] = memory.alloc_tensor(%storage_0482, 0 /* ty=int64 */, meta[relay.Constant][480] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][493]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_064: Tensor[(1), int64] = %tensor_0421;
  %2241 = fn (%p0420: Tensor[(?), float32], Primitive=1) -> Tensor[(?), bool] {
    greater(%p0420, 0.05f /* ty=float32 */) /* ty=Tensor[(?), bool] */
  };
  %2242 = (%in_shape_055,);
  %2243 = (%shape_func_out_064,);
  let %shape_func64: () = vm.shape_func(%2241, %2242, %2243, meta[relay.attrs.ShapeFuncAttrs][64]) /* ty=() */;
  let %storage_0483: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][494]) /* ty=Storage[] */;
  let %tensor_0422: int64 = memory.alloc_tensor(%storage_0483, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][494]) /* ty=int64 */;
  %2244 = fn (%p0421: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0421) /* ty=int64 */
  };
  %2245 = (%shape_func_out_064,);
  %2246 = (%tensor_0422,);
  let %v418: () = vm.invoke_tvm_op(%2244, %2245, %2246) /* ty=() */;
  let %storage_0484: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][495]) /* ty=Storage[] */;
  let %tensor_0423: int64 = memory.alloc_tensor(%storage_0484, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][495]) /* ty=int64 */;
  %2247 = fn (%p0422: int64, Primitive=1) -> int64 {
    multiply(%p0422, 1 /* ty=int64 */) /* ty=int64 */
  };
  %2248 = (%tensor_0422,);
  %2249 = (%tensor_0423,);
  let %v419: () = vm.invoke_tvm_op(%2247, %2248, %2249) /* ty=() */;
  let %storage_0485: Storage[] = memory.alloc_storage(%tensor_0423, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][496]) /* ty=Storage[] */;
  let %out_061: Tensor[(?), bool] = memory.alloc_tensor(%storage_0485, 0 /* ty=int64 */, %shape_func_out_064, meta[relay.attrs.AllocTensorAttrs][496]) /* ty=Tensor[(?), bool] */;
  %2250 = (%x409,);
  %2251 = (%out_061,);
  let %v420: () = vm.invoke_tvm_op(%2241, %2250, %2251) /* ty=() */;
  let %x410: Tensor[(?), bool] = %out_061;
  let %in_shape_056: Tensor[(?), bool] = device_copy(%x410, meta[relay.attrs.DeviceCopyAttrs][54]) /* ty=Tensor[(?), bool] */;
  let %storage_0486: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][497]) /* ty=Storage[] */;
  let %tensor_0424: Tensor[(2), int64] = memory.alloc_tensor(%storage_0486, 0 /* ty=int64 */, meta[relay.Constant][481] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][497]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_065: Tensor[(2), int64] = %tensor_0424;
  %2252 = fn (%p0423: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0423) /* ty=Tensor[(?, 1), int32] */
  };
  %2253 = (%in_shape_056,);
  %2254 = (%shape_func_out_065,);
  let %shape_func65: () = vm.shape_func(%2252, %2253, %2254, meta[relay.attrs.ShapeFuncAttrs][65]) /* ty=() */;
  let %storage_0487: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][498]) /* ty=Storage[] */;
  let %tensor_0425: int64 = memory.alloc_tensor(%storage_0487, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][498]) /* ty=int64 */;
  %2255 = fn (%p0424: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0424) /* ty=int64 */
  };
  %2256 = (%shape_func_out_065,);
  %2257 = (%tensor_0425,);
  let %v421: () = vm.invoke_tvm_op(%2255, %2256, %2257) /* ty=() */;
  let %storage_0488: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][499]) /* ty=Storage[] */;
  let %tensor_0426: int64 = memory.alloc_tensor(%storage_0488, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][499]) /* ty=int64 */;
  %2258 = fn (%p0425: int64, Primitive=1) -> int64 {
    multiply(%p0425, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2259 = (%tensor_0425,);
  %2260 = (%tensor_0426,);
  let %v422: () = vm.invoke_tvm_op(%2258, %2259, %2260) /* ty=() */;
  let %storage_0489: Storage[] = memory.alloc_storage(%tensor_0426, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][500]) /* ty=Storage[] */;
  let %out_062: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0489, 0 /* ty=int64 */, %shape_func_out_065, meta[relay.attrs.AllocTensorAttrs][500]) /* ty=Tensor[(?, 1), int32] */;
  %2261 = (%x410,);
  %2262 = (%out_062,);
  let %v423: () = vm.invoke_tvm_op(%2252, %2261, %2262) /* ty=() */;
  let %x411: Tensor[(?, 1), int32] = %out_062;
  let %in_shape_057: Tensor[(2), int64] = vm.shape_of(%x411, meta[relay.attrs.ShapeOfAttrs][66]) /* ty=Tensor[(2), int64] */;
  let %storage_0490: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][501]) /* ty=Storage[] */;
  let %tensor_0427: Tensor[(1), int64] = memory.alloc_tensor(%storage_0490, 0 /* ty=int64 */, meta[relay.Constant][482] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][501]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_066: Tensor[(1), int64] = %tensor_0427;
  %2266 = fn (%p0426: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int64] {
    %2263 = split(%p0426, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %2264 = %2263.0;
    %2265 = squeeze(%2264, axis=[1]) /* ty=Tensor[(?), int32] */;
    cast(%2265, dtype="int64") /* ty=Tensor[(?), int64] */
  };
  %2267 = (%in_shape_057,);
  %2268 = (%shape_func_out_066,);
  let %shape_func66: () = vm.shape_func(%2266, %2267, %2268, meta[relay.attrs.ShapeFuncAttrs][66]) /* ty=() */;
  let %storage_0491: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][502]) /* ty=Storage[] */;
  let %tensor_0428: int64 = memory.alloc_tensor(%storage_0491, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][502]) /* ty=int64 */;
  %2269 = fn (%p0427: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0427) /* ty=int64 */
  };
  %2270 = (%shape_func_out_066,);
  %2271 = (%tensor_0428,);
  let %v424: () = vm.invoke_tvm_op(%2269, %2270, %2271) /* ty=() */;
  let %storage_0492: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][503]) /* ty=Storage[] */;
  let %tensor_0429: int64 = memory.alloc_tensor(%storage_0492, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][503]) /* ty=int64 */;
  %2272 = fn (%p0428: int64, Primitive=1) -> int64 {
    multiply(%p0428, 8 /* ty=int64 */) /* ty=int64 */
  };
  %2273 = (%tensor_0428,);
  %2274 = (%tensor_0429,);
  let %v425: () = vm.invoke_tvm_op(%2272, %2273, %2274) /* ty=() */;
  let %storage_0493: Storage[] = memory.alloc_storage(%tensor_0429, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][504]) /* ty=Storage[] */;
  let %out_063: Tensor[(?), int64] = memory.alloc_tensor(%storage_0493, 0 /* ty=int64 */, %shape_func_out_066, meta[relay.attrs.AllocTensorAttrs][504]) /* ty=Tensor[(?), int64] */;
  %2275 = (%x411,);
  %2276 = (%out_063,);
  let %v426: () = vm.invoke_tvm_op(%2266, %2275, %2276) /* ty=() */;
  let %x412: Tensor[(?), int64] = %out_063;
  let %storage_0494: Storage[] = memory.alloc_storage(1490944 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][505]) /* ty=Storage[] */;
  let %tensor_0430: Tensor[(364, 1024), float32] = memory.alloc_tensor(%storage_0494, 0 /* ty=int64 */, meta[relay.Constant][483] /* ty=Tensor[(2), int64] */, meta[relay.attrs.AllocTensorAttrs][505]) /* ty=Tensor[(364, 1024), float32] */;
  %2278 = fn (%p0429: Tensor[(364, 1024), float32], Primitive=1) -> Tensor[(364, 1024), float32] {
    %2277 = transpose(%p0429, axes=[1, 0]) /* ty=Tensor[(1024, 364), float32] */;
    transpose(%2277, axes=[1, 0]) /* ty=Tensor[(364, 1024), float32] */
  };
  %2279 = (%model.roi_heads.box_predictor.bbox_pred.weight,);
  %2280 = (%tensor_0430,);
  let %v427: () = vm.invoke_tvm_op(%2278, %2279, %2280) /* ty=() */;
  let %x413: Tensor[(364, 1024), float32] = %tensor_0430;
  let %in_shape_058: Tensor[(2), int64] = vm.shape_of(%x388, meta[relay.attrs.ShapeOfAttrs][67]) /* ty=Tensor[(2), int64] */;
  let %storage_0495: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][506]) /* ty=Storage[] */;
  let %tensor_0431: Tensor[(2), int64] = memory.alloc_tensor(%storage_0495, 0 /* ty=int64 */, meta[relay.Constant][484] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][506]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_067: Tensor[(2), int64] = %tensor_0431;
  %2282 = fn (%p0430: Tensor[(?, 1024), float32], %p1238: Tensor[(364, 1024), float32], %p2115: Tensor[(364), float32], Primitive=1) -> Tensor[(?, 364), float32] {
    %2281 = nn.dense(%p0430, %p1238, units=364) /* ty=Tensor[(?, 364), float32] */;
    add(%2281, %p2115) /* ty=Tensor[(?, 364), float32] */
  };
  %2283 = (%in_shape_058, meta[relay.Constant][485] /* ty=Tensor[(2), int64] */, meta[relay.Constant][486] /* ty=Tensor[(1), int64] */);
  %2284 = (%shape_func_out_067,);
  let %shape_func67: () = vm.shape_func(%2282, %2283, %2284, meta[relay.attrs.ShapeFuncAttrs][67]) /* ty=() */;
  let %storage_0496: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][507]) /* ty=Storage[] */;
  let %tensor_0432: int64 = memory.alloc_tensor(%storage_0496, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][507]) /* ty=int64 */;
  %2285 = fn (%p0431: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0431) /* ty=int64 */
  };
  %2286 = (%shape_func_out_067,);
  %2287 = (%tensor_0432,);
  let %v428: () = vm.invoke_tvm_op(%2285, %2286, %2287) /* ty=() */;
  let %storage_0497: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][508]) /* ty=Storage[] */;
  let %tensor_0433: int64 = memory.alloc_tensor(%storage_0497, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][508]) /* ty=int64 */;
  %2288 = fn (%p0432: int64, Primitive=1) -> int64 {
    multiply(%p0432, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2289 = (%tensor_0432,);
  %2290 = (%tensor_0433,);
  let %v429: () = vm.invoke_tvm_op(%2288, %2289, %2290) /* ty=() */;
  let %storage_0498: Storage[] = memory.alloc_storage(%tensor_0433, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][509]) /* ty=Storage[] */;
  let %out_064: Tensor[(?, 364), float32] = memory.alloc_tensor(%storage_0498, 0 /* ty=int64 */, %shape_func_out_067, meta[relay.attrs.AllocTensorAttrs][509]) /* ty=Tensor[(?, 364), float32] */;
  %2291 = (%x388, %x413, %model.roi_heads.box_predictor.bbox_pred.bias);
  %2292 = (%out_064,);
  let %v430: () = vm.invoke_tvm_op(%2282, %2291, %2292) /* ty=() */;
  let %x414: Tensor[(?, 364), float32] = %out_064;
  let %storage_0499: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][510]) /* ty=Storage[] */;
  let %tensor_0434: Tensor[(1), int64] = memory.alloc_tensor(%storage_0499, 0 /* ty=int64 */, meta[relay.Constant][487] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][510]) /* ty=Tensor[(1), int64] */;
  %2296 = fn (%p0433: Tensor[(2), int32], Primitive=1) -> Tensor[(1), int64] {
    %2293 = take(%p0433, 0 /* ty=int32 */, axis=0) /* ty=int32 */;
    %2294 = add(%2293, 0 /* ty=int32 */) /* ty=int32 */;
    %2295 = cast(%2294, dtype="int64") /* ty=int64 */;
    expand_dims(%2295, axis=0) /* ty=Tensor[(1), int64] */
  };
  %2297 = (%x332,);
  %2298 = (%tensor_0434,);
  let %v431: () = vm.invoke_tvm_op(%2296, %2297, %2298) /* ty=() */;
  let %x415: Tensor[(1), int64] = %tensor_0434;
  let %storage_0500: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][511]) /* ty=Storage[] */;
  let %tensor_0435: Tensor[(2), int64] = memory.alloc_tensor(%storage_0500, 0 /* ty=int64 */, meta[relay.Constant][488] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][511]) /* ty=Tensor[(2), int64] */;
  %2300 = fn (%p0434: Tensor[(1), int64], %p1239: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
    %2299 = (%p0434, %p1239);
    concatenate(%2299) /* ty=Tensor[(2), int64] */
  };
  %2301 = (%x415, meta[relay.Constant][489] /* ty=Tensor[(1), int64] */);
  %2302 = (%tensor_0435,);
  let %v432: () = vm.invoke_tvm_op(%2300, %2301, %2302) /* ty=() */;
  let %x416: Tensor[(2), int64] = %tensor_0435;
  let %in_shape_059: Tensor[(?, 364), float32] = device_copy(%x414, meta[relay.attrs.DeviceCopyAttrs][55]) /* ty=Tensor[(?, 364), float32] */;
  let %in_shape_130: Tensor[(2), int64] = device_copy(%x416, meta[relay.attrs.DeviceCopyAttrs][56]) /* ty=Tensor[(2), int64] */;
  let %storage_0501: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][512]) /* ty=Storage[] */;
  let %tensor_0436: Tensor[(2), int64] = memory.alloc_tensor(%storage_0501, 0 /* ty=int64 */, meta[relay.Constant][490] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][512]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_068: Tensor[(2), int64] = %tensor_0436;
  %2303 = fn (%p0435: Tensor[(?, 364), float32], %p1240: Tensor[(2), int64], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.reshape(%p0435, %p1240, newshape=[]) /* ty=Tensor[(?, ?), float32] */
  };
  %2304 = (%in_shape_059, %in_shape_130);
  %2305 = (%shape_func_out_068,);
  let %shape_func68: () = vm.shape_func(%2303, %2304, %2305, meta[relay.attrs.ShapeFuncAttrs][68]) /* ty=() */;
  let %x417: Tensor[(?, ?), float32] = vm.reshape_tensor(%x414, %shape_func_out_068, meta[relay.attrs.ReshapeTensorAttrs][109]) /* ty=Tensor[(?, ?), float32] */;
  let %storage_0502: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][513]) /* ty=Storage[] */;
  let %tensor_0437: Tensor[(2), int32] = memory.alloc_tensor(%storage_0502, 0 /* ty=int64 */, meta[relay.Constant][491] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][513]) /* ty=Tensor[(2), int32] */;
  %2306 = fn (%p0436: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0436, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2307 = (%x417,);
  %2308 = (%tensor_0437,);
  let %v433: () = vm.invoke_tvm_op(%2306, %2307, %2308) /* ty=() */;
  let %x418: Tensor[(2), int32] = %tensor_0437;
  let %storage_0503: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][514]) /* ty=Storage[] */;
  let %tensor_0438: Tensor[(2), int32] = memory.alloc_tensor(%storage_0503, 0 /* ty=int64 */, meta[relay.Constant][492] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][514]) /* ty=Tensor[(2), int32] */;
  %2311 = fn (%p0437: Tensor[(2), bool], %p1241: Tensor[(2), int32], %p2116: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2309 = cast_like(%p2116, %p1241) /* ty=Tensor[(2), int32] */;
    %2310 = add(%p1241, %2309) /* ty=Tensor[(2), int32] */;
    where(%p0437, %2310, %p1241) /* ty=Tensor[(2), int32] */
  };
  %2312 = (meta[relay.Constant][493] /* ty=Tensor[(2), bool] */, meta[relay.Constant][494] /* ty=Tensor[(2), int32] */, %x418);
  %2313 = (%tensor_0438,);
  let %v434: () = vm.invoke_tvm_op(%2311, %2312, %2313) /* ty=() */;
  let %x419: Tensor[(2), int32] = %tensor_0438;
  let %storage_0504: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][515]) /* ty=Storage[] */;
  let %tensor_0439: Tensor[(2), int64] = memory.alloc_tensor(%storage_0504, 0 /* ty=int64 */, meta[relay.Constant][495] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][515]) /* ty=Tensor[(2), int64] */;
  %2314 = fn (%p0438: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0438, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2315 = (%x418,);
  %2316 = (%tensor_0439,);
  let %v435: () = vm.invoke_tvm_op(%2314, %2315, %2316) /* ty=() */;
  let %x420: Tensor[(2), int64] = %tensor_0439;
  let %in_shape_060: Tensor[(?, ?), float32] = device_copy(%x417, meta[relay.attrs.DeviceCopyAttrs][57]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_131: Tensor[(2), int32] = device_copy(%x419, meta[relay.attrs.DeviceCopyAttrs][58]) /* ty=Tensor[(2), int32] */;
  let %in_shape_218: Tensor[(2), int64] = device_copy(%x420, meta[relay.attrs.DeviceCopyAttrs][59]) /* ty=Tensor[(2), int64] */;
  let %in_shape_314: Tensor[(2), int32] = device_copy(meta[relay.Constant][496] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][60]) /* ty=Tensor[(2), int32] */;
  let %storage_0505: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][516]) /* ty=Storage[] */;
  let %tensor_0440: Tensor[(2), int64] = memory.alloc_tensor(%storage_0505, 0 /* ty=int64 */, meta[relay.Constant][497] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][516]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_069: Tensor[(2), int64] = %tensor_0440;
  %2317 = fn (%p0439: Tensor[(?, ?), float32], %p1242: Tensor[(2), int32], %p2117: Tensor[(2), int64], %p374: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0439, %p1242, %p2117, %p374, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2318 = (%in_shape_060, %in_shape_131, %in_shape_218, %in_shape_314);
  %2319 = (%shape_func_out_069,);
  let %shape_func69: () = vm.shape_func(%2317, %2318, %2319, meta[relay.attrs.ShapeFuncAttrs][69]) /* ty=() */;
  let %storage_0506: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][517]) /* ty=Storage[] */;
  let %tensor_0441: int64 = memory.alloc_tensor(%storage_0506, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][517]) /* ty=int64 */;
  %2320 = fn (%p0440: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0440) /* ty=int64 */
  };
  %2321 = (%shape_func_out_069,);
  %2322 = (%tensor_0441,);
  let %v436: () = vm.invoke_tvm_op(%2320, %2321, %2322) /* ty=() */;
  let %storage_0507: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][518]) /* ty=Storage[] */;
  let %tensor_0442: int64 = memory.alloc_tensor(%storage_0507, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][518]) /* ty=int64 */;
  %2323 = fn (%p0441: int64, Primitive=1) -> int64 {
    multiply(%p0441, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2324 = (%tensor_0441,);
  %2325 = (%tensor_0442,);
  let %v437: () = vm.invoke_tvm_op(%2323, %2324, %2325) /* ty=() */;
  let %storage_0508: Storage[] = memory.alloc_storage(%tensor_0442, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][519]) /* ty=Storage[] */;
  let %out_065: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0508, 0 /* ty=int64 */, %shape_func_out_069, meta[relay.attrs.AllocTensorAttrs][519]) /* ty=Tensor[(?, ?), float32] */;
  %2326 = (%x417, %x419, %x420, meta[relay.Constant][496] /* ty=Tensor[(2), int32] */);
  %2327 = (%out_065,);
  let %v438: () = vm.invoke_tvm_op(%2317, %2326, %2327) /* ty=() */;
  let %x421: Tensor[(?, ?), float32] = %out_065;
  let %storage_0509: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][520]) /* ty=Storage[] */;
  let %tensor_0443: Tensor[(2), int32] = memory.alloc_tensor(%storage_0509, 0 /* ty=int64 */, meta[relay.Constant][498] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][520]) /* ty=Tensor[(2), int32] */;
  %2328 = fn (%p0442: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0442, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2329 = (%x421,);
  %2330 = (%tensor_0443,);
  let %v439: () = vm.invoke_tvm_op(%2328, %2329, %2330) /* ty=() */;
  let %x422: Tensor[(2), int32] = %tensor_0443;
  let %storage_0510: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][521]) /* ty=Storage[] */;
  let %tensor_0444: Tensor[(2), int32] = memory.alloc_tensor(%storage_0510, 0 /* ty=int64 */, meta[relay.Constant][499] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][521]) /* ty=Tensor[(2), int32] */;
  %2333 = fn (%p0443: Tensor[(2), bool], %p1243: Tensor[(2), int32], %p2118: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2331 = cast_like(%p2118, %p1243) /* ty=Tensor[(2), int32] */;
    %2332 = add(%p1243, %2331) /* ty=Tensor[(2), int32] */;
    where(%p0443, %2332, %p1243) /* ty=Tensor[(2), int32] */
  };
  %2334 = (meta[relay.Constant][500] /* ty=Tensor[(2), bool] */, meta[relay.Constant][501] /* ty=Tensor[(2), int32] */, %x422);
  %2335 = (%tensor_0444,);
  let %v440: () = vm.invoke_tvm_op(%2333, %2334, %2335) /* ty=() */;
  let %x423: Tensor[(2), int32] = %tensor_0444;
  let %storage_0511: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][522]) /* ty=Storage[] */;
  let %tensor_0445: Tensor[(2), int64] = memory.alloc_tensor(%storage_0511, 0 /* ty=int64 */, meta[relay.Constant][502] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][522]) /* ty=Tensor[(2), int64] */;
  %2336 = fn (%p0444: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0444, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2337 = (%x422,);
  %2338 = (%tensor_0445,);
  let %v441: () = vm.invoke_tvm_op(%2336, %2337, %2338) /* ty=() */;
  let %x424: Tensor[(2), int64] = %tensor_0445;
  let %in_shape_061: Tensor[(?, ?), float32] = device_copy(%x421, meta[relay.attrs.DeviceCopyAttrs][61]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_132: Tensor[(2), int32] = device_copy(%x423, meta[relay.attrs.DeviceCopyAttrs][62]) /* ty=Tensor[(2), int32] */;
  let %in_shape_219: Tensor[(2), int64] = device_copy(%x424, meta[relay.attrs.DeviceCopyAttrs][63]) /* ty=Tensor[(2), int64] */;
  let %in_shape_315: Tensor[(2), int32] = device_copy(meta[relay.Constant][503] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][64]) /* ty=Tensor[(2), int32] */;
  let %storage_0512: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][523]) /* ty=Storage[] */;
  let %tensor_0446: Tensor[(2), int64] = memory.alloc_tensor(%storage_0512, 0 /* ty=int64 */, meta[relay.Constant][504] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][523]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_070: Tensor[(2), int64] = %tensor_0446;
  %2339 = fn (%p0445: Tensor[(?, ?), float32], %p1244: Tensor[(2), int32], %p2119: Tensor[(2), int64], %p375: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0445, %p1244, %p2119, %p375, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2340 = (%in_shape_061, %in_shape_132, %in_shape_219, %in_shape_315);
  %2341 = (%shape_func_out_070,);
  let %shape_func70: () = vm.shape_func(%2339, %2340, %2341, meta[relay.attrs.ShapeFuncAttrs][70]) /* ty=() */;
  let %storage_0513: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][524]) /* ty=Storage[] */;
  let %tensor_0447: int64 = memory.alloc_tensor(%storage_0513, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][524]) /* ty=int64 */;
  %2342 = fn (%p0446: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0446) /* ty=int64 */
  };
  %2343 = (%shape_func_out_070,);
  %2344 = (%tensor_0447,);
  let %v442: () = vm.invoke_tvm_op(%2342, %2343, %2344) /* ty=() */;
  let %storage_0514: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][525]) /* ty=Storage[] */;
  let %tensor_0448: int64 = memory.alloc_tensor(%storage_0514, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][525]) /* ty=int64 */;
  %2345 = fn (%p0447: int64, Primitive=1) -> int64 {
    multiply(%p0447, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2346 = (%tensor_0447,);
  %2347 = (%tensor_0448,);
  let %v443: () = vm.invoke_tvm_op(%2345, %2346, %2347) /* ty=() */;
  let %storage_0515: Storage[] = memory.alloc_storage(%tensor_0448, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][526]) /* ty=Storage[] */;
  let %out_066: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0515, 0 /* ty=int64 */, %shape_func_out_070, meta[relay.attrs.AllocTensorAttrs][526]) /* ty=Tensor[(?, ?), float32] */;
  %2348 = (%x421, %x423, %x424, meta[relay.Constant][503] /* ty=Tensor[(2), int32] */);
  %2349 = (%out_066,);
  let %v444: () = vm.invoke_tvm_op(%2339, %2348, %2349) /* ty=() */;
  let %x425: Tensor[(?, ?), float32] = %out_066;
  let %in_shape_062: Tensor[(2), int64] = vm.shape_of(%x331, meta[relay.attrs.ShapeOfAttrs][68]) /* ty=Tensor[(2), int64] */;
  let %storage_0516: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][527]) /* ty=Storage[] */;
  let %tensor_0449: Tensor[(2), int64] = memory.alloc_tensor(%storage_0516, 0 /* ty=int64 */, meta[relay.Constant][505] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][527]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_071: Tensor[(2), int64] = %tensor_0449;
  %2351 = fn (%p0448: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(?, 4), float32] {
    %2350 = (%p0448,);
    concatenate(%2350) /* ty=Tensor[(?, 4), float32] */
  };
  %2352 = (%in_shape_062,);
  %2353 = (%shape_func_out_071,);
  let %shape_func71: () = vm.shape_func(%2351, %2352, %2353, meta[relay.attrs.ShapeFuncAttrs][71]) /* ty=() */;
  let %storage_0517: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][528]) /* ty=Storage[] */;
  let %tensor_0450: int64 = memory.alloc_tensor(%storage_0517, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][528]) /* ty=int64 */;
  %2354 = fn (%p0449: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0449) /* ty=int64 */
  };
  %2355 = (%shape_func_out_071,);
  %2356 = (%tensor_0450,);
  let %v445: () = vm.invoke_tvm_op(%2354, %2355, %2356) /* ty=() */;
  let %storage_0518: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][529]) /* ty=Storage[] */;
  let %tensor_0451: int64 = memory.alloc_tensor(%storage_0518, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][529]) /* ty=int64 */;
  %2357 = fn (%p0450: int64, Primitive=1) -> int64 {
    multiply(%p0450, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2358 = (%tensor_0450,);
  %2359 = (%tensor_0451,);
  let %v446: () = vm.invoke_tvm_op(%2357, %2358, %2359) /* ty=() */;
  let %storage_0519: Storage[] = memory.alloc_storage(%tensor_0451, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][530]) /* ty=Storage[] */;
  let %out_067: Tensor[(?, 4), float32] = memory.alloc_tensor(%storage_0519, 0 /* ty=int64 */, %shape_func_out_071, meta[relay.attrs.AllocTensorAttrs][530]) /* ty=Tensor[(?, 4), float32] */;
  %2360 = (%x331,);
  %2361 = (%out_067,);
  let %v447: () = vm.invoke_tvm_op(%2351, %2360, %2361) /* ty=() */;
  let %x426: Tensor[(?, 4), float32] = %out_067;
  let %storage_0520: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][531]) /* ty=Storage[] */;
  let %tensor_0452: Tensor[(2), int32] = memory.alloc_tensor(%storage_0520, 0 /* ty=int64 */, meta[relay.Constant][506] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][531]) /* ty=Tensor[(2), int32] */;
  %2362 = fn (%p0451: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0451, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2363 = (%x426,);
  %2364 = (%tensor_0452,);
  let %v448: () = vm.invoke_tvm_op(%2362, %2363, %2364) /* ty=() */;
  let %x427: Tensor[(2), int32] = %tensor_0452;
  let %storage_0521: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][532]) /* ty=Storage[] */;
  let %tensor_0453: Tensor[(2), int32] = memory.alloc_tensor(%storage_0521, 0 /* ty=int64 */, meta[relay.Constant][507] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][532]) /* ty=Tensor[(2), int32] */;
  %2367 = fn (%p0452: Tensor[(2), bool], %p1245: Tensor[(2), int32], %p2120: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2365 = cast_like(%p2120, %p1245) /* ty=Tensor[(2), int32] */;
    %2366 = add(%p1245, %2365) /* ty=Tensor[(2), int32] */;
    where(%p0452, %2366, %p1245) /* ty=Tensor[(2), int32] */
  };
  %2368 = (meta[relay.Constant][508] /* ty=Tensor[(2), bool] */, meta[relay.Constant][509] /* ty=Tensor[(2), int32] */, %x427);
  %2369 = (%tensor_0453,);
  let %v449: () = vm.invoke_tvm_op(%2367, %2368, %2369) /* ty=() */;
  let %x428: Tensor[(2), int32] = %tensor_0453;
  let %storage_0522: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][533]) /* ty=Storage[] */;
  let %tensor_0454: Tensor[(2), int64] = memory.alloc_tensor(%storage_0522, 0 /* ty=int64 */, meta[relay.Constant][510] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][533]) /* ty=Tensor[(2), int64] */;
  %2370 = fn (%p0453: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0453, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2371 = (%x427,);
  %2372 = (%tensor_0454,);
  let %v450: () = vm.invoke_tvm_op(%2370, %2371, %2372) /* ty=() */;
  let %x429: Tensor[(2), int64] = %tensor_0454;
  let %in_shape_063: Tensor[(?, 4), float32] = device_copy(%x426, meta[relay.attrs.DeviceCopyAttrs][65]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_133: Tensor[(2), int32] = device_copy(%x428, meta[relay.attrs.DeviceCopyAttrs][66]) /* ty=Tensor[(2), int32] */;
  let %in_shape_220: Tensor[(2), int64] = device_copy(%x429, meta[relay.attrs.DeviceCopyAttrs][67]) /* ty=Tensor[(2), int64] */;
  let %in_shape_316: Tensor[(2), int32] = device_copy(meta[relay.Constant][511] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][68]) /* ty=Tensor[(2), int32] */;
  let %storage_0523: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][534]) /* ty=Storage[] */;
  let %tensor_0455: Tensor[(2), int64] = memory.alloc_tensor(%storage_0523, 0 /* ty=int64 */, meta[relay.Constant][512] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][534]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_072: Tensor[(2), int64] = %tensor_0455;
  %2373 = fn (%p0454: Tensor[(?, 4), float32], %p1246: Tensor[(2), int32], %p2121: Tensor[(2), int64], %p376: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0454, %p1246, %p2121, %p376, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2374 = (%in_shape_063, %in_shape_133, %in_shape_220, %in_shape_316);
  %2375 = (%shape_func_out_072,);
  let %shape_func72: () = vm.shape_func(%2373, %2374, %2375, meta[relay.attrs.ShapeFuncAttrs][72]) /* ty=() */;
  let %storage_0524: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][535]) /* ty=Storage[] */;
  let %tensor_0456: int64 = memory.alloc_tensor(%storage_0524, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][535]) /* ty=int64 */;
  %2376 = fn (%p0455: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0455) /* ty=int64 */
  };
  %2377 = (%shape_func_out_072,);
  %2378 = (%tensor_0456,);
  let %v451: () = vm.invoke_tvm_op(%2376, %2377, %2378) /* ty=() */;
  let %storage_0525: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][536]) /* ty=Storage[] */;
  let %tensor_0457: int64 = memory.alloc_tensor(%storage_0525, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][536]) /* ty=int64 */;
  %2379 = fn (%p0456: int64, Primitive=1) -> int64 {
    multiply(%p0456, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2380 = (%tensor_0456,);
  %2381 = (%tensor_0457,);
  let %v452: () = vm.invoke_tvm_op(%2379, %2380, %2381) /* ty=() */;
  let %storage_0526: Storage[] = memory.alloc_storage(%tensor_0457, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][537]) /* ty=Storage[] */;
  let %out_068: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0526, 0 /* ty=int64 */, %shape_func_out_072, meta[relay.attrs.AllocTensorAttrs][537]) /* ty=Tensor[(?, ?), float32] */;
  %2382 = (%x426, %x428, %x429, meta[relay.Constant][511] /* ty=Tensor[(2), int32] */);
  %2383 = (%out_068,);
  let %v453: () = vm.invoke_tvm_op(%2373, %2382, %2383) /* ty=() */;
  let %x430: Tensor[(?, ?), float32] = %out_068;
  let %storage_0527: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][538]) /* ty=Storage[] */;
  let %tensor_0458: Tensor[(2), int32] = memory.alloc_tensor(%storage_0527, 0 /* ty=int64 */, meta[relay.Constant][513] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][538]) /* ty=Tensor[(2), int32] */;
  %2386 = fn (%p0457: Tensor[(2), bool], %p1247: Tensor[(2), int32], %p2122: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2384 = cast_like(%p2122, %p1247) /* ty=Tensor[(2), int32] */;
    %2385 = add(%p1247, %2384) /* ty=Tensor[(2), int32] */;
    where(%p0457, %2385, %p1247) /* ty=Tensor[(2), int32] */
  };
  %2387 = (meta[relay.Constant][514] /* ty=Tensor[(2), bool] */, meta[relay.Constant][515] /* ty=Tensor[(2), int32] */, %x427);
  %2388 = (%tensor_0458,);
  let %v454: () = vm.invoke_tvm_op(%2386, %2387, %2388) /* ty=() */;
  let %x431: Tensor[(2), int32] = %tensor_0458;
  let %in_shape_064: Tensor[(?, 4), float32] = device_copy(%x426, meta[relay.attrs.DeviceCopyAttrs][69]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_134: Tensor[(2), int32] = device_copy(%x431, meta[relay.attrs.DeviceCopyAttrs][70]) /* ty=Tensor[(2), int32] */;
  let %in_shape_221: Tensor[(2), int64] = device_copy(%x429, meta[relay.attrs.DeviceCopyAttrs][71]) /* ty=Tensor[(2), int64] */;
  let %in_shape_317: Tensor[(2), int32] = device_copy(meta[relay.Constant][516] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][72]) /* ty=Tensor[(2), int32] */;
  let %storage_0528: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][539]) /* ty=Storage[] */;
  let %tensor_0459: Tensor[(2), int64] = memory.alloc_tensor(%storage_0528, 0 /* ty=int64 */, meta[relay.Constant][517] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][539]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_073: Tensor[(2), int64] = %tensor_0459;
  %2389 = fn (%p0458: Tensor[(?, 4), float32], %p1248: Tensor[(2), int32], %p2123: Tensor[(2), int64], %p377: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0458, %p1248, %p2123, %p377, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2390 = (%in_shape_064, %in_shape_134, %in_shape_221, %in_shape_317);
  %2391 = (%shape_func_out_073,);
  let %shape_func73: () = vm.shape_func(%2389, %2390, %2391, meta[relay.attrs.ShapeFuncAttrs][73]) /* ty=() */;
  let %storage_0529: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][540]) /* ty=Storage[] */;
  let %tensor_0460: int64 = memory.alloc_tensor(%storage_0529, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][540]) /* ty=int64 */;
  %2392 = fn (%p0459: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0459) /* ty=int64 */
  };
  %2393 = (%shape_func_out_073,);
  %2394 = (%tensor_0460,);
  let %v455: () = vm.invoke_tvm_op(%2392, %2393, %2394) /* ty=() */;
  let %storage_0530: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][541]) /* ty=Storage[] */;
  let %tensor_0461: int64 = memory.alloc_tensor(%storage_0530, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][541]) /* ty=int64 */;
  %2395 = fn (%p0460: int64, Primitive=1) -> int64 {
    multiply(%p0460, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2396 = (%tensor_0460,);
  %2397 = (%tensor_0461,);
  let %v456: () = vm.invoke_tvm_op(%2395, %2396, %2397) /* ty=() */;
  let %storage_0531: Storage[] = memory.alloc_storage(%tensor_0461, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][542]) /* ty=Storage[] */;
  let %out_069: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0531, 0 /* ty=int64 */, %shape_func_out_073, meta[relay.attrs.AllocTensorAttrs][542]) /* ty=Tensor[(?, ?), float32] */;
  %2398 = (%x426, %x431, %x429, meta[relay.Constant][516] /* ty=Tensor[(2), int32] */);
  %2399 = (%out_069,);
  let %v457: () = vm.invoke_tvm_op(%2389, %2398, %2399) /* ty=() */;
  let %x432: Tensor[(?, ?), float32] = %out_069;
  let %in_shape_065: Tensor[(2), int64] = vm.shape_of(%x430, meta[relay.attrs.ShapeOfAttrs][69]) /* ty=Tensor[(2), int64] */;
  let %in_shape_135: Tensor[(2), int64] = vm.shape_of(%x432, meta[relay.attrs.ShapeOfAttrs][70]) /* ty=Tensor[(2), int64] */;
  let %storage_0532: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][543]) /* ty=Storage[] */;
  let %tensor_0462: Tensor[(1), int64] = memory.alloc_tensor(%storage_0532, 0 /* ty=int64 */, meta[relay.Constant][518] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][543]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_074: Tensor[(1), int64] = %tensor_0462;
  %2402 = fn (%p0461: Tensor[(?, ?), float32], %p1249: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?), float32] {
    %2400 = take(%p0461, 2 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %2401 = take(%p1249, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    subtract(%2400, %2401) /* ty=Tensor[(?), float32] */
  };
  %2403 = (%in_shape_065, %in_shape_135);
  %2404 = (%shape_func_out_074,);
  let %shape_func74: () = vm.shape_func(%2402, %2403, %2404, meta[relay.attrs.ShapeFuncAttrs][74]) /* ty=() */;
  let %storage_0533: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][544]) /* ty=Storage[] */;
  let %tensor_0463: int64 = memory.alloc_tensor(%storage_0533, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][544]) /* ty=int64 */;
  %2405 = fn (%p0462: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0462) /* ty=int64 */
  };
  %2406 = (%shape_func_out_074,);
  %2407 = (%tensor_0463,);
  let %v458: () = vm.invoke_tvm_op(%2405, %2406, %2407) /* ty=() */;
  let %storage_0534: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][545]) /* ty=Storage[] */;
  let %tensor_0464: int64 = memory.alloc_tensor(%storage_0534, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][545]) /* ty=int64 */;
  %2408 = fn (%p0463: int64, Primitive=1) -> int64 {
    multiply(%p0463, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2409 = (%tensor_0463,);
  %2410 = (%tensor_0464,);
  let %v459: () = vm.invoke_tvm_op(%2408, %2409, %2410) /* ty=() */;
  let %storage_0535: Storage[] = memory.alloc_storage(%tensor_0464, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][546]) /* ty=Storage[] */;
  let %out_070: Tensor[(?), float32] = memory.alloc_tensor(%storage_0535, 0 /* ty=int64 */, %shape_func_out_074, meta[relay.attrs.AllocTensorAttrs][546]) /* ty=Tensor[(?), float32] */;
  %2411 = (%x430, %x432);
  %2412 = (%out_070,);
  let %v460: () = vm.invoke_tvm_op(%2402, %2411, %2412) /* ty=() */;
  let %x433: Tensor[(?), float32] = %out_070;
  let %storage_0536: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][547]) /* ty=Storage[] */;
  let %tensor_0465: Tensor[(1), int32] = memory.alloc_tensor(%storage_0536, 0 /* ty=int64 */, meta[relay.Constant][519] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][547]) /* ty=Tensor[(1), int32] */;
  %2413 = fn (%p0464: Tensor[(?), float32], Primitive=1) -> Tensor[(1), int32] {
    shape_of(%p0464, dtype="int32") /* ty=Tensor[(1), int32] */
  };
  %2414 = (%x433,);
  %2415 = (%tensor_0465,);
  let %v461: () = vm.invoke_tvm_op(%2413, %2414, %2415) /* ty=() */;
  let %x434: Tensor[(1), int32] = %tensor_0465;
  let %storage_0537: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][548]) /* ty=Storage[] */;
  let %tensor_0466: Tensor[(1), int32] = memory.alloc_tensor(%storage_0537, 0 /* ty=int64 */, meta[relay.Constant][520] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][548]) /* ty=Tensor[(1), int32] */;
  %2418 = fn (%p0465: Tensor[(1), bool], %p1250: Tensor[(1), int32], %p2124: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
    %2416 = cast_like(%p2124, %p1250) /* ty=Tensor[(1), int32] */;
    %2417 = add(%p1250, %2416) /* ty=Tensor[(1), int32] */;
    where(%p0465, %2417, %p1250) /* ty=Tensor[(1), int32] */
  };
  %2419 = (meta[relay.Constant][521] /* ty=Tensor[(1), bool] */, meta[relay.Constant][522] /* ty=Tensor[(1), int32] */, %x434);
  %2420 = (%tensor_0466,);
  let %v462: () = vm.invoke_tvm_op(%2418, %2419, %2420) /* ty=() */;
  let %x435: Tensor[(1), int32] = %tensor_0466;
  let %storage_0538: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][549]) /* ty=Storage[] */;
  let %tensor_0467: Tensor[(1), int64] = memory.alloc_tensor(%storage_0538, 0 /* ty=int64 */, meta[relay.Constant][523] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][549]) /* ty=Tensor[(1), int64] */;
  %2421 = fn (%p0466: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int64] {
    cast(%p0466, dtype="int64") /* ty=Tensor[(1), int64] */
  };
  %2422 = (%x434,);
  %2423 = (%tensor_0467,);
  let %v463: () = vm.invoke_tvm_op(%2421, %2422, %2423) /* ty=() */;
  let %x436: Tensor[(1), int64] = %tensor_0467;
  let %in_shape_066: Tensor[(?), float32] = device_copy(%x433, meta[relay.attrs.DeviceCopyAttrs][73]) /* ty=Tensor[(?), float32] */;
  let %in_shape_136: Tensor[(1), int32] = device_copy(%x435, meta[relay.attrs.DeviceCopyAttrs][74]) /* ty=Tensor[(1), int32] */;
  let %in_shape_222: Tensor[(1), int64] = device_copy(%x436, meta[relay.attrs.DeviceCopyAttrs][75]) /* ty=Tensor[(1), int64] */;
  let %in_shape_318: Tensor[(1), int32] = device_copy(meta[relay.Constant][524] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][76]) /* ty=Tensor[(1), int32] */;
  let %storage_0539: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][550]) /* ty=Storage[] */;
  let %tensor_0468: Tensor[(1), int64] = memory.alloc_tensor(%storage_0539, 0 /* ty=int64 */, meta[relay.Constant][525] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][550]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_075: Tensor[(1), int64] = %tensor_0468;
  %2424 = fn (%p0467: Tensor[(?), float32], %p1251: Tensor[(1), int32], %p2125: Tensor[(1), int64], %p378: Tensor[(1), int32], Primitive=1) -> Tensor[(?), float32] {
    dyn.strided_slice(%p0467, %p1251, %p2125, %p378, begin=None, end=None, strides=None) /* ty=Tensor[(?), float32] */
  };
  %2425 = (%in_shape_066, %in_shape_136, %in_shape_222, %in_shape_318);
  %2426 = (%shape_func_out_075,);
  let %shape_func75: () = vm.shape_func(%2424, %2425, %2426, meta[relay.attrs.ShapeFuncAttrs][75]) /* ty=() */;
  let %storage_0540: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][551]) /* ty=Storage[] */;
  let %tensor_0469: int64 = memory.alloc_tensor(%storage_0540, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][551]) /* ty=int64 */;
  %2427 = fn (%p0468: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0468) /* ty=int64 */
  };
  %2428 = (%shape_func_out_075,);
  %2429 = (%tensor_0469,);
  let %v464: () = vm.invoke_tvm_op(%2427, %2428, %2429) /* ty=() */;
  let %storage_0541: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][552]) /* ty=Storage[] */;
  let %tensor_0470: int64 = memory.alloc_tensor(%storage_0541, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][552]) /* ty=int64 */;
  %2430 = fn (%p0469: int64, Primitive=1) -> int64 {
    multiply(%p0469, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2431 = (%tensor_0469,);
  %2432 = (%tensor_0470,);
  let %v465: () = vm.invoke_tvm_op(%2430, %2431, %2432) /* ty=() */;
  let %storage_0542: Storage[] = memory.alloc_storage(%tensor_0470, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][553]) /* ty=Storage[] */;
  let %out_071: Tensor[(?), float32] = memory.alloc_tensor(%storage_0542, 0 /* ty=int64 */, %shape_func_out_075, meta[relay.attrs.AllocTensorAttrs][553]) /* ty=Tensor[(?), float32] */;
  %2433 = (%x433, %x435, %x436, meta[relay.Constant][524] /* ty=Tensor[(1), int32] */);
  %2434 = (%out_071,);
  let %v466: () = vm.invoke_tvm_op(%2424, %2433, %2434) /* ty=() */;
  let %x437: Tensor[(?), float32] = %out_071;
  let %storage_0543: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][554]) /* ty=Storage[] */;
  let %tensor_0471: Tensor[(2), int32] = memory.alloc_tensor(%storage_0543, 0 /* ty=int64 */, meta[relay.Constant][526] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][554]) /* ty=Tensor[(2), int32] */;
  %2437 = fn (%p0470: Tensor[(2), bool], %p1252: Tensor[(2), int32], %p2126: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2435 = cast_like(%p2126, %p1252) /* ty=Tensor[(2), int32] */;
    %2436 = add(%p1252, %2435) /* ty=Tensor[(2), int32] */;
    where(%p0470, %2436, %p1252) /* ty=Tensor[(2), int32] */
  };
  %2438 = (meta[relay.Constant][527] /* ty=Tensor[(2), bool] */, meta[relay.Constant][528] /* ty=Tensor[(2), int32] */, %x427);
  %2439 = (%tensor_0471,);
  let %v467: () = vm.invoke_tvm_op(%2437, %2438, %2439) /* ty=() */;
  let %x438: Tensor[(2), int32] = %tensor_0471;
  let %in_shape_067: Tensor[(?, 4), float32] = device_copy(%x426, meta[relay.attrs.DeviceCopyAttrs][77]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_137: Tensor[(2), int32] = device_copy(%x438, meta[relay.attrs.DeviceCopyAttrs][78]) /* ty=Tensor[(2), int32] */;
  let %in_shape_223: Tensor[(2), int64] = device_copy(%x429, meta[relay.attrs.DeviceCopyAttrs][79]) /* ty=Tensor[(2), int64] */;
  let %in_shape_319: Tensor[(2), int32] = device_copy(meta[relay.Constant][529] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][80]) /* ty=Tensor[(2), int32] */;
  let %storage_0544: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][555]) /* ty=Storage[] */;
  let %tensor_0472: Tensor[(2), int64] = memory.alloc_tensor(%storage_0544, 0 /* ty=int64 */, meta[relay.Constant][530] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][555]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_076: Tensor[(2), int64] = %tensor_0472;
  %2440 = fn (%p0471: Tensor[(?, 4), float32], %p1253: Tensor[(2), int32], %p2127: Tensor[(2), int64], %p379: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0471, %p1253, %p2127, %p379, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2441 = (%in_shape_067, %in_shape_137, %in_shape_223, %in_shape_319);
  %2442 = (%shape_func_out_076,);
  let %shape_func76: () = vm.shape_func(%2440, %2441, %2442, meta[relay.attrs.ShapeFuncAttrs][76]) /* ty=() */;
  let %storage_0545: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][556]) /* ty=Storage[] */;
  let %tensor_0473: int64 = memory.alloc_tensor(%storage_0545, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][556]) /* ty=int64 */;
  %2443 = fn (%p0472: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0472) /* ty=int64 */
  };
  %2444 = (%shape_func_out_076,);
  %2445 = (%tensor_0473,);
  let %v468: () = vm.invoke_tvm_op(%2443, %2444, %2445) /* ty=() */;
  let %storage_0546: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][557]) /* ty=Storage[] */;
  let %tensor_0474: int64 = memory.alloc_tensor(%storage_0546, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][557]) /* ty=int64 */;
  %2446 = fn (%p0473: int64, Primitive=1) -> int64 {
    multiply(%p0473, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2447 = (%tensor_0473,);
  %2448 = (%tensor_0474,);
  let %v469: () = vm.invoke_tvm_op(%2446, %2447, %2448) /* ty=() */;
  let %storage_0547: Storage[] = memory.alloc_storage(%tensor_0474, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][558]) /* ty=Storage[] */;
  let %out_072: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0547, 0 /* ty=int64 */, %shape_func_out_076, meta[relay.attrs.AllocTensorAttrs][558]) /* ty=Tensor[(?, ?), float32] */;
  %2449 = (%x426, %x438, %x429, meta[relay.Constant][529] /* ty=Tensor[(2), int32] */);
  %2450 = (%out_072,);
  let %v470: () = vm.invoke_tvm_op(%2440, %2449, %2450) /* ty=() */;
  let %x439: Tensor[(?, ?), float32] = %out_072;
  let %in_shape_068: Tensor[(2), int64] = vm.shape_of(%x439, meta[relay.attrs.ShapeOfAttrs][71]) /* ty=Tensor[(2), int64] */;
  let %in_shape_138: Tensor[(1), int64] = vm.shape_of(%x433, meta[relay.attrs.ShapeOfAttrs][72]) /* ty=Tensor[(1), int64] */;
  let %storage_0548: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][559]) /* ty=Storage[] */;
  let %tensor_0475: Tensor[(1), int64] = memory.alloc_tensor(%storage_0548, 0 /* ty=int64 */, meta[relay.Constant][531] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][559]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_077: Tensor[(1), int64] = %tensor_0475;
  %2453 = fn (%p0474: Tensor[(?, ?), float32], %p1254: Tensor[(?), float32], Primitive=1) -> Tensor[(?), float32] {
    %2451 = take(%p0474, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %2452 = multiply(%p1254, 0.5f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    add(%2451, %2452) /* ty=Tensor[(?), float32] */
  };
  %2454 = (%in_shape_068, %in_shape_138);
  %2455 = (%shape_func_out_077,);
  let %shape_func77: () = vm.shape_func(%2453, %2454, %2455, meta[relay.attrs.ShapeFuncAttrs][77]) /* ty=() */;
  let %storage_0549: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][560]) /* ty=Storage[] */;
  let %tensor_0476: int64 = memory.alloc_tensor(%storage_0549, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][560]) /* ty=int64 */;
  %2456 = fn (%p0475: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0475) /* ty=int64 */
  };
  %2457 = (%shape_func_out_077,);
  %2458 = (%tensor_0476,);
  let %v471: () = vm.invoke_tvm_op(%2456, %2457, %2458) /* ty=() */;
  let %storage_0550: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][561]) /* ty=Storage[] */;
  let %tensor_0477: int64 = memory.alloc_tensor(%storage_0550, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][561]) /* ty=int64 */;
  %2459 = fn (%p0476: int64, Primitive=1) -> int64 {
    multiply(%p0476, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2460 = (%tensor_0476,);
  %2461 = (%tensor_0477,);
  let %v472: () = vm.invoke_tvm_op(%2459, %2460, %2461) /* ty=() */;
  let %storage_0551: Storage[] = memory.alloc_storage(%tensor_0477, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][562]) /* ty=Storage[] */;
  let %out_073: Tensor[(?), float32] = memory.alloc_tensor(%storage_0551, 0 /* ty=int64 */, %shape_func_out_077, meta[relay.attrs.AllocTensorAttrs][562]) /* ty=Tensor[(?), float32] */;
  %2462 = (%x439, %x433);
  %2463 = (%out_073,);
  let %v473: () = vm.invoke_tvm_op(%2453, %2462, %2463) /* ty=() */;
  let %x440: Tensor[(?), float32] = %out_073;
  let %storage_0552: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][563]) /* ty=Storage[] */;
  let %tensor_0478: Tensor[(1), int32] = memory.alloc_tensor(%storage_0552, 0 /* ty=int64 */, meta[relay.Constant][532] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][563]) /* ty=Tensor[(1), int32] */;
  %2464 = fn (%p0477: Tensor[(?), float32], Primitive=1) -> Tensor[(1), int32] {
    shape_of(%p0477, dtype="int32") /* ty=Tensor[(1), int32] */
  };
  %2465 = (%x440,);
  %2466 = (%tensor_0478,);
  let %v474: () = vm.invoke_tvm_op(%2464, %2465, %2466) /* ty=() */;
  let %x441: Tensor[(1), int32] = %tensor_0478;
  let %storage_0553: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][564]) /* ty=Storage[] */;
  let %tensor_0479: Tensor[(1), int32] = memory.alloc_tensor(%storage_0553, 0 /* ty=int64 */, meta[relay.Constant][533] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][564]) /* ty=Tensor[(1), int32] */;
  %2469 = fn (%p0478: Tensor[(1), bool], %p1255: Tensor[(1), int32], %p2128: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
    %2467 = cast_like(%p2128, %p1255) /* ty=Tensor[(1), int32] */;
    %2468 = add(%p1255, %2467) /* ty=Tensor[(1), int32] */;
    where(%p0478, %2468, %p1255) /* ty=Tensor[(1), int32] */
  };
  %2470 = (meta[relay.Constant][534] /* ty=Tensor[(1), bool] */, meta[relay.Constant][535] /* ty=Tensor[(1), int32] */, %x441);
  %2471 = (%tensor_0479,);
  let %v475: () = vm.invoke_tvm_op(%2469, %2470, %2471) /* ty=() */;
  let %x442: Tensor[(1), int32] = %tensor_0479;
  let %storage_0554: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][565]) /* ty=Storage[] */;
  let %tensor_0480: Tensor[(1), int64] = memory.alloc_tensor(%storage_0554, 0 /* ty=int64 */, meta[relay.Constant][536] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][565]) /* ty=Tensor[(1), int64] */;
  %2472 = fn (%p0479: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int64] {
    cast(%p0479, dtype="int64") /* ty=Tensor[(1), int64] */
  };
  %2473 = (%x441,);
  %2474 = (%tensor_0480,);
  let %v476: () = vm.invoke_tvm_op(%2472, %2473, %2474) /* ty=() */;
  let %x443: Tensor[(1), int64] = %tensor_0480;
  let %in_shape_069: Tensor[(?), float32] = device_copy(%x440, meta[relay.attrs.DeviceCopyAttrs][81]) /* ty=Tensor[(?), float32] */;
  let %in_shape_139: Tensor[(1), int32] = device_copy(%x442, meta[relay.attrs.DeviceCopyAttrs][82]) /* ty=Tensor[(1), int32] */;
  let %in_shape_224: Tensor[(1), int64] = device_copy(%x443, meta[relay.attrs.DeviceCopyAttrs][83]) /* ty=Tensor[(1), int64] */;
  let %in_shape_320: Tensor[(1), int32] = device_copy(meta[relay.Constant][537] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][84]) /* ty=Tensor[(1), int32] */;
  let %storage_0555: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][566]) /* ty=Storage[] */;
  let %tensor_0481: Tensor[(1), int64] = memory.alloc_tensor(%storage_0555, 0 /* ty=int64 */, meta[relay.Constant][538] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][566]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_078: Tensor[(1), int64] = %tensor_0481;
  %2475 = fn (%p0480: Tensor[(?), float32], %p1256: Tensor[(1), int32], %p2129: Tensor[(1), int64], %p380: Tensor[(1), int32], Primitive=1) -> Tensor[(?), float32] {
    dyn.strided_slice(%p0480, %p1256, %p2129, %p380, begin=None, end=None, strides=None) /* ty=Tensor[(?), float32] */
  };
  %2476 = (%in_shape_069, %in_shape_139, %in_shape_224, %in_shape_320);
  %2477 = (%shape_func_out_078,);
  let %shape_func78: () = vm.shape_func(%2475, %2476, %2477, meta[relay.attrs.ShapeFuncAttrs][78]) /* ty=() */;
  let %storage_0556: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][567]) /* ty=Storage[] */;
  let %tensor_0482: int64 = memory.alloc_tensor(%storage_0556, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][567]) /* ty=int64 */;
  %2478 = fn (%p0481: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0481) /* ty=int64 */
  };
  %2479 = (%shape_func_out_078,);
  %2480 = (%tensor_0482,);
  let %v477: () = vm.invoke_tvm_op(%2478, %2479, %2480) /* ty=() */;
  let %storage_0557: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][568]) /* ty=Storage[] */;
  let %tensor_0483: int64 = memory.alloc_tensor(%storage_0557, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][568]) /* ty=int64 */;
  %2481 = fn (%p0482: int64, Primitive=1) -> int64 {
    multiply(%p0482, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2482 = (%tensor_0482,);
  %2483 = (%tensor_0483,);
  let %v478: () = vm.invoke_tvm_op(%2481, %2482, %2483) /* ty=() */;
  let %storage_0558: Storage[] = memory.alloc_storage(%tensor_0483, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][569]) /* ty=Storage[] */;
  let %out_074: Tensor[(?), float32] = memory.alloc_tensor(%storage_0558, 0 /* ty=int64 */, %shape_func_out_078, meta[relay.attrs.AllocTensorAttrs][569]) /* ty=Tensor[(?), float32] */;
  %2484 = (%x440, %x442, %x443, meta[relay.Constant][537] /* ty=Tensor[(1), int32] */);
  %2485 = (%out_074,);
  let %v479: () = vm.invoke_tvm_op(%2475, %2484, %2485) /* ty=() */;
  let %x444: Tensor[(?), float32] = %out_074;
  let %storage_0559: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][570]) /* ty=Storage[] */;
  let %tensor_0484: Tensor[(2), int32] = memory.alloc_tensor(%storage_0559, 0 /* ty=int64 */, meta[relay.Constant][539] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][570]) /* ty=Tensor[(2), int32] */;
  %2488 = fn (%p0483: Tensor[(2), bool], %p1257: Tensor[(2), int32], %p2130: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2486 = cast_like(%p2130, %p1257) /* ty=Tensor[(2), int32] */;
    %2487 = add(%p1257, %2486) /* ty=Tensor[(2), int32] */;
    where(%p0483, %2487, %p1257) /* ty=Tensor[(2), int32] */
  };
  %2489 = (meta[relay.Constant][540] /* ty=Tensor[(2), bool] */, meta[relay.Constant][541] /* ty=Tensor[(2), int32] */, %x418);
  %2490 = (%tensor_0484,);
  let %v480: () = vm.invoke_tvm_op(%2488, %2489, %2490) /* ty=() */;
  let %x445: Tensor[(2), int32] = %tensor_0484;
  let %in_shape_070: Tensor[(?, ?), float32] = device_copy(%x417, meta[relay.attrs.DeviceCopyAttrs][85]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_140: Tensor[(2), int32] = device_copy(%x445, meta[relay.attrs.DeviceCopyAttrs][86]) /* ty=Tensor[(2), int32] */;
  let %in_shape_225: Tensor[(2), int64] = device_copy(%x420, meta[relay.attrs.DeviceCopyAttrs][87]) /* ty=Tensor[(2), int64] */;
  let %in_shape_321: Tensor[(2), int32] = device_copy(meta[relay.Constant][542] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][88]) /* ty=Tensor[(2), int32] */;
  let %storage_0560: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][571]) /* ty=Storage[] */;
  let %tensor_0485: Tensor[(2), int64] = memory.alloc_tensor(%storage_0560, 0 /* ty=int64 */, meta[relay.Constant][543] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][571]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_079: Tensor[(2), int64] = %tensor_0485;
  %2491 = fn (%p0484: Tensor[(?, ?), float32], %p1258: Tensor[(2), int32], %p2131: Tensor[(2), int64], %p381: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0484, %p1258, %p2131, %p381, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2492 = (%in_shape_070, %in_shape_140, %in_shape_225, %in_shape_321);
  %2493 = (%shape_func_out_079,);
  let %shape_func79: () = vm.shape_func(%2491, %2492, %2493, meta[relay.attrs.ShapeFuncAttrs][79]) /* ty=() */;
  let %storage_0561: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][572]) /* ty=Storage[] */;
  let %tensor_0486: int64 = memory.alloc_tensor(%storage_0561, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][572]) /* ty=int64 */;
  %2494 = fn (%p0485: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0485) /* ty=int64 */
  };
  %2495 = (%shape_func_out_079,);
  %2496 = (%tensor_0486,);
  let %v481: () = vm.invoke_tvm_op(%2494, %2495, %2496) /* ty=() */;
  let %storage_0562: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][573]) /* ty=Storage[] */;
  let %tensor_0487: int64 = memory.alloc_tensor(%storage_0562, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][573]) /* ty=int64 */;
  %2497 = fn (%p0486: int64, Primitive=1) -> int64 {
    multiply(%p0486, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2498 = (%tensor_0486,);
  %2499 = (%tensor_0487,);
  let %v482: () = vm.invoke_tvm_op(%2497, %2498, %2499) /* ty=() */;
  let %storage_0563: Storage[] = memory.alloc_storage(%tensor_0487, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][574]) /* ty=Storage[] */;
  let %out_075: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0563, 0 /* ty=int64 */, %shape_func_out_079, meta[relay.attrs.AllocTensorAttrs][574]) /* ty=Tensor[(?, ?), float32] */;
  %2500 = (%x417, %x445, %x420, meta[relay.Constant][542] /* ty=Tensor[(2), int32] */);
  %2501 = (%out_075,);
  let %v483: () = vm.invoke_tvm_op(%2491, %2500, %2501) /* ty=() */;
  let %x446: Tensor[(?, ?), float32] = %out_075;
  let %storage_0564: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][575]) /* ty=Storage[] */;
  let %tensor_0488: Tensor[(2), int32] = memory.alloc_tensor(%storage_0564, 0 /* ty=int64 */, meta[relay.Constant][544] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][575]) /* ty=Tensor[(2), int32] */;
  %2502 = fn (%p0487: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0487, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2503 = (%x446,);
  %2504 = (%tensor_0488,);
  let %v484: () = vm.invoke_tvm_op(%2502, %2503, %2504) /* ty=() */;
  let %x447: Tensor[(2), int32] = %tensor_0488;
  let %storage_0565: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][576]) /* ty=Storage[] */;
  let %tensor_0489: Tensor[(2), int32] = memory.alloc_tensor(%storage_0565, 0 /* ty=int64 */, meta[relay.Constant][545] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][576]) /* ty=Tensor[(2), int32] */;
  %2507 = fn (%p0488: Tensor[(2), bool], %p1259: Tensor[(2), int32], %p2132: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2505 = cast_like(%p2132, %p1259) /* ty=Tensor[(2), int32] */;
    %2506 = add(%p1259, %2505) /* ty=Tensor[(2), int32] */;
    where(%p0488, %2506, %p1259) /* ty=Tensor[(2), int32] */
  };
  %2508 = (meta[relay.Constant][546] /* ty=Tensor[(2), bool] */, meta[relay.Constant][547] /* ty=Tensor[(2), int32] */, %x447);
  %2509 = (%tensor_0489,);
  let %v485: () = vm.invoke_tvm_op(%2507, %2508, %2509) /* ty=() */;
  let %x448: Tensor[(2), int32] = %tensor_0489;
  let %storage_0566: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][577]) /* ty=Storage[] */;
  let %tensor_0490: Tensor[(2), int64] = memory.alloc_tensor(%storage_0566, 0 /* ty=int64 */, meta[relay.Constant][548] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][577]) /* ty=Tensor[(2), int64] */;
  %2510 = fn (%p0489: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0489, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2511 = (%x447,);
  %2512 = (%tensor_0490,);
  let %v486: () = vm.invoke_tvm_op(%2510, %2511, %2512) /* ty=() */;
  let %x449: Tensor[(2), int64] = %tensor_0490;
  let %in_shape_071: Tensor[(?, ?), float32] = device_copy(%x446, meta[relay.attrs.DeviceCopyAttrs][89]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_141: Tensor[(2), int32] = device_copy(%x448, meta[relay.attrs.DeviceCopyAttrs][90]) /* ty=Tensor[(2), int32] */;
  let %in_shape_226: Tensor[(2), int64] = device_copy(%x449, meta[relay.attrs.DeviceCopyAttrs][91]) /* ty=Tensor[(2), int64] */;
  let %in_shape_322: Tensor[(2), int32] = device_copy(meta[relay.Constant][549] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][92]) /* ty=Tensor[(2), int32] */;
  let %storage_0567: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][578]) /* ty=Storage[] */;
  let %tensor_0491: Tensor[(2), int64] = memory.alloc_tensor(%storage_0567, 0 /* ty=int64 */, meta[relay.Constant][550] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][578]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_080: Tensor[(2), int64] = %tensor_0491;
  %2513 = fn (%p0490: Tensor[(?, ?), float32], %p1260: Tensor[(2), int32], %p2133: Tensor[(2), int64], %p382: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0490, %p1260, %p2133, %p382, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2514 = (%in_shape_071, %in_shape_141, %in_shape_226, %in_shape_322);
  %2515 = (%shape_func_out_080,);
  let %shape_func80: () = vm.shape_func(%2513, %2514, %2515, meta[relay.attrs.ShapeFuncAttrs][80]) /* ty=() */;
  let %storage_0568: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][579]) /* ty=Storage[] */;
  let %tensor_0492: int64 = memory.alloc_tensor(%storage_0568, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][579]) /* ty=int64 */;
  %2516 = fn (%p0491: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0491) /* ty=int64 */
  };
  %2517 = (%shape_func_out_080,);
  %2518 = (%tensor_0492,);
  let %v487: () = vm.invoke_tvm_op(%2516, %2517, %2518) /* ty=() */;
  let %storage_0569: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][580]) /* ty=Storage[] */;
  let %tensor_0493: int64 = memory.alloc_tensor(%storage_0569, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][580]) /* ty=int64 */;
  %2519 = fn (%p0492: int64, Primitive=1) -> int64 {
    multiply(%p0492, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2520 = (%tensor_0492,);
  %2521 = (%tensor_0493,);
  let %v488: () = vm.invoke_tvm_op(%2519, %2520, %2521) /* ty=() */;
  let %storage_0570: Storage[] = memory.alloc_storage(%tensor_0493, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][581]) /* ty=Storage[] */;
  let %out_076: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0570, 0 /* ty=int64 */, %shape_func_out_080, meta[relay.attrs.AllocTensorAttrs][581]) /* ty=Tensor[(?, ?), float32] */;
  %2522 = (%x446, %x448, %x449, meta[relay.Constant][549] /* ty=Tensor[(2), int32] */);
  %2523 = (%out_076,);
  let %v489: () = vm.invoke_tvm_op(%2513, %2522, %2523) /* ty=() */;
  let %x450: Tensor[(?, ?), float32] = %out_076;
  let %storage_0571: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][582]) /* ty=Storage[] */;
  let %tensor_0494: Tensor[(1), int32] = memory.alloc_tensor(%storage_0571, 0 /* ty=int64 */, meta[relay.Constant][551] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][582]) /* ty=Tensor[(1), int32] */;
  %2526 = fn (%p0493: Tensor[(1), bool], %p1261: Tensor[(1), int32], %p2134: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
    %2524 = cast_like(%p2134, %p1261) /* ty=Tensor[(1), int32] */;
    %2525 = add(%p1261, %2524) /* ty=Tensor[(1), int32] */;
    where(%p0493, %2525, %p1261) /* ty=Tensor[(1), int32] */
  };
  %2527 = (meta[relay.Constant][552] /* ty=Tensor[(1), bool] */, meta[relay.Constant][553] /* ty=Tensor[(1), int32] */, %x434);
  %2528 = (%tensor_0494,);
  let %v490: () = vm.invoke_tvm_op(%2526, %2527, %2528) /* ty=() */;
  let %x451: Tensor[(1), int32] = %tensor_0494;
  let %in_shape_072: Tensor[(?), float32] = device_copy(%x433, meta[relay.attrs.DeviceCopyAttrs][93]) /* ty=Tensor[(?), float32] */;
  let %in_shape_142: Tensor[(1), int32] = device_copy(%x451, meta[relay.attrs.DeviceCopyAttrs][94]) /* ty=Tensor[(1), int32] */;
  let %in_shape_227: Tensor[(1), int64] = device_copy(%x436, meta[relay.attrs.DeviceCopyAttrs][95]) /* ty=Tensor[(1), int64] */;
  let %in_shape_323: Tensor[(1), int32] = device_copy(meta[relay.Constant][554] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][96]) /* ty=Tensor[(1), int32] */;
  let %storage_0572: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][583]) /* ty=Storage[] */;
  let %tensor_0495: Tensor[(1), int64] = memory.alloc_tensor(%storage_0572, 0 /* ty=int64 */, meta[relay.Constant][555] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][583]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_081: Tensor[(1), int64] = %tensor_0495;
  %2529 = fn (%p0494: Tensor[(?), float32], %p1262: Tensor[(1), int32], %p2135: Tensor[(1), int64], %p383: Tensor[(1), int32], Primitive=1) -> Tensor[(?), float32] {
    dyn.strided_slice(%p0494, %p1262, %p2135, %p383, begin=None, end=None, strides=None) /* ty=Tensor[(?), float32] */
  };
  %2530 = (%in_shape_072, %in_shape_142, %in_shape_227, %in_shape_323);
  %2531 = (%shape_func_out_081,);
  let %shape_func81: () = vm.shape_func(%2529, %2530, %2531, meta[relay.attrs.ShapeFuncAttrs][81]) /* ty=() */;
  let %storage_0573: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][584]) /* ty=Storage[] */;
  let %tensor_0496: int64 = memory.alloc_tensor(%storage_0573, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][584]) /* ty=int64 */;
  %2532 = fn (%p0495: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0495) /* ty=int64 */
  };
  %2533 = (%shape_func_out_081,);
  %2534 = (%tensor_0496,);
  let %v491: () = vm.invoke_tvm_op(%2532, %2533, %2534) /* ty=() */;
  let %storage_0574: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][585]) /* ty=Storage[] */;
  let %tensor_0497: int64 = memory.alloc_tensor(%storage_0574, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][585]) /* ty=int64 */;
  %2535 = fn (%p0496: int64, Primitive=1) -> int64 {
    multiply(%p0496, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2536 = (%tensor_0496,);
  %2537 = (%tensor_0497,);
  let %v492: () = vm.invoke_tvm_op(%2535, %2536, %2537) /* ty=() */;
  let %storage_0575: Storage[] = memory.alloc_storage(%tensor_0497, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][586]) /* ty=Storage[] */;
  let %out_077: Tensor[(?), float32] = memory.alloc_tensor(%storage_0575, 0 /* ty=int64 */, %shape_func_out_081, meta[relay.attrs.AllocTensorAttrs][586]) /* ty=Tensor[(?), float32] */;
  %2538 = (%x433, %x451, %x436, meta[relay.Constant][554] /* ty=Tensor[(1), int32] */);
  %2539 = (%out_077,);
  let %v493: () = vm.invoke_tvm_op(%2529, %2538, %2539) /* ty=() */;
  let %x452: Tensor[(?), float32] = %out_077;
  let %storage_0576: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][587]) /* ty=Storage[] */;
  let %tensor_0498: Tensor[(2), int32] = memory.alloc_tensor(%storage_0576, 0 /* ty=int64 */, meta[relay.Constant][556] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][587]) /* ty=Tensor[(2), int32] */;
  %2542 = fn (%p0497: Tensor[(2), bool], %p1263: Tensor[(2), int32], %p2136: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2540 = cast_like(%p2136, %p1263) /* ty=Tensor[(2), int32] */;
    %2541 = add(%p1263, %2540) /* ty=Tensor[(2), int32] */;
    where(%p0497, %2541, %p1263) /* ty=Tensor[(2), int32] */
  };
  %2543 = (meta[relay.Constant][557] /* ty=Tensor[(2), bool] */, meta[relay.Constant][558] /* ty=Tensor[(2), int32] */, %x418);
  %2544 = (%tensor_0498,);
  let %v494: () = vm.invoke_tvm_op(%2542, %2543, %2544) /* ty=() */;
  let %x453: Tensor[(2), int32] = %tensor_0498;
  let %in_shape_073: Tensor[(?, ?), float32] = device_copy(%x417, meta[relay.attrs.DeviceCopyAttrs][97]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_143: Tensor[(2), int32] = device_copy(%x453, meta[relay.attrs.DeviceCopyAttrs][98]) /* ty=Tensor[(2), int32] */;
  let %in_shape_228: Tensor[(2), int64] = device_copy(%x420, meta[relay.attrs.DeviceCopyAttrs][99]) /* ty=Tensor[(2), int64] */;
  let %in_shape_324: Tensor[(2), int32] = device_copy(meta[relay.Constant][559] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][100]) /* ty=Tensor[(2), int32] */;
  let %storage_0577: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][588]) /* ty=Storage[] */;
  let %tensor_0499: Tensor[(2), int64] = memory.alloc_tensor(%storage_0577, 0 /* ty=int64 */, meta[relay.Constant][560] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][588]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_082: Tensor[(2), int64] = %tensor_0499;
  %2545 = fn (%p0498: Tensor[(?, ?), float32], %p1264: Tensor[(2), int32], %p2137: Tensor[(2), int64], %p384: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0498, %p1264, %p2137, %p384, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2546 = (%in_shape_073, %in_shape_143, %in_shape_228, %in_shape_324);
  %2547 = (%shape_func_out_082,);
  let %shape_func82: () = vm.shape_func(%2545, %2546, %2547, meta[relay.attrs.ShapeFuncAttrs][82]) /* ty=() */;
  let %storage_0578: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][589]) /* ty=Storage[] */;
  let %tensor_0500: int64 = memory.alloc_tensor(%storage_0578, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][589]) /* ty=int64 */;
  %2548 = fn (%p0499: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0499) /* ty=int64 */
  };
  %2549 = (%shape_func_out_082,);
  %2550 = (%tensor_0500,);
  let %v495: () = vm.invoke_tvm_op(%2548, %2549, %2550) /* ty=() */;
  let %storage_0579: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][590]) /* ty=Storage[] */;
  let %tensor_0501: int64 = memory.alloc_tensor(%storage_0579, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][590]) /* ty=int64 */;
  %2551 = fn (%p0500: int64, Primitive=1) -> int64 {
    multiply(%p0500, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2552 = (%tensor_0500,);
  %2553 = (%tensor_0501,);
  let %v496: () = vm.invoke_tvm_op(%2551, %2552, %2553) /* ty=() */;
  let %storage_0580: Storage[] = memory.alloc_storage(%tensor_0501, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][591]) /* ty=Storage[] */;
  let %out_078: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0580, 0 /* ty=int64 */, %shape_func_out_082, meta[relay.attrs.AllocTensorAttrs][591]) /* ty=Tensor[(?, ?), float32] */;
  %2554 = (%x417, %x453, %x420, meta[relay.Constant][559] /* ty=Tensor[(2), int32] */);
  %2555 = (%out_078,);
  let %v497: () = vm.invoke_tvm_op(%2545, %2554, %2555) /* ty=() */;
  let %x454: Tensor[(?, ?), float32] = %out_078;
  let %storage_0581: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][592]) /* ty=Storage[] */;
  let %tensor_0502: Tensor[(2), int32] = memory.alloc_tensor(%storage_0581, 0 /* ty=int64 */, meta[relay.Constant][561] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][592]) /* ty=Tensor[(2), int32] */;
  %2556 = fn (%p0501: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0501, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2557 = (%x454,);
  %2558 = (%tensor_0502,);
  let %v498: () = vm.invoke_tvm_op(%2556, %2557, %2558) /* ty=() */;
  let %x455: Tensor[(2), int32] = %tensor_0502;
  let %storage_0582: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][593]) /* ty=Storage[] */;
  let %tensor_0503: Tensor[(2), int32] = memory.alloc_tensor(%storage_0582, 0 /* ty=int64 */, meta[relay.Constant][562] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][593]) /* ty=Tensor[(2), int32] */;
  %2561 = fn (%p0502: Tensor[(2), bool], %p1265: Tensor[(2), int32], %p2138: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2559 = cast_like(%p2138, %p1265) /* ty=Tensor[(2), int32] */;
    %2560 = add(%p1265, %2559) /* ty=Tensor[(2), int32] */;
    where(%p0502, %2560, %p1265) /* ty=Tensor[(2), int32] */
  };
  %2562 = (meta[relay.Constant][563] /* ty=Tensor[(2), bool] */, meta[relay.Constant][564] /* ty=Tensor[(2), int32] */, %x455);
  %2563 = (%tensor_0503,);
  let %v499: () = vm.invoke_tvm_op(%2561, %2562, %2563) /* ty=() */;
  let %x456: Tensor[(2), int32] = %tensor_0503;
  let %storage_0583: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][594]) /* ty=Storage[] */;
  let %tensor_0504: Tensor[(2), int64] = memory.alloc_tensor(%storage_0583, 0 /* ty=int64 */, meta[relay.Constant][565] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][594]) /* ty=Tensor[(2), int64] */;
  %2564 = fn (%p0503: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0503, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2565 = (%x455,);
  %2566 = (%tensor_0504,);
  let %v500: () = vm.invoke_tvm_op(%2564, %2565, %2566) /* ty=() */;
  let %x457: Tensor[(2), int64] = %tensor_0504;
  let %in_shape_074: Tensor[(?, ?), float32] = device_copy(%x454, meta[relay.attrs.DeviceCopyAttrs][101]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_144: Tensor[(2), int32] = device_copy(%x456, meta[relay.attrs.DeviceCopyAttrs][102]) /* ty=Tensor[(2), int32] */;
  let %in_shape_229: Tensor[(2), int64] = device_copy(%x457, meta[relay.attrs.DeviceCopyAttrs][103]) /* ty=Tensor[(2), int64] */;
  let %in_shape_325: Tensor[(2), int32] = device_copy(meta[relay.Constant][566] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][104]) /* ty=Tensor[(2), int32] */;
  let %storage_0584: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][595]) /* ty=Storage[] */;
  let %tensor_0505: Tensor[(2), int64] = memory.alloc_tensor(%storage_0584, 0 /* ty=int64 */, meta[relay.Constant][567] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][595]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_083: Tensor[(2), int64] = %tensor_0505;
  %2567 = fn (%p0504: Tensor[(?, ?), float32], %p1266: Tensor[(2), int32], %p2139: Tensor[(2), int64], %p385: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0504, %p1266, %p2139, %p385, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2568 = (%in_shape_074, %in_shape_144, %in_shape_229, %in_shape_325);
  %2569 = (%shape_func_out_083,);
  let %shape_func83: () = vm.shape_func(%2567, %2568, %2569, meta[relay.attrs.ShapeFuncAttrs][83]) /* ty=() */;
  let %storage_0585: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][596]) /* ty=Storage[] */;
  let %tensor_0506: int64 = memory.alloc_tensor(%storage_0585, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][596]) /* ty=int64 */;
  %2570 = fn (%p0505: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0505) /* ty=int64 */
  };
  %2571 = (%shape_func_out_083,);
  %2572 = (%tensor_0506,);
  let %v501: () = vm.invoke_tvm_op(%2570, %2571, %2572) /* ty=() */;
  let %storage_0586: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][597]) /* ty=Storage[] */;
  let %tensor_0507: int64 = memory.alloc_tensor(%storage_0586, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][597]) /* ty=int64 */;
  %2573 = fn (%p0506: int64, Primitive=1) -> int64 {
    multiply(%p0506, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2574 = (%tensor_0506,);
  %2575 = (%tensor_0507,);
  let %v502: () = vm.invoke_tvm_op(%2573, %2574, %2575) /* ty=() */;
  let %storage_0587: Storage[] = memory.alloc_storage(%tensor_0507, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][598]) /* ty=Storage[] */;
  let %out_079: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0587, 0 /* ty=int64 */, %shape_func_out_083, meta[relay.attrs.AllocTensorAttrs][598]) /* ty=Tensor[(?, ?), float32] */;
  %2576 = (%x454, %x456, %x457, meta[relay.Constant][566] /* ty=Tensor[(2), int32] */);
  %2577 = (%out_079,);
  let %v503: () = vm.invoke_tvm_op(%2567, %2576, %2577) /* ty=() */;
  let %x458: Tensor[(?, ?), float32] = %out_079;
  let %storage_0588: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][599]) /* ty=Storage[] */;
  let %tensor_0508: Tensor[(2), int32] = memory.alloc_tensor(%storage_0588, 0 /* ty=int64 */, meta[relay.Constant][568] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][599]) /* ty=Tensor[(2), int32] */;
  %2580 = fn (%p0507: Tensor[(2), bool], %p1267: Tensor[(2), int32], %p2140: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2578 = cast_like(%p2140, %p1267) /* ty=Tensor[(2), int32] */;
    %2579 = add(%p1267, %2578) /* ty=Tensor[(2), int32] */;
    where(%p0507, %2579, %p1267) /* ty=Tensor[(2), int32] */
  };
  %2581 = (meta[relay.Constant][569] /* ty=Tensor[(2), bool] */, meta[relay.Constant][570] /* ty=Tensor[(2), int32] */, %x427);
  %2582 = (%tensor_0508,);
  let %v504: () = vm.invoke_tvm_op(%2580, %2581, %2582) /* ty=() */;
  let %x459: Tensor[(2), int32] = %tensor_0508;
  let %in_shape_075: Tensor[(?, 4), float32] = device_copy(%x426, meta[relay.attrs.DeviceCopyAttrs][105]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_145: Tensor[(2), int32] = device_copy(%x459, meta[relay.attrs.DeviceCopyAttrs][106]) /* ty=Tensor[(2), int32] */;
  let %in_shape_230: Tensor[(2), int64] = device_copy(%x429, meta[relay.attrs.DeviceCopyAttrs][107]) /* ty=Tensor[(2), int64] */;
  let %in_shape_326: Tensor[(2), int32] = device_copy(meta[relay.Constant][571] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][108]) /* ty=Tensor[(2), int32] */;
  let %storage_0589: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][600]) /* ty=Storage[] */;
  let %tensor_0509: Tensor[(2), int64] = memory.alloc_tensor(%storage_0589, 0 /* ty=int64 */, meta[relay.Constant][572] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][600]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_084: Tensor[(2), int64] = %tensor_0509;
  %2583 = fn (%p0508: Tensor[(?, 4), float32], %p1268: Tensor[(2), int32], %p2141: Tensor[(2), int64], %p386: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0508, %p1268, %p2141, %p386, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2584 = (%in_shape_075, %in_shape_145, %in_shape_230, %in_shape_326);
  %2585 = (%shape_func_out_084,);
  let %shape_func84: () = vm.shape_func(%2583, %2584, %2585, meta[relay.attrs.ShapeFuncAttrs][84]) /* ty=() */;
  let %storage_0590: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][601]) /* ty=Storage[] */;
  let %tensor_0510: int64 = memory.alloc_tensor(%storage_0590, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][601]) /* ty=int64 */;
  %2586 = fn (%p0509: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0509) /* ty=int64 */
  };
  %2587 = (%shape_func_out_084,);
  %2588 = (%tensor_0510,);
  let %v505: () = vm.invoke_tvm_op(%2586, %2587, %2588) /* ty=() */;
  let %storage_0591: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][602]) /* ty=Storage[] */;
  let %tensor_0511: int64 = memory.alloc_tensor(%storage_0591, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][602]) /* ty=int64 */;
  %2589 = fn (%p0510: int64, Primitive=1) -> int64 {
    multiply(%p0510, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2590 = (%tensor_0510,);
  %2591 = (%tensor_0511,);
  let %v506: () = vm.invoke_tvm_op(%2589, %2590, %2591) /* ty=() */;
  let %storage_0592: Storage[] = memory.alloc_storage(%tensor_0511, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][603]) /* ty=Storage[] */;
  let %out_080: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0592, 0 /* ty=int64 */, %shape_func_out_084, meta[relay.attrs.AllocTensorAttrs][603]) /* ty=Tensor[(?, ?), float32] */;
  %2592 = (%x426, %x459, %x429, meta[relay.Constant][571] /* ty=Tensor[(2), int32] */);
  %2593 = (%out_080,);
  let %v507: () = vm.invoke_tvm_op(%2583, %2592, %2593) /* ty=() */;
  let %x460: Tensor[(?, ?), float32] = %out_080;
  let %storage_0593: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][604]) /* ty=Storage[] */;
  let %tensor_0512: Tensor[(2), int32] = memory.alloc_tensor(%storage_0593, 0 /* ty=int64 */, meta[relay.Constant][573] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][604]) /* ty=Tensor[(2), int32] */;
  %2596 = fn (%p0511: Tensor[(2), bool], %p1269: Tensor[(2), int32], %p2142: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2594 = cast_like(%p2142, %p1269) /* ty=Tensor[(2), int32] */;
    %2595 = add(%p1269, %2594) /* ty=Tensor[(2), int32] */;
    where(%p0511, %2595, %p1269) /* ty=Tensor[(2), int32] */
  };
  %2597 = (meta[relay.Constant][574] /* ty=Tensor[(2), bool] */, meta[relay.Constant][575] /* ty=Tensor[(2), int32] */, %x427);
  %2598 = (%tensor_0512,);
  let %v508: () = vm.invoke_tvm_op(%2596, %2597, %2598) /* ty=() */;
  let %x461: Tensor[(2), int32] = %tensor_0512;
  let %in_shape_076: Tensor[(?, 4), float32] = device_copy(%x426, meta[relay.attrs.DeviceCopyAttrs][109]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_146: Tensor[(2), int32] = device_copy(%x461, meta[relay.attrs.DeviceCopyAttrs][110]) /* ty=Tensor[(2), int32] */;
  let %in_shape_231: Tensor[(2), int64] = device_copy(%x429, meta[relay.attrs.DeviceCopyAttrs][111]) /* ty=Tensor[(2), int64] */;
  let %in_shape_327: Tensor[(2), int32] = device_copy(meta[relay.Constant][576] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][112]) /* ty=Tensor[(2), int32] */;
  let %storage_0594: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][605]) /* ty=Storage[] */;
  let %tensor_0513: Tensor[(2), int64] = memory.alloc_tensor(%storage_0594, 0 /* ty=int64 */, meta[relay.Constant][577] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][605]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_085: Tensor[(2), int64] = %tensor_0513;
  %2599 = fn (%p0512: Tensor[(?, 4), float32], %p1270: Tensor[(2), int32], %p2143: Tensor[(2), int64], %p387: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0512, %p1270, %p2143, %p387, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2600 = (%in_shape_076, %in_shape_146, %in_shape_231, %in_shape_327);
  %2601 = (%shape_func_out_085,);
  let %shape_func85: () = vm.shape_func(%2599, %2600, %2601, meta[relay.attrs.ShapeFuncAttrs][85]) /* ty=() */;
  let %storage_0595: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][606]) /* ty=Storage[] */;
  let %tensor_0514: int64 = memory.alloc_tensor(%storage_0595, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][606]) /* ty=int64 */;
  %2602 = fn (%p0513: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0513) /* ty=int64 */
  };
  %2603 = (%shape_func_out_085,);
  %2604 = (%tensor_0514,);
  let %v509: () = vm.invoke_tvm_op(%2602, %2603, %2604) /* ty=() */;
  let %storage_0596: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][607]) /* ty=Storage[] */;
  let %tensor_0515: int64 = memory.alloc_tensor(%storage_0596, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][607]) /* ty=int64 */;
  %2605 = fn (%p0514: int64, Primitive=1) -> int64 {
    multiply(%p0514, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2606 = (%tensor_0514,);
  %2607 = (%tensor_0515,);
  let %v510: () = vm.invoke_tvm_op(%2605, %2606, %2607) /* ty=() */;
  let %storage_0597: Storage[] = memory.alloc_storage(%tensor_0515, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][608]) /* ty=Storage[] */;
  let %out_081: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0597, 0 /* ty=int64 */, %shape_func_out_085, meta[relay.attrs.AllocTensorAttrs][608]) /* ty=Tensor[(?, ?), float32] */;
  %2608 = (%x426, %x461, %x429, meta[relay.Constant][576] /* ty=Tensor[(2), int32] */);
  %2609 = (%out_081,);
  let %v511: () = vm.invoke_tvm_op(%2599, %2608, %2609) /* ty=() */;
  let %x462: Tensor[(?, ?), float32] = %out_081;
  let %in_shape_077: Tensor[(2), int64] = vm.shape_of(%x460, meta[relay.attrs.ShapeOfAttrs][73]) /* ty=Tensor[(2), int64] */;
  let %in_shape_147: Tensor[(2), int64] = vm.shape_of(%x462, meta[relay.attrs.ShapeOfAttrs][74]) /* ty=Tensor[(2), int64] */;
  let %storage_0598: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][609]) /* ty=Storage[] */;
  let %tensor_0516: Tensor[(1), int64] = memory.alloc_tensor(%storage_0598, 0 /* ty=int64 */, meta[relay.Constant][578] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][609]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_086: Tensor[(1), int64] = %tensor_0516;
  %2612 = fn (%p0515: Tensor[(?, ?), float32], %p1271: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?), float32] {
    %2610 = take(%p0515, 3 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %2611 = take(%p1271, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    subtract(%2610, %2611) /* ty=Tensor[(?), float32] */
  };
  %2613 = (%in_shape_077, %in_shape_147);
  %2614 = (%shape_func_out_086,);
  let %shape_func86: () = vm.shape_func(%2612, %2613, %2614, meta[relay.attrs.ShapeFuncAttrs][86]) /* ty=() */;
  let %storage_0599: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][610]) /* ty=Storage[] */;
  let %tensor_0517: int64 = memory.alloc_tensor(%storage_0599, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][610]) /* ty=int64 */;
  %2615 = fn (%p0516: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0516) /* ty=int64 */
  };
  %2616 = (%shape_func_out_086,);
  %2617 = (%tensor_0517,);
  let %v512: () = vm.invoke_tvm_op(%2615, %2616, %2617) /* ty=() */;
  let %storage_0600: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][611]) /* ty=Storage[] */;
  let %tensor_0518: int64 = memory.alloc_tensor(%storage_0600, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][611]) /* ty=int64 */;
  %2618 = fn (%p0517: int64, Primitive=1) -> int64 {
    multiply(%p0517, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2619 = (%tensor_0517,);
  %2620 = (%tensor_0518,);
  let %v513: () = vm.invoke_tvm_op(%2618, %2619, %2620) /* ty=() */;
  let %storage_0601: Storage[] = memory.alloc_storage(%tensor_0518, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][612]) /* ty=Storage[] */;
  let %out_082: Tensor[(?), float32] = memory.alloc_tensor(%storage_0601, 0 /* ty=int64 */, %shape_func_out_086, meta[relay.attrs.AllocTensorAttrs][612]) /* ty=Tensor[(?), float32] */;
  %2621 = (%x460, %x462);
  %2622 = (%out_082,);
  let %v514: () = vm.invoke_tvm_op(%2612, %2621, %2622) /* ty=() */;
  let %x463: Tensor[(?), float32] = %out_082;
  let %storage_0602: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][613]) /* ty=Storage[] */;
  let %tensor_0519: Tensor[(1), int32] = memory.alloc_tensor(%storage_0602, 0 /* ty=int64 */, meta[relay.Constant][579] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][613]) /* ty=Tensor[(1), int32] */;
  %2623 = fn (%p0518: Tensor[(?), float32], Primitive=1) -> Tensor[(1), int32] {
    shape_of(%p0518, dtype="int32") /* ty=Tensor[(1), int32] */
  };
  %2624 = (%x463,);
  %2625 = (%tensor_0519,);
  let %v515: () = vm.invoke_tvm_op(%2623, %2624, %2625) /* ty=() */;
  let %x464: Tensor[(1), int32] = %tensor_0519;
  let %storage_0603: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][614]) /* ty=Storage[] */;
  let %tensor_0520: Tensor[(1), int32] = memory.alloc_tensor(%storage_0603, 0 /* ty=int64 */, meta[relay.Constant][580] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][614]) /* ty=Tensor[(1), int32] */;
  %2628 = fn (%p0519: Tensor[(1), bool], %p1272: Tensor[(1), int32], %p2144: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
    %2626 = cast_like(%p2144, %p1272) /* ty=Tensor[(1), int32] */;
    %2627 = add(%p1272, %2626) /* ty=Tensor[(1), int32] */;
    where(%p0519, %2627, %p1272) /* ty=Tensor[(1), int32] */
  };
  %2629 = (meta[relay.Constant][581] /* ty=Tensor[(1), bool] */, meta[relay.Constant][582] /* ty=Tensor[(1), int32] */, %x464);
  %2630 = (%tensor_0520,);
  let %v516: () = vm.invoke_tvm_op(%2628, %2629, %2630) /* ty=() */;
  let %x465: Tensor[(1), int32] = %tensor_0520;
  let %storage_0604: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][615]) /* ty=Storage[] */;
  let %tensor_0521: Tensor[(1), int64] = memory.alloc_tensor(%storage_0604, 0 /* ty=int64 */, meta[relay.Constant][583] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][615]) /* ty=Tensor[(1), int64] */;
  %2631 = fn (%p0520: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int64] {
    cast(%p0520, dtype="int64") /* ty=Tensor[(1), int64] */
  };
  %2632 = (%x464,);
  %2633 = (%tensor_0521,);
  let %v517: () = vm.invoke_tvm_op(%2631, %2632, %2633) /* ty=() */;
  let %x466: Tensor[(1), int64] = %tensor_0521;
  let %in_shape_078: Tensor[(?), float32] = device_copy(%x463, meta[relay.attrs.DeviceCopyAttrs][113]) /* ty=Tensor[(?), float32] */;
  let %in_shape_148: Tensor[(1), int32] = device_copy(%x465, meta[relay.attrs.DeviceCopyAttrs][114]) /* ty=Tensor[(1), int32] */;
  let %in_shape_232: Tensor[(1), int64] = device_copy(%x466, meta[relay.attrs.DeviceCopyAttrs][115]) /* ty=Tensor[(1), int64] */;
  let %in_shape_328: Tensor[(1), int32] = device_copy(meta[relay.Constant][584] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][116]) /* ty=Tensor[(1), int32] */;
  let %storage_0605: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][616]) /* ty=Storage[] */;
  let %tensor_0522: Tensor[(1), int64] = memory.alloc_tensor(%storage_0605, 0 /* ty=int64 */, meta[relay.Constant][585] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][616]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_087: Tensor[(1), int64] = %tensor_0522;
  %2634 = fn (%p0521: Tensor[(?), float32], %p1273: Tensor[(1), int32], %p2145: Tensor[(1), int64], %p388: Tensor[(1), int32], Primitive=1) -> Tensor[(?), float32] {
    dyn.strided_slice(%p0521, %p1273, %p2145, %p388, begin=None, end=None, strides=None) /* ty=Tensor[(?), float32] */
  };
  %2635 = (%in_shape_078, %in_shape_148, %in_shape_232, %in_shape_328);
  %2636 = (%shape_func_out_087,);
  let %shape_func87: () = vm.shape_func(%2634, %2635, %2636, meta[relay.attrs.ShapeFuncAttrs][87]) /* ty=() */;
  let %storage_0606: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][617]) /* ty=Storage[] */;
  let %tensor_0523: int64 = memory.alloc_tensor(%storage_0606, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][617]) /* ty=int64 */;
  %2637 = fn (%p0522: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0522) /* ty=int64 */
  };
  %2638 = (%shape_func_out_087,);
  %2639 = (%tensor_0523,);
  let %v518: () = vm.invoke_tvm_op(%2637, %2638, %2639) /* ty=() */;
  let %storage_0607: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][618]) /* ty=Storage[] */;
  let %tensor_0524: int64 = memory.alloc_tensor(%storage_0607, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][618]) /* ty=int64 */;
  %2640 = fn (%p0523: int64, Primitive=1) -> int64 {
    multiply(%p0523, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2641 = (%tensor_0523,);
  %2642 = (%tensor_0524,);
  let %v519: () = vm.invoke_tvm_op(%2640, %2641, %2642) /* ty=() */;
  let %storage_0608: Storage[] = memory.alloc_storage(%tensor_0524, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][619]) /* ty=Storage[] */;
  let %out_083: Tensor[(?), float32] = memory.alloc_tensor(%storage_0608, 0 /* ty=int64 */, %shape_func_out_087, meta[relay.attrs.AllocTensorAttrs][619]) /* ty=Tensor[(?), float32] */;
  %2643 = (%x463, %x465, %x466, meta[relay.Constant][584] /* ty=Tensor[(1), int32] */);
  %2644 = (%out_083,);
  let %v520: () = vm.invoke_tvm_op(%2634, %2643, %2644) /* ty=() */;
  let %x467: Tensor[(?), float32] = %out_083;
  let %storage_0609: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][620]) /* ty=Storage[] */;
  let %tensor_0525: Tensor[(2), int32] = memory.alloc_tensor(%storage_0609, 0 /* ty=int64 */, meta[relay.Constant][586] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][620]) /* ty=Tensor[(2), int32] */;
  %2647 = fn (%p0524: Tensor[(2), bool], %p1274: Tensor[(2), int32], %p2146: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2645 = cast_like(%p2146, %p1274) /* ty=Tensor[(2), int32] */;
    %2646 = add(%p1274, %2645) /* ty=Tensor[(2), int32] */;
    where(%p0524, %2646, %p1274) /* ty=Tensor[(2), int32] */
  };
  %2648 = (meta[relay.Constant][587] /* ty=Tensor[(2), bool] */, meta[relay.Constant][588] /* ty=Tensor[(2), int32] */, %x427);
  %2649 = (%tensor_0525,);
  let %v521: () = vm.invoke_tvm_op(%2647, %2648, %2649) /* ty=() */;
  let %x468: Tensor[(2), int32] = %tensor_0525;
  let %in_shape_079: Tensor[(?, 4), float32] = device_copy(%x426, meta[relay.attrs.DeviceCopyAttrs][117]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_149: Tensor[(2), int32] = device_copy(%x468, meta[relay.attrs.DeviceCopyAttrs][118]) /* ty=Tensor[(2), int32] */;
  let %in_shape_233: Tensor[(2), int64] = device_copy(%x429, meta[relay.attrs.DeviceCopyAttrs][119]) /* ty=Tensor[(2), int64] */;
  let %in_shape_329: Tensor[(2), int32] = device_copy(meta[relay.Constant][589] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][120]) /* ty=Tensor[(2), int32] */;
  let %storage_0610: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][621]) /* ty=Storage[] */;
  let %tensor_0526: Tensor[(2), int64] = memory.alloc_tensor(%storage_0610, 0 /* ty=int64 */, meta[relay.Constant][590] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][621]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_088: Tensor[(2), int64] = %tensor_0526;
  %2650 = fn (%p0525: Tensor[(?, 4), float32], %p1275: Tensor[(2), int32], %p2147: Tensor[(2), int64], %p389: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0525, %p1275, %p2147, %p389, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2651 = (%in_shape_079, %in_shape_149, %in_shape_233, %in_shape_329);
  %2652 = (%shape_func_out_088,);
  let %shape_func88: () = vm.shape_func(%2650, %2651, %2652, meta[relay.attrs.ShapeFuncAttrs][88]) /* ty=() */;
  let %storage_0611: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][622]) /* ty=Storage[] */;
  let %tensor_0527: int64 = memory.alloc_tensor(%storage_0611, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][622]) /* ty=int64 */;
  %2653 = fn (%p0526: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0526) /* ty=int64 */
  };
  %2654 = (%shape_func_out_088,);
  %2655 = (%tensor_0527,);
  let %v522: () = vm.invoke_tvm_op(%2653, %2654, %2655) /* ty=() */;
  let %storage_0612: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][623]) /* ty=Storage[] */;
  let %tensor_0528: int64 = memory.alloc_tensor(%storage_0612, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][623]) /* ty=int64 */;
  %2656 = fn (%p0527: int64, Primitive=1) -> int64 {
    multiply(%p0527, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2657 = (%tensor_0527,);
  %2658 = (%tensor_0528,);
  let %v523: () = vm.invoke_tvm_op(%2656, %2657, %2658) /* ty=() */;
  let %storage_0613: Storage[] = memory.alloc_storage(%tensor_0528, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][624]) /* ty=Storage[] */;
  let %out_084: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0613, 0 /* ty=int64 */, %shape_func_out_088, meta[relay.attrs.AllocTensorAttrs][624]) /* ty=Tensor[(?, ?), float32] */;
  %2659 = (%x426, %x468, %x429, meta[relay.Constant][589] /* ty=Tensor[(2), int32] */);
  %2660 = (%out_084,);
  let %v524: () = vm.invoke_tvm_op(%2650, %2659, %2660) /* ty=() */;
  let %x469: Tensor[(?, ?), float32] = %out_084;
  let %in_shape_080: Tensor[(2), int64] = vm.shape_of(%x469, meta[relay.attrs.ShapeOfAttrs][75]) /* ty=Tensor[(2), int64] */;
  let %in_shape_150: Tensor[(1), int64] = vm.shape_of(%x463, meta[relay.attrs.ShapeOfAttrs][76]) /* ty=Tensor[(1), int64] */;
  let %storage_0614: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][625]) /* ty=Storage[] */;
  let %tensor_0529: Tensor[(1), int64] = memory.alloc_tensor(%storage_0614, 0 /* ty=int64 */, meta[relay.Constant][591] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][625]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_089: Tensor[(1), int64] = %tensor_0529;
  %2663 = fn (%p0528: Tensor[(?, ?), float32], %p1276: Tensor[(?), float32], Primitive=1) -> Tensor[(?), float32] {
    %2661 = take(%p0528, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %2662 = multiply(%p1276, 0.5f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    add(%2661, %2662) /* ty=Tensor[(?), float32] */
  };
  %2664 = (%in_shape_080, %in_shape_150);
  %2665 = (%shape_func_out_089,);
  let %shape_func89: () = vm.shape_func(%2663, %2664, %2665, meta[relay.attrs.ShapeFuncAttrs][89]) /* ty=() */;
  let %storage_0615: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][626]) /* ty=Storage[] */;
  let %tensor_0530: int64 = memory.alloc_tensor(%storage_0615, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][626]) /* ty=int64 */;
  %2666 = fn (%p0529: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0529) /* ty=int64 */
  };
  %2667 = (%shape_func_out_089,);
  %2668 = (%tensor_0530,);
  let %v525: () = vm.invoke_tvm_op(%2666, %2667, %2668) /* ty=() */;
  let %storage_0616: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][627]) /* ty=Storage[] */;
  let %tensor_0531: int64 = memory.alloc_tensor(%storage_0616, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][627]) /* ty=int64 */;
  %2669 = fn (%p0530: int64, Primitive=1) -> int64 {
    multiply(%p0530, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2670 = (%tensor_0530,);
  %2671 = (%tensor_0531,);
  let %v526: () = vm.invoke_tvm_op(%2669, %2670, %2671) /* ty=() */;
  let %storage_0617: Storage[] = memory.alloc_storage(%tensor_0531, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][628]) /* ty=Storage[] */;
  let %out_085: Tensor[(?), float32] = memory.alloc_tensor(%storage_0617, 0 /* ty=int64 */, %shape_func_out_089, meta[relay.attrs.AllocTensorAttrs][628]) /* ty=Tensor[(?), float32] */;
  %2672 = (%x469, %x463);
  %2673 = (%out_085,);
  let %v527: () = vm.invoke_tvm_op(%2663, %2672, %2673) /* ty=() */;
  let %x470: Tensor[(?), float32] = %out_085;
  let %storage_0618: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][629]) /* ty=Storage[] */;
  let %tensor_0532: Tensor[(1), int32] = memory.alloc_tensor(%storage_0618, 0 /* ty=int64 */, meta[relay.Constant][592] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][629]) /* ty=Tensor[(1), int32] */;
  %2674 = fn (%p0531: Tensor[(?), float32], Primitive=1) -> Tensor[(1), int32] {
    shape_of(%p0531, dtype="int32") /* ty=Tensor[(1), int32] */
  };
  %2675 = (%x470,);
  %2676 = (%tensor_0532,);
  let %v528: () = vm.invoke_tvm_op(%2674, %2675, %2676) /* ty=() */;
  let %x471: Tensor[(1), int32] = %tensor_0532;
  let %storage_0619: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][630]) /* ty=Storage[] */;
  let %tensor_0533: Tensor[(1), int32] = memory.alloc_tensor(%storage_0619, 0 /* ty=int64 */, meta[relay.Constant][593] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][630]) /* ty=Tensor[(1), int32] */;
  %2679 = fn (%p0532: Tensor[(1), bool], %p1277: Tensor[(1), int32], %p2148: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
    %2677 = cast_like(%p2148, %p1277) /* ty=Tensor[(1), int32] */;
    %2678 = add(%p1277, %2677) /* ty=Tensor[(1), int32] */;
    where(%p0532, %2678, %p1277) /* ty=Tensor[(1), int32] */
  };
  %2680 = (meta[relay.Constant][594] /* ty=Tensor[(1), bool] */, meta[relay.Constant][595] /* ty=Tensor[(1), int32] */, %x471);
  %2681 = (%tensor_0533,);
  let %v529: () = vm.invoke_tvm_op(%2679, %2680, %2681) /* ty=() */;
  let %x472: Tensor[(1), int32] = %tensor_0533;
  let %storage_0620: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][631]) /* ty=Storage[] */;
  let %tensor_0534: Tensor[(1), int64] = memory.alloc_tensor(%storage_0620, 0 /* ty=int64 */, meta[relay.Constant][596] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][631]) /* ty=Tensor[(1), int64] */;
  %2682 = fn (%p0533: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int64] {
    cast(%p0533, dtype="int64") /* ty=Tensor[(1), int64] */
  };
  %2683 = (%x471,);
  %2684 = (%tensor_0534,);
  let %v530: () = vm.invoke_tvm_op(%2682, %2683, %2684) /* ty=() */;
  let %x473: Tensor[(1), int64] = %tensor_0534;
  let %in_shape_081: Tensor[(?), float32] = device_copy(%x470, meta[relay.attrs.DeviceCopyAttrs][121]) /* ty=Tensor[(?), float32] */;
  let %in_shape_151: Tensor[(1), int32] = device_copy(%x472, meta[relay.attrs.DeviceCopyAttrs][122]) /* ty=Tensor[(1), int32] */;
  let %in_shape_234: Tensor[(1), int64] = device_copy(%x473, meta[relay.attrs.DeviceCopyAttrs][123]) /* ty=Tensor[(1), int64] */;
  let %in_shape_330: Tensor[(1), int32] = device_copy(meta[relay.Constant][597] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][124]) /* ty=Tensor[(1), int32] */;
  let %storage_0621: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][632]) /* ty=Storage[] */;
  let %tensor_0535: Tensor[(1), int64] = memory.alloc_tensor(%storage_0621, 0 /* ty=int64 */, meta[relay.Constant][598] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][632]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_090: Tensor[(1), int64] = %tensor_0535;
  %2685 = fn (%p0534: Tensor[(?), float32], %p1278: Tensor[(1), int32], %p2149: Tensor[(1), int64], %p390: Tensor[(1), int32], Primitive=1) -> Tensor[(?), float32] {
    dyn.strided_slice(%p0534, %p1278, %p2149, %p390, begin=None, end=None, strides=None) /* ty=Tensor[(?), float32] */
  };
  %2686 = (%in_shape_081, %in_shape_151, %in_shape_234, %in_shape_330);
  %2687 = (%shape_func_out_090,);
  let %shape_func90: () = vm.shape_func(%2685, %2686, %2687, meta[relay.attrs.ShapeFuncAttrs][90]) /* ty=() */;
  let %storage_0622: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][633]) /* ty=Storage[] */;
  let %tensor_0536: int64 = memory.alloc_tensor(%storage_0622, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][633]) /* ty=int64 */;
  %2688 = fn (%p0535: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0535) /* ty=int64 */
  };
  %2689 = (%shape_func_out_090,);
  %2690 = (%tensor_0536,);
  let %v531: () = vm.invoke_tvm_op(%2688, %2689, %2690) /* ty=() */;
  let %storage_0623: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][634]) /* ty=Storage[] */;
  let %tensor_0537: int64 = memory.alloc_tensor(%storage_0623, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][634]) /* ty=int64 */;
  %2691 = fn (%p0536: int64, Primitive=1) -> int64 {
    multiply(%p0536, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2692 = (%tensor_0536,);
  %2693 = (%tensor_0537,);
  let %v532: () = vm.invoke_tvm_op(%2691, %2692, %2693) /* ty=() */;
  let %storage_0624: Storage[] = memory.alloc_storage(%tensor_0537, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][635]) /* ty=Storage[] */;
  let %out_086: Tensor[(?), float32] = memory.alloc_tensor(%storage_0624, 0 /* ty=int64 */, %shape_func_out_090, meta[relay.attrs.AllocTensorAttrs][635]) /* ty=Tensor[(?), float32] */;
  %2694 = (%x470, %x472, %x473, meta[relay.Constant][597] /* ty=Tensor[(1), int32] */);
  %2695 = (%out_086,);
  let %v533: () = vm.invoke_tvm_op(%2685, %2694, %2695) /* ty=() */;
  let %x474: Tensor[(?), float32] = %out_086;
  let %storage_0625: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][636]) /* ty=Storage[] */;
  let %tensor_0538: Tensor[(2), int32] = memory.alloc_tensor(%storage_0625, 0 /* ty=int64 */, meta[relay.Constant][599] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][636]) /* ty=Tensor[(2), int32] */;
  %2698 = fn (%p0537: Tensor[(2), bool], %p1279: Tensor[(2), int32], %p2150: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2696 = cast_like(%p2150, %p1279) /* ty=Tensor[(2), int32] */;
    %2697 = add(%p1279, %2696) /* ty=Tensor[(2), int32] */;
    where(%p0537, %2697, %p1279) /* ty=Tensor[(2), int32] */
  };
  %2699 = (meta[relay.Constant][600] /* ty=Tensor[(2), bool] */, meta[relay.Constant][601] /* ty=Tensor[(2), int32] */, %x418);
  %2700 = (%tensor_0538,);
  let %v534: () = vm.invoke_tvm_op(%2698, %2699, %2700) /* ty=() */;
  let %x475: Tensor[(2), int32] = %tensor_0538;
  let %in_shape_082: Tensor[(?, ?), float32] = device_copy(%x417, meta[relay.attrs.DeviceCopyAttrs][125]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_152: Tensor[(2), int32] = device_copy(%x475, meta[relay.attrs.DeviceCopyAttrs][126]) /* ty=Tensor[(2), int32] */;
  let %in_shape_235: Tensor[(2), int64] = device_copy(%x420, meta[relay.attrs.DeviceCopyAttrs][127]) /* ty=Tensor[(2), int64] */;
  let %in_shape_331: Tensor[(2), int32] = device_copy(meta[relay.Constant][602] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][128]) /* ty=Tensor[(2), int32] */;
  let %storage_0626: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][637]) /* ty=Storage[] */;
  let %tensor_0539: Tensor[(2), int64] = memory.alloc_tensor(%storage_0626, 0 /* ty=int64 */, meta[relay.Constant][603] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][637]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_091: Tensor[(2), int64] = %tensor_0539;
  %2701 = fn (%p0538: Tensor[(?, ?), float32], %p1280: Tensor[(2), int32], %p2151: Tensor[(2), int64], %p391: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0538, %p1280, %p2151, %p391, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2702 = (%in_shape_082, %in_shape_152, %in_shape_235, %in_shape_331);
  %2703 = (%shape_func_out_091,);
  let %shape_func91: () = vm.shape_func(%2701, %2702, %2703, meta[relay.attrs.ShapeFuncAttrs][91]) /* ty=() */;
  let %storage_0627: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][638]) /* ty=Storage[] */;
  let %tensor_0540: int64 = memory.alloc_tensor(%storage_0627, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][638]) /* ty=int64 */;
  %2704 = fn (%p0539: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0539) /* ty=int64 */
  };
  %2705 = (%shape_func_out_091,);
  %2706 = (%tensor_0540,);
  let %v535: () = vm.invoke_tvm_op(%2704, %2705, %2706) /* ty=() */;
  let %storage_0628: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][639]) /* ty=Storage[] */;
  let %tensor_0541: int64 = memory.alloc_tensor(%storage_0628, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][639]) /* ty=int64 */;
  %2707 = fn (%p0540: int64, Primitive=1) -> int64 {
    multiply(%p0540, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2708 = (%tensor_0540,);
  %2709 = (%tensor_0541,);
  let %v536: () = vm.invoke_tvm_op(%2707, %2708, %2709) /* ty=() */;
  let %storage_0629: Storage[] = memory.alloc_storage(%tensor_0541, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][640]) /* ty=Storage[] */;
  let %out_087: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0629, 0 /* ty=int64 */, %shape_func_out_091, meta[relay.attrs.AllocTensorAttrs][640]) /* ty=Tensor[(?, ?), float32] */;
  %2710 = (%x417, %x475, %x420, meta[relay.Constant][602] /* ty=Tensor[(2), int32] */);
  %2711 = (%out_087,);
  let %v537: () = vm.invoke_tvm_op(%2701, %2710, %2711) /* ty=() */;
  let %x476: Tensor[(?, ?), float32] = %out_087;
  let %storage_0630: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][641]) /* ty=Storage[] */;
  let %tensor_0542: Tensor[(2), int32] = memory.alloc_tensor(%storage_0630, 0 /* ty=int64 */, meta[relay.Constant][604] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][641]) /* ty=Tensor[(2), int32] */;
  %2712 = fn (%p0541: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0541, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2713 = (%x476,);
  %2714 = (%tensor_0542,);
  let %v538: () = vm.invoke_tvm_op(%2712, %2713, %2714) /* ty=() */;
  let %x477: Tensor[(2), int32] = %tensor_0542;
  let %storage_0631: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][642]) /* ty=Storage[] */;
  let %tensor_0543: Tensor[(2), int32] = memory.alloc_tensor(%storage_0631, 0 /* ty=int64 */, meta[relay.Constant][605] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][642]) /* ty=Tensor[(2), int32] */;
  %2717 = fn (%p0542: Tensor[(2), bool], %p1281: Tensor[(2), int32], %p2152: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2715 = cast_like(%p2152, %p1281) /* ty=Tensor[(2), int32] */;
    %2716 = add(%p1281, %2715) /* ty=Tensor[(2), int32] */;
    where(%p0542, %2716, %p1281) /* ty=Tensor[(2), int32] */
  };
  %2718 = (meta[relay.Constant][606] /* ty=Tensor[(2), bool] */, meta[relay.Constant][607] /* ty=Tensor[(2), int32] */, %x477);
  %2719 = (%tensor_0543,);
  let %v539: () = vm.invoke_tvm_op(%2717, %2718, %2719) /* ty=() */;
  let %x478: Tensor[(2), int32] = %tensor_0543;
  let %storage_0632: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][643]) /* ty=Storage[] */;
  let %tensor_0544: Tensor[(2), int64] = memory.alloc_tensor(%storage_0632, 0 /* ty=int64 */, meta[relay.Constant][608] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][643]) /* ty=Tensor[(2), int64] */;
  %2720 = fn (%p0543: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0543, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2721 = (%x477,);
  %2722 = (%tensor_0544,);
  let %v540: () = vm.invoke_tvm_op(%2720, %2721, %2722) /* ty=() */;
  let %x479: Tensor[(2), int64] = %tensor_0544;
  let %in_shape_083: Tensor[(?, ?), float32] = device_copy(%x476, meta[relay.attrs.DeviceCopyAttrs][129]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_153: Tensor[(2), int32] = device_copy(%x478, meta[relay.attrs.DeviceCopyAttrs][130]) /* ty=Tensor[(2), int32] */;
  let %in_shape_236: Tensor[(2), int64] = device_copy(%x479, meta[relay.attrs.DeviceCopyAttrs][131]) /* ty=Tensor[(2), int64] */;
  let %in_shape_332: Tensor[(2), int32] = device_copy(meta[relay.Constant][609] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][132]) /* ty=Tensor[(2), int32] */;
  let %storage_0633: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][644]) /* ty=Storage[] */;
  let %tensor_0545: Tensor[(2), int64] = memory.alloc_tensor(%storage_0633, 0 /* ty=int64 */, meta[relay.Constant][610] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][644]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_092: Tensor[(2), int64] = %tensor_0545;
  %2723 = fn (%p0544: Tensor[(?, ?), float32], %p1282: Tensor[(2), int32], %p2153: Tensor[(2), int64], %p392: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0544, %p1282, %p2153, %p392, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2724 = (%in_shape_083, %in_shape_153, %in_shape_236, %in_shape_332);
  %2725 = (%shape_func_out_092,);
  let %shape_func92: () = vm.shape_func(%2723, %2724, %2725, meta[relay.attrs.ShapeFuncAttrs][92]) /* ty=() */;
  let %storage_0634: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][645]) /* ty=Storage[] */;
  let %tensor_0546: int64 = memory.alloc_tensor(%storage_0634, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][645]) /* ty=int64 */;
  %2726 = fn (%p0545: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0545) /* ty=int64 */
  };
  %2727 = (%shape_func_out_092,);
  %2728 = (%tensor_0546,);
  let %v541: () = vm.invoke_tvm_op(%2726, %2727, %2728) /* ty=() */;
  let %storage_0635: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][646]) /* ty=Storage[] */;
  let %tensor_0547: int64 = memory.alloc_tensor(%storage_0635, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][646]) /* ty=int64 */;
  %2729 = fn (%p0546: int64, Primitive=1) -> int64 {
    multiply(%p0546, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2730 = (%tensor_0546,);
  %2731 = (%tensor_0547,);
  let %v542: () = vm.invoke_tvm_op(%2729, %2730, %2731) /* ty=() */;
  let %storage_0636: Storage[] = memory.alloc_storage(%tensor_0547, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][647]) /* ty=Storage[] */;
  let %out_088: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0636, 0 /* ty=int64 */, %shape_func_out_092, meta[relay.attrs.AllocTensorAttrs][647]) /* ty=Tensor[(?, ?), float32] */;
  %2732 = (%x476, %x478, %x479, meta[relay.Constant][609] /* ty=Tensor[(2), int32] */);
  %2733 = (%out_088,);
  let %v543: () = vm.invoke_tvm_op(%2723, %2732, %2733) /* ty=() */;
  let %x480: Tensor[(?, ?), float32] = %out_088;
  let %storage_0637: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][648]) /* ty=Storage[] */;
  let %tensor_0548: Tensor[(1), int32] = memory.alloc_tensor(%storage_0637, 0 /* ty=int64 */, meta[relay.Constant][611] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][648]) /* ty=Tensor[(1), int32] */;
  %2736 = fn (%p0547: Tensor[(1), bool], %p1283: Tensor[(1), int32], %p2154: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
    %2734 = cast_like(%p2154, %p1283) /* ty=Tensor[(1), int32] */;
    %2735 = add(%p1283, %2734) /* ty=Tensor[(1), int32] */;
    where(%p0547, %2735, %p1283) /* ty=Tensor[(1), int32] */
  };
  %2737 = (meta[relay.Constant][612] /* ty=Tensor[(1), bool] */, meta[relay.Constant][613] /* ty=Tensor[(1), int32] */, %x464);
  %2738 = (%tensor_0548,);
  let %v544: () = vm.invoke_tvm_op(%2736, %2737, %2738) /* ty=() */;
  let %x481: Tensor[(1), int32] = %tensor_0548;
  let %in_shape_084: Tensor[(?), float32] = device_copy(%x463, meta[relay.attrs.DeviceCopyAttrs][133]) /* ty=Tensor[(?), float32] */;
  let %in_shape_154: Tensor[(1), int32] = device_copy(%x481, meta[relay.attrs.DeviceCopyAttrs][134]) /* ty=Tensor[(1), int32] */;
  let %in_shape_237: Tensor[(1), int64] = device_copy(%x466, meta[relay.attrs.DeviceCopyAttrs][135]) /* ty=Tensor[(1), int64] */;
  let %in_shape_333: Tensor[(1), int32] = device_copy(meta[relay.Constant][614] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][136]) /* ty=Tensor[(1), int32] */;
  let %storage_0638: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][649]) /* ty=Storage[] */;
  let %tensor_0549: Tensor[(1), int64] = memory.alloc_tensor(%storage_0638, 0 /* ty=int64 */, meta[relay.Constant][615] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][649]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_093: Tensor[(1), int64] = %tensor_0549;
  %2739 = fn (%p0548: Tensor[(?), float32], %p1284: Tensor[(1), int32], %p2155: Tensor[(1), int64], %p393: Tensor[(1), int32], Primitive=1) -> Tensor[(?), float32] {
    dyn.strided_slice(%p0548, %p1284, %p2155, %p393, begin=None, end=None, strides=None) /* ty=Tensor[(?), float32] */
  };
  %2740 = (%in_shape_084, %in_shape_154, %in_shape_237, %in_shape_333);
  %2741 = (%shape_func_out_093,);
  let %shape_func93: () = vm.shape_func(%2739, %2740, %2741, meta[relay.attrs.ShapeFuncAttrs][93]) /* ty=() */;
  let %storage_0639: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][650]) /* ty=Storage[] */;
  let %tensor_0550: int64 = memory.alloc_tensor(%storage_0639, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][650]) /* ty=int64 */;
  %2742 = fn (%p0549: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0549) /* ty=int64 */
  };
  %2743 = (%shape_func_out_093,);
  %2744 = (%tensor_0550,);
  let %v545: () = vm.invoke_tvm_op(%2742, %2743, %2744) /* ty=() */;
  let %storage_0640: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][651]) /* ty=Storage[] */;
  let %tensor_0551: int64 = memory.alloc_tensor(%storage_0640, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][651]) /* ty=int64 */;
  %2745 = fn (%p0550: int64, Primitive=1) -> int64 {
    multiply(%p0550, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2746 = (%tensor_0550,);
  %2747 = (%tensor_0551,);
  let %v546: () = vm.invoke_tvm_op(%2745, %2746, %2747) /* ty=() */;
  let %storage_0641: Storage[] = memory.alloc_storage(%tensor_0551, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][652]) /* ty=Storage[] */;
  let %out_089: Tensor[(?), float32] = memory.alloc_tensor(%storage_0641, 0 /* ty=int64 */, %shape_func_out_093, meta[relay.attrs.AllocTensorAttrs][652]) /* ty=Tensor[(?), float32] */;
  %2748 = (%x463, %x481, %x466, meta[relay.Constant][614] /* ty=Tensor[(1), int32] */);
  %2749 = (%out_089,);
  let %v547: () = vm.invoke_tvm_op(%2739, %2748, %2749) /* ty=() */;
  let %x482: Tensor[(?), float32] = %out_089;
  let %in_shape_085: Tensor[(2), int64] = vm.shape_of(%x425, meta[relay.attrs.ShapeOfAttrs][77]) /* ty=Tensor[(2), int64] */;
  let %in_shape_155: Tensor[(1), int64] = vm.shape_of(%x437, meta[relay.attrs.ShapeOfAttrs][78]) /* ty=Tensor[(1), int64] */;
  let %in_shape_238: Tensor[(1), int64] = vm.shape_of(%x444, meta[relay.attrs.ShapeOfAttrs][79]) /* ty=Tensor[(1), int64] */;
  let %in_shape_334: Tensor[(2), int64] = vm.shape_of(%x450, meta[relay.attrs.ShapeOfAttrs][80]) /* ty=Tensor[(2), int64] */;
  let %in_shape_41: Tensor[(1), int64] = vm.shape_of(%x452, meta[relay.attrs.ShapeOfAttrs][81]) /* ty=Tensor[(1), int64] */;
  let %in_shape_51: Tensor[(2), int64] = vm.shape_of(%x458, meta[relay.attrs.ShapeOfAttrs][82]) /* ty=Tensor[(2), int64] */;
  let %in_shape_6: Tensor[(1), int64] = vm.shape_of(%x467, meta[relay.attrs.ShapeOfAttrs][83]) /* ty=Tensor[(1), int64] */;
  let %in_shape_7: Tensor[(1), int64] = vm.shape_of(%x474, meta[relay.attrs.ShapeOfAttrs][84]) /* ty=Tensor[(1), int64] */;
  let %in_shape_8: Tensor[(2), int64] = vm.shape_of(%x480, meta[relay.attrs.ShapeOfAttrs][85]) /* ty=Tensor[(2), int64] */;
  let %in_shape_9: Tensor[(1), int64] = vm.shape_of(%x482, meta[relay.attrs.ShapeOfAttrs][86]) /* ty=Tensor[(1), int64] */;
  let %storage_0642: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][653]) /* ty=Storage[] */;
  let %tensor_0552: Tensor[(2), int64] = memory.alloc_tensor(%storage_0642, 0 /* ty=int64 */, meta[relay.Constant][616] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][653]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_094: Tensor[(2), int64] = %tensor_0552;
  %2779 = fn (%p0551: Tensor[(?, ?), float32], %p1285: Tensor[(?), float32], %p2156: Tensor[(?), float32], %p394: Tensor[(?, ?), float32], %p458: Tensor[(?), float32], %p519: Tensor[(?, ?), float32], %p62: Tensor[(?), float32], %p72: Tensor[(?), float32], %p82: Tensor[(?, ?), float32], %p91: Tensor[(?), float32], Primitive=1) -> Tensor[(?, ?), float32] {
    %2750 = divide(%p0551, 10f /* ty=float32 */) /* ty=Tensor[(?, ?), float32] */;
    %2751 = expand_dims(%p1285, axis=1) /* ty=Tensor[(?, 1), float32] */;
    %2752 = multiply(%2750, %2751) /* ty=Tensor[(?, ?), float32] */;
    %2753 = expand_dims(%p2156, axis=1) /* ty=Tensor[(?, 1), float32] */;
    %2754 = add(%2752, %2753) /* ty=Tensor[(?, ?), float32] */;
    %2755 = divide(%p394, 5f /* ty=float32 */) /* ty=Tensor[(?, ?), float32] */;
    %2756 = clip(%2755, a_min=-3.40282e+38f, a_max=4.13517f) /* ty=Tensor[(?, ?), float32] */;
    %2757 = exp(%2756) /* ty=Tensor[(?, ?), float32] */;
    %2758 = expand_dims(%p458, axis=1) /* ty=Tensor[(?, 1), float32] */;
    %2759 = multiply(%2757, %2758) /* ty=Tensor[(?, ?), float32] */;
    %2760 = multiply(0.5f /* ty=float32 */, %2759) /* ty=Tensor[(?, ?), float32] */;
    %2761 = subtract(%2754, %2760) /* ty=Tensor[(?, ?), float32] */;
    %2762 = divide(%p519, 10f /* ty=float32 */) /* ty=Tensor[(?, ?), float32] */;
    %2763 = expand_dims(%p62, axis=1) /* ty=Tensor[(?, 1), float32] */;
    %2764 = multiply(%2762, %2763) /* ty=Tensor[(?, ?), float32] */;
    %2765 = expand_dims(%p72, axis=1) /* ty=Tensor[(?, 1), float32] */;
    %2766 = add(%2764, %2765) /* ty=Tensor[(?, ?), float32] */;
    %2767 = divide(%p82, 5f /* ty=float32 */) /* ty=Tensor[(?, ?), float32] */;
    %2768 = clip(%2767, a_min=-3.40282e+38f, a_max=4.13517f) /* ty=Tensor[(?, ?), float32] */;
    %2769 = exp(%2768) /* ty=Tensor[(?, ?), float32] */;
    %2770 = expand_dims(%p91, axis=1) /* ty=Tensor[(?, 1), float32] */;
    %2771 = multiply(%2769, %2770) /* ty=Tensor[(?, ?), float32] */;
    %2772 = multiply(0.5f /* ty=float32 */, %2771) /* ty=Tensor[(?, ?), float32] */;
    %2773 = subtract(%2766, %2772) /* ty=Tensor[(?, ?), float32] */;
    %2774 = add(%2754, %2760) /* ty=Tensor[(?, ?), float32] */;
    %2775 = add(%2766, %2772) /* ty=Tensor[(?, ?), float32] */;
    %2776 = (%2761, %2773, %2774, %2775);
    %2777 = stack(%2776, axis=2) /* ty=Tensor[(?, ?, 4), float32] */;
    %2778 = reshape(%2777, newshape=[0, -1, 1]) /* ty=Tensor[(?, ?, 1), float32] */;
    squeeze(%2778, axis=[2]) /* ty=Tensor[(?, ?), float32] */
  };
  %2780 = (%in_shape_085, %in_shape_155, %in_shape_238, %in_shape_334, %in_shape_41, %in_shape_51, %in_shape_6, %in_shape_7, %in_shape_8, %in_shape_9);
  %2781 = (%shape_func_out_094,);
  let %shape_func94: () = vm.shape_func(%2779, %2780, %2781, meta[relay.attrs.ShapeFuncAttrs][94]) /* ty=() */;
  let %storage_0643: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][654]) /* ty=Storage[] */;
  let %tensor_0553: int64 = memory.alloc_tensor(%storage_0643, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][654]) /* ty=int64 */;
  %2782 = fn (%p0552: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0552) /* ty=int64 */
  };
  %2783 = (%shape_func_out_094,);
  %2784 = (%tensor_0553,);
  let %v548: () = vm.invoke_tvm_op(%2782, %2783, %2784) /* ty=() */;
  let %storage_0644: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][655]) /* ty=Storage[] */;
  let %tensor_0554: int64 = memory.alloc_tensor(%storage_0644, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][655]) /* ty=int64 */;
  %2785 = fn (%p0553: int64, Primitive=1) -> int64 {
    multiply(%p0553, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2786 = (%tensor_0553,);
  %2787 = (%tensor_0554,);
  let %v549: () = vm.invoke_tvm_op(%2785, %2786, %2787) /* ty=() */;
  let %storage_0645: Storage[] = memory.alloc_storage(%tensor_0554, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][656]) /* ty=Storage[] */;
  let %out_090: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0645, 0 /* ty=int64 */, %shape_func_out_094, meta[relay.attrs.AllocTensorAttrs][656]) /* ty=Tensor[(?, ?), float32] */;
  %2788 = (%x425, %x437, %x444, %x450, %x452, %x458, %x467, %x474, %x480, %x482);
  %2789 = (%out_090,);
  let %v550: () = vm.invoke_tvm_op(%2779, %2788, %2789) /* ty=() */;
  let %x483: Tensor[(?, ?), float32] = %out_090;
  let %storage_0646: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][657]) /* ty=Storage[] */;
  let %tensor_0555: Tensor[(3), int64] = memory.alloc_tensor(%storage_0646, 0 /* ty=int64 */, meta[relay.Constant][617] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][657]) /* ty=Tensor[(3), int64] */;
  %2791 = fn (%p0554: Tensor[(1), int64], %p1286: Tensor[(1), int64], %p2157: Tensor[(1), int64], Primitive=1) -> Tensor[(3), int64] {
    %2790 = (%p0554, %p1286, %p2157);
    concatenate(%2790) /* ty=Tensor[(3), int64] */
  };
  %2792 = (%x415, meta[relay.Constant][489] /* ty=Tensor[(1), int64] */, meta[relay.Constant][618] /* ty=Tensor[(1), int64] */);
  %2793 = (%tensor_0555,);
  let %v551: () = vm.invoke_tvm_op(%2791, %2792, %2793) /* ty=() */;
  let %x484: Tensor[(3), int64] = %tensor_0555;
  let %in_shape_086: Tensor[(?, ?), float32] = device_copy(%x483, meta[relay.attrs.DeviceCopyAttrs][137]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_156: Tensor[(3), int64] = device_copy(%x484, meta[relay.attrs.DeviceCopyAttrs][138]) /* ty=Tensor[(3), int64] */;
  let %storage_0647: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][658]) /* ty=Storage[] */;
  let %tensor_0556: Tensor[(3), int64] = memory.alloc_tensor(%storage_0647, 0 /* ty=int64 */, meta[relay.Constant][619] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][658]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_095: Tensor[(3), int64] = %tensor_0556;
  %2794 = fn (%p0555: Tensor[(?, ?), float32], %p1287: Tensor[(3), int64], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.reshape(%p0555, %p1287, newshape=[]) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %2795 = (%in_shape_086, %in_shape_156);
  %2796 = (%shape_func_out_095,);
  let %shape_func95: () = vm.shape_func(%2794, %2795, %2796, meta[relay.attrs.ShapeFuncAttrs][95]) /* ty=() */;
  let %x485: Tensor[(?, ?, ?), float32] = vm.reshape_tensor(%x483, %shape_func_out_095, meta[relay.attrs.ReshapeTensorAttrs][110]) /* ty=Tensor[(?, ?, ?), float32] */;
  let %storage_0648: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][659]) /* ty=Storage[] */;
  let %tensor_0557: Tensor[(3), int32] = memory.alloc_tensor(%storage_0648, 0 /* ty=int64 */, meta[relay.Constant][620] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][659]) /* ty=Tensor[(3), int32] */;
  %2797 = fn (%p0556: Tensor[(?, ?, ?), float32], Primitive=1) -> Tensor[(3), int32] {
    shape_of(%p0556, dtype="int32") /* ty=Tensor[(3), int32] */
  };
  %2798 = (%x485,);
  %2799 = (%tensor_0557,);
  let %v552: () = vm.invoke_tvm_op(%2797, %2798, %2799) /* ty=() */;
  let %x486: Tensor[(3), int32] = %tensor_0557;
  let %storage_0649: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][660]) /* ty=Storage[] */;
  let %tensor_0558: Tensor[(3), int32] = memory.alloc_tensor(%storage_0649, 0 /* ty=int64 */, meta[relay.Constant][621] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][660]) /* ty=Tensor[(3), int32] */;
  %2802 = fn (%p0557: Tensor[(3), bool], %p1288: Tensor[(3), int32], %p2158: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int32] {
    %2800 = cast_like(%p2158, %p1288) /* ty=Tensor[(3), int32] */;
    %2801 = add(%p1288, %2800) /* ty=Tensor[(3), int32] */;
    where(%p0557, %2801, %p1288) /* ty=Tensor[(3), int32] */
  };
  %2803 = (meta[relay.Constant][622] /* ty=Tensor[(3), bool] */, meta[relay.Constant][623] /* ty=Tensor[(3), int32] */, %x486);
  %2804 = (%tensor_0558,);
  let %v553: () = vm.invoke_tvm_op(%2802, %2803, %2804) /* ty=() */;
  let %x487: Tensor[(3), int32] = %tensor_0558;
  let %storage_0650: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][661]) /* ty=Storage[] */;
  let %tensor_0559: Tensor[(3), int64] = memory.alloc_tensor(%storage_0650, 0 /* ty=int64 */, meta[relay.Constant][624] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][661]) /* ty=Tensor[(3), int64] */;
  %2805 = fn (%p0558: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int64] {
    cast(%p0558, dtype="int64") /* ty=Tensor[(3), int64] */
  };
  %2806 = (%x486,);
  %2807 = (%tensor_0559,);
  let %v554: () = vm.invoke_tvm_op(%2805, %2806, %2807) /* ty=() */;
  let %x488: Tensor[(3), int64] = %tensor_0559;
  let %in_shape_087: Tensor[(?, ?, ?), float32] = device_copy(%x485, meta[relay.attrs.DeviceCopyAttrs][139]) /* ty=Tensor[(?, ?, ?), float32] */;
  let %in_shape_157: Tensor[(3), int32] = device_copy(%x487, meta[relay.attrs.DeviceCopyAttrs][140]) /* ty=Tensor[(3), int32] */;
  let %in_shape_239: Tensor[(3), int64] = device_copy(%x488, meta[relay.attrs.DeviceCopyAttrs][141]) /* ty=Tensor[(3), int64] */;
  let %in_shape_335: Tensor[(3), int32] = device_copy(meta[relay.Constant][625] /* ty=Tensor[(3), int32] */, meta[relay.attrs.DeviceCopyAttrs][142]) /* ty=Tensor[(3), int32] */;
  let %storage_0651: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][662]) /* ty=Storage[] */;
  let %tensor_0560: Tensor[(3), int64] = memory.alloc_tensor(%storage_0651, 0 /* ty=int64 */, meta[relay.Constant][626] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][662]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_096: Tensor[(3), int64] = %tensor_0560;
  %2808 = fn (%p0559: Tensor[(?, ?, ?), float32], %p1289: Tensor[(3), int32], %p2159: Tensor[(3), int64], %p395: Tensor[(3), int32], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.strided_slice(%p0559, %p1289, %p2159, %p395, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %2809 = (%in_shape_087, %in_shape_157, %in_shape_239, %in_shape_335);
  %2810 = (%shape_func_out_096,);
  let %shape_func96: () = vm.shape_func(%2808, %2809, %2810, meta[relay.attrs.ShapeFuncAttrs][96]) /* ty=() */;
  let %storage_0652: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][663]) /* ty=Storage[] */;
  let %tensor_0561: int64 = memory.alloc_tensor(%storage_0652, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][663]) /* ty=int64 */;
  %2811 = fn (%p0560: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0560) /* ty=int64 */
  };
  %2812 = (%shape_func_out_096,);
  %2813 = (%tensor_0561,);
  let %v555: () = vm.invoke_tvm_op(%2811, %2812, %2813) /* ty=() */;
  let %storage_0653: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][664]) /* ty=Storage[] */;
  let %tensor_0562: int64 = memory.alloc_tensor(%storage_0653, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][664]) /* ty=int64 */;
  %2814 = fn (%p0561: int64, Primitive=1) -> int64 {
    multiply(%p0561, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2815 = (%tensor_0561,);
  %2816 = (%tensor_0562,);
  let %v556: () = vm.invoke_tvm_op(%2814, %2815, %2816) /* ty=() */;
  let %storage_0654: Storage[] = memory.alloc_storage(%tensor_0562, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][665]) /* ty=Storage[] */;
  let %out_091: Tensor[(?, ?, ?), float32] = memory.alloc_tensor(%storage_0654, 0 /* ty=int64 */, %shape_func_out_096, meta[relay.attrs.AllocTensorAttrs][665]) /* ty=Tensor[(?, ?, ?), float32] */;
  %2817 = (%x485, %x487, %x488, meta[relay.Constant][625] /* ty=Tensor[(3), int32] */);
  %2818 = (%out_091,);
  let %v557: () = vm.invoke_tvm_op(%2808, %2817, %2818) /* ty=() */;
  let %x489: Tensor[(?, ?, ?), float32] = %out_091;
  let %storage_0655: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][666]) /* ty=Storage[] */;
  let %tensor_0563: Tensor[(3), int32] = memory.alloc_tensor(%storage_0655, 0 /* ty=int64 */, meta[relay.Constant][627] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][666]) /* ty=Tensor[(3), int32] */;
  %2821 = fn (%p0562: Tensor[(3), bool], %p1290: Tensor[(3), int32], %p2160: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int32] {
    %2819 = cast_like(%p2160, %p1290) /* ty=Tensor[(3), int32] */;
    %2820 = add(%p1290, %2819) /* ty=Tensor[(3), int32] */;
    where(%p0562, %2820, %p1290) /* ty=Tensor[(3), int32] */
  };
  %2822 = (meta[relay.Constant][628] /* ty=Tensor[(3), bool] */, meta[relay.Constant][629] /* ty=Tensor[(3), int32] */, %x486);
  %2823 = (%tensor_0563,);
  let %v558: () = vm.invoke_tvm_op(%2821, %2822, %2823) /* ty=() */;
  let %x490: Tensor[(3), int32] = %tensor_0563;
  let %in_shape_088: Tensor[(?, ?, ?), float32] = device_copy(%x485, meta[relay.attrs.DeviceCopyAttrs][143]) /* ty=Tensor[(?, ?, ?), float32] */;
  let %in_shape_158: Tensor[(3), int32] = device_copy(%x490, meta[relay.attrs.DeviceCopyAttrs][144]) /* ty=Tensor[(3), int32] */;
  let %in_shape_240: Tensor[(3), int64] = device_copy(%x488, meta[relay.attrs.DeviceCopyAttrs][145]) /* ty=Tensor[(3), int64] */;
  let %in_shape_336: Tensor[(3), int32] = device_copy(meta[relay.Constant][630] /* ty=Tensor[(3), int32] */, meta[relay.attrs.DeviceCopyAttrs][146]) /* ty=Tensor[(3), int32] */;
  let %storage_0656: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][667]) /* ty=Storage[] */;
  let %tensor_0564: Tensor[(3), int64] = memory.alloc_tensor(%storage_0656, 0 /* ty=int64 */, meta[relay.Constant][631] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][667]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_097: Tensor[(3), int64] = %tensor_0564;
  %2824 = fn (%p0563: Tensor[(?, ?, ?), float32], %p1291: Tensor[(3), int32], %p2161: Tensor[(3), int64], %p396: Tensor[(3), int32], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.strided_slice(%p0563, %p1291, %p2161, %p396, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %2825 = (%in_shape_088, %in_shape_158, %in_shape_240, %in_shape_336);
  %2826 = (%shape_func_out_097,);
  let %shape_func97: () = vm.shape_func(%2824, %2825, %2826, meta[relay.attrs.ShapeFuncAttrs][97]) /* ty=() */;
  let %storage_0657: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][668]) /* ty=Storage[] */;
  let %tensor_0565: int64 = memory.alloc_tensor(%storage_0657, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][668]) /* ty=int64 */;
  %2827 = fn (%p0564: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0564) /* ty=int64 */
  };
  %2828 = (%shape_func_out_097,);
  %2829 = (%tensor_0565,);
  let %v559: () = vm.invoke_tvm_op(%2827, %2828, %2829) /* ty=() */;
  let %storage_0658: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][669]) /* ty=Storage[] */;
  let %tensor_0566: int64 = memory.alloc_tensor(%storage_0658, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][669]) /* ty=int64 */;
  %2830 = fn (%p0565: int64, Primitive=1) -> int64 {
    multiply(%p0565, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2831 = (%tensor_0565,);
  %2832 = (%tensor_0566,);
  let %v560: () = vm.invoke_tvm_op(%2830, %2831, %2832) /* ty=() */;
  let %storage_0659: Storage[] = memory.alloc_storage(%tensor_0566, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][670]) /* ty=Storage[] */;
  let %out_092: Tensor[(?, ?, ?), float32] = memory.alloc_tensor(%storage_0659, 0 /* ty=int64 */, %shape_func_out_097, meta[relay.attrs.AllocTensorAttrs][670]) /* ty=Tensor[(?, ?, ?), float32] */;
  %2833 = (%x485, %x490, %x488, meta[relay.Constant][630] /* ty=Tensor[(3), int32] */);
  %2834 = (%out_092,);
  let %v561: () = vm.invoke_tvm_op(%2824, %2833, %2834) /* ty=() */;
  let %x491: Tensor[(?, ?, ?), float32] = %out_092;
  let %in_shape_089: Tensor[(3), int64] = vm.shape_of(%x489, meta[relay.attrs.ShapeOfAttrs][87]) /* ty=Tensor[(3), int64] */;
  let %in_shape_241: Tensor[(3), int64] = vm.shape_of(%x491, meta[relay.attrs.ShapeOfAttrs][88]) /* ty=Tensor[(3), int64] */;
  let %storage_0660: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][671]) /* ty=Storage[] */;
  let %tensor_0567: Tensor[(4), int64] = memory.alloc_tensor(%storage_0660, 0 /* ty=int64 */, meta[relay.Constant][632] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][671]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_098: Tensor[(4), int64] = %tensor_0567;
  %2840 = fn (%p0566: Tensor[(?, ?, ?), float32], %p1292: float32, %p2162: Tensor[(?, ?, ?), float32], %p397: float32, Primitive=1) -> Tensor[(?, ?, ?, 2), float32] {
    %2835 = maximum(%p0566, 0f /* ty=float32 */) /* ty=Tensor[(?, ?, ?), float32] */;
    %2836 = minimum(%2835, %p1292) /* ty=Tensor[(?, ?, ?), float32] */;
    %2837 = maximum(%p2162, 0f /* ty=float32 */) /* ty=Tensor[(?, ?, ?), float32] */;
    %2838 = minimum(%2837, %p397) /* ty=Tensor[(?, ?, ?), float32] */;
    %2839 = (%2836, %2838);
    stack(%2839, axis=3) /* ty=Tensor[(?, ?, ?, 2), float32] */
  };
  %2841 = (%in_shape_089, 1499394704 /* ty=int64 */, %in_shape_241, 1911719216 /* ty=int64 */);
  %2842 = (%shape_func_out_098,);
  let %shape_func98: () = vm.shape_func(%2840, %2841, %2842, meta[relay.attrs.ShapeFuncAttrs][98]) /* ty=() */;
  let %storage_0661: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][672]) /* ty=Storage[] */;
  let %tensor_0568: int64 = memory.alloc_tensor(%storage_0661, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][672]) /* ty=int64 */;
  %2843 = fn (%p0567: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0567) /* ty=int64 */
  };
  %2844 = (%shape_func_out_098,);
  %2845 = (%tensor_0568,);
  let %v562: () = vm.invoke_tvm_op(%2843, %2844, %2845) /* ty=() */;
  let %storage_0662: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][673]) /* ty=Storage[] */;
  let %tensor_0569: int64 = memory.alloc_tensor(%storage_0662, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][673]) /* ty=int64 */;
  %2846 = fn (%p0568: int64, Primitive=1) -> int64 {
    multiply(%p0568, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2847 = (%tensor_0568,);
  %2848 = (%tensor_0569,);
  let %v563: () = vm.invoke_tvm_op(%2846, %2847, %2848) /* ty=() */;
  let %storage_0663: Storage[] = memory.alloc_storage(%tensor_0569, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][674]) /* ty=Storage[] */;
  let %out_093: Tensor[(?, ?, ?, 2), float32] = memory.alloc_tensor(%storage_0663, 0 /* ty=int64 */, %shape_func_out_098, meta[relay.attrs.AllocTensorAttrs][674]) /* ty=Tensor[(?, ?, ?, 2), float32] */;
  %2849 = (%x489, 800f /* ty=float32 */, %x491, 800f /* ty=float32 */);
  %2850 = (%out_093,);
  let %v564: () = vm.invoke_tvm_op(%2840, %2849, %2850) /* ty=() */;
  let %x492: Tensor[(?, ?, ?, 2), float32] = %out_093;
  let %storage_0664: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][675]) /* ty=Storage[] */;
  let %tensor_0570: Tensor[(3), int64] = memory.alloc_tensor(%storage_0664, 0 /* ty=int64 */, meta[relay.Constant][633] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][675]) /* ty=Tensor[(3), int64] */;
  %2861 = fn (%p0569: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int64] {
    %2851 = take(%p0569, 0 /* ty=int32 */, axis=0) /* ty=int32 */;
    %2852 = cast(%2851, dtype="int64") /* ty=int64 */;
    %2853 = expand_dims(%2852, axis=0) /* ty=Tensor[(1), int64] */;
    %2854 = take(%p0569, 1 /* ty=int32 */, axis=0) /* ty=int32 */;
    %2855 = cast(%2854, dtype="int64") /* ty=int64 */;
    %2856 = expand_dims(%2855, axis=0) /* ty=Tensor[(1), int64] */;
    %2857 = take(%p0569, 2 /* ty=int32 */, axis=0) /* ty=int32 */;
    %2858 = cast(%2857, dtype="int64") /* ty=int64 */;
    %2859 = expand_dims(%2858, axis=0) /* ty=Tensor[(1), int64] */;
    %2860 = (%2853, %2856, %2859);
    concatenate(%2860) /* ty=Tensor[(3), int64] */
  };
  %2862 = (%x486,);
  %2863 = (%tensor_0570,);
  let %v565: () = vm.invoke_tvm_op(%2861, %2862, %2863) /* ty=() */;
  let %x493: Tensor[(3), int64] = %tensor_0570;
  let %in_shape_090: Tensor[(?, ?, ?, 2), float32] = device_copy(%x492, meta[relay.attrs.DeviceCopyAttrs][147]) /* ty=Tensor[(?, ?, ?, 2), float32] */;
  let %in_shape_159: Tensor[(3), int64] = device_copy(%x493, meta[relay.attrs.DeviceCopyAttrs][148]) /* ty=Tensor[(3), int64] */;
  let %storage_0665: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][676]) /* ty=Storage[] */;
  let %tensor_0571: Tensor[(3), int64] = memory.alloc_tensor(%storage_0665, 0 /* ty=int64 */, meta[relay.Constant][634] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][676]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_099: Tensor[(3), int64] = %tensor_0571;
  %2864 = fn (%p0570: Tensor[(?, ?, ?, 2), float32], %p1293: Tensor[(3), int64], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.reshape(%p0570, %p1293, newshape=[]) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %2865 = (%in_shape_090, %in_shape_159);
  %2866 = (%shape_func_out_099,);
  let %shape_func99: () = vm.shape_func(%2864, %2865, %2866, meta[relay.attrs.ShapeFuncAttrs][99]) /* ty=() */;
  let %x494: Tensor[(?, ?, ?), float32] = vm.reshape_tensor(%x492, %shape_func_out_099, meta[relay.attrs.ReshapeTensorAttrs][111]) /* ty=Tensor[(?, ?, ?), float32] */;
  let %storage_0666: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][677]) /* ty=Storage[] */;
  let %tensor_0572: Tensor[(3), int32] = memory.alloc_tensor(%storage_0666, 0 /* ty=int64 */, meta[relay.Constant][635] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][677]) /* ty=Tensor[(3), int32] */;
  %2867 = fn (%p0571: Tensor[(?, ?, ?), float32], Primitive=1) -> Tensor[(3), int32] {
    shape_of(%p0571, dtype="int32") /* ty=Tensor[(3), int32] */
  };
  %2868 = (%x494,);
  %2869 = (%tensor_0572,);
  let %v566: () = vm.invoke_tvm_op(%2867, %2868, %2869) /* ty=() */;
  let %x495: Tensor[(3), int32] = %tensor_0572;
  let %storage_0667: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][678]) /* ty=Storage[] */;
  let %tensor_0573: Tensor[(3), int32] = memory.alloc_tensor(%storage_0667, 0 /* ty=int64 */, meta[relay.Constant][636] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][678]) /* ty=Tensor[(3), int32] */;
  %2872 = fn (%p0572: Tensor[(3), bool], %p1294: Tensor[(3), int32], %p2163: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int32] {
    %2870 = cast_like(%p2163, %p1294) /* ty=Tensor[(3), int32] */;
    %2871 = add(%p1294, %2870) /* ty=Tensor[(3), int32] */;
    where(%p0572, %2871, %p1294) /* ty=Tensor[(3), int32] */
  };
  %2873 = (meta[relay.Constant][637] /* ty=Tensor[(3), bool] */, meta[relay.Constant][638] /* ty=Tensor[(3), int32] */, %x495);
  %2874 = (%tensor_0573,);
  let %v567: () = vm.invoke_tvm_op(%2872, %2873, %2874) /* ty=() */;
  let %x496: Tensor[(3), int32] = %tensor_0573;
  let %storage_0668: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][679]) /* ty=Storage[] */;
  let %tensor_0574: Tensor[(3), int64] = memory.alloc_tensor(%storage_0668, 0 /* ty=int64 */, meta[relay.Constant][639] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][679]) /* ty=Tensor[(3), int64] */;
  %2875 = fn (%p0573: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int64] {
    cast(%p0573, dtype="int64") /* ty=Tensor[(3), int64] */
  };
  %2876 = (%x495,);
  %2877 = (%tensor_0574,);
  let %v568: () = vm.invoke_tvm_op(%2875, %2876, %2877) /* ty=() */;
  let %x497: Tensor[(3), int64] = %tensor_0574;
  let %in_shape_091: Tensor[(?, ?, ?), float32] = device_copy(%x494, meta[relay.attrs.DeviceCopyAttrs][149]) /* ty=Tensor[(?, ?, ?), float32] */;
  let %in_shape_160: Tensor[(3), int32] = device_copy(%x496, meta[relay.attrs.DeviceCopyAttrs][150]) /* ty=Tensor[(3), int32] */;
  let %in_shape_242: Tensor[(3), int64] = device_copy(%x497, meta[relay.attrs.DeviceCopyAttrs][151]) /* ty=Tensor[(3), int64] */;
  let %in_shape_337: Tensor[(3), int32] = device_copy(meta[relay.Constant][640] /* ty=Tensor[(3), int32] */, meta[relay.attrs.DeviceCopyAttrs][152]) /* ty=Tensor[(3), int32] */;
  let %storage_0669: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][680]) /* ty=Storage[] */;
  let %tensor_0575: Tensor[(3), int64] = memory.alloc_tensor(%storage_0669, 0 /* ty=int64 */, meta[relay.Constant][641] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][680]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_0100: Tensor[(3), int64] = %tensor_0575;
  %2878 = fn (%p0574: Tensor[(?, ?, ?), float32], %p1295: Tensor[(3), int32], %p2164: Tensor[(3), int64], %p398: Tensor[(3), int32], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.strided_slice(%p0574, %p1295, %p2164, %p398, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %2879 = (%in_shape_091, %in_shape_160, %in_shape_242, %in_shape_337);
  %2880 = (%shape_func_out_0100,);
  let %shape_func100: () = vm.shape_func(%2878, %2879, %2880, meta[relay.attrs.ShapeFuncAttrs][100]) /* ty=() */;
  let %storage_0670: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][681]) /* ty=Storage[] */;
  let %tensor_0576: int64 = memory.alloc_tensor(%storage_0670, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][681]) /* ty=int64 */;
  %2881 = fn (%p0575: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0575) /* ty=int64 */
  };
  %2882 = (%shape_func_out_0100,);
  %2883 = (%tensor_0576,);
  let %v569: () = vm.invoke_tvm_op(%2881, %2882, %2883) /* ty=() */;
  let %storage_0671: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][682]) /* ty=Storage[] */;
  let %tensor_0577: int64 = memory.alloc_tensor(%storage_0671, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][682]) /* ty=int64 */;
  %2884 = fn (%p0576: int64, Primitive=1) -> int64 {
    multiply(%p0576, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2885 = (%tensor_0576,);
  %2886 = (%tensor_0577,);
  let %v570: () = vm.invoke_tvm_op(%2884, %2885, %2886) /* ty=() */;
  let %storage_0672: Storage[] = memory.alloc_storage(%tensor_0577, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][683]) /* ty=Storage[] */;
  let %out_094: Tensor[(?, ?, ?), float32] = memory.alloc_tensor(%storage_0672, 0 /* ty=int64 */, %shape_func_out_0100, meta[relay.attrs.AllocTensorAttrs][683]) /* ty=Tensor[(?, ?, ?), float32] */;
  %2887 = (%x494, %x496, %x497, meta[relay.Constant][640] /* ty=Tensor[(3), int32] */);
  %2888 = (%out_094,);
  let %v571: () = vm.invoke_tvm_op(%2878, %2887, %2888) /* ty=() */;
  let %x498: Tensor[(?, ?, ?), float32] = %out_094;
  let %storage_0673: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][684]) /* ty=Storage[] */;
  let %tensor_0578: Tensor[(3), int32] = memory.alloc_tensor(%storage_0673, 0 /* ty=int64 */, meta[relay.Constant][642] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][684]) /* ty=Tensor[(3), int32] */;
  %2889 = fn (%p0577: Tensor[(?, ?, ?), float32], Primitive=1) -> Tensor[(3), int32] {
    shape_of(%p0577, dtype="int32") /* ty=Tensor[(3), int32] */
  };
  %2890 = (%x498,);
  %2891 = (%tensor_0578,);
  let %v572: () = vm.invoke_tvm_op(%2889, %2890, %2891) /* ty=() */;
  let %x499: Tensor[(3), int32] = %tensor_0578;
  let %storage_0674: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][685]) /* ty=Storage[] */;
  let %tensor_0579: Tensor[(3), int32] = memory.alloc_tensor(%storage_0674, 0 /* ty=int64 */, meta[relay.Constant][643] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][685]) /* ty=Tensor[(3), int32] */;
  %2894 = fn (%p0578: Tensor[(3), bool], %p1296: Tensor[(3), int32], %p2165: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int32] {
    %2892 = cast_like(%p2165, %p1296) /* ty=Tensor[(3), int32] */;
    %2893 = add(%p1296, %2892) /* ty=Tensor[(3), int32] */;
    where(%p0578, %2893, %p1296) /* ty=Tensor[(3), int32] */
  };
  %2895 = (meta[relay.Constant][644] /* ty=Tensor[(3), bool] */, meta[relay.Constant][645] /* ty=Tensor[(3), int32] */, %x499);
  %2896 = (%tensor_0579,);
  let %v573: () = vm.invoke_tvm_op(%2894, %2895, %2896) /* ty=() */;
  let %x500: Tensor[(3), int32] = %tensor_0579;
  let %storage_0675: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][686]) /* ty=Storage[] */;
  let %tensor_0580: Tensor[(3), int64] = memory.alloc_tensor(%storage_0675, 0 /* ty=int64 */, meta[relay.Constant][646] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][686]) /* ty=Tensor[(3), int64] */;
  %2897 = fn (%p0579: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int64] {
    cast(%p0579, dtype="int64") /* ty=Tensor[(3), int64] */
  };
  %2898 = (%x499,);
  %2899 = (%tensor_0580,);
  let %v574: () = vm.invoke_tvm_op(%2897, %2898, %2899) /* ty=() */;
  let %x501: Tensor[(3), int64] = %tensor_0580;
  let %in_shape_092: Tensor[(?, ?, ?), float32] = device_copy(%x498, meta[relay.attrs.DeviceCopyAttrs][153]) /* ty=Tensor[(?, ?, ?), float32] */;
  let %in_shape_161: Tensor[(3), int32] = device_copy(%x500, meta[relay.attrs.DeviceCopyAttrs][154]) /* ty=Tensor[(3), int32] */;
  let %in_shape_243: Tensor[(3), int64] = device_copy(%x501, meta[relay.attrs.DeviceCopyAttrs][155]) /* ty=Tensor[(3), int64] */;
  let %in_shape_338: Tensor[(3), int32] = device_copy(meta[relay.Constant][647] /* ty=Tensor[(3), int32] */, meta[relay.attrs.DeviceCopyAttrs][156]) /* ty=Tensor[(3), int32] */;
  let %storage_0676: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][687]) /* ty=Storage[] */;
  let %tensor_0581: Tensor[(3), int64] = memory.alloc_tensor(%storage_0676, 0 /* ty=int64 */, meta[relay.Constant][648] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][687]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_0101: Tensor[(3), int64] = %tensor_0581;
  %2900 = fn (%p0580: Tensor[(?, ?, ?), float32], %p1297: Tensor[(3), int32], %p2166: Tensor[(3), int64], %p399: Tensor[(3), int32], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.strided_slice(%p0580, %p1297, %p2166, %p399, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %2901 = (%in_shape_092, %in_shape_161, %in_shape_243, %in_shape_338);
  %2902 = (%shape_func_out_0101,);
  let %shape_func101: () = vm.shape_func(%2900, %2901, %2902, meta[relay.attrs.ShapeFuncAttrs][101]) /* ty=() */;
  let %storage_0677: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][688]) /* ty=Storage[] */;
  let %tensor_0582: int64 = memory.alloc_tensor(%storage_0677, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][688]) /* ty=int64 */;
  %2903 = fn (%p0581: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0581) /* ty=int64 */
  };
  %2904 = (%shape_func_out_0101,);
  %2905 = (%tensor_0582,);
  let %v575: () = vm.invoke_tvm_op(%2903, %2904, %2905) /* ty=() */;
  let %storage_0678: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][689]) /* ty=Storage[] */;
  let %tensor_0583: int64 = memory.alloc_tensor(%storage_0678, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][689]) /* ty=int64 */;
  %2906 = fn (%p0582: int64, Primitive=1) -> int64 {
    multiply(%p0582, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2907 = (%tensor_0582,);
  %2908 = (%tensor_0583,);
  let %v576: () = vm.invoke_tvm_op(%2906, %2907, %2908) /* ty=() */;
  let %storage_0679: Storage[] = memory.alloc_storage(%tensor_0583, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][690]) /* ty=Storage[] */;
  let %out_095: Tensor[(?, ?, ?), float32] = memory.alloc_tensor(%storage_0679, 0 /* ty=int64 */, %shape_func_out_0101, meta[relay.attrs.AllocTensorAttrs][690]) /* ty=Tensor[(?, ?, ?), float32] */;
  %2909 = (%x498, %x500, %x501, meta[relay.Constant][647] /* ty=Tensor[(3), int32] */);
  %2910 = (%out_095,);
  let %v577: () = vm.invoke_tvm_op(%2900, %2909, %2910) /* ty=() */;
  let %x502: Tensor[(?, ?, ?), float32] = %out_095;
  let %in_shape_093: Tensor[(3), int64] = vm.shape_of(%x502, meta[relay.attrs.ShapeOfAttrs][89]) /* ty=Tensor[(3), int64] */;
  let %in_shape_162: Tensor[(1), int64] = vm.shape_of(%x412, meta[relay.attrs.ShapeOfAttrs][90]) /* ty=Tensor[(1), int64] */;
  let %storage_0680: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][691]) /* ty=Storage[] */;
  let %tensor_0584: Tensor[(2), int64] = memory.alloc_tensor(%storage_0680, 0 /* ty=int64 */, meta[relay.Constant][649] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][691]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0102: Tensor[(2), int64] = %tensor_0584;
  %2913 = fn (%p0583: Tensor[(?, ?, ?), float32], %p1298: Tensor[(?), int64], Primitive=1) -> Tensor[(?, 4), float32] {
    %2911 = reshape(%p0583, newshape=[-1, 4]) /* ty=Tensor[(?, 4), float32] */;
    %2912 = (%2911, %p1298);
    adv_index(%2912) /* ty=Tensor[(?, 4), float32] */
  };
  %2914 = (%in_shape_093, %in_shape_162);
  %2915 = (%shape_func_out_0102,);
  let %shape_func102: () = vm.shape_func(%2913, %2914, %2915, meta[relay.attrs.ShapeFuncAttrs][102]) /* ty=() */;
  let %storage_0681: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][692]) /* ty=Storage[] */;
  let %tensor_0585: int64 = memory.alloc_tensor(%storage_0681, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][692]) /* ty=int64 */;
  %2916 = fn (%p0584: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0584) /* ty=int64 */
  };
  %2917 = (%shape_func_out_0102,);
  %2918 = (%tensor_0585,);
  let %v578: () = vm.invoke_tvm_op(%2916, %2917, %2918) /* ty=() */;
  let %storage_0682: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][693]) /* ty=Storage[] */;
  let %tensor_0586: int64 = memory.alloc_tensor(%storage_0682, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][693]) /* ty=int64 */;
  %2919 = fn (%p0585: int64, Primitive=1) -> int64 {
    multiply(%p0585, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2920 = (%tensor_0585,);
  %2921 = (%tensor_0586,);
  let %v579: () = vm.invoke_tvm_op(%2919, %2920, %2921) /* ty=() */;
  let %storage_0683: Storage[] = memory.alloc_storage(%tensor_0586, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][694]) /* ty=Storage[] */;
  let %out_096: Tensor[(?, 4), float32] = memory.alloc_tensor(%storage_0683, 0 /* ty=int64 */, %shape_func_out_0102, meta[relay.attrs.AllocTensorAttrs][694]) /* ty=Tensor[(?, 4), float32] */;
  %2922 = (%x502, %x412);
  %2923 = (%out_096,);
  let %v580: () = vm.invoke_tvm_op(%2913, %2922, %2923) /* ty=() */;
  let %x503: Tensor[(?, 4), float32] = %out_096;
  let %storage_0684: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][695]) /* ty=Storage[] */;
  let %tensor_0587: Tensor[(2), int32] = memory.alloc_tensor(%storage_0684, 0 /* ty=int64 */, meta[relay.Constant][650] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][695]) /* ty=Tensor[(2), int32] */;
  %2924 = fn (%p0586: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0586, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %2925 = (%x503,);
  %2926 = (%tensor_0587,);
  let %v581: () = vm.invoke_tvm_op(%2924, %2925, %2926) /* ty=() */;
  let %x504: Tensor[(2), int32] = %tensor_0587;
  let %storage_0685: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][696]) /* ty=Storage[] */;
  let %tensor_0588: Tensor[(2), int32] = memory.alloc_tensor(%storage_0685, 0 /* ty=int64 */, meta[relay.Constant][651] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][696]) /* ty=Tensor[(2), int32] */;
  %2929 = fn (%p0587: Tensor[(2), bool], %p1299: Tensor[(2), int32], %p2167: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2927 = cast_like(%p2167, %p1299) /* ty=Tensor[(2), int32] */;
    %2928 = add(%p1299, %2927) /* ty=Tensor[(2), int32] */;
    where(%p0587, %2928, %p1299) /* ty=Tensor[(2), int32] */
  };
  %2930 = (meta[relay.Constant][652] /* ty=Tensor[(2), bool] */, meta[relay.Constant][653] /* ty=Tensor[(2), int32] */, %x504);
  %2931 = (%tensor_0588,);
  let %v582: () = vm.invoke_tvm_op(%2929, %2930, %2931) /* ty=() */;
  let %x505: Tensor[(2), int32] = %tensor_0588;
  let %storage_0686: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][697]) /* ty=Storage[] */;
  let %tensor_0589: Tensor[(2), int64] = memory.alloc_tensor(%storage_0686, 0 /* ty=int64 */, meta[relay.Constant][654] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][697]) /* ty=Tensor[(2), int64] */;
  %2932 = fn (%p0588: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0588, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %2933 = (%x504,);
  %2934 = (%tensor_0589,);
  let %v583: () = vm.invoke_tvm_op(%2932, %2933, %2934) /* ty=() */;
  let %x506: Tensor[(2), int64] = %tensor_0589;
  let %in_shape_094: Tensor[(?, 4), float32] = device_copy(%x503, meta[relay.attrs.DeviceCopyAttrs][157]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_163: Tensor[(2), int32] = device_copy(%x505, meta[relay.attrs.DeviceCopyAttrs][158]) /* ty=Tensor[(2), int32] */;
  let %in_shape_244: Tensor[(2), int64] = device_copy(%x506, meta[relay.attrs.DeviceCopyAttrs][159]) /* ty=Tensor[(2), int64] */;
  let %in_shape_339: Tensor[(2), int32] = device_copy(meta[relay.Constant][655] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][160]) /* ty=Tensor[(2), int32] */;
  let %storage_0687: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][698]) /* ty=Storage[] */;
  let %tensor_0590: Tensor[(2), int64] = memory.alloc_tensor(%storage_0687, 0 /* ty=int64 */, meta[relay.Constant][656] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][698]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0103: Tensor[(2), int64] = %tensor_0590;
  %2935 = fn (%p0589: Tensor[(?, 4), float32], %p1300: Tensor[(2), int32], %p2168: Tensor[(2), int64], %p3100: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0589, %p1300, %p2168, %p3100, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2936 = (%in_shape_094, %in_shape_163, %in_shape_244, %in_shape_339);
  %2937 = (%shape_func_out_0103,);
  let %shape_func103: () = vm.shape_func(%2935, %2936, %2937, meta[relay.attrs.ShapeFuncAttrs][103]) /* ty=() */;
  let %storage_0688: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][699]) /* ty=Storage[] */;
  let %tensor_0591: int64 = memory.alloc_tensor(%storage_0688, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][699]) /* ty=int64 */;
  %2938 = fn (%p0590: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0590) /* ty=int64 */
  };
  %2939 = (%shape_func_out_0103,);
  %2940 = (%tensor_0591,);
  let %v584: () = vm.invoke_tvm_op(%2938, %2939, %2940) /* ty=() */;
  let %storage_0689: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][700]) /* ty=Storage[] */;
  let %tensor_0592: int64 = memory.alloc_tensor(%storage_0689, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][700]) /* ty=int64 */;
  %2941 = fn (%p0591: int64, Primitive=1) -> int64 {
    multiply(%p0591, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2942 = (%tensor_0591,);
  %2943 = (%tensor_0592,);
  let %v585: () = vm.invoke_tvm_op(%2941, %2942, %2943) /* ty=() */;
  let %storage_0690: Storage[] = memory.alloc_storage(%tensor_0592, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][701]) /* ty=Storage[] */;
  let %out_097: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0690, 0 /* ty=int64 */, %shape_func_out_0103, meta[relay.attrs.AllocTensorAttrs][701]) /* ty=Tensor[(?, ?), float32] */;
  %2944 = (%x503, %x505, %x506, meta[relay.Constant][655] /* ty=Tensor[(2), int32] */);
  %2945 = (%out_097,);
  let %v586: () = vm.invoke_tvm_op(%2935, %2944, %2945) /* ty=() */;
  let %x507: Tensor[(?, ?), float32] = %out_097;
  let %storage_0691: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][702]) /* ty=Storage[] */;
  let %tensor_0593: Tensor[(2), int32] = memory.alloc_tensor(%storage_0691, 0 /* ty=int64 */, meta[relay.Constant][657] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][702]) /* ty=Tensor[(2), int32] */;
  %2948 = fn (%p0592: Tensor[(2), bool], %p1301: Tensor[(2), int32], %p2169: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2946 = cast_like(%p2169, %p1301) /* ty=Tensor[(2), int32] */;
    %2947 = add(%p1301, %2946) /* ty=Tensor[(2), int32] */;
    where(%p0592, %2947, %p1301) /* ty=Tensor[(2), int32] */
  };
  %2949 = (meta[relay.Constant][658] /* ty=Tensor[(2), bool] */, meta[relay.Constant][659] /* ty=Tensor[(2), int32] */, %x504);
  %2950 = (%tensor_0593,);
  let %v587: () = vm.invoke_tvm_op(%2948, %2949, %2950) /* ty=() */;
  let %x508: Tensor[(2), int32] = %tensor_0593;
  let %in_shape_095: Tensor[(?, 4), float32] = device_copy(%x503, meta[relay.attrs.DeviceCopyAttrs][161]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_164: Tensor[(2), int32] = device_copy(%x508, meta[relay.attrs.DeviceCopyAttrs][162]) /* ty=Tensor[(2), int32] */;
  let %in_shape_245: Tensor[(2), int64] = device_copy(%x506, meta[relay.attrs.DeviceCopyAttrs][163]) /* ty=Tensor[(2), int64] */;
  let %in_shape_340: Tensor[(2), int32] = device_copy(meta[relay.Constant][660] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][164]) /* ty=Tensor[(2), int32] */;
  let %storage_0692: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][703]) /* ty=Storage[] */;
  let %tensor_0594: Tensor[(2), int64] = memory.alloc_tensor(%storage_0692, 0 /* ty=int64 */, meta[relay.Constant][661] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][703]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0104: Tensor[(2), int64] = %tensor_0594;
  %2951 = fn (%p0593: Tensor[(?, 4), float32], %p1302: Tensor[(2), int32], %p2170: Tensor[(2), int64], %p3101: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0593, %p1302, %p2170, %p3101, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2952 = (%in_shape_095, %in_shape_164, %in_shape_245, %in_shape_340);
  %2953 = (%shape_func_out_0104,);
  let %shape_func104: () = vm.shape_func(%2951, %2952, %2953, meta[relay.attrs.ShapeFuncAttrs][104]) /* ty=() */;
  let %storage_0693: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][704]) /* ty=Storage[] */;
  let %tensor_0595: int64 = memory.alloc_tensor(%storage_0693, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][704]) /* ty=int64 */;
  %2954 = fn (%p0594: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0594) /* ty=int64 */
  };
  %2955 = (%shape_func_out_0104,);
  %2956 = (%tensor_0595,);
  let %v588: () = vm.invoke_tvm_op(%2954, %2955, %2956) /* ty=() */;
  let %storage_0694: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][705]) /* ty=Storage[] */;
  let %tensor_0596: int64 = memory.alloc_tensor(%storage_0694, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][705]) /* ty=int64 */;
  %2957 = fn (%p0595: int64, Primitive=1) -> int64 {
    multiply(%p0595, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2958 = (%tensor_0595,);
  %2959 = (%tensor_0596,);
  let %v589: () = vm.invoke_tvm_op(%2957, %2958, %2959) /* ty=() */;
  let %storage_0695: Storage[] = memory.alloc_storage(%tensor_0596, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][706]) /* ty=Storage[] */;
  let %out_098: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0695, 0 /* ty=int64 */, %shape_func_out_0104, meta[relay.attrs.AllocTensorAttrs][706]) /* ty=Tensor[(?, ?), float32] */;
  %2960 = (%x503, %x508, %x506, meta[relay.Constant][660] /* ty=Tensor[(2), int32] */);
  %2961 = (%out_098,);
  let %v590: () = vm.invoke_tvm_op(%2951, %2960, %2961) /* ty=() */;
  let %x509: Tensor[(?, ?), float32] = %out_098;
  let %storage_0696: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][707]) /* ty=Storage[] */;
  let %tensor_0597: Tensor[(2), int32] = memory.alloc_tensor(%storage_0696, 0 /* ty=int64 */, meta[relay.Constant][662] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][707]) /* ty=Tensor[(2), int32] */;
  %2964 = fn (%p0596: Tensor[(2), bool], %p1303: Tensor[(2), int32], %p2171: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2962 = cast_like(%p2171, %p1303) /* ty=Tensor[(2), int32] */;
    %2963 = add(%p1303, %2962) /* ty=Tensor[(2), int32] */;
    where(%p0596, %2963, %p1303) /* ty=Tensor[(2), int32] */
  };
  %2965 = (meta[relay.Constant][663] /* ty=Tensor[(2), bool] */, meta[relay.Constant][664] /* ty=Tensor[(2), int32] */, %x504);
  %2966 = (%tensor_0597,);
  let %v591: () = vm.invoke_tvm_op(%2964, %2965, %2966) /* ty=() */;
  let %x510: Tensor[(2), int32] = %tensor_0597;
  let %in_shape_096: Tensor[(?, 4), float32] = device_copy(%x503, meta[relay.attrs.DeviceCopyAttrs][165]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_165: Tensor[(2), int32] = device_copy(%x510, meta[relay.attrs.DeviceCopyAttrs][166]) /* ty=Tensor[(2), int32] */;
  let %in_shape_246: Tensor[(2), int64] = device_copy(%x506, meta[relay.attrs.DeviceCopyAttrs][167]) /* ty=Tensor[(2), int64] */;
  let %in_shape_341: Tensor[(2), int32] = device_copy(meta[relay.Constant][665] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][168]) /* ty=Tensor[(2), int32] */;
  let %storage_0697: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][708]) /* ty=Storage[] */;
  let %tensor_0598: Tensor[(2), int64] = memory.alloc_tensor(%storage_0697, 0 /* ty=int64 */, meta[relay.Constant][666] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][708]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0105: Tensor[(2), int64] = %tensor_0598;
  %2967 = fn (%p0597: Tensor[(?, 4), float32], %p1304: Tensor[(2), int32], %p2172: Tensor[(2), int64], %p3102: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0597, %p1304, %p2172, %p3102, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2968 = (%in_shape_096, %in_shape_165, %in_shape_246, %in_shape_341);
  %2969 = (%shape_func_out_0105,);
  let %shape_func105: () = vm.shape_func(%2967, %2968, %2969, meta[relay.attrs.ShapeFuncAttrs][105]) /* ty=() */;
  let %storage_0698: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][709]) /* ty=Storage[] */;
  let %tensor_0599: int64 = memory.alloc_tensor(%storage_0698, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][709]) /* ty=int64 */;
  %2970 = fn (%p0598: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0598) /* ty=int64 */
  };
  %2971 = (%shape_func_out_0105,);
  %2972 = (%tensor_0599,);
  let %v592: () = vm.invoke_tvm_op(%2970, %2971, %2972) /* ty=() */;
  let %storage_0699: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][710]) /* ty=Storage[] */;
  let %tensor_0600: int64 = memory.alloc_tensor(%storage_0699, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][710]) /* ty=int64 */;
  %2973 = fn (%p0599: int64, Primitive=1) -> int64 {
    multiply(%p0599, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2974 = (%tensor_0599,);
  %2975 = (%tensor_0600,);
  let %v593: () = vm.invoke_tvm_op(%2973, %2974, %2975) /* ty=() */;
  let %storage_0700: Storage[] = memory.alloc_storage(%tensor_0600, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][711]) /* ty=Storage[] */;
  let %out_099: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0700, 0 /* ty=int64 */, %shape_func_out_0105, meta[relay.attrs.AllocTensorAttrs][711]) /* ty=Tensor[(?, ?), float32] */;
  %2976 = (%x503, %x510, %x506, meta[relay.Constant][665] /* ty=Tensor[(2), int32] */);
  %2977 = (%out_099,);
  let %v594: () = vm.invoke_tvm_op(%2967, %2976, %2977) /* ty=() */;
  let %x511: Tensor[(?, ?), float32] = %out_099;
  let %storage_0701: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][712]) /* ty=Storage[] */;
  let %tensor_0601: Tensor[(2), int32] = memory.alloc_tensor(%storage_0701, 0 /* ty=int64 */, meta[relay.Constant][667] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][712]) /* ty=Tensor[(2), int32] */;
  %2980 = fn (%p0600: Tensor[(2), bool], %p1305: Tensor[(2), int32], %p2173: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %2978 = cast_like(%p2173, %p1305) /* ty=Tensor[(2), int32] */;
    %2979 = add(%p1305, %2978) /* ty=Tensor[(2), int32] */;
    where(%p0600, %2979, %p1305) /* ty=Tensor[(2), int32] */
  };
  %2981 = (meta[relay.Constant][668] /* ty=Tensor[(2), bool] */, meta[relay.Constant][669] /* ty=Tensor[(2), int32] */, %x504);
  %2982 = (%tensor_0601,);
  let %v595: () = vm.invoke_tvm_op(%2980, %2981, %2982) /* ty=() */;
  let %x512: Tensor[(2), int32] = %tensor_0601;
  let %in_shape_097: Tensor[(?, 4), float32] = device_copy(%x503, meta[relay.attrs.DeviceCopyAttrs][169]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_166: Tensor[(2), int32] = device_copy(%x512, meta[relay.attrs.DeviceCopyAttrs][170]) /* ty=Tensor[(2), int32] */;
  let %in_shape_247: Tensor[(2), int64] = device_copy(%x506, meta[relay.attrs.DeviceCopyAttrs][171]) /* ty=Tensor[(2), int64] */;
  let %in_shape_342: Tensor[(2), int32] = device_copy(meta[relay.Constant][670] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][172]) /* ty=Tensor[(2), int32] */;
  let %storage_0702: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][713]) /* ty=Storage[] */;
  let %tensor_0602: Tensor[(2), int64] = memory.alloc_tensor(%storage_0702, 0 /* ty=int64 */, meta[relay.Constant][671] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][713]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0106: Tensor[(2), int64] = %tensor_0602;
  %2983 = fn (%p0601: Tensor[(?, 4), float32], %p1306: Tensor[(2), int32], %p2174: Tensor[(2), int64], %p3103: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0601, %p1306, %p2174, %p3103, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %2984 = (%in_shape_097, %in_shape_166, %in_shape_247, %in_shape_342);
  %2985 = (%shape_func_out_0106,);
  let %shape_func106: () = vm.shape_func(%2983, %2984, %2985, meta[relay.attrs.ShapeFuncAttrs][106]) /* ty=() */;
  let %storage_0703: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][714]) /* ty=Storage[] */;
  let %tensor_0603: int64 = memory.alloc_tensor(%storage_0703, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][714]) /* ty=int64 */;
  %2986 = fn (%p0602: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0602) /* ty=int64 */
  };
  %2987 = (%shape_func_out_0106,);
  %2988 = (%tensor_0603,);
  let %v596: () = vm.invoke_tvm_op(%2986, %2987, %2988) /* ty=() */;
  let %storage_0704: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][715]) /* ty=Storage[] */;
  let %tensor_0604: int64 = memory.alloc_tensor(%storage_0704, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][715]) /* ty=int64 */;
  %2989 = fn (%p0603: int64, Primitive=1) -> int64 {
    multiply(%p0603, 4 /* ty=int64 */) /* ty=int64 */
  };
  %2990 = (%tensor_0603,);
  %2991 = (%tensor_0604,);
  let %v597: () = vm.invoke_tvm_op(%2989, %2990, %2991) /* ty=() */;
  let %storage_0705: Storage[] = memory.alloc_storage(%tensor_0604, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][716]) /* ty=Storage[] */;
  let %out_0100: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0705, 0 /* ty=int64 */, %shape_func_out_0106, meta[relay.attrs.AllocTensorAttrs][716]) /* ty=Tensor[(?, ?), float32] */;
  %2992 = (%x503, %x512, %x506, meta[relay.Constant][670] /* ty=Tensor[(2), int32] */);
  %2993 = (%out_0100,);
  let %v598: () = vm.invoke_tvm_op(%2983, %2992, %2993) /* ty=() */;
  let %x513: Tensor[(?, ?), float32] = %out_0100;
  let %in_shape_098: Tensor[(2), int64] = vm.shape_of(%x507, meta[relay.attrs.ShapeOfAttrs][91]) /* ty=Tensor[(2), int64] */;
  let %in_shape_167: Tensor[(2), int64] = vm.shape_of(%x509, meta[relay.attrs.ShapeOfAttrs][92]) /* ty=Tensor[(2), int64] */;
  let %in_shape_248: Tensor[(2), int64] = vm.shape_of(%x511, meta[relay.attrs.ShapeOfAttrs][93]) /* ty=Tensor[(2), int64] */;
  let %in_shape_343: Tensor[(2), int64] = vm.shape_of(%x513, meta[relay.attrs.ShapeOfAttrs][94]) /* ty=Tensor[(2), int64] */;
  let %storage_0706: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][717]) /* ty=Storage[] */;
  let %tensor_0605: Tensor[(1), int64] = memory.alloc_tensor(%storage_0706, 0 /* ty=int64 */, meta[relay.Constant][672] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][717]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0107: Tensor[(1), int64] = %tensor_0605;
  %3004 = fn (%p0604: Tensor[(?, ?), float32], %p1307: Tensor[(?, ?), float32], %p2175: Tensor[(?, ?), float32], %p3104: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?), bool] {
    %2994 = take(%p0604, 2 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %2995 = take(%p1307, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %2996 = subtract(%2994, %2995) /* ty=Tensor[(?), float32] */;
    %2997 = greater_equal(%2996, 0.01f /* ty=float32 */) /* ty=Tensor[(?), bool] */;
    %2998 = cast(%2997, dtype="bool") /* ty=Tensor[(?), bool] */;
    %2999 = take(%p2175, 3 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %3000 = take(%p3104, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %3001 = subtract(%2999, %3000) /* ty=Tensor[(?), float32] */;
    %3002 = greater_equal(%3001, 0.01f /* ty=float32 */) /* ty=Tensor[(?), bool] */;
    %3003 = cast(%3002, dtype="bool") /* ty=Tensor[(?), bool] */;
    logical_and(%2998, %3003) /* ty=Tensor[(?), bool] */
  };
  %3005 = (%in_shape_098, %in_shape_167, %in_shape_248, %in_shape_343);
  %3006 = (%shape_func_out_0107,);
  let %shape_func107: () = vm.shape_func(%3004, %3005, %3006, meta[relay.attrs.ShapeFuncAttrs][107]) /* ty=() */;
  let %storage_0707: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][718]) /* ty=Storage[] */;
  let %tensor_0606: int64 = memory.alloc_tensor(%storage_0707, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][718]) /* ty=int64 */;
  %3007 = fn (%p0605: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0605) /* ty=int64 */
  };
  %3008 = (%shape_func_out_0107,);
  %3009 = (%tensor_0606,);
  let %v599: () = vm.invoke_tvm_op(%3007, %3008, %3009) /* ty=() */;
  let %storage_0708: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][719]) /* ty=Storage[] */;
  let %tensor_0607: int64 = memory.alloc_tensor(%storage_0708, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][719]) /* ty=int64 */;
  %3010 = fn (%p0606: int64, Primitive=1) -> int64 {
    multiply(%p0606, 1 /* ty=int64 */) /* ty=int64 */
  };
  %3011 = (%tensor_0606,);
  %3012 = (%tensor_0607,);
  let %v600: () = vm.invoke_tvm_op(%3010, %3011, %3012) /* ty=() */;
  let %storage_0709: Storage[] = memory.alloc_storage(%tensor_0607, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][720]) /* ty=Storage[] */;
  let %out_0101: Tensor[(?), bool] = memory.alloc_tensor(%storage_0709, 0 /* ty=int64 */, %shape_func_out_0107, meta[relay.attrs.AllocTensorAttrs][720]) /* ty=Tensor[(?), bool] */;
  %3013 = (%x507, %x509, %x511, %x513);
  %3014 = (%out_0101,);
  let %v601: () = vm.invoke_tvm_op(%3004, %3013, %3014) /* ty=() */;
  let %x514: Tensor[(?), bool] = %out_0101;
  let %in_shape_099: Tensor[(?), bool] = device_copy(%x514, meta[relay.attrs.DeviceCopyAttrs][173]) /* ty=Tensor[(?), bool] */;
  let %storage_0710: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][721]) /* ty=Storage[] */;
  let %tensor_0608: Tensor[(2), int64] = memory.alloc_tensor(%storage_0710, 0 /* ty=int64 */, meta[relay.Constant][673] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][721]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0108: Tensor[(2), int64] = %tensor_0608;
  %3015 = fn (%p0607: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0607) /* ty=Tensor[(?, 1), int32] */
  };
  %3016 = (%in_shape_099,);
  %3017 = (%shape_func_out_0108,);
  let %shape_func108: () = vm.shape_func(%3015, %3016, %3017, meta[relay.attrs.ShapeFuncAttrs][108]) /* ty=() */;
  let %storage_0711: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][722]) /* ty=Storage[] */;
  let %tensor_0609: int64 = memory.alloc_tensor(%storage_0711, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][722]) /* ty=int64 */;
  %3018 = fn (%p0608: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0608) /* ty=int64 */
  };
  %3019 = (%shape_func_out_0108,);
  %3020 = (%tensor_0609,);
  let %v602: () = vm.invoke_tvm_op(%3018, %3019, %3020) /* ty=() */;
  let %storage_0712: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][723]) /* ty=Storage[] */;
  let %tensor_0610: int64 = memory.alloc_tensor(%storage_0712, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][723]) /* ty=int64 */;
  %3021 = fn (%p0609: int64, Primitive=1) -> int64 {
    multiply(%p0609, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3022 = (%tensor_0609,);
  %3023 = (%tensor_0610,);
  let %v603: () = vm.invoke_tvm_op(%3021, %3022, %3023) /* ty=() */;
  let %storage_0713: Storage[] = memory.alloc_storage(%tensor_0610, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][724]) /* ty=Storage[] */;
  let %out_0102: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0713, 0 /* ty=int64 */, %shape_func_out_0108, meta[relay.attrs.AllocTensorAttrs][724]) /* ty=Tensor[(?, 1), int32] */;
  %3024 = (%x514,);
  %3025 = (%out_0102,);
  let %v604: () = vm.invoke_tvm_op(%3015, %3024, %3025) /* ty=() */;
  let %x515: Tensor[(?, 1), int32] = %out_0102;
  let %in_shape_0100: Tensor[(2), int64] = vm.shape_of(%x515, meta[relay.attrs.ShapeOfAttrs][95]) /* ty=Tensor[(2), int64] */;
  let %storage_0714: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][725]) /* ty=Storage[] */;
  let %tensor_0611: Tensor[(1), int64] = memory.alloc_tensor(%storage_0714, 0 /* ty=int64 */, meta[relay.Constant][674] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][725]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0109: Tensor[(1), int64] = %tensor_0611;
  %3029 = fn (%p0610: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int64] {
    %3026 = split(%p0610, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %3027 = %3026.0;
    %3028 = squeeze(%3027, axis=[1]) /* ty=Tensor[(?), int32] */;
    cast(%3028, dtype="int64") /* ty=Tensor[(?), int64] */
  };
  %3030 = (%in_shape_0100,);
  %3031 = (%shape_func_out_0109,);
  let %shape_func109: () = vm.shape_func(%3029, %3030, %3031, meta[relay.attrs.ShapeFuncAttrs][109]) /* ty=() */;
  let %storage_0715: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][726]) /* ty=Storage[] */;
  let %tensor_0612: int64 = memory.alloc_tensor(%storage_0715, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][726]) /* ty=int64 */;
  %3032 = fn (%p0611: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0611) /* ty=int64 */
  };
  %3033 = (%shape_func_out_0109,);
  %3034 = (%tensor_0612,);
  let %v605: () = vm.invoke_tvm_op(%3032, %3033, %3034) /* ty=() */;
  let %storage_0716: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][727]) /* ty=Storage[] */;
  let %tensor_0613: int64 = memory.alloc_tensor(%storage_0716, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][727]) /* ty=int64 */;
  %3035 = fn (%p0612: int64, Primitive=1) -> int64 {
    multiply(%p0612, 8 /* ty=int64 */) /* ty=int64 */
  };
  %3036 = (%tensor_0612,);
  %3037 = (%tensor_0613,);
  let %v606: () = vm.invoke_tvm_op(%3035, %3036, %3037) /* ty=() */;
  let %storage_0717: Storage[] = memory.alloc_storage(%tensor_0613, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][728]) /* ty=Storage[] */;
  let %out_0103: Tensor[(?), int64] = memory.alloc_tensor(%storage_0717, 0 /* ty=int64 */, %shape_func_out_0109, meta[relay.attrs.AllocTensorAttrs][728]) /* ty=Tensor[(?), int64] */;
  %3038 = (%x515,);
  %3039 = (%out_0103,);
  let %v607: () = vm.invoke_tvm_op(%3029, %3038, %3039) /* ty=() */;
  let %x516: Tensor[(?), int64] = %out_0103;
  let %in_shape_0101: Tensor[(2), int64] = vm.shape_of(%x400, meta[relay.attrs.ShapeOfAttrs][96]) /* ty=Tensor[(2), int64] */;
  let %in_shape_168: Tensor[(1), int64] = vm.shape_of(%x412, meta[relay.attrs.ShapeOfAttrs][97]) /* ty=Tensor[(1), int64] */;
  let %in_shape_249: Tensor[(1), int64] = vm.shape_of(%x516, meta[relay.attrs.ShapeOfAttrs][98]) /* ty=Tensor[(1), int64] */;
  let %storage_0718: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][729]) /* ty=Storage[] */;
  let %tensor_0614: Tensor[(1), int64] = memory.alloc_tensor(%storage_0718, 0 /* ty=int64 */, meta[relay.Constant][675] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][729]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0110: Tensor[(1), int64] = %tensor_0614;
  %3044 = fn (%p0613: Tensor[(?, ?), int64], %p1308: Tensor[(?), int64], %p2176: Tensor[(?), int64], Primitive=1) -> Tensor[(?), int64] {
    %3040 = reshape(%p0613, newshape=[-1]) /* ty=Tensor[(?), int64] */;
    %3041 = (%3040, %p1308);
    %3042 = adv_index(%3041) /* ty=Tensor[(?), int64] */;
    %3043 = (%3042, %p2176);
    adv_index(%3043) /* ty=Tensor[(?), int64] */
  };
  %3045 = (%in_shape_0101, %in_shape_168, %in_shape_249);
  %3046 = (%shape_func_out_0110,);
  let %shape_func110: () = vm.shape_func(%3044, %3045, %3046, meta[relay.attrs.ShapeFuncAttrs][110]) /* ty=() */;
  let %storage_0719: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][730]) /* ty=Storage[] */;
  let %tensor_0615: int64 = memory.alloc_tensor(%storage_0719, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][730]) /* ty=int64 */;
  %3047 = fn (%p0614: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0614) /* ty=int64 */
  };
  %3048 = (%shape_func_out_0110,);
  %3049 = (%tensor_0615,);
  let %v608: () = vm.invoke_tvm_op(%3047, %3048, %3049) /* ty=() */;
  let %storage_0720: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][731]) /* ty=Storage[] */;
  let %tensor_0616: int64 = memory.alloc_tensor(%storage_0720, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][731]) /* ty=int64 */;
  %3050 = fn (%p0615: int64, Primitive=1) -> int64 {
    multiply(%p0615, 8 /* ty=int64 */) /* ty=int64 */
  };
  %3051 = (%tensor_0615,);
  %3052 = (%tensor_0616,);
  let %v609: () = vm.invoke_tvm_op(%3050, %3051, %3052) /* ty=() */;
  let %storage_0721: Storage[] = memory.alloc_storage(%tensor_0616, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][732]) /* ty=Storage[] */;
  let %out_0104: Tensor[(?), int64] = memory.alloc_tensor(%storage_0721, 0 /* ty=int64 */, %shape_func_out_0110, meta[relay.attrs.AllocTensorAttrs][732]) /* ty=Tensor[(?), int64] */;
  %3053 = (%x400, %x412, %x516);
  %3054 = (%out_0104,);
  let %v610: () = vm.invoke_tvm_op(%3044, %3053, %3054) /* ty=() */;
  let %x517: Tensor[(?), int64] = %out_0104;
  let %x518: (Tensor[(?, 4), float32], Tensor[(?), float32], Tensor[(?), int64], Tensor[(?, 1, ?, ?), float32]) = let %in_shape_0102: Tensor[(1), int64] = vm.shape_of(%x409, meta[relay.attrs.ShapeOfAttrs][99]) /* ty=Tensor[(1), int64] */;
  let %in_shape_169: Tensor[(1), int64] = vm.shape_of(%x412, meta[relay.attrs.ShapeOfAttrs][100]) /* ty=Tensor[(1), int64] */;
  let %in_shape_250: Tensor[(1), int64] = vm.shape_of(%x516, meta[relay.attrs.ShapeOfAttrs][101]) /* ty=Tensor[(1), int64] */;
  let %storage_0722: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][733]) /* ty=Storage[] */;
  let %tensor_0617: Tensor[(1), int64] = memory.alloc_tensor(%storage_0722, 0 /* ty=int64 */, meta[relay.Constant][676] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][733]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0111: Tensor[(1), int64] = %tensor_0617;
  %3058 = fn (%p0616: Tensor[(?), float32], %p1309: Tensor[(?), int64], %p2177: Tensor[(?), int64], Primitive=1) -> Tensor[(?), float32] {
    %3055 = (%p0616, %p1309);
    %3056 = adv_index(%3055) /* ty=Tensor[(?), float32] */;
    %3057 = (%3056, %p2177);
    adv_index(%3057) /* ty=Tensor[(?), float32] */
  };
  %3059 = (%in_shape_0102, %in_shape_169, %in_shape_250);
  %3060 = (%shape_func_out_0111,);
  let %shape_func111: () = vm.shape_func(%3058, %3059, %3060, meta[relay.attrs.ShapeFuncAttrs][111]) /* ty=() */;
  let %storage_0723: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][734]) /* ty=Storage[] */;
  let %tensor_0618: int64 = memory.alloc_tensor(%storage_0723, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][734]) /* ty=int64 */;
  %3061 = fn (%p0617: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0617) /* ty=int64 */
  };
  %3062 = (%shape_func_out_0111,);
  %3063 = (%tensor_0618,);
  let %v611: () = vm.invoke_tvm_op(%3061, %3062, %3063) /* ty=() */;
  let %storage_0724: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][735]) /* ty=Storage[] */;
  let %tensor_0619: int64 = memory.alloc_tensor(%storage_0724, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][735]) /* ty=int64 */;
  %3064 = fn (%p0618: int64, Primitive=1) -> int64 {
    multiply(%p0618, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3065 = (%tensor_0618,);
  %3066 = (%tensor_0619,);
  let %v612: () = vm.invoke_tvm_op(%3064, %3065, %3066) /* ty=() */;
  let %storage_0725: Storage[] = memory.alloc_storage(%tensor_0619, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][736]) /* ty=Storage[] */;
  let %out_0105: Tensor[(?), float32] = memory.alloc_tensor(%storage_0725, 0 /* ty=int64 */, %shape_func_out_0111, meta[relay.attrs.AllocTensorAttrs][736]) /* ty=Tensor[(?), float32] */;
  %3067 = (%x409, %x412, %x516);
  %3068 = (%out_0105,);
  let %v613: () = vm.invoke_tvm_op(%3058, %3067, %3068) /* ty=() */;
  let %x519: Tensor[(?), float32] = %out_0105;
  let %x520: (Tensor[(?, 4), float32], Tensor[(?), float32], Tensor[(?), int64], Tensor[(?, 1, ?, ?), float32]) = let %in_shape_0103: Tensor[(2), int64] = vm.shape_of(%x503, meta[relay.attrs.ShapeOfAttrs][102]) /* ty=Tensor[(2), int64] */;
  let %in_shape_170: Tensor[(1), int64] = vm.shape_of(%x516, meta[relay.attrs.ShapeOfAttrs][103]) /* ty=Tensor[(1), int64] */;
  let %storage_0726: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][737]) /* ty=Storage[] */;
  let %tensor_0620: Tensor[(2), int64] = memory.alloc_tensor(%storage_0726, 0 /* ty=int64 */, meta[relay.Constant][677] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][737]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0112: Tensor[(2), int64] = %tensor_0620;
  %3070 = fn (%p0619: Tensor[(?, 4), float32], %p1310: Tensor[(?), int64], Primitive=1) -> Tensor[(?, 4), float32] {
    %3069 = (%p0619, %p1310);
    adv_index(%3069) /* ty=Tensor[(?, 4), float32] */
  };
  %3071 = (%in_shape_0103, %in_shape_170);
  %3072 = (%shape_func_out_0112,);
  let %shape_func112: () = vm.shape_func(%3070, %3071, %3072, meta[relay.attrs.ShapeFuncAttrs][112]) /* ty=() */;
  let %storage_0727: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][738]) /* ty=Storage[] */;
  let %tensor_0621: int64 = memory.alloc_tensor(%storage_0727, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][738]) /* ty=int64 */;
  %3073 = fn (%p0620: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0620) /* ty=int64 */
  };
  %3074 = (%shape_func_out_0112,);
  %3075 = (%tensor_0621,);
  let %v614: () = vm.invoke_tvm_op(%3073, %3074, %3075) /* ty=() */;
  let %storage_0728: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][739]) /* ty=Storage[] */;
  let %tensor_0622: int64 = memory.alloc_tensor(%storage_0728, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][739]) /* ty=int64 */;
  %3076 = fn (%p0621: int64, Primitive=1) -> int64 {
    multiply(%p0621, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3077 = (%tensor_0621,);
  %3078 = (%tensor_0622,);
  let %v615: () = vm.invoke_tvm_op(%3076, %3077, %3078) /* ty=() */;
  let %storage_0729: Storage[] = memory.alloc_storage(%tensor_0622, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][740]) /* ty=Storage[] */;
  let %out_0106: Tensor[(?, 4), float32] = memory.alloc_tensor(%storage_0729, 0 /* ty=int64 */, %shape_func_out_0112, meta[relay.attrs.AllocTensorAttrs][740]) /* ty=Tensor[(?, 4), float32] */;
  %3079 = (%x503, %x516);
  %3080 = (%out_0106,);
  let %v616: () = vm.invoke_tvm_op(%3070, %3079, %3080) /* ty=() */;
  let %x521: Tensor[(?, 4), float32] = %out_0106;
  let %storage_0730: Storage[] = memory.alloc_storage(1 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][741]) /* ty=Storage[] */;
  let %tensor_0623: bool = memory.alloc_tensor(%storage_0730, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][741]) /* ty=bool */;
  %3082 = fn (%p0622: Tensor[(?, 4), float32], Primitive=1) -> bool {
    %3081 = ndarray_size(%p0622, dtype="int32") /* ty=int32 */;
    equal(%3081, 0 /* ty=int32 */) /* ty=bool */
  };
  %3083 = (%x521,);
  %3084 = (%tensor_0623,);
  let %v617: () = vm.invoke_tvm_op(%3082, %3083, %3084) /* ty=() */;
  let %x522: bool = %tensor_0623;
  let %x523: Tensor[(?), int64] = if (%x522) {
    let %storage_0731: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][742]) /* ty=Storage[] */;
    let %tensor_0624: Tensor[(1), int64] = memory.alloc_tensor(%storage_0731, 0 /* ty=int64 */, meta[relay.Constant][678] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][742]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_0113: Tensor[(1), int64] = %tensor_0624;
    %3085 = fn (Primitive=1) -> Tensor[(?), int64] {
      zeros(shape=[0], dtype="int64") /* ty=Tensor[(?), int64] */
    };
    %3086 = ();
    %3087 = (%shape_func_out_0113,);
    let %shape_func113: () = vm.shape_func(%3085, %3086, %3087, meta[relay.attrs.ShapeFuncAttrs][113]) /* ty=() */;
    let %storage_0732: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][743]) /* ty=Storage[] */;
    let %tensor_0625: int64 = memory.alloc_tensor(%storage_0732, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][743]) /* ty=int64 */;
    %3088 = fn (%p0623: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0623) /* ty=int64 */
    };
    %3089 = (%shape_func_out_0113,);
    %3090 = (%tensor_0625,);
    let %v618: () = vm.invoke_tvm_op(%3088, %3089, %3090) /* ty=() */;
    let %storage_0733: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][744]) /* ty=Storage[] */;
    let %tensor_0626: int64 = memory.alloc_tensor(%storage_0733, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][744]) /* ty=int64 */;
    %3091 = fn (%p0624: int64, Primitive=1) -> int64 {
      multiply(%p0624, 8 /* ty=int64 */) /* ty=int64 */
    };
    %3092 = (%tensor_0625,);
    %3093 = (%tensor_0626,);
    let %v619: () = vm.invoke_tvm_op(%3091, %3092, %3093) /* ty=() */;
    let %storage_0734: Storage[] = memory.alloc_storage(%tensor_0626, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][745]) /* ty=Storage[] */;
    let %out_0107: Tensor[(?), int64] = memory.alloc_tensor(%storage_0734, 0 /* ty=int64 */, %shape_func_out_0113, meta[relay.attrs.AllocTensorAttrs][745]) /* ty=Tensor[(?), int64] */;
    %3094 = ();
    %3095 = (%out_0107,);
    let %v620: () = vm.invoke_tvm_op(%3085, %3094, %3095) /* ty=() */;
    let %x524: Tensor[(?), int64] = %out_0107;
    %x524
  } else {
    let %storage_0735: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][746]) /* ty=Storage[] */;
    let %tensor_0627: float32 = memory.alloc_tensor(%storage_0735, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][746]) /* ty=float32 */;
    %3096 = fn (%p0625: Tensor[(?), float32], Primitive=1) -> float32 {
      min(%p0625) /* ty=float32 */
    };
    %3097 = (%x519,);
    %3098 = (%tensor_0627,);
    let %v621: () = vm.invoke_tvm_op(%3096, %3097, %3098) /* ty=() */;
    let %x525: float32 = %tensor_0627;
    let %in_shape_0104: Tensor[(1), int64] = vm.shape_of(%x519, meta[relay.attrs.ShapeOfAttrs][104]) /* ty=Tensor[(1), int64] */;
    let %storage_0736: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][747]) /* ty=Storage[] */;
    let %tensor_0628: Tensor[(1), int64] = memory.alloc_tensor(%storage_0736, 0 /* ty=int64 */, meta[relay.Constant][679] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][747]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_0114: Tensor[(1), int64] = %tensor_0628;
    %3100 = fn (%p0626: Tensor[(?), float32], %p1311: float32, Primitive=1) -> Tensor[(?), float32] {
      %3099 = subtract(%p0626, %p1311) /* ty=Tensor[(?), float32] */;
      add(%3099, 1f /* ty=float32 */) /* ty=Tensor[(?), float32] */
    };
    %3101 = (%in_shape_0104, 1795887344 /* ty=int64 */);
    %3102 = (%shape_func_out_0114,);
    let %shape_func114: () = vm.shape_func(%3100, %3101, %3102, meta[relay.attrs.ShapeFuncAttrs][114]) /* ty=() */;
    let %storage_0737: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][748]) /* ty=Storage[] */;
    let %tensor_0629: int64 = memory.alloc_tensor(%storage_0737, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][748]) /* ty=int64 */;
    %3103 = fn (%p0627: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0627) /* ty=int64 */
    };
    %3104 = (%shape_func_out_0114,);
    %3105 = (%tensor_0629,);
    let %v622: () = vm.invoke_tvm_op(%3103, %3104, %3105) /* ty=() */;
    let %storage_0738: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][749]) /* ty=Storage[] */;
    let %tensor_0630: int64 = memory.alloc_tensor(%storage_0738, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][749]) /* ty=int64 */;
    %3106 = fn (%p0628: int64, Primitive=1) -> int64 {
      multiply(%p0628, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3107 = (%tensor_0629,);
    %3108 = (%tensor_0630,);
    let %v623: () = vm.invoke_tvm_op(%3106, %3107, %3108) /* ty=() */;
    let %storage_0739: Storage[] = memory.alloc_storage(%tensor_0630, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][750]) /* ty=Storage[] */;
    let %out_0108: Tensor[(?), float32] = memory.alloc_tensor(%storage_0739, 0 /* ty=int64 */, %shape_func_out_0114, meta[relay.attrs.AllocTensorAttrs][750]) /* ty=Tensor[(?), float32] */;
    %3109 = (%x519, %x525);
    %3110 = (%out_0108,);
    let %v624: () = vm.invoke_tvm_op(%3100, %3109, %3110) /* ty=() */;
    let %x526: Tensor[(?), float32] = %out_0108;
    let %in_shape_0105: Tensor[(1), int64] = vm.shape_of(%x517, meta[relay.attrs.ShapeOfAttrs][105]) /* ty=Tensor[(1), int64] */;
    let %in_shape_171: Tensor[(1), int64] = vm.shape_of(%x526, meta[relay.attrs.ShapeOfAttrs][106]) /* ty=Tensor[(1), int64] */;
    let %in_shape_251: Tensor[(2), int64] = vm.shape_of(%x521, meta[relay.attrs.ShapeOfAttrs][107]) /* ty=Tensor[(2), int64] */;
    let %storage_0740: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][751]) /* ty=Storage[] */;
    let %tensor_0631: Tensor[(3), int64] = memory.alloc_tensor(%storage_0740, 0 /* ty=int64 */, meta[relay.Constant][680] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][751]) /* ty=Tensor[(3), int64] */;
    let %shape_func_out_0115: Tensor[(3), int64] = %tensor_0631;
    %3116 = fn (%p0629: Tensor[(?), int64], %p1312: Tensor[(?), float32], %p2178: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(1, ?, 6), float32] {
      %3111 = expand_dims(%p0629, axis=-1) /* ty=Tensor[(?, 1), int64] */;
      %3112 = cast(%3111, dtype="float32") /* ty=Tensor[(?, 1), float32] */;
      %3113 = expand_dims(%p1312, axis=-1) /* ty=Tensor[(?, 1), float32] */;
      %3114 = (%3112, %3113, %p2178);
      %3115 = concatenate(%3114, axis=-1) /* ty=Tensor[(?, 6), float32] */;
      expand_dims(%3115, axis=0) /* ty=Tensor[(1, ?, 6), float32] */
    };
    %3117 = (%in_shape_0105, %in_shape_171, %in_shape_251);
    %3118 = (%shape_func_out_0115,);
    let %shape_func115: () = vm.shape_func(%3116, %3117, %3118, meta[relay.attrs.ShapeFuncAttrs][115]) /* ty=() */;
    let %storage_0741: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][752]) /* ty=Storage[] */;
    let %tensor_0632: int64 = memory.alloc_tensor(%storage_0741, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][752]) /* ty=int64 */;
    %3119 = fn (%p0630: Tensor[(3), int64], Primitive=1) -> int64 {
      prod(%p0630) /* ty=int64 */
    };
    %3120 = (%shape_func_out_0115,);
    %3121 = (%tensor_0632,);
    let %v625: () = vm.invoke_tvm_op(%3119, %3120, %3121) /* ty=() */;
    let %storage_0742: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][753]) /* ty=Storage[] */;
    let %tensor_0633: int64 = memory.alloc_tensor(%storage_0742, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][753]) /* ty=int64 */;
    %3122 = fn (%p0631: int64, Primitive=1) -> int64 {
      multiply(%p0631, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3123 = (%tensor_0632,);
    %3124 = (%tensor_0633,);
    let %v626: () = vm.invoke_tvm_op(%3122, %3123, %3124) /* ty=() */;
    let %storage_0743: Storage[] = memory.alloc_storage(%tensor_0633, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][754]) /* ty=Storage[] */;
    let %out_0109: Tensor[(1, ?, 6), float32] = memory.alloc_tensor(%storage_0743, 0 /* ty=int64 */, %shape_func_out_0115, meta[relay.attrs.AllocTensorAttrs][754]) /* ty=Tensor[(1, ?, 6), float32] */;
    %3125 = (%x517, %x526, %x521);
    %3126 = (%out_0109,);
    let %v627: () = vm.invoke_tvm_op(%3116, %3125, %3126) /* ty=() */;
    let %x527: Tensor[(1, ?, 6), float32] = %out_0109;
    let %storage_0744: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][755]) /* ty=Storage[] */;
    let %tensor_0634: Tensor[(1), int32] = memory.alloc_tensor(%storage_0744, 0 /* ty=int64 */, meta[relay.Constant][681] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][755]) /* ty=Tensor[(1), int32] */;
    %3127 = fn (%p0632: Tensor[(?), float32], Primitive=1) -> Tensor[(1), int32] {
      shape_of(%p0632, dtype="int32") /* ty=Tensor[(1), int32] */
    };
    %3128 = (%x526,);
    %3129 = (%tensor_0634,);
    let %v628: () = vm.invoke_tvm_op(%3127, %3128, %3129) /* ty=() */;
    let %x528: Tensor[(1), int32] = %tensor_0634;
    let %storage_0745: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][756]) /* ty=Storage[] */;
    let %tensor_0635: int32 = memory.alloc_tensor(%storage_0745, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][756]) /* ty=int32 */;
    %3130 = fn (%p0633: Tensor[(1), int32], Primitive=1) -> int32 {
      squeeze(%p0633) /* ty=int32 */
    };
    %3131 = (%x528,);
    %3132 = (%tensor_0635,);
    let %v629: () = vm.invoke_tvm_op(%3130, %3131, %3132) /* ty=() */;
    let %x529: int32 = %tensor_0635;
    let %in_shape_0106: int32 = device_copy(0 /* ty=int32 */, meta[relay.attrs.DeviceCopyAttrs][174]) /* ty=int32 */;
    let %in_shape_172: int32 = device_copy(%x529, meta[relay.attrs.DeviceCopyAttrs][175]) /* ty=int32 */;
    let %in_shape_252: int32 = device_copy(1 /* ty=int32 */, meta[relay.attrs.DeviceCopyAttrs][176]) /* ty=int32 */;
    let %storage_0746: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][757]) /* ty=Storage[] */;
    let %tensor_0636: Tensor[(1), int64] = memory.alloc_tensor(%storage_0746, 0 /* ty=int64 */, meta[relay.Constant][682] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][757]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_0116: Tensor[(1), int64] = %tensor_0636;
    %3133 = fn (%p0634: int32, %p1313: int32, %p2179: int32, Primitive=1) -> Tensor[(?), int32] {
      arange(%p0634, %p1313, %p2179, start=meta[relay.Constant][683], stop=meta[relay.Call][1], step=meta[relay.Constant][684], dtype="int32") /* ty=Tensor[(?), int32] */
    };
    %3134 = (%in_shape_0106, %in_shape_172, %in_shape_252);
    %3135 = (%shape_func_out_0116,);
    let %shape_func116: () = vm.shape_func(%3133, %3134, %3135, meta[relay.attrs.ShapeFuncAttrs][116]) /* ty=() */;
    let %storage_0747: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][758]) /* ty=Storage[] */;
    let %tensor_0637: int64 = memory.alloc_tensor(%storage_0747, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][758]) /* ty=int64 */;
    %3136 = fn (%p0635: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0635) /* ty=int64 */
    };
    %3137 = (%shape_func_out_0116,);
    %3138 = (%tensor_0637,);
    let %v630: () = vm.invoke_tvm_op(%3136, %3137, %3138) /* ty=() */;
    let %storage_0748: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][759]) /* ty=Storage[] */;
    let %tensor_0638: int64 = memory.alloc_tensor(%storage_0748, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][759]) /* ty=int64 */;
    %3139 = fn (%p0636: int64, Primitive=1) -> int64 {
      multiply(%p0636, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3140 = (%tensor_0637,);
    %3141 = (%tensor_0638,);
    let %v631: () = vm.invoke_tvm_op(%3139, %3140, %3141) /* ty=() */;
    let %storage_0749: Storage[] = memory.alloc_storage(%tensor_0638, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][760]) /* ty=Storage[] */;
    let %out_0110: Tensor[(?), int32] = memory.alloc_tensor(%storage_0749, 0 /* ty=int64 */, %shape_func_out_0116, meta[relay.attrs.AllocTensorAttrs][760]) /* ty=Tensor[(?), int32] */;
    %3142 = (0 /* ty=int32 */, %x529, 1 /* ty=int32 */);
    %3143 = (%out_0110,);
    let %v632: () = vm.invoke_tvm_op(%3133, %3142, %3143) /* ty=() */;
    let %x530: Tensor[(?), int32] = %out_0110;
    let %in_shape_0107: Tensor[(1), int64] = vm.shape_of(%x530, meta[relay.attrs.ShapeOfAttrs][108]) /* ty=Tensor[(1), int64] */;
    let %storage_0750: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][761]) /* ty=Storage[] */;
    let %tensor_0639: Tensor[(2), int64] = memory.alloc_tensor(%storage_0750, 0 /* ty=int64 */, meta[relay.Constant][685] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][761]) /* ty=Tensor[(2), int64] */;
    let %shape_func_out_0117: Tensor[(2), int64] = %tensor_0639;
    %3144 = fn (%p0637: Tensor[(?), int32], Primitive=1) -> Tensor[(1, ?), int32] {
      expand_dims(%p0637, axis=0) /* ty=Tensor[(1, ?), int32] */
    };
    %3145 = (%in_shape_0107,);
    %3146 = (%shape_func_out_0117,);
    let %shape_func117: () = vm.shape_func(%3144, %3145, %3146, meta[relay.attrs.ShapeFuncAttrs][117]) /* ty=() */;
    let %storage_0751: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][762]) /* ty=Storage[] */;
    let %tensor_0640: int64 = memory.alloc_tensor(%storage_0751, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][762]) /* ty=int64 */;
    %3147 = fn (%p0638: Tensor[(2), int64], Primitive=1) -> int64 {
      prod(%p0638) /* ty=int64 */
    };
    %3148 = (%shape_func_out_0117,);
    %3149 = (%tensor_0640,);
    let %v633: () = vm.invoke_tvm_op(%3147, %3148, %3149) /* ty=() */;
    let %storage_0752: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][763]) /* ty=Storage[] */;
    let %tensor_0641: int64 = memory.alloc_tensor(%storage_0752, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][763]) /* ty=int64 */;
    %3150 = fn (%p0639: int64, Primitive=1) -> int64 {
      multiply(%p0639, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3151 = (%tensor_0640,);
    %3152 = (%tensor_0641,);
    let %v634: () = vm.invoke_tvm_op(%3150, %3151, %3152) /* ty=() */;
    let %storage_0753: Storage[] = memory.alloc_storage(%tensor_0641, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][764]) /* ty=Storage[] */;
    let %out_0111: Tensor[(1, ?), int32] = memory.alloc_tensor(%storage_0753, 0 /* ty=int64 */, %shape_func_out_0117, meta[relay.attrs.AllocTensorAttrs][764]) /* ty=Tensor[(1, ?), int32] */;
    %3153 = (%x530,);
    %3154 = (%out_0111,);
    let %v635: () = vm.invoke_tvm_op(%3144, %3153, %3154) /* ty=() */;
    let %x531: Tensor[(1, ?), int32] = %out_0111;
    let %in_shape_0108: Tensor[(3), int64] = vm.shape_of(%x527, meta[relay.attrs.ShapeOfAttrs][109]) /* ty=Tensor[(3), int64] */;
    let %in_shape_253: Tensor[(2), int64] = vm.shape_of(%x531, meta[relay.attrs.ShapeOfAttrs][110]) /* ty=Tensor[(2), int64] */;
    let %storage_0754: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][765]) /* ty=Storage[] */;
    let %tensor_0642: Tensor[(2), int64] = memory.alloc_tensor(%storage_0754, 0 /* ty=int64 */, meta[relay.Constant][686] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][765]) /* ty=Tensor[(2), int64] */;
    let %shape_func_out_0118: Tensor[(2), int64] = %tensor_0642;
    let %storage_18: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][766]) /* ty=Storage[] */;
    let %tensor_17: Tensor[(2), int64] = memory.alloc_tensor(%storage_18, 0 /* ty=int64 */, meta[relay.Constant][687] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][766]) /* ty=Tensor[(2), int64] */;
    let %shape_func_out_11: Tensor[(2), int64] = %tensor_17;
    %3155 = fn (%p0640: Tensor[(1, ?, 6), float32], %p1314: Tensor[(1), int32], %p2180: Tensor[(1, ?), int32], %p3105: int32, %p459: float32, Primitive=1) -> (Tensor[(1, ?), int32], Tensor[(1, 1), int32]) {
      vision.non_max_suppression(%p0640, %p1314, %p2180, %p3105, %p459, meta[relay.attrs.NonMaximumSuppressionAttrs][1]) /* ty=(Tensor[(1, ?), int32], Tensor[(1, 1), int32]) */
    };
    %3156 = (%in_shape_0108, meta[relay.Constant][688] /* ty=Tensor[(1), int64] */, %in_shape_253, 931749024 /* ty=int64 */, 1892780176 /* ty=int64 */);
    %3157 = (%shape_func_out_0118, %shape_func_out_11);
    let %shape_func118: () = vm.shape_func(%3155, %3156, %3157, meta[relay.attrs.ShapeFuncAttrs][118]) /* ty=() */;
    let %storage_0755: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][767]) /* ty=Storage[] */;
    let %tensor_0643: int64 = memory.alloc_tensor(%storage_0755, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][767]) /* ty=int64 */;
    %3158 = fn (%p0641: Tensor[(2), int64], Primitive=1) -> int64 {
      prod(%p0641) /* ty=int64 */
    };
    %3159 = (%shape_func_out_0118,);
    %3160 = (%tensor_0643,);
    let %v636: () = vm.invoke_tvm_op(%3158, %3159, %3160) /* ty=() */;
    let %storage_0756: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][768]) /* ty=Storage[] */;
    let %tensor_0644: int64 = memory.alloc_tensor(%storage_0756, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][768]) /* ty=int64 */;
    %3161 = fn (%p0642: int64, Primitive=1) -> int64 {
      multiply(%p0642, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3162 = (%tensor_0643,);
    %3163 = (%tensor_0644,);
    let %v637: () = vm.invoke_tvm_op(%3161, %3162, %3163) /* ty=() */;
    let %storage_0757: Storage[] = memory.alloc_storage(%tensor_0644, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][769]) /* ty=Storage[] */;
    let %storage_0758: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][770]) /* ty=Storage[] */;
    let %tensor_0645: int64 = memory.alloc_tensor(%storage_0758, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][769]) /* ty=int64 */;
    %3164 = fn (%p0643: Tensor[(2), int64], Primitive=1) -> int64 {
      prod(%p0643) /* ty=int64 */
    };
    %3165 = (%shape_func_out_11,);
    %3166 = (%tensor_0645,);
    let %v638: () = vm.invoke_tvm_op(%3164, %3165, %3166) /* ty=() */;
    let %storage_0759: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][771]) /* ty=Storage[] */;
    let %tensor_0646: int64 = memory.alloc_tensor(%storage_0759, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][770]) /* ty=int64 */;
    %3167 = fn (%p0644: int64, Primitive=1) -> int64 {
      multiply(%p0644, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3168 = (%tensor_0645,);
    %3169 = (%tensor_0646,);
    let %v639: () = vm.invoke_tvm_op(%3167, %3168, %3169) /* ty=() */;
    let %storage_19: Storage[] = memory.alloc_storage(%tensor_0646, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][772]) /* ty=Storage[] */;
    let %out_0112: Tensor[(1, ?), int32] = memory.alloc_tensor(%storage_0757, 0 /* ty=int64 */, %shape_func_out_0118, meta[relay.attrs.AllocTensorAttrs][771]) /* ty=Tensor[(1, ?), int32] */;
    let %out_11: Tensor[(1, 1), int32] = memory.alloc_tensor(%storage_19, 0 /* ty=int64 */, %shape_func_out_11, meta[relay.attrs.AllocTensorAttrs][772]) /* ty=Tensor[(1, 1), int32] */;
    %3170 = (%x527, %x528, %x531, 100 /* ty=int32 */, 0.5f /* ty=float32 */);
    %3171 = (%out_0112, %out_11);
    let %v640: () = vm.invoke_tvm_op(%3155, %3170, %3171) /* ty=() */;
    let %x532: (Tensor[(1, ?), int32], Tensor[(1, 1), int32]) = (%out_0112, %out_11);
    %3172 = %x532.0;
    let %in_shape_0109: Tensor[(2), int64] = vm.shape_of(%3172, meta[relay.attrs.ShapeOfAttrs][111]) /* ty=Tensor[(2), int64] */;
    let %storage_0760: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][773]) /* ty=Storage[] */;
    let %tensor_0647: Tensor[(1), int64] = memory.alloc_tensor(%storage_0760, 0 /* ty=int64 */, meta[relay.Constant][689] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][773]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_0119: Tensor[(1), int64] = %tensor_0647;
    %3174 = fn (%p0645: (Tensor[(1, ?), int32], Tensor[(1, 1), int32]), Primitive=1) -> Tensor[(?), int32] {
      %3173 = %p0645.0;
      squeeze(%3173, axis=[0]) /* ty=Tensor[(?), int32] */
    };
    %3175 = (%in_shape_0109, meta[relay.Constant][690] /* ty=Tensor[(2), int64] */);
    %3176 = (%shape_func_out_0119,);
    let %shape_func119: () = vm.shape_func(%3174, %3175, %3176, meta[relay.attrs.ShapeFuncAttrs][119]) /* ty=() */;
    let %storage_0761: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][774]) /* ty=Storage[] */;
    let %tensor_0648: int64 = memory.alloc_tensor(%storage_0761, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][774]) /* ty=int64 */;
    %3177 = fn (%p0646: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0646) /* ty=int64 */
    };
    %3178 = (%shape_func_out_0119,);
    %3179 = (%tensor_0648,);
    let %v641: () = vm.invoke_tvm_op(%3177, %3178, %3179) /* ty=() */;
    let %storage_0762: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][775]) /* ty=Storage[] */;
    let %tensor_0649: int64 = memory.alloc_tensor(%storage_0762, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][775]) /* ty=int64 */;
    %3180 = fn (%p0647: int64, Primitive=1) -> int64 {
      multiply(%p0647, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3181 = (%tensor_0648,);
    %3182 = (%tensor_0649,);
    let %v642: () = vm.invoke_tvm_op(%3180, %3181, %3182) /* ty=() */;
    let %storage_0763: Storage[] = memory.alloc_storage(%tensor_0649, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][776]) /* ty=Storage[] */;
    let %out_0113: Tensor[(?), int32] = memory.alloc_tensor(%storage_0763, 0 /* ty=int64 */, %shape_func_out_0119, meta[relay.attrs.AllocTensorAttrs][776]) /* ty=Tensor[(?), int32] */;
    %3183 = (%x532,);
    %3184 = (%out_0113,);
    let %v643: () = vm.invoke_tvm_op(%3174, %3183, %3184) /* ty=() */;
    let %x533: Tensor[(?), int32] = %out_0113;
    let %storage_0764: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][777]) /* ty=Storage[] */;
    let %tensor_0650: Tensor[(1), int32] = memory.alloc_tensor(%storage_0764, 0 /* ty=int64 */, meta[relay.Constant][691] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][777]) /* ty=Tensor[(1), int32] */;
    %3185 = fn (%p0648: Tensor[(?), int32], Primitive=1) -> Tensor[(1), int32] {
      shape_of(%p0648, dtype="int32") /* ty=Tensor[(1), int32] */
    };
    %3186 = (%x533,);
    %3187 = (%tensor_0650,);
    let %v644: () = vm.invoke_tvm_op(%3185, %3186, %3187) /* ty=() */;
    let %x534: Tensor[(1), int32] = %tensor_0650;
    let %storage_0765: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][778]) /* ty=Storage[] */;
    let %tensor_0651: Tensor[(1), int32] = memory.alloc_tensor(%storage_0765, 0 /* ty=int64 */, meta[relay.Constant][692] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][778]) /* ty=Tensor[(1), int32] */;
    %3190 = fn (%p0649: Tensor[(1), bool], %p1315: Tensor[(1), int32], %p2181: Tensor[(1), int32], Primitive=1) -> Tensor[(1), int32] {
      %3188 = cast_like(%p2181, %p1315) /* ty=Tensor[(1), int32] */;
      %3189 = add(%p1315, %3188) /* ty=Tensor[(1), int32] */;
      where(%p0649, %3189, %p1315) /* ty=Tensor[(1), int32] */
    };
    %3191 = (meta[relay.Constant][693] /* ty=Tensor[(1), bool] */, meta[relay.Constant][694] /* ty=Tensor[(1), int32] */, %x534);
    %3192 = (%tensor_0651,);
    let %v645: () = vm.invoke_tvm_op(%3190, %3191, %3192) /* ty=() */;
    let %x535: Tensor[(1), int32] = %tensor_0651;
    let %storage_0766: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][779]) /* ty=Storage[] */;
    let %tensor_0652: Tensor[(1), int32] = memory.alloc_tensor(%storage_0766, 0 /* ty=int64 */, meta[relay.Constant][695] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][779]) /* ty=Tensor[(1), int32] */;
    %3194 = fn (%p0650: (Tensor[(1, ?), int32], Tensor[(1, 1), int32]), Primitive=1) -> Tensor[(1), int32] {
      %3193 = %p0650.1;
      squeeze(%3193, axis=[1]) /* ty=Tensor[(1), int32] */
    };
    %3195 = (%x532,);
    %3196 = (%tensor_0652,);
    let %v646: () = vm.invoke_tvm_op(%3194, %3195, %3196) /* ty=() */;
    let %x536: Tensor[(1), int32] = %tensor_0652;
    let %in_shape_0110: Tensor[(?), int32] = device_copy(%x533, meta[relay.attrs.DeviceCopyAttrs][177]) /* ty=Tensor[(?), int32] */;
    let %in_shape_173: Tensor[(1), int32] = device_copy(%x535, meta[relay.attrs.DeviceCopyAttrs][178]) /* ty=Tensor[(1), int32] */;
    let %in_shape_254: Tensor[(1), int32] = device_copy(%x536, meta[relay.attrs.DeviceCopyAttrs][179]) /* ty=Tensor[(1), int32] */;
    let %in_shape_344: Tensor[(1), int32] = device_copy(meta[relay.Constant][696] /* ty=Tensor[(1), int32] */, meta[relay.attrs.DeviceCopyAttrs][180]) /* ty=Tensor[(1), int32] */;
    let %storage_0767: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][780]) /* ty=Storage[] */;
    let %tensor_0653: Tensor[(1), int64] = memory.alloc_tensor(%storage_0767, 0 /* ty=int64 */, meta[relay.Constant][697] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][780]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_0120: Tensor[(1), int64] = %tensor_0653;
    %3197 = fn (%p0651: Tensor[(?), int32], %p1316: Tensor[(1), int32], %p2182: Tensor[(1), int32], %p3106: Tensor[(1), int32], Primitive=1) -> Tensor[(?), int32] {
      dyn.strided_slice(%p0651, %p1316, %p2182, %p3106, begin=None, end=None, strides=None, slice_mode="size") /* ty=Tensor[(?), int32] */
    };
    %3198 = (%in_shape_0110, %in_shape_173, %in_shape_254, %in_shape_344);
    %3199 = (%shape_func_out_0120,);
    let %shape_func120: () = vm.shape_func(%3197, %3198, %3199, meta[relay.attrs.ShapeFuncAttrs][120]) /* ty=() */;
    let %storage_0768: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][781]) /* ty=Storage[] */;
    let %tensor_0654: int64 = memory.alloc_tensor(%storage_0768, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][781]) /* ty=int64 */;
    %3200 = fn (%p0652: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0652) /* ty=int64 */
    };
    %3201 = (%shape_func_out_0120,);
    %3202 = (%tensor_0654,);
    let %v647: () = vm.invoke_tvm_op(%3200, %3201, %3202) /* ty=() */;
    let %storage_0769: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][782]) /* ty=Storage[] */;
    let %tensor_0655: int64 = memory.alloc_tensor(%storage_0769, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][782]) /* ty=int64 */;
    %3203 = fn (%p0653: int64, Primitive=1) -> int64 {
      multiply(%p0653, 4 /* ty=int64 */) /* ty=int64 */
    };
    %3204 = (%tensor_0654,);
    %3205 = (%tensor_0655,);
    let %v648: () = vm.invoke_tvm_op(%3203, %3204, %3205) /* ty=() */;
    let %storage_0770: Storage[] = memory.alloc_storage(%tensor_0655, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][783]) /* ty=Storage[] */;
    let %out_0114: Tensor[(?), int32] = memory.alloc_tensor(%storage_0770, 0 /* ty=int64 */, %shape_func_out_0120, meta[relay.attrs.AllocTensorAttrs][783]) /* ty=Tensor[(?), int32] */;
    %3206 = (%x533, %x535, %x536, meta[relay.Constant][696] /* ty=Tensor[(1), int32] */);
    %3207 = (%out_0114,);
    let %v649: () = vm.invoke_tvm_op(%3197, %3206, %3207) /* ty=() */;
    let %x537: Tensor[(?), int32] = %out_0114;
    let %in_shape_0111: Tensor[(1), int64] = vm.shape_of(%x537, meta[relay.attrs.ShapeOfAttrs][112]) /* ty=Tensor[(1), int64] */;
    let %storage_0771: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][784]) /* ty=Storage[] */;
    let %tensor_0656: Tensor[(1), int64] = memory.alloc_tensor(%storage_0771, 0 /* ty=int64 */, meta[relay.Constant][698] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][784]) /* ty=Tensor[(1), int64] */;
    let %shape_func_out_0121: Tensor[(1), int64] = %tensor_0656;
    %3208 = fn (%p0654: Tensor[(?), int32], Primitive=1) -> Tensor[(?), int64] {
      cast(%p0654, dtype="int64") /* ty=Tensor[(?), int64] */
    };
    %3209 = (%in_shape_0111,);
    %3210 = (%shape_func_out_0121,);
    let %shape_func121: () = vm.shape_func(%3208, %3209, %3210, meta[relay.attrs.ShapeFuncAttrs][121]) /* ty=() */;
    let %storage_0772: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][785]) /* ty=Storage[] */;
    let %tensor_0657: int64 = memory.alloc_tensor(%storage_0772, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][785]) /* ty=int64 */;
    %3211 = fn (%p0655: Tensor[(1), int64], Primitive=1) -> int64 {
      prod(%p0655) /* ty=int64 */
    };
    %3212 = (%shape_func_out_0121,);
    %3213 = (%tensor_0657,);
    let %v650: () = vm.invoke_tvm_op(%3211, %3212, %3213) /* ty=() */;
    let %storage_0773: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][786]) /* ty=Storage[] */;
    let %tensor_0658: int64 = memory.alloc_tensor(%storage_0773, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][786]) /* ty=int64 */;
    %3214 = fn (%p0656: int64, Primitive=1) -> int64 {
      multiply(%p0656, 8 /* ty=int64 */) /* ty=int64 */
    };
    %3215 = (%tensor_0657,);
    %3216 = (%tensor_0658,);
    let %v651: () = vm.invoke_tvm_op(%3214, %3215, %3216) /* ty=() */;
    let %storage_0774: Storage[] = memory.alloc_storage(%tensor_0658, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][787]) /* ty=Storage[] */;
    let %out_0115: Tensor[(?), int64] = memory.alloc_tensor(%storage_0774, 0 /* ty=int64 */, %shape_func_out_0121, meta[relay.attrs.AllocTensorAttrs][787]) /* ty=Tensor[(?), int64] */;
    %3217 = (%x537,);
    %3218 = (%out_0115,);
    let %v652: () = vm.invoke_tvm_op(%3208, %3217, %3218) /* ty=() */;
    let %x538: Tensor[(?), int64] = %out_0115;
    %x538
  };
  let %in_shape_0112: Tensor[(2), int64] = vm.shape_of(%x521, meta[relay.attrs.ShapeOfAttrs][113]) /* ty=Tensor[(2), int64] */;
  let %in_shape_174: Tensor[(1), int64] = vm.shape_of(%x523, meta[relay.attrs.ShapeOfAttrs][114]) /* ty=Tensor[(1), int64] */;
  let %storage_0775: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][788]) /* ty=Storage[] */;
  let %tensor_0659: Tensor[(2), int64] = memory.alloc_tensor(%storage_0775, 0 /* ty=int64 */, meta[relay.Constant][699] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][788]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0122: Tensor[(2), int64] = %tensor_0659;
  %3220 = fn (%p0657: Tensor[(?, 4), float32], %p1317: Tensor[(?), int64], Primitive=1) -> Tensor[(?, 4), float32] {
    %3219 = (%p0657, %p1317);
    adv_index(%3219) /* ty=Tensor[(?, 4), float32] */
  };
  %3221 = (%in_shape_0112, %in_shape_174);
  %3222 = (%shape_func_out_0122,);
  let %shape_func122: () = vm.shape_func(%3220, %3221, %3222, meta[relay.attrs.ShapeFuncAttrs][122]) /* ty=() */;
  let %storage_0776: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][789]) /* ty=Storage[] */;
  let %tensor_0660: int64 = memory.alloc_tensor(%storage_0776, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][789]) /* ty=int64 */;
  %3223 = fn (%p0658: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0658) /* ty=int64 */
  };
  %3224 = (%shape_func_out_0122,);
  %3225 = (%tensor_0660,);
  let %v653: () = vm.invoke_tvm_op(%3223, %3224, %3225) /* ty=() */;
  let %storage_0777: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][790]) /* ty=Storage[] */;
  let %tensor_0661: int64 = memory.alloc_tensor(%storage_0777, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][790]) /* ty=int64 */;
  %3226 = fn (%p0659: int64, Primitive=1) -> int64 {
    multiply(%p0659, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3227 = (%tensor_0660,);
  %3228 = (%tensor_0661,);
  let %v654: () = vm.invoke_tvm_op(%3226, %3227, %3228) /* ty=() */;
  let %storage_0778: Storage[] = memory.alloc_storage(%tensor_0661, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][791]) /* ty=Storage[] */;
  let %out_0116: Tensor[(?, 4), float32] = memory.alloc_tensor(%storage_0778, 0 /* ty=int64 */, %shape_func_out_0122, meta[relay.attrs.AllocTensorAttrs][791]) /* ty=Tensor[(?, 4), float32] */;
  %3229 = (%x521, %x523);
  %3230 = (%out_0116,);
  let %v655: () = vm.invoke_tvm_op(%3220, %3229, %3230) /* ty=() */;
  let %x539: Tensor[(?, 4), float32] = %out_0116;
  let %storage_0779: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][792]) /* ty=Storage[] */;
  let %tensor_0662: Tensor[(2), int32] = memory.alloc_tensor(%storage_0779, 0 /* ty=int64 */, meta[relay.Constant][700] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][792]) /* ty=Tensor[(2), int32] */;
  %3231 = fn (%p0660: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0660, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %3232 = (%x539,);
  %3233 = (%tensor_0662,);
  let %v656: () = vm.invoke_tvm_op(%3231, %3232, %3233) /* ty=() */;
  let %x540: Tensor[(2), int32] = %tensor_0662;
  let %storage_0780: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][793]) /* ty=Storage[] */;
  let %tensor_0663: Tensor[(2), int32] = memory.alloc_tensor(%storage_0780, 0 /* ty=int64 */, meta[relay.Constant][701] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][793]) /* ty=Tensor[(2), int32] */;
  %3236 = fn (%p0661: Tensor[(2), bool], %p1318: Tensor[(2), int32], %p2183: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3234 = cast_like(%p2183, %p1318) /* ty=Tensor[(2), int32] */;
    %3235 = add(%p1318, %3234) /* ty=Tensor[(2), int32] */;
    where(%p0661, %3235, %p1318) /* ty=Tensor[(2), int32] */
  };
  %3237 = (meta[relay.Constant][702] /* ty=Tensor[(2), bool] */, meta[relay.Constant][703] /* ty=Tensor[(2), int32] */, %x540);
  %3238 = (%tensor_0663,);
  let %v657: () = vm.invoke_tvm_op(%3236, %3237, %3238) /* ty=() */;
  let %x541: Tensor[(2), int32] = %tensor_0663;
  let %storage_0781: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][794]) /* ty=Storage[] */;
  let %tensor_0664: Tensor[(2), int64] = memory.alloc_tensor(%storage_0781, 0 /* ty=int64 */, meta[relay.Constant][704] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][794]) /* ty=Tensor[(2), int64] */;
  %3239 = fn (%p0662: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0662, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %3240 = (%x540,);
  %3241 = (%tensor_0664,);
  let %v658: () = vm.invoke_tvm_op(%3239, %3240, %3241) /* ty=() */;
  let %x542: Tensor[(2), int64] = %tensor_0664;
  let %in_shape_0113: Tensor[(?, 4), float32] = device_copy(%x539, meta[relay.attrs.DeviceCopyAttrs][181]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_175: Tensor[(2), int32] = device_copy(%x541, meta[relay.attrs.DeviceCopyAttrs][182]) /* ty=Tensor[(2), int32] */;
  let %in_shape_255: Tensor[(2), int64] = device_copy(%x542, meta[relay.attrs.DeviceCopyAttrs][183]) /* ty=Tensor[(2), int64] */;
  let %in_shape_345: Tensor[(2), int32] = device_copy(meta[relay.Constant][705] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][184]) /* ty=Tensor[(2), int32] */;
  let %storage_0782: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][795]) /* ty=Storage[] */;
  let %tensor_0665: Tensor[(2), int64] = memory.alloc_tensor(%storage_0782, 0 /* ty=int64 */, meta[relay.Constant][706] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][795]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0123: Tensor[(2), int64] = %tensor_0665;
  %3242 = fn (%p0663: Tensor[(?, 4), float32], %p1319: Tensor[(2), int32], %p2184: Tensor[(2), int64], %p3107: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0663, %p1319, %p2184, %p3107, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %3243 = (%in_shape_0113, %in_shape_175, %in_shape_255, %in_shape_345);
  %3244 = (%shape_func_out_0123,);
  let %shape_func123: () = vm.shape_func(%3242, %3243, %3244, meta[relay.attrs.ShapeFuncAttrs][123]) /* ty=() */;
  let %storage_0783: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][796]) /* ty=Storage[] */;
  let %tensor_0666: int64 = memory.alloc_tensor(%storage_0783, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][796]) /* ty=int64 */;
  %3245 = fn (%p0664: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0664) /* ty=int64 */
  };
  %3246 = (%shape_func_out_0123,);
  %3247 = (%tensor_0666,);
  let %v659: () = vm.invoke_tvm_op(%3245, %3246, %3247) /* ty=() */;
  let %storage_0784: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][797]) /* ty=Storage[] */;
  let %tensor_0667: int64 = memory.alloc_tensor(%storage_0784, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][797]) /* ty=int64 */;
  %3248 = fn (%p0665: int64, Primitive=1) -> int64 {
    multiply(%p0665, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3249 = (%tensor_0666,);
  %3250 = (%tensor_0667,);
  let %v660: () = vm.invoke_tvm_op(%3248, %3249, %3250) /* ty=() */;
  let %storage_0785: Storage[] = memory.alloc_storage(%tensor_0667, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][798]) /* ty=Storage[] */;
  let %out_0117: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0785, 0 /* ty=int64 */, %shape_func_out_0123, meta[relay.attrs.AllocTensorAttrs][798]) /* ty=Tensor[(?, ?), float32] */;
  %3251 = (%x539, %x541, %x542, meta[relay.Constant][705] /* ty=Tensor[(2), int32] */);
  %3252 = (%out_0117,);
  let %v661: () = vm.invoke_tvm_op(%3242, %3251, %3252) /* ty=() */;
  let %x543: Tensor[(?, ?), float32] = %out_0117;
  let %storage_0786: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][799]) /* ty=Storage[] */;
  let %tensor_0668: Tensor[(2), int32] = memory.alloc_tensor(%storage_0786, 0 /* ty=int64 */, meta[relay.Constant][707] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][799]) /* ty=Tensor[(2), int32] */;
  %3255 = fn (%p0666: Tensor[(2), bool], %p1320: Tensor[(2), int32], %p2185: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3253 = cast_like(%p2185, %p1320) /* ty=Tensor[(2), int32] */;
    %3254 = add(%p1320, %3253) /* ty=Tensor[(2), int32] */;
    where(%p0666, %3254, %p1320) /* ty=Tensor[(2), int32] */
  };
  %3256 = (meta[relay.Constant][708] /* ty=Tensor[(2), bool] */, meta[relay.Constant][709] /* ty=Tensor[(2), int32] */, %x540);
  %3257 = (%tensor_0668,);
  let %v662: () = vm.invoke_tvm_op(%3255, %3256, %3257) /* ty=() */;
  let %x544: Tensor[(2), int32] = %tensor_0668;
  let %in_shape_0114: Tensor[(?, 4), float32] = device_copy(%x539, meta[relay.attrs.DeviceCopyAttrs][185]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_176: Tensor[(2), int32] = device_copy(%x544, meta[relay.attrs.DeviceCopyAttrs][186]) /* ty=Tensor[(2), int32] */;
  let %in_shape_256: Tensor[(2), int64] = device_copy(%x542, meta[relay.attrs.DeviceCopyAttrs][187]) /* ty=Tensor[(2), int64] */;
  let %in_shape_346: Tensor[(2), int32] = device_copy(meta[relay.Constant][710] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][188]) /* ty=Tensor[(2), int32] */;
  let %storage_0787: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][800]) /* ty=Storage[] */;
  let %tensor_0669: Tensor[(2), int64] = memory.alloc_tensor(%storage_0787, 0 /* ty=int64 */, meta[relay.Constant][711] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][800]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0124: Tensor[(2), int64] = %tensor_0669;
  %3258 = fn (%p0667: Tensor[(?, 4), float32], %p1321: Tensor[(2), int32], %p2186: Tensor[(2), int64], %p3108: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0667, %p1321, %p2186, %p3108, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %3259 = (%in_shape_0114, %in_shape_176, %in_shape_256, %in_shape_346);
  %3260 = (%shape_func_out_0124,);
  let %shape_func124: () = vm.shape_func(%3258, %3259, %3260, meta[relay.attrs.ShapeFuncAttrs][124]) /* ty=() */;
  let %storage_0788: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][801]) /* ty=Storage[] */;
  let %tensor_0670: int64 = memory.alloc_tensor(%storage_0788, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][801]) /* ty=int64 */;
  %3261 = fn (%p0668: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0668) /* ty=int64 */
  };
  %3262 = (%shape_func_out_0124,);
  %3263 = (%tensor_0670,);
  let %v663: () = vm.invoke_tvm_op(%3261, %3262, %3263) /* ty=() */;
  let %storage_0789: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][802]) /* ty=Storage[] */;
  let %tensor_0671: int64 = memory.alloc_tensor(%storage_0789, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][802]) /* ty=int64 */;
  %3264 = fn (%p0669: int64, Primitive=1) -> int64 {
    multiply(%p0669, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3265 = (%tensor_0670,);
  %3266 = (%tensor_0671,);
  let %v664: () = vm.invoke_tvm_op(%3264, %3265, %3266) /* ty=() */;
  let %storage_0790: Storage[] = memory.alloc_storage(%tensor_0671, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][803]) /* ty=Storage[] */;
  let %out_0118: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0790, 0 /* ty=int64 */, %shape_func_out_0124, meta[relay.attrs.AllocTensorAttrs][803]) /* ty=Tensor[(?, ?), float32] */;
  %3267 = (%x539, %x544, %x542, meta[relay.Constant][710] /* ty=Tensor[(2), int32] */);
  %3268 = (%out_0118,);
  let %v665: () = vm.invoke_tvm_op(%3258, %3267, %3268) /* ty=() */;
  let %x545: Tensor[(?, ?), float32] = %out_0118;
  let %storage_0791: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][804]) /* ty=Storage[] */;
  let %tensor_0672: Tensor[(2), int32] = memory.alloc_tensor(%storage_0791, 0 /* ty=int64 */, meta[relay.Constant][712] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][804]) /* ty=Tensor[(2), int32] */;
  %3271 = fn (%p0670: Tensor[(2), bool], %p1322: Tensor[(2), int32], %p2187: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3269 = cast_like(%p2187, %p1322) /* ty=Tensor[(2), int32] */;
    %3270 = add(%p1322, %3269) /* ty=Tensor[(2), int32] */;
    where(%p0670, %3270, %p1322) /* ty=Tensor[(2), int32] */
  };
  %3272 = (meta[relay.Constant][713] /* ty=Tensor[(2), bool] */, meta[relay.Constant][714] /* ty=Tensor[(2), int32] */, %x540);
  %3273 = (%tensor_0672,);
  let %v666: () = vm.invoke_tvm_op(%3271, %3272, %3273) /* ty=() */;
  let %x546: Tensor[(2), int32] = %tensor_0672;
  let %in_shape_0115: Tensor[(?, 4), float32] = device_copy(%x539, meta[relay.attrs.DeviceCopyAttrs][189]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_177: Tensor[(2), int32] = device_copy(%x546, meta[relay.attrs.DeviceCopyAttrs][190]) /* ty=Tensor[(2), int32] */;
  let %in_shape_257: Tensor[(2), int64] = device_copy(%x542, meta[relay.attrs.DeviceCopyAttrs][191]) /* ty=Tensor[(2), int64] */;
  let %in_shape_347: Tensor[(2), int32] = device_copy(meta[relay.Constant][715] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][192]) /* ty=Tensor[(2), int32] */;
  let %storage_0792: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][805]) /* ty=Storage[] */;
  let %tensor_0673: Tensor[(2), int64] = memory.alloc_tensor(%storage_0792, 0 /* ty=int64 */, meta[relay.Constant][716] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][805]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0125: Tensor[(2), int64] = %tensor_0673;
  %3274 = fn (%p0671: Tensor[(?, 4), float32], %p1323: Tensor[(2), int32], %p2188: Tensor[(2), int64], %p3109: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0671, %p1323, %p2188, %p3109, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %3275 = (%in_shape_0115, %in_shape_177, %in_shape_257, %in_shape_347);
  %3276 = (%shape_func_out_0125,);
  let %shape_func125: () = vm.shape_func(%3274, %3275, %3276, meta[relay.attrs.ShapeFuncAttrs][125]) /* ty=() */;
  let %storage_0793: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][806]) /* ty=Storage[] */;
  let %tensor_0674: int64 = memory.alloc_tensor(%storage_0793, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][806]) /* ty=int64 */;
  %3277 = fn (%p0672: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0672) /* ty=int64 */
  };
  %3278 = (%shape_func_out_0125,);
  %3279 = (%tensor_0674,);
  let %v667: () = vm.invoke_tvm_op(%3277, %3278, %3279) /* ty=() */;
  let %storage_0794: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][807]) /* ty=Storage[] */;
  let %tensor_0675: int64 = memory.alloc_tensor(%storage_0794, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][807]) /* ty=int64 */;
  %3280 = fn (%p0673: int64, Primitive=1) -> int64 {
    multiply(%p0673, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3281 = (%tensor_0674,);
  %3282 = (%tensor_0675,);
  let %v668: () = vm.invoke_tvm_op(%3280, %3281, %3282) /* ty=() */;
  let %storage_0795: Storage[] = memory.alloc_storage(%tensor_0675, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][808]) /* ty=Storage[] */;
  let %out_0119: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0795, 0 /* ty=int64 */, %shape_func_out_0125, meta[relay.attrs.AllocTensorAttrs][808]) /* ty=Tensor[(?, ?), float32] */;
  %3283 = (%x539, %x546, %x542, meta[relay.Constant][715] /* ty=Tensor[(2), int32] */);
  %3284 = (%out_0119,);
  let %v669: () = vm.invoke_tvm_op(%3274, %3283, %3284) /* ty=() */;
  let %x547: Tensor[(?, ?), float32] = %out_0119;
  let %storage_0796: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][809]) /* ty=Storage[] */;
  let %tensor_0676: Tensor[(2), int32] = memory.alloc_tensor(%storage_0796, 0 /* ty=int64 */, meta[relay.Constant][717] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][809]) /* ty=Tensor[(2), int32] */;
  %3287 = fn (%p0674: Tensor[(2), bool], %p1324: Tensor[(2), int32], %p2189: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3285 = cast_like(%p2189, %p1324) /* ty=Tensor[(2), int32] */;
    %3286 = add(%p1324, %3285) /* ty=Tensor[(2), int32] */;
    where(%p0674, %3286, %p1324) /* ty=Tensor[(2), int32] */
  };
  %3288 = (meta[relay.Constant][718] /* ty=Tensor[(2), bool] */, meta[relay.Constant][719] /* ty=Tensor[(2), int32] */, %x540);
  %3289 = (%tensor_0676,);
  let %v670: () = vm.invoke_tvm_op(%3287, %3288, %3289) /* ty=() */;
  let %x548: Tensor[(2), int32] = %tensor_0676;
  let %in_shape_0116: Tensor[(?, 4), float32] = device_copy(%x539, meta[relay.attrs.DeviceCopyAttrs][193]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_178: Tensor[(2), int32] = device_copy(%x548, meta[relay.attrs.DeviceCopyAttrs][194]) /* ty=Tensor[(2), int32] */;
  let %in_shape_258: Tensor[(2), int64] = device_copy(%x542, meta[relay.attrs.DeviceCopyAttrs][195]) /* ty=Tensor[(2), int64] */;
  let %in_shape_348: Tensor[(2), int32] = device_copy(meta[relay.Constant][720] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][196]) /* ty=Tensor[(2), int32] */;
  let %storage_0797: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][810]) /* ty=Storage[] */;
  let %tensor_0677: Tensor[(2), int64] = memory.alloc_tensor(%storage_0797, 0 /* ty=int64 */, meta[relay.Constant][721] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][810]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0126: Tensor[(2), int64] = %tensor_0677;
  %3290 = fn (%p0675: Tensor[(?, 4), float32], %p1325: Tensor[(2), int32], %p2190: Tensor[(2), int64], %p3110: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0675, %p1325, %p2190, %p3110, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %3291 = (%in_shape_0116, %in_shape_178, %in_shape_258, %in_shape_348);
  %3292 = (%shape_func_out_0126,);
  let %shape_func126: () = vm.shape_func(%3290, %3291, %3292, meta[relay.attrs.ShapeFuncAttrs][126]) /* ty=() */;
  let %storage_0798: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][811]) /* ty=Storage[] */;
  let %tensor_0678: int64 = memory.alloc_tensor(%storage_0798, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][811]) /* ty=int64 */;
  %3293 = fn (%p0676: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0676) /* ty=int64 */
  };
  %3294 = (%shape_func_out_0126,);
  %3295 = (%tensor_0678,);
  let %v671: () = vm.invoke_tvm_op(%3293, %3294, %3295) /* ty=() */;
  let %storage_0799: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][812]) /* ty=Storage[] */;
  let %tensor_0679: int64 = memory.alloc_tensor(%storage_0799, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][812]) /* ty=int64 */;
  %3296 = fn (%p0677: int64, Primitive=1) -> int64 {
    multiply(%p0677, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3297 = (%tensor_0678,);
  %3298 = (%tensor_0679,);
  let %v672: () = vm.invoke_tvm_op(%3296, %3297, %3298) /* ty=() */;
  let %storage_0800: Storage[] = memory.alloc_storage(%tensor_0679, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][813]) /* ty=Storage[] */;
  let %out_0120: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0800, 0 /* ty=int64 */, %shape_func_out_0126, meta[relay.attrs.AllocTensorAttrs][813]) /* ty=Tensor[(?, ?), float32] */;
  %3299 = (%x539, %x548, %x542, meta[relay.Constant][720] /* ty=Tensor[(2), int32] */);
  %3300 = (%out_0120,);
  let %v673: () = vm.invoke_tvm_op(%3290, %3299, %3300) /* ty=() */;
  let %x549: Tensor[(?, ?), float32] = %out_0120;
  let %in_shape_0117: Tensor[(2), int64] = vm.shape_of(%x543, meta[relay.attrs.ShapeOfAttrs][115]) /* ty=Tensor[(2), int64] */;
  let %in_shape_179: Tensor[(2), int64] = vm.shape_of(%x545, meta[relay.attrs.ShapeOfAttrs][116]) /* ty=Tensor[(2), int64] */;
  let %in_shape_259: Tensor[(2), int64] = vm.shape_of(%x547, meta[relay.attrs.ShapeOfAttrs][117]) /* ty=Tensor[(2), int64] */;
  let %in_shape_349: Tensor[(2), int64] = vm.shape_of(%x549, meta[relay.attrs.ShapeOfAttrs][118]) /* ty=Tensor[(2), int64] */;
  let %storage_0801: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][814]) /* ty=Storage[] */;
  let %tensor_0680: Tensor[(1), int64] = memory.alloc_tensor(%storage_0801, 0 /* ty=int64 */, meta[relay.Constant][722] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][814]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0127: Tensor[(1), int64] = %tensor_0680;
  %3318 = fn (%p0678: Tensor[(?, ?), float32], %p1326: Tensor[(?, ?), float32], %p2191: Tensor[(?, ?), float32], %p3111: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?), int64] {
    %3301 = take(%p0678, 2 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %3302 = take(%p1326, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %3303 = subtract(%3301, %3302) /* ty=Tensor[(?), float32] */;
    %3304 = take(%p2191, 3 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %3305 = take(%p3111, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %3306 = subtract(%3304, %3305) /* ty=Tensor[(?), float32] */;
    %3307 = multiply(%3303, %3306) /* ty=Tensor[(?), float32] */;
    %3308 = (%3307,);
    %3309 = concatenate(%3308) /* ty=Tensor[(?), float32] */;
    %3310 = sqrt(%3309) /* ty=Tensor[(?), float32] */;
    %3311 = divide(%3310, 224f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %3312 = log2(%3311) /* ty=Tensor[(?), float32] */;
    %3313 = add(%3312, 4f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %3314 = add(%3313, 1e-06f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %3315 = floor(%3314) /* ty=Tensor[(?), float32] */;
    %3316 = clip(%3315, a_min=2f, a_max=5f) /* ty=Tensor[(?), float32] */;
    %3317 = cast(%3316, dtype="int64") /* ty=Tensor[(?), int64] */;
    subtract(%3317, 2 /* ty=int64 */) /* ty=Tensor[(?), int64] */
  };
  %3319 = (%in_shape_0117, %in_shape_179, %in_shape_259, %in_shape_349);
  %3320 = (%shape_func_out_0127,);
  let %shape_func127: () = vm.shape_func(%3318, %3319, %3320, meta[relay.attrs.ShapeFuncAttrs][127]) /* ty=() */;
  let %storage_0802: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][815]) /* ty=Storage[] */;
  let %tensor_0681: int64 = memory.alloc_tensor(%storage_0802, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][815]) /* ty=int64 */;
  %3321 = fn (%p0679: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0679) /* ty=int64 */
  };
  %3322 = (%shape_func_out_0127,);
  %3323 = (%tensor_0681,);
  let %v674: () = vm.invoke_tvm_op(%3321, %3322, %3323) /* ty=() */;
  let %storage_0803: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][816]) /* ty=Storage[] */;
  let %tensor_0682: int64 = memory.alloc_tensor(%storage_0803, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][816]) /* ty=int64 */;
  %3324 = fn (%p0680: int64, Primitive=1) -> int64 {
    multiply(%p0680, 8 /* ty=int64 */) /* ty=int64 */
  };
  %3325 = (%tensor_0681,);
  %3326 = (%tensor_0682,);
  let %v675: () = vm.invoke_tvm_op(%3324, %3325, %3326) /* ty=() */;
  let %storage_0804: Storage[] = memory.alloc_storage(%tensor_0682, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][817]) /* ty=Storage[] */;
  let %out_0121: Tensor[(?), int64] = memory.alloc_tensor(%storage_0804, 0 /* ty=int64 */, %shape_func_out_0127, meta[relay.attrs.AllocTensorAttrs][817]) /* ty=Tensor[(?), int64] */;
  %3327 = (%x543, %x545, %x547, %x549);
  %3328 = (%out_0121,);
  let %v676: () = vm.invoke_tvm_op(%3318, %3327, %3328) /* ty=() */;
  let %x550: Tensor[(?), int64] = %out_0121;
  let %storage_0805: Storage[] = memory.alloc_storage(4 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][818]) /* ty=Storage[] */;
  let %tensor_0683: Tensor[(1), int32] = memory.alloc_tensor(%storage_0805, 0 /* ty=int64 */, meta[relay.Constant][723] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][818]) /* ty=Tensor[(1), int32] */;
  %3329 = fn (%p0681: Tensor[(?), int64], Primitive=1) -> Tensor[(1), int32] {
    shape_of(%p0681, dtype="int32") /* ty=Tensor[(1), int32] */
  };
  %3330 = (%x550,);
  %3331 = (%tensor_0683,);
  let %v677: () = vm.invoke_tvm_op(%3329, %3330, %3331) /* ty=() */;
  let %x551: Tensor[(1), int32] = %tensor_0683;
  let %storage_0806: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][819]) /* ty=Storage[] */;
  let %tensor_0684: Tensor[(4), int64] = memory.alloc_tensor(%storage_0806, 0 /* ty=int64 */, meta[relay.Constant][724] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][819]) /* ty=Tensor[(4), int64] */;
  %3336 = fn (%p0682: Tensor[(1), int32], %p1327: Tensor[(1), int64], %p2192: Tensor[(1), int64], Primitive=1) -> Tensor[(4), int64] {
    %3332 = take(%p0682, 0 /* ty=int32 */, axis=0) /* ty=int32 */;
    %3333 = expand_dims(%3332, axis=0) /* ty=Tensor[(1), int32] */;
    %3334 = cast(%3333, dtype="int64") /* ty=Tensor[(1), int64] */;
    %3335 = (%3334, %p1327, %p2192, %p2192);
    concatenate(%3335) /* ty=Tensor[(4), int64] */
  };
  %3337 = (%x551, meta[relay.Constant][382] /* ty=Tensor[(1), int64] */, meta[relay.Constant][725] /* ty=Tensor[(1), int64] */);
  %3338 = (%tensor_0684,);
  let %v678: () = vm.invoke_tvm_op(%3336, %3337, %3338) /* ty=() */;
  let %x552: Tensor[(4), int64] = %tensor_0684;
  let %in_shape_0118: int32 = device_copy(0 /* ty=int32 */, meta[relay.attrs.DeviceCopyAttrs][197]) /* ty=int32 */;
  let %in_shape_180: Tensor[(4), int64] = device_copy(%x552, meta[relay.attrs.DeviceCopyAttrs][198]) /* ty=Tensor[(4), int64] */;
  let %storage_0807: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][820]) /* ty=Storage[] */;
  let %tensor_0685: Tensor[(4), int64] = memory.alloc_tensor(%storage_0807, 0 /* ty=int64 */, meta[relay.Constant][726] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][820]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0128: Tensor[(4), int64] = %tensor_0685;
  %3339 = fn (%p0683: int32, %p1328: Tensor[(4), int64], Primitive=1) -> Tensor[(?, ?, ?, ?), float32] {
    dyn.full(%p0683, %p1328, shape=None, dtype="float32") /* ty=Tensor[(?, ?, ?, ?), float32] */
  };
  %3340 = (%in_shape_0118, %in_shape_180);
  %3341 = (%shape_func_out_0128,);
  let %shape_func128: () = vm.shape_func(%3339, %3340, %3341, meta[relay.attrs.ShapeFuncAttrs][128]) /* ty=() */;
  let %storage_0808: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][821]) /* ty=Storage[] */;
  let %tensor_0686: int64 = memory.alloc_tensor(%storage_0808, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][821]) /* ty=int64 */;
  %3342 = fn (%p0684: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0684) /* ty=int64 */
  };
  %3343 = (%shape_func_out_0128,);
  %3344 = (%tensor_0686,);
  let %v679: () = vm.invoke_tvm_op(%3342, %3343, %3344) /* ty=() */;
  let %storage_0809: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][822]) /* ty=Storage[] */;
  let %tensor_0687: int64 = memory.alloc_tensor(%storage_0809, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][822]) /* ty=int64 */;
  %3345 = fn (%p0685: int64, Primitive=1) -> int64 {
    multiply(%p0685, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3346 = (%tensor_0686,);
  %3347 = (%tensor_0687,);
  let %v680: () = vm.invoke_tvm_op(%3345, %3346, %3347) /* ty=() */;
  let %storage_0810: Storage[] = memory.alloc_storage(%tensor_0687, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][823]) /* ty=Storage[] */;
  let %out_0122: Tensor[(?, ?, ?, ?), float32] = memory.alloc_tensor(%storage_0810, 0 /* ty=int64 */, %shape_func_out_0128, meta[relay.attrs.AllocTensorAttrs][823]) /* ty=Tensor[(?, ?, ?, ?), float32] */;
  %3348 = (0 /* ty=int32 */, %x552);
  %3349 = (%out_0122,);
  let %v681: () = vm.invoke_tvm_op(%3339, %3348, %3349) /* ty=() */;
  let %x553: Tensor[(?, ?, ?, ?), float32] = %out_0122;
  let %in_shape_0119: Tensor[(4), int64] = vm.shape_of(%x553, meta[relay.attrs.ShapeOfAttrs][119]) /* ty=Tensor[(4), int64] */;
  let %storage_0811: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][824]) /* ty=Storage[] */;
  let %tensor_0688: Tensor[(4), int64] = memory.alloc_tensor(%storage_0811, 0 /* ty=int64 */, meta[relay.Constant][727] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][824]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0129: Tensor[(4), int64] = %tensor_0688;
  %3350 = fn (%p0686: Tensor[(?, ?, ?, ?), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    reshape(%p0686, newshape=[0, 256, 14, 14]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3351 = (%in_shape_0119,);
  %3352 = (%shape_func_out_0129,);
  let %shape_func129: () = vm.shape_func(%3350, %3351, %3352, meta[relay.attrs.ShapeFuncAttrs][129]) /* ty=() */;
  let %x554: Tensor[(?, 256, 14, 14), float32] = vm.reshape_tensor(%x553, %shape_func_out_0129, meta[relay.attrs.ReshapeTensorAttrs][112]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  let %in_shape_0120: Tensor[(1), int64] = vm.shape_of(%x550, meta[relay.attrs.ShapeOfAttrs][120]) /* ty=Tensor[(1), int64] */;
  let %storage_0812: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][825]) /* ty=Storage[] */;
  let %tensor_0689: Tensor[(1), int64] = memory.alloc_tensor(%storage_0812, 0 /* ty=int64 */, meta[relay.Constant][728] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][825]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0130: Tensor[(1), int64] = %tensor_0689;
  %3353 = fn (%p0687: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0687, 0 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %3354 = (%in_shape_0120,);
  %3355 = (%shape_func_out_0130,);
  let %shape_func130: () = vm.shape_func(%3353, %3354, %3355, meta[relay.attrs.ShapeFuncAttrs][130]) /* ty=() */;
  let %storage_0813: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][826]) /* ty=Storage[] */;
  let %tensor_0690: int64 = memory.alloc_tensor(%storage_0813, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][826]) /* ty=int64 */;
  %3356 = fn (%p0688: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0688) /* ty=int64 */
  };
  %3357 = (%shape_func_out_0130,);
  %3358 = (%tensor_0690,);
  let %v682: () = vm.invoke_tvm_op(%3356, %3357, %3358) /* ty=() */;
  let %storage_0814: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][827]) /* ty=Storage[] */;
  let %tensor_0691: int64 = memory.alloc_tensor(%storage_0814, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][827]) /* ty=int64 */;
  %3359 = fn (%p0689: int64, Primitive=1) -> int64 {
    multiply(%p0689, 1 /* ty=int64 */) /* ty=int64 */
  };
  %3360 = (%tensor_0690,);
  %3361 = (%tensor_0691,);
  let %v683: () = vm.invoke_tvm_op(%3359, %3360, %3361) /* ty=() */;
  let %storage_0815: Storage[] = memory.alloc_storage(%tensor_0691, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][828]) /* ty=Storage[] */;
  let %out_0123: Tensor[(?), bool] = memory.alloc_tensor(%storage_0815, 0 /* ty=int64 */, %shape_func_out_0130, meta[relay.attrs.AllocTensorAttrs][828]) /* ty=Tensor[(?), bool] */;
  %3362 = (%x550,);
  %3363 = (%out_0123,);
  let %v684: () = vm.invoke_tvm_op(%3353, %3362, %3363) /* ty=() */;
  let %x555: Tensor[(?), bool] = %out_0123;
  let %in_shape_0121: Tensor[(?), bool] = device_copy(%x555, meta[relay.attrs.DeviceCopyAttrs][199]) /* ty=Tensor[(?), bool] */;
  let %storage_0816: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][829]) /* ty=Storage[] */;
  let %tensor_0692: Tensor[(2), int64] = memory.alloc_tensor(%storage_0816, 0 /* ty=int64 */, meta[relay.Constant][729] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][829]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0131: Tensor[(2), int64] = %tensor_0692;
  %3364 = fn (%p0690: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0690) /* ty=Tensor[(?, 1), int32] */
  };
  %3365 = (%in_shape_0121,);
  %3366 = (%shape_func_out_0131,);
  let %shape_func131: () = vm.shape_func(%3364, %3365, %3366, meta[relay.attrs.ShapeFuncAttrs][131]) /* ty=() */;
  let %storage_0817: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][830]) /* ty=Storage[] */;
  let %tensor_0693: int64 = memory.alloc_tensor(%storage_0817, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][830]) /* ty=int64 */;
  %3367 = fn (%p0691: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0691) /* ty=int64 */
  };
  %3368 = (%shape_func_out_0131,);
  %3369 = (%tensor_0693,);
  let %v685: () = vm.invoke_tvm_op(%3367, %3368, %3369) /* ty=() */;
  let %storage_0818: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][831]) /* ty=Storage[] */;
  let %tensor_0694: int64 = memory.alloc_tensor(%storage_0818, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][831]) /* ty=int64 */;
  %3370 = fn (%p0692: int64, Primitive=1) -> int64 {
    multiply(%p0692, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3371 = (%tensor_0693,);
  %3372 = (%tensor_0694,);
  let %v686: () = vm.invoke_tvm_op(%3370, %3371, %3372) /* ty=() */;
  let %storage_0819: Storage[] = memory.alloc_storage(%tensor_0694, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][832]) /* ty=Storage[] */;
  let %out_0124: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0819, 0 /* ty=int64 */, %shape_func_out_0131, meta[relay.attrs.AllocTensorAttrs][832]) /* ty=Tensor[(?, 1), int32] */;
  %3373 = (%x555,);
  %3374 = (%out_0124,);
  let %v687: () = vm.invoke_tvm_op(%3364, %3373, %3374) /* ty=() */;
  let %x556: Tensor[(?, 1), int32] = %out_0124;
  let %in_shape_0122: Tensor[(2), int64] = vm.shape_of(%x556, meta[relay.attrs.ShapeOfAttrs][121]) /* ty=Tensor[(2), int64] */;
  let %storage_0820: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][833]) /* ty=Storage[] */;
  let %tensor_0695: Tensor[(1), int64] = memory.alloc_tensor(%storage_0820, 0 /* ty=int64 */, meta[relay.Constant][730] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][833]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0132: Tensor[(1), int64] = %tensor_0695;
  %3377 = fn (%p0693: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %3375 = split(%p0693, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %3376 = %3375.0;
    squeeze(%3376, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %3378 = (%in_shape_0122,);
  %3379 = (%shape_func_out_0132,);
  let %shape_func132: () = vm.shape_func(%3377, %3378, %3379, meta[relay.attrs.ShapeFuncAttrs][132]) /* ty=() */;
  let %storage_0821: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][834]) /* ty=Storage[] */;
  let %tensor_0696: int64 = memory.alloc_tensor(%storage_0821, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][834]) /* ty=int64 */;
  %3380 = fn (%p0694: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0694) /* ty=int64 */
  };
  %3381 = (%shape_func_out_0132,);
  %3382 = (%tensor_0696,);
  let %v688: () = vm.invoke_tvm_op(%3380, %3381, %3382) /* ty=() */;
  let %storage_0822: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][835]) /* ty=Storage[] */;
  let %tensor_0697: int64 = memory.alloc_tensor(%storage_0822, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][835]) /* ty=int64 */;
  %3383 = fn (%p0695: int64, Primitive=1) -> int64 {
    multiply(%p0695, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3384 = (%tensor_0696,);
  %3385 = (%tensor_0697,);
  let %v689: () = vm.invoke_tvm_op(%3383, %3384, %3385) /* ty=() */;
  let %storage_0823: Storage[] = memory.alloc_storage(%tensor_0697, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][836]) /* ty=Storage[] */;
  let %out_0125: Tensor[(?), int32] = memory.alloc_tensor(%storage_0823, 0 /* ty=int64 */, %shape_func_out_0132, meta[relay.attrs.AllocTensorAttrs][836]) /* ty=Tensor[(?), int32] */;
  %3386 = (%x556,);
  %3387 = (%out_0125,);
  let %v690: () = vm.invoke_tvm_op(%3377, %3386, %3387) /* ty=() */;
  let %x557: Tensor[(?), int32] = %out_0125;
  let %in_shape_0123: Tensor[(1), int64] = vm.shape_of(%x557, meta[relay.attrs.ShapeOfAttrs][122]) /* ty=Tensor[(1), int64] */;
  let %storage_0824: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][837]) /* ty=Storage[] */;
  let %tensor_0698: Tensor[(4), int64] = memory.alloc_tensor(%storage_0824, 0 /* ty=int64 */, meta[relay.Constant][731] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][837]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0133: Tensor[(4), int64] = %tensor_0698;
  %3391 = fn (%p0696: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 14, 14), int32] {
    %3388 = reshape(%p0696, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %3389 = repeat(%3388, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %3390 = repeat(%3389, repeats=14, axis=2) /* ty=Tensor[(?, 256, 14, 1), int32] */;
    repeat(%3390, repeats=14, axis=3) /* ty=Tensor[(?, 256, 14, 14), int32] */
  };
  %3392 = (%in_shape_0123,);
  %3393 = (%shape_func_out_0133,);
  let %shape_func133: () = vm.shape_func(%3391, %3392, %3393, meta[relay.attrs.ShapeFuncAttrs][133]) /* ty=() */;
  let %storage_0825: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][838]) /* ty=Storage[] */;
  let %tensor_0699: int64 = memory.alloc_tensor(%storage_0825, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][838]) /* ty=int64 */;
  %3394 = fn (%p0697: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0697) /* ty=int64 */
  };
  %3395 = (%shape_func_out_0133,);
  %3396 = (%tensor_0699,);
  let %v691: () = vm.invoke_tvm_op(%3394, %3395, %3396) /* ty=() */;
  let %storage_0826: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][839]) /* ty=Storage[] */;
  let %tensor_0700: int64 = memory.alloc_tensor(%storage_0826, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][839]) /* ty=int64 */;
  %3397 = fn (%p0698: int64, Primitive=1) -> int64 {
    multiply(%p0698, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3398 = (%tensor_0699,);
  %3399 = (%tensor_0700,);
  let %v692: () = vm.invoke_tvm_op(%3397, %3398, %3399) /* ty=() */;
  let %storage_0827: Storage[] = memory.alloc_storage(%tensor_0700, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][840]) /* ty=Storage[] */;
  let %out_0126: Tensor[(?, 256, 14, 14), int32] = memory.alloc_tensor(%storage_0827, 0 /* ty=int64 */, %shape_func_out_0133, meta[relay.attrs.AllocTensorAttrs][840]) /* ty=Tensor[(?, 256, 14, 14), int32] */;
  %3400 = (%x557,);
  %3401 = (%out_0126,);
  let %v693: () = vm.invoke_tvm_op(%3391, %3400, %3401) /* ty=() */;
  let %x558: Tensor[(?, 256, 14, 14), int32] = %out_0126;
  let %storage_0828: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][841]) /* ty=Storage[] */;
  let %tensor_0701: Tensor[(2), int32] = memory.alloc_tensor(%storage_0828, 0 /* ty=int64 */, meta[relay.Constant][732] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][841]) /* ty=Tensor[(2), int32] */;
  %3404 = fn (%p0699: Tensor[(2), bool], %p1329: Tensor[(2), int32], %p2193: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3402 = cast_like(%p2193, %p1329) /* ty=Tensor[(2), int32] */;
    %3403 = add(%p1329, %3402) /* ty=Tensor[(2), int32] */;
    where(%p0699, %3403, %p1329) /* ty=Tensor[(2), int32] */
  };
  %3405 = (meta[relay.Constant][733] /* ty=Tensor[(2), bool] */, meta[relay.Constant][734] /* ty=Tensor[(2), int32] */, %x540);
  %3406 = (%tensor_0701,);
  let %v694: () = vm.invoke_tvm_op(%3404, %3405, %3406) /* ty=() */;
  let %x559: Tensor[(2), int32] = %tensor_0701;
  let %in_shape_0124: Tensor[(?, 4), float32] = device_copy(%x539, meta[relay.attrs.DeviceCopyAttrs][200]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_181: Tensor[(2), int32] = device_copy(%x559, meta[relay.attrs.DeviceCopyAttrs][201]) /* ty=Tensor[(2), int32] */;
  let %in_shape_260: Tensor[(2), int64] = device_copy(%x542, meta[relay.attrs.DeviceCopyAttrs][202]) /* ty=Tensor[(2), int64] */;
  let %in_shape_350: Tensor[(2), int32] = device_copy(meta[relay.Constant][735] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][203]) /* ty=Tensor[(2), int32] */;
  let %storage_0829: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][842]) /* ty=Storage[] */;
  let %tensor_0702: Tensor[(2), int64] = memory.alloc_tensor(%storage_0829, 0 /* ty=int64 */, meta[relay.Constant][736] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][842]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0134: Tensor[(2), int64] = %tensor_0702;
  %3407 = fn (%p0700: Tensor[(?, 4), float32], %p1330: Tensor[(2), int32], %p2194: Tensor[(2), int64], %p3112: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0700, %p1330, %p2194, %p3112, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %3408 = (%in_shape_0124, %in_shape_181, %in_shape_260, %in_shape_350);
  %3409 = (%shape_func_out_0134,);
  let %shape_func134: () = vm.shape_func(%3407, %3408, %3409, meta[relay.attrs.ShapeFuncAttrs][134]) /* ty=() */;
  let %storage_0830: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][843]) /* ty=Storage[] */;
  let %tensor_0703: int64 = memory.alloc_tensor(%storage_0830, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][843]) /* ty=int64 */;
  %3410 = fn (%p0701: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0701) /* ty=int64 */
  };
  %3411 = (%shape_func_out_0134,);
  %3412 = (%tensor_0703,);
  let %v695: () = vm.invoke_tvm_op(%3410, %3411, %3412) /* ty=() */;
  let %storage_0831: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][844]) /* ty=Storage[] */;
  let %tensor_0704: int64 = memory.alloc_tensor(%storage_0831, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][844]) /* ty=int64 */;
  %3413 = fn (%p0702: int64, Primitive=1) -> int64 {
    multiply(%p0702, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3414 = (%tensor_0703,);
  %3415 = (%tensor_0704,);
  let %v696: () = vm.invoke_tvm_op(%3413, %3414, %3415) /* ty=() */;
  let %storage_0832: Storage[] = memory.alloc_storage(%tensor_0704, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][845]) /* ty=Storage[] */;
  let %out_0127: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0832, 0 /* ty=int64 */, %shape_func_out_0134, meta[relay.attrs.AllocTensorAttrs][845]) /* ty=Tensor[(?, ?), float32] */;
  %3416 = (%x539, %x559, %x542, meta[relay.Constant][735] /* ty=Tensor[(2), int32] */);
  %3417 = (%out_0127,);
  let %v697: () = vm.invoke_tvm_op(%3407, %3416, %3417) /* ty=() */;
  let %x560: Tensor[(?, ?), float32] = %out_0127;
  let %storage_0833: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][846]) /* ty=Storage[] */;
  let %tensor_0705: Tensor[(2), int32] = memory.alloc_tensor(%storage_0833, 0 /* ty=int64 */, meta[relay.Constant][737] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][846]) /* ty=Tensor[(2), int32] */;
  %3418 = fn (%p0703: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0703, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %3419 = (%x560,);
  %3420 = (%tensor_0705,);
  let %v698: () = vm.invoke_tvm_op(%3418, %3419, %3420) /* ty=() */;
  let %x561: Tensor[(2), int32] = %tensor_0705;
  let %storage_0834: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][847]) /* ty=Storage[] */;
  let %tensor_0706: Tensor[(2), int32] = memory.alloc_tensor(%storage_0834, 0 /* ty=int64 */, meta[relay.Constant][738] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][847]) /* ty=Tensor[(2), int32] */;
  %3423 = fn (%p0704: Tensor[(2), bool], %p1331: Tensor[(2), int32], %p2195: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3421 = cast_like(%p2195, %p1331) /* ty=Tensor[(2), int32] */;
    %3422 = add(%p1331, %3421) /* ty=Tensor[(2), int32] */;
    where(%p0704, %3422, %p1331) /* ty=Tensor[(2), int32] */
  };
  %3424 = (meta[relay.Constant][739] /* ty=Tensor[(2), bool] */, meta[relay.Constant][740] /* ty=Tensor[(2), int32] */, %x561);
  %3425 = (%tensor_0706,);
  let %v699: () = vm.invoke_tvm_op(%3423, %3424, %3425) /* ty=() */;
  let %x562: Tensor[(2), int32] = %tensor_0706;
  let %storage_0835: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][848]) /* ty=Storage[] */;
  let %tensor_0707: Tensor[(2), int32] = memory.alloc_tensor(%storage_0835, 0 /* ty=int64 */, meta[relay.Constant][741] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][848]) /* ty=Tensor[(2), int32] */;
  %3426 = fn (%p0705: Tensor[(2), int32], %p1332: Tensor[(1), int32], Primitive=1) -> Tensor[(2), int32] {
    scatter(%p0705, %p1332, %p1332, meta[relay.attrs.ScatterAttrs][5]) /* ty=Tensor[(2), int32] */
  };
  %3427 = (%x561, meta[relay.Constant][400] /* ty=Tensor[(1), int32] */);
  %3428 = (%tensor_0707,);
  let %v700: () = vm.invoke_tvm_op(%3426, %3427, %3428) /* ty=() */;
  let %x563: Tensor[(2), int32] = %tensor_0707;
  let %storage_0836: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][849]) /* ty=Storage[] */;
  let %tensor_0708: Tensor[(2), int64] = memory.alloc_tensor(%storage_0836, 0 /* ty=int64 */, meta[relay.Constant][742] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][849]) /* ty=Tensor[(2), int64] */;
  %3429 = fn (%p0706: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0706, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %3430 = (%x563,);
  %3431 = (%tensor_0708,);
  let %v701: () = vm.invoke_tvm_op(%3429, %3430, %3431) /* ty=() */;
  let %x564: Tensor[(2), int64] = %tensor_0708;
  let %in_shape_0125: Tensor[(?, ?), float32] = device_copy(%x560, meta[relay.attrs.DeviceCopyAttrs][204]) /* ty=Tensor[(?, ?), float32] */;
  let %in_shape_182: Tensor[(2), int32] = device_copy(%x562, meta[relay.attrs.DeviceCopyAttrs][205]) /* ty=Tensor[(2), int32] */;
  let %in_shape_261: Tensor[(2), int64] = device_copy(%x564, meta[relay.attrs.DeviceCopyAttrs][206]) /* ty=Tensor[(2), int64] */;
  let %in_shape_351: Tensor[(2), int32] = device_copy(meta[relay.Constant][743] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][207]) /* ty=Tensor[(2), int32] */;
  let %storage_0837: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][850]) /* ty=Storage[] */;
  let %tensor_0709: Tensor[(2), int64] = memory.alloc_tensor(%storage_0837, 0 /* ty=int64 */, meta[relay.Constant][744] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][850]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0135: Tensor[(2), int64] = %tensor_0709;
  %3432 = fn (%p0707: Tensor[(?, ?), float32], %p1333: Tensor[(2), int32], %p2196: Tensor[(2), int64], %p3113: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0707, %p1333, %p2196, %p3113, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %3433 = (%in_shape_0125, %in_shape_182, %in_shape_261, %in_shape_351);
  %3434 = (%shape_func_out_0135,);
  let %shape_func135: () = vm.shape_func(%3432, %3433, %3434, meta[relay.attrs.ShapeFuncAttrs][135]) /* ty=() */;
  let %storage_0838: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][851]) /* ty=Storage[] */;
  let %tensor_0710: int64 = memory.alloc_tensor(%storage_0838, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][851]) /* ty=int64 */;
  %3435 = fn (%p0708: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0708) /* ty=int64 */
  };
  %3436 = (%shape_func_out_0135,);
  %3437 = (%tensor_0710,);
  let %v702: () = vm.invoke_tvm_op(%3435, %3436, %3437) /* ty=() */;
  let %storage_0839: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][852]) /* ty=Storage[] */;
  let %tensor_0711: int64 = memory.alloc_tensor(%storage_0839, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][852]) /* ty=int64 */;
  %3438 = fn (%p0709: int64, Primitive=1) -> int64 {
    multiply(%p0709, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3439 = (%tensor_0710,);
  %3440 = (%tensor_0711,);
  let %v703: () = vm.invoke_tvm_op(%3438, %3439, %3440) /* ty=() */;
  let %storage_0840: Storage[] = memory.alloc_storage(%tensor_0711, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][853]) /* ty=Storage[] */;
  let %out_0128: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0840, 0 /* ty=int64 */, %shape_func_out_0135, meta[relay.attrs.AllocTensorAttrs][853]) /* ty=Tensor[(?, ?), float32] */;
  %3441 = (%x560, %x562, %x564, meta[relay.Constant][743] /* ty=Tensor[(2), int32] */);
  %3442 = (%out_0128,);
  let %v704: () = vm.invoke_tvm_op(%3432, %3441, %3442) /* ty=() */;
  let %x565: Tensor[(?, ?), float32] = %out_0128;
  let %in_shape_0126: Tensor[(2), int64] = vm.shape_of(%x565, meta[relay.attrs.ShapeOfAttrs][123]) /* ty=Tensor[(2), int64] */;
  let %in_shape_183: Tensor[(2), int64] = vm.shape_of(%x539, meta[relay.attrs.ShapeOfAttrs][124]) /* ty=Tensor[(2), int64] */;
  let %storage_0841: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][854]) /* ty=Storage[] */;
  let %tensor_0712: Tensor[(2), int64] = memory.alloc_tensor(%storage_0841, 0 /* ty=int64 */, meta[relay.Constant][745] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][854]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0136: Tensor[(2), int64] = %tensor_0712;
  %3449 = fn (%p0710: Tensor[(?, ?), float32], %p1334: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(?, ?), float32] {
    %3443 = full_like(%p0710, 0 /* ty=int32 */) /* ty=Tensor[(?, ?), float32] */;
    %3444 = (%3443,);
    %3445 = concatenate(%3444) /* ty=Tensor[(?, ?), float32] */;
    %3446 = (%p1334,);
    %3447 = concatenate(%3446) /* ty=Tensor[(?, 4), float32] */;
    %3448 = (%3445, %3447);
    concatenate(%3448, axis=1) /* ty=Tensor[(?, ?), float32] */
  };
  %3450 = (%in_shape_0126, %in_shape_183);
  %3451 = (%shape_func_out_0136,);
  let %shape_func136: () = vm.shape_func(%3449, %3450, %3451, meta[relay.attrs.ShapeFuncAttrs][136]) /* ty=() */;
  let %storage_0842: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][855]) /* ty=Storage[] */;
  let %tensor_0713: int64 = memory.alloc_tensor(%storage_0842, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][855]) /* ty=int64 */;
  %3452 = fn (%p0711: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0711) /* ty=int64 */
  };
  %3453 = (%shape_func_out_0136,);
  %3454 = (%tensor_0713,);
  let %v705: () = vm.invoke_tvm_op(%3452, %3453, %3454) /* ty=() */;
  let %storage_0843: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][856]) /* ty=Storage[] */;
  let %tensor_0714: int64 = memory.alloc_tensor(%storage_0843, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][856]) /* ty=int64 */;
  %3455 = fn (%p0712: int64, Primitive=1) -> int64 {
    multiply(%p0712, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3456 = (%tensor_0713,);
  %3457 = (%tensor_0714,);
  let %v706: () = vm.invoke_tvm_op(%3455, %3456, %3457) /* ty=() */;
  let %storage_0844: Storage[] = memory.alloc_storage(%tensor_0714, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][857]) /* ty=Storage[] */;
  let %out_0129: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0844, 0 /* ty=int64 */, %shape_func_out_0136, meta[relay.attrs.AllocTensorAttrs][857]) /* ty=Tensor[(?, ?), float32] */;
  %3458 = (%x565, %x539);
  %3459 = (%out_0129,);
  let %v707: () = vm.invoke_tvm_op(%3449, %3458, %3459) /* ty=() */;
  let %x566: Tensor[(?, ?), float32] = %out_0129;
  let %in_shape_0127: Tensor[(2), int64] = vm.shape_of(%x566, meta[relay.attrs.ShapeOfAttrs][125]) /* ty=Tensor[(2), int64] */;
  let %in_shape_184: Tensor[(1), int64] = vm.shape_of(%x557, meta[relay.attrs.ShapeOfAttrs][126]) /* ty=Tensor[(1), int64] */;
  let %storage_0845: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][858]) /* ty=Storage[] */;
  let %tensor_0715: Tensor[(2), int64] = memory.alloc_tensor(%storage_0845, 0 /* ty=int64 */, meta[relay.Constant][746] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][858]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0137: Tensor[(2), int64] = %tensor_0715;
  %3462 = fn (%p0713: Tensor[(?, ?), float32], %p1335: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %3460 = cast(%p1335, dtype="int64") /* ty=Tensor[(?), int64] */;
    %3461 = (%p0713, %3460);
    adv_index(%3461) /* ty=Tensor[(?, ?), float32] */
  };
  %3463 = (%in_shape_0127, %in_shape_184);
  %3464 = (%shape_func_out_0137,);
  let %shape_func137: () = vm.shape_func(%3462, %3463, %3464, meta[relay.attrs.ShapeFuncAttrs][137]) /* ty=() */;
  let %storage_0846: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][859]) /* ty=Storage[] */;
  let %tensor_0716: int64 = memory.alloc_tensor(%storage_0846, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][859]) /* ty=int64 */;
  %3465 = fn (%p0714: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0714) /* ty=int64 */
  };
  %3466 = (%shape_func_out_0137,);
  %3467 = (%tensor_0716,);
  let %v708: () = vm.invoke_tvm_op(%3465, %3466, %3467) /* ty=() */;
  let %storage_0847: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][860]) /* ty=Storage[] */;
  let %tensor_0717: int64 = memory.alloc_tensor(%storage_0847, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][860]) /* ty=int64 */;
  %3468 = fn (%p0715: int64, Primitive=1) -> int64 {
    multiply(%p0715, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3469 = (%tensor_0716,);
  %3470 = (%tensor_0717,);
  let %v709: () = vm.invoke_tvm_op(%3468, %3469, %3470) /* ty=() */;
  let %storage_0848: Storage[] = memory.alloc_storage(%tensor_0717, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][861]) /* ty=Storage[] */;
  let %out_0130: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0848, 0 /* ty=int64 */, %shape_func_out_0137, meta[relay.attrs.AllocTensorAttrs][861]) /* ty=Tensor[(?, ?), float32] */;
  %3471 = (%x566, %x557);
  %3472 = (%out_0130,);
  let %v710: () = vm.invoke_tvm_op(%3462, %3471, %3472) /* ty=() */;
  let %x567: Tensor[(?, ?), float32] = %out_0130;
  let %in_shape_185: Tensor[(2), int64] = vm.shape_of(%x567, meta[relay.attrs.ShapeOfAttrs][127]) /* ty=Tensor[(2), int64] */;
  let %storage_0849: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][862]) /* ty=Storage[] */;
  let %tensor_0718: Tensor[(4), int64] = memory.alloc_tensor(%storage_0849, 0 /* ty=int64 */, meta[relay.Constant][747] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][862]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0138: Tensor[(4), int64] = %tensor_0718;
  %3473 = fn (%p0716: Tensor[(1, 256, 200, 200), float32], %p1336: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    vision.roi_align(%p0716, %p1336, meta[relay.attrs.ROIAlignAttrs][4]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3474 = (meta[relay.Constant][748] /* ty=Tensor[(4), int64] */, %in_shape_185);
  %3475 = (%shape_func_out_0138,);
  let %shape_func138: () = vm.shape_func(%3473, %3474, %3475, meta[relay.attrs.ShapeFuncAttrs][138]) /* ty=() */;
  let %storage_0850: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][863]) /* ty=Storage[] */;
  let %tensor_0719: int64 = memory.alloc_tensor(%storage_0850, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][863]) /* ty=int64 */;
  %3476 = fn (%p0717: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0717) /* ty=int64 */
  };
  %3477 = (%shape_func_out_0138,);
  %3478 = (%tensor_0719,);
  let %v711: () = vm.invoke_tvm_op(%3476, %3477, %3478) /* ty=() */;
  let %storage_0851: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][864]) /* ty=Storage[] */;
  let %tensor_0720: int64 = memory.alloc_tensor(%storage_0851, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][864]) /* ty=int64 */;
  %3479 = fn (%p0718: int64, Primitive=1) -> int64 {
    multiply(%p0718, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3480 = (%tensor_0719,);
  %3481 = (%tensor_0720,);
  let %v712: () = vm.invoke_tvm_op(%3479, %3480, %3481) /* ty=() */;
  let %storage_0852: Storage[] = memory.alloc_storage(%tensor_0720, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][865]) /* ty=Storage[] */;
  let %out_0131: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0852, 0 /* ty=int64 */, %shape_func_out_0138, meta[relay.attrs.AllocTensorAttrs][865]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3482 = (%x275, %x567);
  %3483 = (%out_0131,);
  let %v713: () = vm.invoke_tvm_op(%3473, %3482, %3483) /* ty=() */;
  let %x568: Tensor[(?, 256, 14, 14), float32] = %out_0131;
  let %in_shape_0128: Tensor[(4), int64] = vm.shape_of(%x554, meta[relay.attrs.ShapeOfAttrs][128]) /* ty=Tensor[(4), int64] */;
  let %in_shape_186: Tensor[(4), int64] = vm.shape_of(%x558, meta[relay.attrs.ShapeOfAttrs][129]) /* ty=Tensor[(4), int64] */;
  let %in_shape_262: Tensor[(4), int64] = vm.shape_of(%x568, meta[relay.attrs.ShapeOfAttrs][130]) /* ty=Tensor[(4), int64] */;
  let %storage_0853: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][866]) /* ty=Storage[] */;
  let %tensor_0721: Tensor[(4), int64] = memory.alloc_tensor(%storage_0853, 0 /* ty=int64 */, meta[relay.Constant][749] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][866]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0139: Tensor[(4), int64] = %tensor_0721;
  %3484 = fn (%p0719: Tensor[(?, 256, 14, 14), float32], %p1337: Tensor[(?, 256, 14, 14), int32], %p2197: Tensor[(?, 256, 14, 14), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    scatter(%p0719, %p1337, %p2197, meta[relay.attrs.ScatterAttrs][6]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3485 = (%in_shape_0128, %in_shape_186, %in_shape_262);
  %3486 = (%shape_func_out_0139,);
  let %shape_func139: () = vm.shape_func(%3484, %3485, %3486, meta[relay.attrs.ShapeFuncAttrs][139]) /* ty=() */;
  let %storage_0854: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][867]) /* ty=Storage[] */;
  let %tensor_0722: int64 = memory.alloc_tensor(%storage_0854, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][867]) /* ty=int64 */;
  %3487 = fn (%p0720: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0720) /* ty=int64 */
  };
  %3488 = (%shape_func_out_0139,);
  %3489 = (%tensor_0722,);
  let %v714: () = vm.invoke_tvm_op(%3487, %3488, %3489) /* ty=() */;
  let %storage_0855: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][868]) /* ty=Storage[] */;
  let %tensor_0723: int64 = memory.alloc_tensor(%storage_0855, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][868]) /* ty=int64 */;
  %3490 = fn (%p0721: int64, Primitive=1) -> int64 {
    multiply(%p0721, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3491 = (%tensor_0722,);
  %3492 = (%tensor_0723,);
  let %v715: () = vm.invoke_tvm_op(%3490, %3491, %3492) /* ty=() */;
  let %storage_0856: Storage[] = memory.alloc_storage(%tensor_0723, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][869]) /* ty=Storage[] */;
  let %out_0132: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0856, 0 /* ty=int64 */, %shape_func_out_0139, meta[relay.attrs.AllocTensorAttrs][869]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3493 = (%x554, %x558, %x568);
  %3494 = (%out_0132,);
  let %v716: () = vm.invoke_tvm_op(%3484, %3493, %3494) /* ty=() */;
  let %x569: Tensor[(?, 256, 14, 14), float32] = %out_0132;
  let %in_shape_0129: Tensor[(1), int64] = vm.shape_of(%x550, meta[relay.attrs.ShapeOfAttrs][131]) /* ty=Tensor[(1), int64] */;
  let %storage_0857: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][870]) /* ty=Storage[] */;
  let %tensor_0724: Tensor[(1), int64] = memory.alloc_tensor(%storage_0857, 0 /* ty=int64 */, meta[relay.Constant][750] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][870]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0140: Tensor[(1), int64] = %tensor_0724;
  %3495 = fn (%p0722: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0722, 1 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %3496 = (%in_shape_0129,);
  %3497 = (%shape_func_out_0140,);
  let %shape_func140: () = vm.shape_func(%3495, %3496, %3497, meta[relay.attrs.ShapeFuncAttrs][140]) /* ty=() */;
  let %storage_0858: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][871]) /* ty=Storage[] */;
  let %tensor_0725: int64 = memory.alloc_tensor(%storage_0858, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][871]) /* ty=int64 */;
  %3498 = fn (%p0723: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0723) /* ty=int64 */
  };
  %3499 = (%shape_func_out_0140,);
  %3500 = (%tensor_0725,);
  let %v717: () = vm.invoke_tvm_op(%3498, %3499, %3500) /* ty=() */;
  let %storage_0859: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][872]) /* ty=Storage[] */;
  let %tensor_0726: int64 = memory.alloc_tensor(%storage_0859, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][872]) /* ty=int64 */;
  %3501 = fn (%p0724: int64, Primitive=1) -> int64 {
    multiply(%p0724, 1 /* ty=int64 */) /* ty=int64 */
  };
  %3502 = (%tensor_0725,);
  %3503 = (%tensor_0726,);
  let %v718: () = vm.invoke_tvm_op(%3501, %3502, %3503) /* ty=() */;
  let %storage_0860: Storage[] = memory.alloc_storage(%tensor_0726, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][873]) /* ty=Storage[] */;
  let %out_0133: Tensor[(?), bool] = memory.alloc_tensor(%storage_0860, 0 /* ty=int64 */, %shape_func_out_0140, meta[relay.attrs.AllocTensorAttrs][873]) /* ty=Tensor[(?), bool] */;
  %3504 = (%x550,);
  %3505 = (%out_0133,);
  let %v719: () = vm.invoke_tvm_op(%3495, %3504, %3505) /* ty=() */;
  let %x570: Tensor[(?), bool] = %out_0133;
  let %in_shape_0130: Tensor[(?), bool] = device_copy(%x570, meta[relay.attrs.DeviceCopyAttrs][208]) /* ty=Tensor[(?), bool] */;
  let %storage_0861: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][874]) /* ty=Storage[] */;
  let %tensor_0727: Tensor[(2), int64] = memory.alloc_tensor(%storage_0861, 0 /* ty=int64 */, meta[relay.Constant][751] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][874]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0141: Tensor[(2), int64] = %tensor_0727;
  %3506 = fn (%p0725: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0725) /* ty=Tensor[(?, 1), int32] */
  };
  %3507 = (%in_shape_0130,);
  %3508 = (%shape_func_out_0141,);
  let %shape_func141: () = vm.shape_func(%3506, %3507, %3508, meta[relay.attrs.ShapeFuncAttrs][141]) /* ty=() */;
  let %storage_0862: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][875]) /* ty=Storage[] */;
  let %tensor_0728: int64 = memory.alloc_tensor(%storage_0862, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][875]) /* ty=int64 */;
  %3509 = fn (%p0726: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0726) /* ty=int64 */
  };
  %3510 = (%shape_func_out_0141,);
  %3511 = (%tensor_0728,);
  let %v720: () = vm.invoke_tvm_op(%3509, %3510, %3511) /* ty=() */;
  let %storage_0863: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][876]) /* ty=Storage[] */;
  let %tensor_0729: int64 = memory.alloc_tensor(%storage_0863, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][876]) /* ty=int64 */;
  %3512 = fn (%p0727: int64, Primitive=1) -> int64 {
    multiply(%p0727, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3513 = (%tensor_0728,);
  %3514 = (%tensor_0729,);
  let %v721: () = vm.invoke_tvm_op(%3512, %3513, %3514) /* ty=() */;
  let %storage_0864: Storage[] = memory.alloc_storage(%tensor_0729, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][877]) /* ty=Storage[] */;
  let %out_0134: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0864, 0 /* ty=int64 */, %shape_func_out_0141, meta[relay.attrs.AllocTensorAttrs][877]) /* ty=Tensor[(?, 1), int32] */;
  %3515 = (%x570,);
  %3516 = (%out_0134,);
  let %v722: () = vm.invoke_tvm_op(%3506, %3515, %3516) /* ty=() */;
  let %x571: Tensor[(?, 1), int32] = %out_0134;
  let %in_shape_0131: Tensor[(2), int64] = vm.shape_of(%x571, meta[relay.attrs.ShapeOfAttrs][132]) /* ty=Tensor[(2), int64] */;
  let %storage_0865: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][878]) /* ty=Storage[] */;
  let %tensor_0730: Tensor[(1), int64] = memory.alloc_tensor(%storage_0865, 0 /* ty=int64 */, meta[relay.Constant][752] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][878]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0142: Tensor[(1), int64] = %tensor_0730;
  %3519 = fn (%p0728: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %3517 = split(%p0728, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %3518 = %3517.0;
    squeeze(%3518, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %3520 = (%in_shape_0131,);
  %3521 = (%shape_func_out_0142,);
  let %shape_func142: () = vm.shape_func(%3519, %3520, %3521, meta[relay.attrs.ShapeFuncAttrs][142]) /* ty=() */;
  let %storage_0866: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][879]) /* ty=Storage[] */;
  let %tensor_0731: int64 = memory.alloc_tensor(%storage_0866, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][879]) /* ty=int64 */;
  %3522 = fn (%p0729: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0729) /* ty=int64 */
  };
  %3523 = (%shape_func_out_0142,);
  %3524 = (%tensor_0731,);
  let %v723: () = vm.invoke_tvm_op(%3522, %3523, %3524) /* ty=() */;
  let %storage_0867: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][880]) /* ty=Storage[] */;
  let %tensor_0732: int64 = memory.alloc_tensor(%storage_0867, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][880]) /* ty=int64 */;
  %3525 = fn (%p0730: int64, Primitive=1) -> int64 {
    multiply(%p0730, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3526 = (%tensor_0731,);
  %3527 = (%tensor_0732,);
  let %v724: () = vm.invoke_tvm_op(%3525, %3526, %3527) /* ty=() */;
  let %storage_0868: Storage[] = memory.alloc_storage(%tensor_0732, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][881]) /* ty=Storage[] */;
  let %out_0135: Tensor[(?), int32] = memory.alloc_tensor(%storage_0868, 0 /* ty=int64 */, %shape_func_out_0142, meta[relay.attrs.AllocTensorAttrs][881]) /* ty=Tensor[(?), int32] */;
  %3528 = (%x571,);
  %3529 = (%out_0135,);
  let %v725: () = vm.invoke_tvm_op(%3519, %3528, %3529) /* ty=() */;
  let %x572: Tensor[(?), int32] = %out_0135;
  let %in_shape_0132: Tensor[(1), int64] = vm.shape_of(%x572, meta[relay.attrs.ShapeOfAttrs][133]) /* ty=Tensor[(1), int64] */;
  let %storage_0869: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][882]) /* ty=Storage[] */;
  let %tensor_0733: Tensor[(4), int64] = memory.alloc_tensor(%storage_0869, 0 /* ty=int64 */, meta[relay.Constant][753] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][882]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0143: Tensor[(4), int64] = %tensor_0733;
  %3533 = fn (%p0731: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 14, 14), int32] {
    %3530 = reshape(%p0731, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %3531 = repeat(%3530, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %3532 = repeat(%3531, repeats=14, axis=2) /* ty=Tensor[(?, 256, 14, 1), int32] */;
    repeat(%3532, repeats=14, axis=3) /* ty=Tensor[(?, 256, 14, 14), int32] */
  };
  %3534 = (%in_shape_0132,);
  %3535 = (%shape_func_out_0143,);
  let %shape_func143: () = vm.shape_func(%3533, %3534, %3535, meta[relay.attrs.ShapeFuncAttrs][143]) /* ty=() */;
  let %storage_0870: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][883]) /* ty=Storage[] */;
  let %tensor_0734: int64 = memory.alloc_tensor(%storage_0870, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][883]) /* ty=int64 */;
  %3536 = fn (%p0732: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0732) /* ty=int64 */
  };
  %3537 = (%shape_func_out_0143,);
  %3538 = (%tensor_0734,);
  let %v726: () = vm.invoke_tvm_op(%3536, %3537, %3538) /* ty=() */;
  let %storage_0871: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][884]) /* ty=Storage[] */;
  let %tensor_0735: int64 = memory.alloc_tensor(%storage_0871, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][884]) /* ty=int64 */;
  %3539 = fn (%p0733: int64, Primitive=1) -> int64 {
    multiply(%p0733, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3540 = (%tensor_0734,);
  %3541 = (%tensor_0735,);
  let %v727: () = vm.invoke_tvm_op(%3539, %3540, %3541) /* ty=() */;
  let %storage_0872: Storage[] = memory.alloc_storage(%tensor_0735, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][885]) /* ty=Storage[] */;
  let %out_0136: Tensor[(?, 256, 14, 14), int32] = memory.alloc_tensor(%storage_0872, 0 /* ty=int64 */, %shape_func_out_0143, meta[relay.attrs.AllocTensorAttrs][885]) /* ty=Tensor[(?, 256, 14, 14), int32] */;
  %3542 = (%x572,);
  %3543 = (%out_0136,);
  let %v728: () = vm.invoke_tvm_op(%3533, %3542, %3543) /* ty=() */;
  let %x573: Tensor[(?, 256, 14, 14), int32] = %out_0136;
  let %in_shape_0133: Tensor[(2), int64] = vm.shape_of(%x566, meta[relay.attrs.ShapeOfAttrs][134]) /* ty=Tensor[(2), int64] */;
  let %in_shape_187: Tensor[(1), int64] = vm.shape_of(%x572, meta[relay.attrs.ShapeOfAttrs][135]) /* ty=Tensor[(1), int64] */;
  let %storage_0873: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][886]) /* ty=Storage[] */;
  let %tensor_0736: Tensor[(2), int64] = memory.alloc_tensor(%storage_0873, 0 /* ty=int64 */, meta[relay.Constant][754] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][886]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0144: Tensor[(2), int64] = %tensor_0736;
  %3546 = fn (%p0734: Tensor[(?, ?), float32], %p1338: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %3544 = cast(%p1338, dtype="int64") /* ty=Tensor[(?), int64] */;
    %3545 = (%p0734, %3544);
    adv_index(%3545) /* ty=Tensor[(?, ?), float32] */
  };
  %3547 = (%in_shape_0133, %in_shape_187);
  %3548 = (%shape_func_out_0144,);
  let %shape_func144: () = vm.shape_func(%3546, %3547, %3548, meta[relay.attrs.ShapeFuncAttrs][144]) /* ty=() */;
  let %storage_0874: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][887]) /* ty=Storage[] */;
  let %tensor_0737: int64 = memory.alloc_tensor(%storage_0874, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][887]) /* ty=int64 */;
  %3549 = fn (%p0735: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0735) /* ty=int64 */
  };
  %3550 = (%shape_func_out_0144,);
  %3551 = (%tensor_0737,);
  let %v729: () = vm.invoke_tvm_op(%3549, %3550, %3551) /* ty=() */;
  let %storage_0875: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][888]) /* ty=Storage[] */;
  let %tensor_0738: int64 = memory.alloc_tensor(%storage_0875, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][888]) /* ty=int64 */;
  %3552 = fn (%p0736: int64, Primitive=1) -> int64 {
    multiply(%p0736, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3553 = (%tensor_0737,);
  %3554 = (%tensor_0738,);
  let %v730: () = vm.invoke_tvm_op(%3552, %3553, %3554) /* ty=() */;
  let %storage_0876: Storage[] = memory.alloc_storage(%tensor_0738, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][889]) /* ty=Storage[] */;
  let %out_0137: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0876, 0 /* ty=int64 */, %shape_func_out_0144, meta[relay.attrs.AllocTensorAttrs][889]) /* ty=Tensor[(?, ?), float32] */;
  %3555 = (%x566, %x572);
  %3556 = (%out_0137,);
  let %v731: () = vm.invoke_tvm_op(%3546, %3555, %3556) /* ty=() */;
  let %x574: Tensor[(?, ?), float32] = %out_0137;
  let %in_shape_188: Tensor[(2), int64] = vm.shape_of(%x574, meta[relay.attrs.ShapeOfAttrs][136]) /* ty=Tensor[(2), int64] */;
  let %storage_0877: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][890]) /* ty=Storage[] */;
  let %tensor_0739: Tensor[(4), int64] = memory.alloc_tensor(%storage_0877, 0 /* ty=int64 */, meta[relay.Constant][755] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][890]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0145: Tensor[(4), int64] = %tensor_0739;
  %3557 = fn (%p0737: Tensor[(1, 256, 100, 100), float32], %p1339: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    vision.roi_align(%p0737, %p1339, meta[relay.attrs.ROIAlignAttrs][5]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3558 = (meta[relay.Constant][756] /* ty=Tensor[(4), int64] */, %in_shape_188);
  %3559 = (%shape_func_out_0145,);
  let %shape_func145: () = vm.shape_func(%3557, %3558, %3559, meta[relay.attrs.ShapeFuncAttrs][145]) /* ty=() */;
  let %storage_0878: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][891]) /* ty=Storage[] */;
  let %tensor_0740: int64 = memory.alloc_tensor(%storage_0878, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][891]) /* ty=int64 */;
  %3560 = fn (%p0738: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0738) /* ty=int64 */
  };
  %3561 = (%shape_func_out_0145,);
  %3562 = (%tensor_0740,);
  let %v732: () = vm.invoke_tvm_op(%3560, %3561, %3562) /* ty=() */;
  let %storage_0879: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][892]) /* ty=Storage[] */;
  let %tensor_0741: int64 = memory.alloc_tensor(%storage_0879, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][892]) /* ty=int64 */;
  %3563 = fn (%p0739: int64, Primitive=1) -> int64 {
    multiply(%p0739, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3564 = (%tensor_0740,);
  %3565 = (%tensor_0741,);
  let %v733: () = vm.invoke_tvm_op(%3563, %3564, %3565) /* ty=() */;
  let %storage_0880: Storage[] = memory.alloc_storage(%tensor_0741, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][893]) /* ty=Storage[] */;
  let %out_0138: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0880, 0 /* ty=int64 */, %shape_func_out_0145, meta[relay.attrs.AllocTensorAttrs][893]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3566 = (%x278, %x574);
  %3567 = (%out_0138,);
  let %v734: () = vm.invoke_tvm_op(%3557, %3566, %3567) /* ty=() */;
  let %x575: Tensor[(?, 256, 14, 14), float32] = %out_0138;
  let %in_shape_0134: Tensor[(4), int64] = vm.shape_of(%x569, meta[relay.attrs.ShapeOfAttrs][137]) /* ty=Tensor[(4), int64] */;
  let %in_shape_189: Tensor[(4), int64] = vm.shape_of(%x573, meta[relay.attrs.ShapeOfAttrs][138]) /* ty=Tensor[(4), int64] */;
  let %in_shape_263: Tensor[(4), int64] = vm.shape_of(%x575, meta[relay.attrs.ShapeOfAttrs][139]) /* ty=Tensor[(4), int64] */;
  let %storage_0881: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][894]) /* ty=Storage[] */;
  let %tensor_0742: Tensor[(4), int64] = memory.alloc_tensor(%storage_0881, 0 /* ty=int64 */, meta[relay.Constant][757] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][894]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0146: Tensor[(4), int64] = %tensor_0742;
  %3568 = fn (%p0740: Tensor[(?, 256, 14, 14), float32], %p1340: Tensor[(?, 256, 14, 14), int32], %p2198: Tensor[(?, 256, 14, 14), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    scatter(%p0740, %p1340, %p2198, meta[relay.attrs.ScatterAttrs][7]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3569 = (%in_shape_0134, %in_shape_189, %in_shape_263);
  %3570 = (%shape_func_out_0146,);
  let %shape_func146: () = vm.shape_func(%3568, %3569, %3570, meta[relay.attrs.ShapeFuncAttrs][146]) /* ty=() */;
  let %storage_0882: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][895]) /* ty=Storage[] */;
  let %tensor_0743: int64 = memory.alloc_tensor(%storage_0882, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][895]) /* ty=int64 */;
  %3571 = fn (%p0741: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0741) /* ty=int64 */
  };
  %3572 = (%shape_func_out_0146,);
  %3573 = (%tensor_0743,);
  let %v735: () = vm.invoke_tvm_op(%3571, %3572, %3573) /* ty=() */;
  let %storage_0883: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][896]) /* ty=Storage[] */;
  let %tensor_0744: int64 = memory.alloc_tensor(%storage_0883, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][896]) /* ty=int64 */;
  %3574 = fn (%p0742: int64, Primitive=1) -> int64 {
    multiply(%p0742, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3575 = (%tensor_0743,);
  %3576 = (%tensor_0744,);
  let %v736: () = vm.invoke_tvm_op(%3574, %3575, %3576) /* ty=() */;
  let %storage_0884: Storage[] = memory.alloc_storage(%tensor_0744, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][897]) /* ty=Storage[] */;
  let %out_0139: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0884, 0 /* ty=int64 */, %shape_func_out_0146, meta[relay.attrs.AllocTensorAttrs][897]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3577 = (%x569, %x573, %x575);
  %3578 = (%out_0139,);
  let %v737: () = vm.invoke_tvm_op(%3568, %3577, %3578) /* ty=() */;
  let %x576: Tensor[(?, 256, 14, 14), float32] = %out_0139;
  let %in_shape_0135: Tensor[(1), int64] = vm.shape_of(%x550, meta[relay.attrs.ShapeOfAttrs][140]) /* ty=Tensor[(1), int64] */;
  let %storage_0885: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][898]) /* ty=Storage[] */;
  let %tensor_0745: Tensor[(1), int64] = memory.alloc_tensor(%storage_0885, 0 /* ty=int64 */, meta[relay.Constant][758] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][898]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0147: Tensor[(1), int64] = %tensor_0745;
  %3579 = fn (%p0743: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0743, 2 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %3580 = (%in_shape_0135,);
  %3581 = (%shape_func_out_0147,);
  let %shape_func147: () = vm.shape_func(%3579, %3580, %3581, meta[relay.attrs.ShapeFuncAttrs][147]) /* ty=() */;
  let %storage_0886: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][899]) /* ty=Storage[] */;
  let %tensor_0746: int64 = memory.alloc_tensor(%storage_0886, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][899]) /* ty=int64 */;
  %3582 = fn (%p0744: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0744) /* ty=int64 */
  };
  %3583 = (%shape_func_out_0147,);
  %3584 = (%tensor_0746,);
  let %v738: () = vm.invoke_tvm_op(%3582, %3583, %3584) /* ty=() */;
  let %storage_0887: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][900]) /* ty=Storage[] */;
  let %tensor_0747: int64 = memory.alloc_tensor(%storage_0887, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][900]) /* ty=int64 */;
  %3585 = fn (%p0745: int64, Primitive=1) -> int64 {
    multiply(%p0745, 1 /* ty=int64 */) /* ty=int64 */
  };
  %3586 = (%tensor_0746,);
  %3587 = (%tensor_0747,);
  let %v739: () = vm.invoke_tvm_op(%3585, %3586, %3587) /* ty=() */;
  let %storage_0888: Storage[] = memory.alloc_storage(%tensor_0747, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][901]) /* ty=Storage[] */;
  let %out_0140: Tensor[(?), bool] = memory.alloc_tensor(%storage_0888, 0 /* ty=int64 */, %shape_func_out_0147, meta[relay.attrs.AllocTensorAttrs][901]) /* ty=Tensor[(?), bool] */;
  %3588 = (%x550,);
  %3589 = (%out_0140,);
  let %v740: () = vm.invoke_tvm_op(%3579, %3588, %3589) /* ty=() */;
  let %x577: Tensor[(?), bool] = %out_0140;
  let %in_shape_0136: Tensor[(?), bool] = device_copy(%x577, meta[relay.attrs.DeviceCopyAttrs][209]) /* ty=Tensor[(?), bool] */;
  let %storage_0889: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][902]) /* ty=Storage[] */;
  let %tensor_0748: Tensor[(2), int64] = memory.alloc_tensor(%storage_0889, 0 /* ty=int64 */, meta[relay.Constant][759] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][902]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0148: Tensor[(2), int64] = %tensor_0748;
  %3590 = fn (%p0746: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0746) /* ty=Tensor[(?, 1), int32] */
  };
  %3591 = (%in_shape_0136,);
  %3592 = (%shape_func_out_0148,);
  let %shape_func148: () = vm.shape_func(%3590, %3591, %3592, meta[relay.attrs.ShapeFuncAttrs][148]) /* ty=() */;
  let %storage_0890: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][903]) /* ty=Storage[] */;
  let %tensor_0749: int64 = memory.alloc_tensor(%storage_0890, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][903]) /* ty=int64 */;
  %3593 = fn (%p0747: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0747) /* ty=int64 */
  };
  %3594 = (%shape_func_out_0148,);
  %3595 = (%tensor_0749,);
  let %v741: () = vm.invoke_tvm_op(%3593, %3594, %3595) /* ty=() */;
  let %storage_0891: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][904]) /* ty=Storage[] */;
  let %tensor_0750: int64 = memory.alloc_tensor(%storage_0891, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][904]) /* ty=int64 */;
  %3596 = fn (%p0748: int64, Primitive=1) -> int64 {
    multiply(%p0748, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3597 = (%tensor_0749,);
  %3598 = (%tensor_0750,);
  let %v742: () = vm.invoke_tvm_op(%3596, %3597, %3598) /* ty=() */;
  let %storage_0892: Storage[] = memory.alloc_storage(%tensor_0750, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][905]) /* ty=Storage[] */;
  let %out_0141: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0892, 0 /* ty=int64 */, %shape_func_out_0148, meta[relay.attrs.AllocTensorAttrs][905]) /* ty=Tensor[(?, 1), int32] */;
  %3599 = (%x577,);
  %3600 = (%out_0141,);
  let %v743: () = vm.invoke_tvm_op(%3590, %3599, %3600) /* ty=() */;
  let %x578: Tensor[(?, 1), int32] = %out_0141;
  let %in_shape_0137: Tensor[(2), int64] = vm.shape_of(%x578, meta[relay.attrs.ShapeOfAttrs][141]) /* ty=Tensor[(2), int64] */;
  let %storage_0893: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][906]) /* ty=Storage[] */;
  let %tensor_0751: Tensor[(1), int64] = memory.alloc_tensor(%storage_0893, 0 /* ty=int64 */, meta[relay.Constant][760] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][906]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0149: Tensor[(1), int64] = %tensor_0751;
  %3603 = fn (%p0749: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %3601 = split(%p0749, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %3602 = %3601.0;
    squeeze(%3602, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %3604 = (%in_shape_0137,);
  %3605 = (%shape_func_out_0149,);
  let %shape_func149: () = vm.shape_func(%3603, %3604, %3605, meta[relay.attrs.ShapeFuncAttrs][149]) /* ty=() */;
  let %storage_0894: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][907]) /* ty=Storage[] */;
  let %tensor_0752: int64 = memory.alloc_tensor(%storage_0894, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][907]) /* ty=int64 */;
  %3606 = fn (%p0750: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0750) /* ty=int64 */
  };
  %3607 = (%shape_func_out_0149,);
  %3608 = (%tensor_0752,);
  let %v744: () = vm.invoke_tvm_op(%3606, %3607, %3608) /* ty=() */;
  let %storage_0895: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][908]) /* ty=Storage[] */;
  let %tensor_0753: int64 = memory.alloc_tensor(%storage_0895, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][908]) /* ty=int64 */;
  %3609 = fn (%p0751: int64, Primitive=1) -> int64 {
    multiply(%p0751, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3610 = (%tensor_0752,);
  %3611 = (%tensor_0753,);
  let %v745: () = vm.invoke_tvm_op(%3609, %3610, %3611) /* ty=() */;
  let %storage_0896: Storage[] = memory.alloc_storage(%tensor_0753, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][909]) /* ty=Storage[] */;
  let %out_0142: Tensor[(?), int32] = memory.alloc_tensor(%storage_0896, 0 /* ty=int64 */, %shape_func_out_0149, meta[relay.attrs.AllocTensorAttrs][909]) /* ty=Tensor[(?), int32] */;
  %3612 = (%x578,);
  %3613 = (%out_0142,);
  let %v746: () = vm.invoke_tvm_op(%3603, %3612, %3613) /* ty=() */;
  let %x579: Tensor[(?), int32] = %out_0142;
  let %in_shape_0138: Tensor[(1), int64] = vm.shape_of(%x579, meta[relay.attrs.ShapeOfAttrs][142]) /* ty=Tensor[(1), int64] */;
  let %storage_0897: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][910]) /* ty=Storage[] */;
  let %tensor_0754: Tensor[(4), int64] = memory.alloc_tensor(%storage_0897, 0 /* ty=int64 */, meta[relay.Constant][761] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][910]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0150: Tensor[(4), int64] = %tensor_0754;
  %3617 = fn (%p0752: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 14, 14), int32] {
    %3614 = reshape(%p0752, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %3615 = repeat(%3614, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %3616 = repeat(%3615, repeats=14, axis=2) /* ty=Tensor[(?, 256, 14, 1), int32] */;
    repeat(%3616, repeats=14, axis=3) /* ty=Tensor[(?, 256, 14, 14), int32] */
  };
  %3618 = (%in_shape_0138,);
  %3619 = (%shape_func_out_0150,);
  let %shape_func150: () = vm.shape_func(%3617, %3618, %3619, meta[relay.attrs.ShapeFuncAttrs][150]) /* ty=() */;
  let %storage_0898: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][911]) /* ty=Storage[] */;
  let %tensor_0755: int64 = memory.alloc_tensor(%storage_0898, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][911]) /* ty=int64 */;
  %3620 = fn (%p0753: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0753) /* ty=int64 */
  };
  %3621 = (%shape_func_out_0150,);
  %3622 = (%tensor_0755,);
  let %v747: () = vm.invoke_tvm_op(%3620, %3621, %3622) /* ty=() */;
  let %storage_0899: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][912]) /* ty=Storage[] */;
  let %tensor_0756: int64 = memory.alloc_tensor(%storage_0899, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][912]) /* ty=int64 */;
  %3623 = fn (%p0754: int64, Primitive=1) -> int64 {
    multiply(%p0754, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3624 = (%tensor_0755,);
  %3625 = (%tensor_0756,);
  let %v748: () = vm.invoke_tvm_op(%3623, %3624, %3625) /* ty=() */;
  let %storage_0900: Storage[] = memory.alloc_storage(%tensor_0756, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][913]) /* ty=Storage[] */;
  let %out_0143: Tensor[(?, 256, 14, 14), int32] = memory.alloc_tensor(%storage_0900, 0 /* ty=int64 */, %shape_func_out_0150, meta[relay.attrs.AllocTensorAttrs][913]) /* ty=Tensor[(?, 256, 14, 14), int32] */;
  %3626 = (%x579,);
  %3627 = (%out_0143,);
  let %v749: () = vm.invoke_tvm_op(%3617, %3626, %3627) /* ty=() */;
  let %x580: Tensor[(?, 256, 14, 14), int32] = %out_0143;
  let %in_shape_0139: Tensor[(2), int64] = vm.shape_of(%x566, meta[relay.attrs.ShapeOfAttrs][143]) /* ty=Tensor[(2), int64] */;
  let %in_shape_190: Tensor[(1), int64] = vm.shape_of(%x579, meta[relay.attrs.ShapeOfAttrs][144]) /* ty=Tensor[(1), int64] */;
  let %storage_0901: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][914]) /* ty=Storage[] */;
  let %tensor_0757: Tensor[(2), int64] = memory.alloc_tensor(%storage_0901, 0 /* ty=int64 */, meta[relay.Constant][762] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][914]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0151: Tensor[(2), int64] = %tensor_0757;
  %3630 = fn (%p0755: Tensor[(?, ?), float32], %p1341: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %3628 = cast(%p1341, dtype="int64") /* ty=Tensor[(?), int64] */;
    %3629 = (%p0755, %3628);
    adv_index(%3629) /* ty=Tensor[(?, ?), float32] */
  };
  %3631 = (%in_shape_0139, %in_shape_190);
  %3632 = (%shape_func_out_0151,);
  let %shape_func151: () = vm.shape_func(%3630, %3631, %3632, meta[relay.attrs.ShapeFuncAttrs][151]) /* ty=() */;
  let %storage_0902: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][915]) /* ty=Storage[] */;
  let %tensor_0758: int64 = memory.alloc_tensor(%storage_0902, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][915]) /* ty=int64 */;
  %3633 = fn (%p0756: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0756) /* ty=int64 */
  };
  %3634 = (%shape_func_out_0151,);
  %3635 = (%tensor_0758,);
  let %v750: () = vm.invoke_tvm_op(%3633, %3634, %3635) /* ty=() */;
  let %storage_0903: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][916]) /* ty=Storage[] */;
  let %tensor_0759: int64 = memory.alloc_tensor(%storage_0903, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][916]) /* ty=int64 */;
  %3636 = fn (%p0757: int64, Primitive=1) -> int64 {
    multiply(%p0757, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3637 = (%tensor_0758,);
  %3638 = (%tensor_0759,);
  let %v751: () = vm.invoke_tvm_op(%3636, %3637, %3638) /* ty=() */;
  let %storage_0904: Storage[] = memory.alloc_storage(%tensor_0759, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][917]) /* ty=Storage[] */;
  let %out_0144: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0904, 0 /* ty=int64 */, %shape_func_out_0151, meta[relay.attrs.AllocTensorAttrs][917]) /* ty=Tensor[(?, ?), float32] */;
  %3639 = (%x566, %x579);
  %3640 = (%out_0144,);
  let %v752: () = vm.invoke_tvm_op(%3630, %3639, %3640) /* ty=() */;
  let %x581: Tensor[(?, ?), float32] = %out_0144;
  let %in_shape_191: Tensor[(2), int64] = vm.shape_of(%x581, meta[relay.attrs.ShapeOfAttrs][145]) /* ty=Tensor[(2), int64] */;
  let %storage_0905: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][918]) /* ty=Storage[] */;
  let %tensor_0760: Tensor[(4), int64] = memory.alloc_tensor(%storage_0905, 0 /* ty=int64 */, meta[relay.Constant][763] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][918]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0152: Tensor[(4), int64] = %tensor_0760;
  %3641 = fn (%p0758: Tensor[(1, 256, 50, 50), float32], %p1342: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    vision.roi_align(%p0758, %p1342, meta[relay.attrs.ROIAlignAttrs][6]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3642 = (meta[relay.Constant][764] /* ty=Tensor[(4), int64] */, %in_shape_191);
  %3643 = (%shape_func_out_0152,);
  let %shape_func152: () = vm.shape_func(%3641, %3642, %3643, meta[relay.attrs.ShapeFuncAttrs][152]) /* ty=() */;
  let %storage_0906: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][919]) /* ty=Storage[] */;
  let %tensor_0761: int64 = memory.alloc_tensor(%storage_0906, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][919]) /* ty=int64 */;
  %3644 = fn (%p0759: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0759) /* ty=int64 */
  };
  %3645 = (%shape_func_out_0152,);
  %3646 = (%tensor_0761,);
  let %v753: () = vm.invoke_tvm_op(%3644, %3645, %3646) /* ty=() */;
  let %storage_0907: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][920]) /* ty=Storage[] */;
  let %tensor_0762: int64 = memory.alloc_tensor(%storage_0907, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][920]) /* ty=int64 */;
  %3647 = fn (%p0760: int64, Primitive=1) -> int64 {
    multiply(%p0760, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3648 = (%tensor_0761,);
  %3649 = (%tensor_0762,);
  let %v754: () = vm.invoke_tvm_op(%3647, %3648, %3649) /* ty=() */;
  let %storage_0908: Storage[] = memory.alloc_storage(%tensor_0762, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][921]) /* ty=Storage[] */;
  let %out_0145: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0908, 0 /* ty=int64 */, %shape_func_out_0152, meta[relay.attrs.AllocTensorAttrs][921]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3650 = (%x281, %x581);
  %3651 = (%out_0145,);
  let %v755: () = vm.invoke_tvm_op(%3641, %3650, %3651) /* ty=() */;
  let %x582: Tensor[(?, 256, 14, 14), float32] = %out_0145;
  let %in_shape_0140: Tensor[(4), int64] = vm.shape_of(%x576, meta[relay.attrs.ShapeOfAttrs][146]) /* ty=Tensor[(4), int64] */;
  let %in_shape_192: Tensor[(4), int64] = vm.shape_of(%x580, meta[relay.attrs.ShapeOfAttrs][147]) /* ty=Tensor[(4), int64] */;
  let %in_shape_264: Tensor[(4), int64] = vm.shape_of(%x582, meta[relay.attrs.ShapeOfAttrs][148]) /* ty=Tensor[(4), int64] */;
  let %storage_0909: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][922]) /* ty=Storage[] */;
  let %tensor_0763: Tensor[(4), int64] = memory.alloc_tensor(%storage_0909, 0 /* ty=int64 */, meta[relay.Constant][765] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][922]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0153: Tensor[(4), int64] = %tensor_0763;
  %3652 = fn (%p0761: Tensor[(?, 256, 14, 14), float32], %p1343: Tensor[(?, 256, 14, 14), int32], %p2199: Tensor[(?, 256, 14, 14), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    scatter(%p0761, %p1343, %p2199, meta[relay.attrs.ScatterAttrs][8]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3653 = (%in_shape_0140, %in_shape_192, %in_shape_264);
  %3654 = (%shape_func_out_0153,);
  let %shape_func153: () = vm.shape_func(%3652, %3653, %3654, meta[relay.attrs.ShapeFuncAttrs][153]) /* ty=() */;
  let %storage_0910: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][923]) /* ty=Storage[] */;
  let %tensor_0764: int64 = memory.alloc_tensor(%storage_0910, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][923]) /* ty=int64 */;
  %3655 = fn (%p0762: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0762) /* ty=int64 */
  };
  %3656 = (%shape_func_out_0153,);
  %3657 = (%tensor_0764,);
  let %v756: () = vm.invoke_tvm_op(%3655, %3656, %3657) /* ty=() */;
  let %storage_0911: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][924]) /* ty=Storage[] */;
  let %tensor_0765: int64 = memory.alloc_tensor(%storage_0911, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][924]) /* ty=int64 */;
  %3658 = fn (%p0763: int64, Primitive=1) -> int64 {
    multiply(%p0763, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3659 = (%tensor_0764,);
  %3660 = (%tensor_0765,);
  let %v757: () = vm.invoke_tvm_op(%3658, %3659, %3660) /* ty=() */;
  let %storage_0912: Storage[] = memory.alloc_storage(%tensor_0765, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][925]) /* ty=Storage[] */;
  let %out_0146: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0912, 0 /* ty=int64 */, %shape_func_out_0153, meta[relay.attrs.AllocTensorAttrs][925]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3661 = (%x576, %x580, %x582);
  %3662 = (%out_0146,);
  let %v758: () = vm.invoke_tvm_op(%3652, %3661, %3662) /* ty=() */;
  let %x583: Tensor[(?, 256, 14, 14), float32] = %out_0146;
  let %in_shape_0141: Tensor[(1), int64] = vm.shape_of(%x550, meta[relay.attrs.ShapeOfAttrs][149]) /* ty=Tensor[(1), int64] */;
  let %storage_0913: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][926]) /* ty=Storage[] */;
  let %tensor_0766: Tensor[(1), int64] = memory.alloc_tensor(%storage_0913, 0 /* ty=int64 */, meta[relay.Constant][766] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][926]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0154: Tensor[(1), int64] = %tensor_0766;
  %3663 = fn (%p0764: Tensor[(?), int64], Primitive=1) -> Tensor[(?), bool] {
    equal(%p0764, 3 /* ty=int64 */) /* ty=Tensor[(?), bool] */
  };
  %3664 = (%in_shape_0141,);
  %3665 = (%shape_func_out_0154,);
  let %shape_func154: () = vm.shape_func(%3663, %3664, %3665, meta[relay.attrs.ShapeFuncAttrs][154]) /* ty=() */;
  let %storage_0914: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][927]) /* ty=Storage[] */;
  let %tensor_0767: int64 = memory.alloc_tensor(%storage_0914, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][927]) /* ty=int64 */;
  %3666 = fn (%p0765: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0765) /* ty=int64 */
  };
  %3667 = (%shape_func_out_0154,);
  %3668 = (%tensor_0767,);
  let %v759: () = vm.invoke_tvm_op(%3666, %3667, %3668) /* ty=() */;
  let %storage_0915: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][928]) /* ty=Storage[] */;
  let %tensor_0768: int64 = memory.alloc_tensor(%storage_0915, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][928]) /* ty=int64 */;
  %3669 = fn (%p0766: int64, Primitive=1) -> int64 {
    multiply(%p0766, 1 /* ty=int64 */) /* ty=int64 */
  };
  %3670 = (%tensor_0767,);
  %3671 = (%tensor_0768,);
  let %v760: () = vm.invoke_tvm_op(%3669, %3670, %3671) /* ty=() */;
  let %storage_0916: Storage[] = memory.alloc_storage(%tensor_0768, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][929]) /* ty=Storage[] */;
  let %out_0147: Tensor[(?), bool] = memory.alloc_tensor(%storage_0916, 0 /* ty=int64 */, %shape_func_out_0154, meta[relay.attrs.AllocTensorAttrs][929]) /* ty=Tensor[(?), bool] */;
  %3672 = (%x550,);
  %3673 = (%out_0147,);
  let %v761: () = vm.invoke_tvm_op(%3663, %3672, %3673) /* ty=() */;
  let %x584: Tensor[(?), bool] = %out_0147;
  let %in_shape_0142: Tensor[(?), bool] = device_copy(%x584, meta[relay.attrs.DeviceCopyAttrs][210]) /* ty=Tensor[(?), bool] */;
  let %storage_0917: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][930]) /* ty=Storage[] */;
  let %tensor_0769: Tensor[(2), int64] = memory.alloc_tensor(%storage_0917, 0 /* ty=int64 */, meta[relay.Constant][767] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][930]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0155: Tensor[(2), int64] = %tensor_0769;
  %3674 = fn (%p0767: Tensor[(?), bool], Primitive=1) -> Tensor[(?, 1), int32] {
    argwhere(%p0767) /* ty=Tensor[(?, 1), int32] */
  };
  %3675 = (%in_shape_0142,);
  %3676 = (%shape_func_out_0155,);
  let %shape_func155: () = vm.shape_func(%3674, %3675, %3676, meta[relay.attrs.ShapeFuncAttrs][155]) /* ty=() */;
  let %storage_0918: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][931]) /* ty=Storage[] */;
  let %tensor_0770: int64 = memory.alloc_tensor(%storage_0918, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][931]) /* ty=int64 */;
  %3677 = fn (%p0768: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0768) /* ty=int64 */
  };
  %3678 = (%shape_func_out_0155,);
  %3679 = (%tensor_0770,);
  let %v762: () = vm.invoke_tvm_op(%3677, %3678, %3679) /* ty=() */;
  let %storage_0919: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][932]) /* ty=Storage[] */;
  let %tensor_0771: int64 = memory.alloc_tensor(%storage_0919, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][932]) /* ty=int64 */;
  %3680 = fn (%p0769: int64, Primitive=1) -> int64 {
    multiply(%p0769, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3681 = (%tensor_0770,);
  %3682 = (%tensor_0771,);
  let %v763: () = vm.invoke_tvm_op(%3680, %3681, %3682) /* ty=() */;
  let %storage_0920: Storage[] = memory.alloc_storage(%tensor_0771, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][933]) /* ty=Storage[] */;
  let %out_0148: Tensor[(?, 1), int32] = memory.alloc_tensor(%storage_0920, 0 /* ty=int64 */, %shape_func_out_0155, meta[relay.attrs.AllocTensorAttrs][933]) /* ty=Tensor[(?, 1), int32] */;
  %3683 = (%x584,);
  %3684 = (%out_0148,);
  let %v764: () = vm.invoke_tvm_op(%3674, %3683, %3684) /* ty=() */;
  let %x585: Tensor[(?, 1), int32] = %out_0148;
  let %in_shape_0143: Tensor[(2), int64] = vm.shape_of(%x585, meta[relay.attrs.ShapeOfAttrs][150]) /* ty=Tensor[(2), int64] */;
  let %storage_0921: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][934]) /* ty=Storage[] */;
  let %tensor_0772: Tensor[(1), int64] = memory.alloc_tensor(%storage_0921, 0 /* ty=int64 */, meta[relay.Constant][768] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][934]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0156: Tensor[(1), int64] = %tensor_0772;
  %3687 = fn (%p0770: Tensor[(?, 1), int32], Primitive=1) -> Tensor[(?), int32] {
    %3685 = split(%p0770, indices_or_sections=1, axis=1) /* ty=(Tensor[(?, 1), int32],) */;
    %3686 = %3685.0;
    squeeze(%3686, axis=[1]) /* ty=Tensor[(?), int32] */
  };
  %3688 = (%in_shape_0143,);
  %3689 = (%shape_func_out_0156,);
  let %shape_func156: () = vm.shape_func(%3687, %3688, %3689, meta[relay.attrs.ShapeFuncAttrs][156]) /* ty=() */;
  let %storage_0922: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][935]) /* ty=Storage[] */;
  let %tensor_0773: int64 = memory.alloc_tensor(%storage_0922, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][935]) /* ty=int64 */;
  %3690 = fn (%p0771: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0771) /* ty=int64 */
  };
  %3691 = (%shape_func_out_0156,);
  %3692 = (%tensor_0773,);
  let %v765: () = vm.invoke_tvm_op(%3690, %3691, %3692) /* ty=() */;
  let %storage_0923: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][936]) /* ty=Storage[] */;
  let %tensor_0774: int64 = memory.alloc_tensor(%storage_0923, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][936]) /* ty=int64 */;
  %3693 = fn (%p0772: int64, Primitive=1) -> int64 {
    multiply(%p0772, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3694 = (%tensor_0773,);
  %3695 = (%tensor_0774,);
  let %v766: () = vm.invoke_tvm_op(%3693, %3694, %3695) /* ty=() */;
  let %storage_0924: Storage[] = memory.alloc_storage(%tensor_0774, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][937]) /* ty=Storage[] */;
  let %out_0149: Tensor[(?), int32] = memory.alloc_tensor(%storage_0924, 0 /* ty=int64 */, %shape_func_out_0156, meta[relay.attrs.AllocTensorAttrs][937]) /* ty=Tensor[(?), int32] */;
  %3696 = (%x585,);
  %3697 = (%out_0149,);
  let %v767: () = vm.invoke_tvm_op(%3687, %3696, %3697) /* ty=() */;
  let %x586: Tensor[(?), int32] = %out_0149;
  let %in_shape_0144: Tensor[(1), int64] = vm.shape_of(%x586, meta[relay.attrs.ShapeOfAttrs][151]) /* ty=Tensor[(1), int64] */;
  let %storage_0925: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][938]) /* ty=Storage[] */;
  let %tensor_0775: Tensor[(4), int64] = memory.alloc_tensor(%storage_0925, 0 /* ty=int64 */, meta[relay.Constant][769] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][938]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0157: Tensor[(4), int64] = %tensor_0775;
  %3701 = fn (%p0773: Tensor[(?), int32], Primitive=1) -> Tensor[(?, 256, 14, 14), int32] {
    %3698 = reshape(%p0773, newshape=[-1, 1, 1, 1]) /* ty=Tensor[(?, 1, 1, 1), int32] */;
    %3699 = repeat(%3698, repeats=256, axis=1) /* ty=Tensor[(?, 256, 1, 1), int32] */;
    %3700 = repeat(%3699, repeats=14, axis=2) /* ty=Tensor[(?, 256, 14, 1), int32] */;
    repeat(%3700, repeats=14, axis=3) /* ty=Tensor[(?, 256, 14, 14), int32] */
  };
  %3702 = (%in_shape_0144,);
  %3703 = (%shape_func_out_0157,);
  let %shape_func157: () = vm.shape_func(%3701, %3702, %3703, meta[relay.attrs.ShapeFuncAttrs][157]) /* ty=() */;
  let %storage_0926: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][939]) /* ty=Storage[] */;
  let %tensor_0776: int64 = memory.alloc_tensor(%storage_0926, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][939]) /* ty=int64 */;
  %3704 = fn (%p0774: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0774) /* ty=int64 */
  };
  %3705 = (%shape_func_out_0157,);
  %3706 = (%tensor_0776,);
  let %v768: () = vm.invoke_tvm_op(%3704, %3705, %3706) /* ty=() */;
  let %storage_0927: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][940]) /* ty=Storage[] */;
  let %tensor_0777: int64 = memory.alloc_tensor(%storage_0927, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][940]) /* ty=int64 */;
  %3707 = fn (%p0775: int64, Primitive=1) -> int64 {
    multiply(%p0775, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3708 = (%tensor_0776,);
  %3709 = (%tensor_0777,);
  let %v769: () = vm.invoke_tvm_op(%3707, %3708, %3709) /* ty=() */;
  let %storage_0928: Storage[] = memory.alloc_storage(%tensor_0777, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][941]) /* ty=Storage[] */;
  let %out_0150: Tensor[(?, 256, 14, 14), int32] = memory.alloc_tensor(%storage_0928, 0 /* ty=int64 */, %shape_func_out_0157, meta[relay.attrs.AllocTensorAttrs][941]) /* ty=Tensor[(?, 256, 14, 14), int32] */;
  %3710 = (%x586,);
  %3711 = (%out_0150,);
  let %v770: () = vm.invoke_tvm_op(%3701, %3710, %3711) /* ty=() */;
  let %x587: Tensor[(?, 256, 14, 14), int32] = %out_0150;
  let %in_shape_0145: Tensor[(2), int64] = vm.shape_of(%x566, meta[relay.attrs.ShapeOfAttrs][152]) /* ty=Tensor[(2), int64] */;
  let %in_shape_193: Tensor[(1), int64] = vm.shape_of(%x586, meta[relay.attrs.ShapeOfAttrs][153]) /* ty=Tensor[(1), int64] */;
  let %storage_0929: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][942]) /* ty=Storage[] */;
  let %tensor_0778: Tensor[(2), int64] = memory.alloc_tensor(%storage_0929, 0 /* ty=int64 */, meta[relay.Constant][770] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][942]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0158: Tensor[(2), int64] = %tensor_0778;
  %3714 = fn (%p0776: Tensor[(?, ?), float32], %p1344: Tensor[(?), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    %3712 = cast(%p1344, dtype="int64") /* ty=Tensor[(?), int64] */;
    %3713 = (%p0776, %3712);
    adv_index(%3713) /* ty=Tensor[(?, ?), float32] */
  };
  %3715 = (%in_shape_0145, %in_shape_193);
  %3716 = (%shape_func_out_0158,);
  let %shape_func158: () = vm.shape_func(%3714, %3715, %3716, meta[relay.attrs.ShapeFuncAttrs][158]) /* ty=() */;
  let %storage_0930: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][943]) /* ty=Storage[] */;
  let %tensor_0779: int64 = memory.alloc_tensor(%storage_0930, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][943]) /* ty=int64 */;
  %3717 = fn (%p0777: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0777) /* ty=int64 */
  };
  %3718 = (%shape_func_out_0158,);
  %3719 = (%tensor_0779,);
  let %v771: () = vm.invoke_tvm_op(%3717, %3718, %3719) /* ty=() */;
  let %storage_0931: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][944]) /* ty=Storage[] */;
  let %tensor_0780: int64 = memory.alloc_tensor(%storage_0931, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][944]) /* ty=int64 */;
  %3720 = fn (%p0778: int64, Primitive=1) -> int64 {
    multiply(%p0778, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3721 = (%tensor_0779,);
  %3722 = (%tensor_0780,);
  let %v772: () = vm.invoke_tvm_op(%3720, %3721, %3722) /* ty=() */;
  let %storage_0932: Storage[] = memory.alloc_storage(%tensor_0780, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][945]) /* ty=Storage[] */;
  let %out_0151: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_0932, 0 /* ty=int64 */, %shape_func_out_0158, meta[relay.attrs.AllocTensorAttrs][945]) /* ty=Tensor[(?, ?), float32] */;
  %3723 = (%x566, %x586);
  %3724 = (%out_0151,);
  let %v773: () = vm.invoke_tvm_op(%3714, %3723, %3724) /* ty=() */;
  let %x588: Tensor[(?, ?), float32] = %out_0151;
  let %in_shape_194: Tensor[(2), int64] = vm.shape_of(%x588, meta[relay.attrs.ShapeOfAttrs][154]) /* ty=Tensor[(2), int64] */;
  let %storage_0933: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][946]) /* ty=Storage[] */;
  let %tensor_0781: Tensor[(4), int64] = memory.alloc_tensor(%storage_0933, 0 /* ty=int64 */, meta[relay.Constant][771] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][946]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0159: Tensor[(4), int64] = %tensor_0781;
  %3725 = fn (%p0779: Tensor[(1, 256, 25, 25), float32], %p1345: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    vision.roi_align(%p0779, %p1345, meta[relay.attrs.ROIAlignAttrs][7]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3726 = (meta[relay.Constant][772] /* ty=Tensor[(4), int64] */, %in_shape_194);
  %3727 = (%shape_func_out_0159,);
  let %shape_func159: () = vm.shape_func(%3725, %3726, %3727, meta[relay.attrs.ShapeFuncAttrs][159]) /* ty=() */;
  let %storage_0934: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][947]) /* ty=Storage[] */;
  let %tensor_0782: int64 = memory.alloc_tensor(%storage_0934, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][947]) /* ty=int64 */;
  %3728 = fn (%p0780: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0780) /* ty=int64 */
  };
  %3729 = (%shape_func_out_0159,);
  %3730 = (%tensor_0782,);
  let %v774: () = vm.invoke_tvm_op(%3728, %3729, %3730) /* ty=() */;
  let %storage_0935: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][948]) /* ty=Storage[] */;
  let %tensor_0783: int64 = memory.alloc_tensor(%storage_0935, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][948]) /* ty=int64 */;
  %3731 = fn (%p0781: int64, Primitive=1) -> int64 {
    multiply(%p0781, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3732 = (%tensor_0782,);
  %3733 = (%tensor_0783,);
  let %v775: () = vm.invoke_tvm_op(%3731, %3732, %3733) /* ty=() */;
  let %storage_0936: Storage[] = memory.alloc_storage(%tensor_0783, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][949]) /* ty=Storage[] */;
  let %out_0152: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0936, 0 /* ty=int64 */, %shape_func_out_0159, meta[relay.attrs.AllocTensorAttrs][949]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3734 = (%x284, %x588);
  %3735 = (%out_0152,);
  let %v776: () = vm.invoke_tvm_op(%3725, %3734, %3735) /* ty=() */;
  let %x589: Tensor[(?, 256, 14, 14), float32] = %out_0152;
  let %in_shape_0146: Tensor[(4), int64] = vm.shape_of(%x583, meta[relay.attrs.ShapeOfAttrs][155]) /* ty=Tensor[(4), int64] */;
  let %in_shape_195: Tensor[(4), int64] = vm.shape_of(%x587, meta[relay.attrs.ShapeOfAttrs][156]) /* ty=Tensor[(4), int64] */;
  let %in_shape_265: Tensor[(4), int64] = vm.shape_of(%x589, meta[relay.attrs.ShapeOfAttrs][157]) /* ty=Tensor[(4), int64] */;
  let %storage_0937: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][950]) /* ty=Storage[] */;
  let %tensor_0784: Tensor[(4), int64] = memory.alloc_tensor(%storage_0937, 0 /* ty=int64 */, meta[relay.Constant][773] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][950]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0160: Tensor[(4), int64] = %tensor_0784;
  %3736 = fn (%p0782: Tensor[(?, 256, 14, 14), float32], %p1346: Tensor[(?, 256, 14, 14), int32], %p2200: Tensor[(?, 256, 14, 14), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    scatter(%p0782, %p1346, %p2200, meta[relay.attrs.ScatterAttrs][9]) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3737 = (%in_shape_0146, %in_shape_195, %in_shape_265);
  %3738 = (%shape_func_out_0160,);
  let %shape_func160: () = vm.shape_func(%3736, %3737, %3738, meta[relay.attrs.ShapeFuncAttrs][160]) /* ty=() */;
  let %storage_0938: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][951]) /* ty=Storage[] */;
  let %tensor_0785: int64 = memory.alloc_tensor(%storage_0938, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][951]) /* ty=int64 */;
  %3739 = fn (%p0783: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0783) /* ty=int64 */
  };
  %3740 = (%shape_func_out_0160,);
  %3741 = (%tensor_0785,);
  let %v777: () = vm.invoke_tvm_op(%3739, %3740, %3741) /* ty=() */;
  let %storage_0939: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][952]) /* ty=Storage[] */;
  let %tensor_0786: int64 = memory.alloc_tensor(%storage_0939, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][952]) /* ty=int64 */;
  %3742 = fn (%p0784: int64, Primitive=1) -> int64 {
    multiply(%p0784, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3743 = (%tensor_0785,);
  %3744 = (%tensor_0786,);
  let %v778: () = vm.invoke_tvm_op(%3742, %3743, %3744) /* ty=() */;
  let %storage_0940: Storage[] = memory.alloc_storage(%tensor_0786, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][953]) /* ty=Storage[] */;
  let %out_0153: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0940, 0 /* ty=int64 */, %shape_func_out_0160, meta[relay.attrs.AllocTensorAttrs][953]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3745 = (%x583, %x587, %x589);
  %3746 = (%out_0153,);
  let %v779: () = vm.invoke_tvm_op(%3736, %3745, %3746) /* ty=() */;
  let %x590: Tensor[(?, 256, 14, 14), float32] = %out_0153;
  let %in_shape_0147: Tensor[(4), int64] = vm.shape_of(%x590, meta[relay.attrs.ShapeOfAttrs][158]) /* ty=Tensor[(4), int64] */;
  let %storage_0941: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][954]) /* ty=Storage[] */;
  let %tensor_0787: Tensor[(4), int64] = memory.alloc_tensor(%storage_0941, 0 /* ty=int64 */, meta[relay.Constant][774] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][954]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0161: Tensor[(4), int64] = %tensor_0787;
  %3751 = fn (%p0785: Tensor[(?, 256, 14, 14), float32], %p1347: Tensor[(256, 256, 3, 3), float32], %p2201: Tensor[(256), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    %3747 = nn.conv2d(%p0785, %p1347, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    %3748 = expand_dims(%p2201, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %3749 = expand_dims(%3748, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %3750 = add(%3747, %3749) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    nn.relu(%3750) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3752 = (%in_shape_0147, meta[relay.Constant][775] /* ty=Tensor[(4), int64] */, meta[relay.Constant][776] /* ty=Tensor[(1), int64] */);
  %3753 = (%shape_func_out_0161,);
  let %shape_func161: () = vm.shape_func(%3751, %3752, %3753, meta[relay.attrs.ShapeFuncAttrs][161]) /* ty=() */;
  let %storage_0942: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][955]) /* ty=Storage[] */;
  let %tensor_0788: int64 = memory.alloc_tensor(%storage_0942, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][955]) /* ty=int64 */;
  %3754 = fn (%p0786: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0786) /* ty=int64 */
  };
  %3755 = (%shape_func_out_0161,);
  %3756 = (%tensor_0788,);
  let %v780: () = vm.invoke_tvm_op(%3754, %3755, %3756) /* ty=() */;
  let %storage_0943: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][956]) /* ty=Storage[] */;
  let %tensor_0789: int64 = memory.alloc_tensor(%storage_0943, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][956]) /* ty=int64 */;
  %3757 = fn (%p0787: int64, Primitive=1) -> int64 {
    multiply(%p0787, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3758 = (%tensor_0788,);
  %3759 = (%tensor_0789,);
  let %v781: () = vm.invoke_tvm_op(%3757, %3758, %3759) /* ty=() */;
  let %storage_0944: Storage[] = memory.alloc_storage(%tensor_0789, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][957]) /* ty=Storage[] */;
  let %out_0154: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0944, 0 /* ty=int64 */, %shape_func_out_0161, meta[relay.attrs.AllocTensorAttrs][957]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3760 = (%x590, %model.roi_heads.mask_head.mask_fcn1.weight, %model.roi_heads.mask_head.mask_fcn1.bias);
  %3761 = (%out_0154,);
  let %v782: () = vm.invoke_tvm_op(%3751, %3760, %3761) /* ty=() */;
  let %x591: Tensor[(?, 256, 14, 14), float32] = %out_0154;
  let %in_shape_0148: Tensor[(4), int64] = vm.shape_of(%x591, meta[relay.attrs.ShapeOfAttrs][159]) /* ty=Tensor[(4), int64] */;
  let %storage_0945: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][958]) /* ty=Storage[] */;
  let %tensor_0790: Tensor[(4), int64] = memory.alloc_tensor(%storage_0945, 0 /* ty=int64 */, meta[relay.Constant][777] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][958]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0162: Tensor[(4), int64] = %tensor_0790;
  %3766 = fn (%p0788: Tensor[(?, 256, 14, 14), float32], %p1348: Tensor[(256, 256, 3, 3), float32], %p2202: Tensor[(256), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    %3762 = nn.conv2d(%p0788, %p1348, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    %3763 = expand_dims(%p2202, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %3764 = expand_dims(%3763, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %3765 = add(%3762, %3764) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    nn.relu(%3765) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3767 = (%in_shape_0148, meta[relay.Constant][778] /* ty=Tensor[(4), int64] */, meta[relay.Constant][779] /* ty=Tensor[(1), int64] */);
  %3768 = (%shape_func_out_0162,);
  let %shape_func162: () = vm.shape_func(%3766, %3767, %3768, meta[relay.attrs.ShapeFuncAttrs][162]) /* ty=() */;
  let %storage_0946: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][959]) /* ty=Storage[] */;
  let %tensor_0791: int64 = memory.alloc_tensor(%storage_0946, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][959]) /* ty=int64 */;
  %3769 = fn (%p0789: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0789) /* ty=int64 */
  };
  %3770 = (%shape_func_out_0162,);
  %3771 = (%tensor_0791,);
  let %v783: () = vm.invoke_tvm_op(%3769, %3770, %3771) /* ty=() */;
  let %storage_0947: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][960]) /* ty=Storage[] */;
  let %tensor_0792: int64 = memory.alloc_tensor(%storage_0947, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][960]) /* ty=int64 */;
  %3772 = fn (%p0790: int64, Primitive=1) -> int64 {
    multiply(%p0790, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3773 = (%tensor_0791,);
  %3774 = (%tensor_0792,);
  let %v784: () = vm.invoke_tvm_op(%3772, %3773, %3774) /* ty=() */;
  let %storage_0948: Storage[] = memory.alloc_storage(%tensor_0792, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][961]) /* ty=Storage[] */;
  let %out_0155: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0948, 0 /* ty=int64 */, %shape_func_out_0162, meta[relay.attrs.AllocTensorAttrs][961]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3775 = (%x591, %model.roi_heads.mask_head.mask_fcn2.weight, %model.roi_heads.mask_head.mask_fcn2.bias);
  %3776 = (%out_0155,);
  let %v785: () = vm.invoke_tvm_op(%3766, %3775, %3776) /* ty=() */;
  let %x592: Tensor[(?, 256, 14, 14), float32] = %out_0155;
  let %in_shape_0149: Tensor[(4), int64] = vm.shape_of(%x592, meta[relay.attrs.ShapeOfAttrs][160]) /* ty=Tensor[(4), int64] */;
  let %storage_0949: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][962]) /* ty=Storage[] */;
  let %tensor_0793: Tensor[(4), int64] = memory.alloc_tensor(%storage_0949, 0 /* ty=int64 */, meta[relay.Constant][780] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][962]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0163: Tensor[(4), int64] = %tensor_0793;
  %3781 = fn (%p0791: Tensor[(?, 256, 14, 14), float32], %p1349: Tensor[(256, 256, 3, 3), float32], %p2203: Tensor[(256), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    %3777 = nn.conv2d(%p0791, %p1349, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    %3778 = expand_dims(%p2203, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %3779 = expand_dims(%3778, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %3780 = add(%3777, %3779) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    nn.relu(%3780) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3782 = (%in_shape_0149, meta[relay.Constant][781] /* ty=Tensor[(4), int64] */, meta[relay.Constant][782] /* ty=Tensor[(1), int64] */);
  %3783 = (%shape_func_out_0163,);
  let %shape_func163: () = vm.shape_func(%3781, %3782, %3783, meta[relay.attrs.ShapeFuncAttrs][163]) /* ty=() */;
  let %storage_0950: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][963]) /* ty=Storage[] */;
  let %tensor_0794: int64 = memory.alloc_tensor(%storage_0950, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][963]) /* ty=int64 */;
  %3784 = fn (%p0792: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0792) /* ty=int64 */
  };
  %3785 = (%shape_func_out_0163,);
  %3786 = (%tensor_0794,);
  let %v786: () = vm.invoke_tvm_op(%3784, %3785, %3786) /* ty=() */;
  let %storage_0951: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][964]) /* ty=Storage[] */;
  let %tensor_0795: int64 = memory.alloc_tensor(%storage_0951, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][964]) /* ty=int64 */;
  %3787 = fn (%p0793: int64, Primitive=1) -> int64 {
    multiply(%p0793, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3788 = (%tensor_0794,);
  %3789 = (%tensor_0795,);
  let %v787: () = vm.invoke_tvm_op(%3787, %3788, %3789) /* ty=() */;
  let %storage_0952: Storage[] = memory.alloc_storage(%tensor_0795, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][965]) /* ty=Storage[] */;
  let %out_0156: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0952, 0 /* ty=int64 */, %shape_func_out_0163, meta[relay.attrs.AllocTensorAttrs][965]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3790 = (%x592, %model.roi_heads.mask_head.mask_fcn3.weight, %model.roi_heads.mask_head.mask_fcn3.bias);
  %3791 = (%out_0156,);
  let %v788: () = vm.invoke_tvm_op(%3781, %3790, %3791) /* ty=() */;
  let %x593: Tensor[(?, 256, 14, 14), float32] = %out_0156;
  let %in_shape_0150: Tensor[(4), int64] = vm.shape_of(%x593, meta[relay.attrs.ShapeOfAttrs][161]) /* ty=Tensor[(4), int64] */;
  let %storage_0953: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][966]) /* ty=Storage[] */;
  let %tensor_0796: Tensor[(4), int64] = memory.alloc_tensor(%storage_0953, 0 /* ty=int64 */, meta[relay.Constant][783] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][966]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0164: Tensor[(4), int64] = %tensor_0796;
  %3796 = fn (%p0794: Tensor[(?, 256, 14, 14), float32], %p1350: Tensor[(256, 256, 3, 3), float32], %p2204: Tensor[(256), float32], Primitive=1) -> Tensor[(?, 256, 14, 14), float32] {
    %3792 = nn.conv2d(%p0794, %p1350, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    %3793 = expand_dims(%p2204, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %3794 = expand_dims(%3793, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %3795 = add(%3792, %3794) /* ty=Tensor[(?, 256, 14, 14), float32] */;
    nn.relu(%3795) /* ty=Tensor[(?, 256, 14, 14), float32] */
  };
  %3797 = (%in_shape_0150, meta[relay.Constant][784] /* ty=Tensor[(4), int64] */, meta[relay.Constant][785] /* ty=Tensor[(1), int64] */);
  %3798 = (%shape_func_out_0164,);
  let %shape_func164: () = vm.shape_func(%3796, %3797, %3798, meta[relay.attrs.ShapeFuncAttrs][164]) /* ty=() */;
  let %storage_0954: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][967]) /* ty=Storage[] */;
  let %tensor_0797: int64 = memory.alloc_tensor(%storage_0954, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][967]) /* ty=int64 */;
  %3799 = fn (%p0795: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0795) /* ty=int64 */
  };
  %3800 = (%shape_func_out_0164,);
  %3801 = (%tensor_0797,);
  let %v789: () = vm.invoke_tvm_op(%3799, %3800, %3801) /* ty=() */;
  let %storage_0955: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][968]) /* ty=Storage[] */;
  let %tensor_0798: int64 = memory.alloc_tensor(%storage_0955, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][968]) /* ty=int64 */;
  %3802 = fn (%p0796: int64, Primitive=1) -> int64 {
    multiply(%p0796, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3803 = (%tensor_0797,);
  %3804 = (%tensor_0798,);
  let %v790: () = vm.invoke_tvm_op(%3802, %3803, %3804) /* ty=() */;
  let %storage_0956: Storage[] = memory.alloc_storage(%tensor_0798, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][969]) /* ty=Storage[] */;
  let %out_0157: Tensor[(?, 256, 14, 14), float32] = memory.alloc_tensor(%storage_0956, 0 /* ty=int64 */, %shape_func_out_0164, meta[relay.attrs.AllocTensorAttrs][969]) /* ty=Tensor[(?, 256, 14, 14), float32] */;
  %3805 = (%x593, %model.roi_heads.mask_head.mask_fcn4.weight, %model.roi_heads.mask_head.mask_fcn4.bias);
  %3806 = (%out_0157,);
  let %v791: () = vm.invoke_tvm_op(%3796, %3805, %3806) /* ty=() */;
  let %x594: Tensor[(?, 256, 14, 14), float32] = %out_0157;
  let %in_shape_0151: Tensor[(4), int64] = vm.shape_of(%x594, meta[relay.attrs.ShapeOfAttrs][162]) /* ty=Tensor[(4), int64] */;
  let %storage_0957: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][970]) /* ty=Storage[] */;
  let %tensor_0799: Tensor[(4), int64] = memory.alloc_tensor(%storage_0957, 0 /* ty=int64 */, meta[relay.Constant][786] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][970]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0165: Tensor[(4), int64] = %tensor_0799;
  %3811 = fn (%p0797: Tensor[(?, 256, 14, 14), float32], %p1351: Tensor[(256, 256, 2, 2), float32], %p2205: Tensor[(256), float32], Primitive=1) -> Tensor[(?, 256, 28, 28), float32] {
    %3807 = nn.conv2d_transpose(%p0797, %p1351, channels=256, kernel_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(?, 256, 28, 28), float32] */;
    %3808 = expand_dims(%p2205, axis=1, num_newaxis=2) /* ty=Tensor[(256, 1, 1), float32] */;
    %3809 = expand_dims(%3808, axis=0) /* ty=Tensor[(1, 256, 1, 1), float32] */;
    %3810 = add(%3807, %3809) /* ty=Tensor[(?, 256, 28, 28), float32] */;
    nn.relu(%3810) /* ty=Tensor[(?, 256, 28, 28), float32] */
  };
  %3812 = (%in_shape_0151, meta[relay.Constant][787] /* ty=Tensor[(4), int64] */, meta[relay.Constant][788] /* ty=Tensor[(1), int64] */);
  %3813 = (%shape_func_out_0165,);
  let %shape_func165: () = vm.shape_func(%3811, %3812, %3813, meta[relay.attrs.ShapeFuncAttrs][165]) /* ty=() */;
  let %storage_0958: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][971]) /* ty=Storage[] */;
  let %tensor_0800: int64 = memory.alloc_tensor(%storage_0958, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][971]) /* ty=int64 */;
  %3814 = fn (%p0798: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0798) /* ty=int64 */
  };
  %3815 = (%shape_func_out_0165,);
  %3816 = (%tensor_0800,);
  let %v792: () = vm.invoke_tvm_op(%3814, %3815, %3816) /* ty=() */;
  let %storage_0959: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][972]) /* ty=Storage[] */;
  let %tensor_0801: int64 = memory.alloc_tensor(%storage_0959, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][972]) /* ty=int64 */;
  %3817 = fn (%p0799: int64, Primitive=1) -> int64 {
    multiply(%p0799, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3818 = (%tensor_0800,);
  %3819 = (%tensor_0801,);
  let %v793: () = vm.invoke_tvm_op(%3817, %3818, %3819) /* ty=() */;
  let %storage_0960: Storage[] = memory.alloc_storage(%tensor_0801, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][973]) /* ty=Storage[] */;
  let %out_0158: Tensor[(?, 256, 28, 28), float32] = memory.alloc_tensor(%storage_0960, 0 /* ty=int64 */, %shape_func_out_0165, meta[relay.attrs.AllocTensorAttrs][973]) /* ty=Tensor[(?, 256, 28, 28), float32] */;
  %3820 = (%x594, %model.roi_heads.mask_predictor.conv5_mask.weight, %model.roi_heads.mask_predictor.conv5_mask.bias);
  %3821 = (%out_0158,);
  let %v794: () = vm.invoke_tvm_op(%3811, %3820, %3821) /* ty=() */;
  let %x595: Tensor[(?, 256, 28, 28), float32] = %out_0158;
  let %in_shape_0152: Tensor[(4), int64] = vm.shape_of(%x595, meta[relay.attrs.ShapeOfAttrs][163]) /* ty=Tensor[(4), int64] */;
  let %storage_0961: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][974]) /* ty=Storage[] */;
  let %tensor_0802: Tensor[(4), int64] = memory.alloc_tensor(%storage_0961, 0 /* ty=int64 */, meta[relay.Constant][789] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][974]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0166: Tensor[(4), int64] = %tensor_0802;
  %3825 = fn (%p0800: Tensor[(?, 256, 28, 28), float32], %p1352: Tensor[(91, 256, 1, 1), float32], %p2206: Tensor[(91), float32], Primitive=1) -> Tensor[(?, 91, 28, 28), float32] {
    %3822 = nn.conv2d(%p0800, %p1352, padding=[0, 0, 0, 0], channels=91, kernel_size=[1, 1]) /* ty=Tensor[(?, 91, 28, 28), float32] */;
    %3823 = expand_dims(%p2206, axis=1, num_newaxis=2) /* ty=Tensor[(91, 1, 1), float32] */;
    %3824 = expand_dims(%3823, axis=0) /* ty=Tensor[(1, 91, 1, 1), float32] */;
    add(%3822, %3824) /* ty=Tensor[(?, 91, 28, 28), float32] */
  };
  %3826 = (%in_shape_0152, meta[relay.Constant][790] /* ty=Tensor[(4), int64] */, meta[relay.Constant][791] /* ty=Tensor[(1), int64] */);
  %3827 = (%shape_func_out_0166,);
  let %shape_func166: () = vm.shape_func(%3825, %3826, %3827, meta[relay.attrs.ShapeFuncAttrs][166]) /* ty=() */;
  let %storage_0962: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][975]) /* ty=Storage[] */;
  let %tensor_0803: int64 = memory.alloc_tensor(%storage_0962, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][975]) /* ty=int64 */;
  %3828 = fn (%p0801: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0801) /* ty=int64 */
  };
  %3829 = (%shape_func_out_0166,);
  %3830 = (%tensor_0803,);
  let %v795: () = vm.invoke_tvm_op(%3828, %3829, %3830) /* ty=() */;
  let %storage_0963: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][976]) /* ty=Storage[] */;
  let %tensor_0804: int64 = memory.alloc_tensor(%storage_0963, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][976]) /* ty=int64 */;
  %3831 = fn (%p0802: int64, Primitive=1) -> int64 {
    multiply(%p0802, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3832 = (%tensor_0803,);
  %3833 = (%tensor_0804,);
  let %v796: () = vm.invoke_tvm_op(%3831, %3832, %3833) /* ty=() */;
  let %storage_0964: Storage[] = memory.alloc_storage(%tensor_0804, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][977]) /* ty=Storage[] */;
  let %out_0159: Tensor[(?, 91, 28, 28), float32] = memory.alloc_tensor(%storage_0964, 0 /* ty=int64 */, %shape_func_out_0166, meta[relay.attrs.AllocTensorAttrs][977]) /* ty=Tensor[(?, 91, 28, 28), float32] */;
  %3834 = (%x595, %model.roi_heads.mask_predictor.mask_fcn_logits.weight, %model.roi_heads.mask_predictor.mask_fcn_logits.bias);
  %3835 = (%out_0159,);
  let %v797: () = vm.invoke_tvm_op(%3825, %3834, %3835) /* ty=() */;
  let %x596: Tensor[(?, 91, 28, 28), float32] = %out_0159;
  let %storage_0965: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][978]) /* ty=Storage[] */;
  let %tensor_0805: Tensor[(4), int32] = memory.alloc_tensor(%storage_0965, 0 /* ty=int64 */, meta[relay.Constant][792] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][978]) /* ty=Tensor[(4), int32] */;
  %3836 = fn (%p0803: Tensor[(?, 91, 28, 28), float32], Primitive=1) -> Tensor[(4), int32] {
    shape_of(%p0803, dtype="int32") /* ty=Tensor[(4), int32] */
  };
  %3837 = (%x596,);
  %3838 = (%tensor_0805,);
  let %v798: () = vm.invoke_tvm_op(%3836, %3837, %3838) /* ty=() */;
  let %x597: Tensor[(4), int32] = %tensor_0805;
  let %storage_0966: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][979]) /* ty=Storage[] */;
  let %tensor_0806: int64 = memory.alloc_tensor(%storage_0966, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][979]) /* ty=int64 */;
  %3840 = fn (%p0804: Tensor[(4), int32], Primitive=1) -> int64 {
    %3839 = take(%p0804, 0 /* ty=int32 */, axis=0) /* ty=int32 */;
    cast(%3839, dtype="int64") /* ty=int64 */
  };
  %3841 = (%x597,);
  %3842 = (%tensor_0806,);
  let %v799: () = vm.invoke_tvm_op(%3840, %3841, %3842) /* ty=() */;
  let %x598: int64 = %tensor_0806;
  let %in_shape_0153: int64 = device_copy(0 /* ty=int64 */, meta[relay.attrs.DeviceCopyAttrs][211]) /* ty=int64 */;
  let %in_shape_196: int64 = device_copy(%x598, meta[relay.attrs.DeviceCopyAttrs][212]) /* ty=int64 */;
  let %in_shape_266: int64 = device_copy(1 /* ty=int64 */, meta[relay.attrs.DeviceCopyAttrs][213]) /* ty=int64 */;
  let %storage_0967: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][980]) /* ty=Storage[] */;
  let %tensor_0807: Tensor[(1), int64] = memory.alloc_tensor(%storage_0967, 0 /* ty=int64 */, meta[relay.Constant][793] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][980]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0167: Tensor[(1), int64] = %tensor_0807;
  %3843 = fn (%p0805: int64, %p1353: int64, %p2207: int64, Primitive=1) -> Tensor[(?), int64] {
    arange(%p0805, %p1353, %p2207, start=meta[relay.Constant][794], stop=meta[relay.Call][2], step=meta[relay.Constant][795], dtype="int64") /* ty=Tensor[(?), int64] */
  };
  %3844 = (%in_shape_0153, %in_shape_196, %in_shape_266);
  %3845 = (%shape_func_out_0167,);
  let %shape_func167: () = vm.shape_func(%3843, %3844, %3845, meta[relay.attrs.ShapeFuncAttrs][167]) /* ty=() */;
  let %storage_0968: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][981]) /* ty=Storage[] */;
  let %tensor_0808: int64 = memory.alloc_tensor(%storage_0968, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][981]) /* ty=int64 */;
  %3846 = fn (%p0806: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0806) /* ty=int64 */
  };
  %3847 = (%shape_func_out_0167,);
  %3848 = (%tensor_0808,);
  let %v800: () = vm.invoke_tvm_op(%3846, %3847, %3848) /* ty=() */;
  let %storage_0969: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][982]) /* ty=Storage[] */;
  let %tensor_0809: int64 = memory.alloc_tensor(%storage_0969, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][982]) /* ty=int64 */;
  %3849 = fn (%p0807: int64, Primitive=1) -> int64 {
    multiply(%p0807, 8 /* ty=int64 */) /* ty=int64 */
  };
  %3850 = (%tensor_0808,);
  %3851 = (%tensor_0809,);
  let %v801: () = vm.invoke_tvm_op(%3849, %3850, %3851) /* ty=() */;
  let %storage_0970: Storage[] = memory.alloc_storage(%tensor_0809, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][983]) /* ty=Storage[] */;
  let %out_0160: Tensor[(?), int64] = memory.alloc_tensor(%storage_0970, 0 /* ty=int64 */, %shape_func_out_0167, meta[relay.attrs.AllocTensorAttrs][983]) /* ty=Tensor[(?), int64] */;
  %3852 = (0 /* ty=int64 */, %x598, 1 /* ty=int64 */);
  %3853 = (%out_0160,);
  let %v802: () = vm.invoke_tvm_op(%3843, %3852, %3853) /* ty=() */;
  let %x599: Tensor[(?), int64] = %out_0160;
  let %in_shape_0154: Tensor[(1), int64] = vm.shape_of(%x517, meta[relay.attrs.ShapeOfAttrs][164]) /* ty=Tensor[(1), int64] */;
  let %in_shape_197: Tensor[(1), int64] = vm.shape_of(%x523, meta[relay.attrs.ShapeOfAttrs][165]) /* ty=Tensor[(1), int64] */;
  let %storage_0971: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][984]) /* ty=Storage[] */;
  let %tensor_0810: Tensor[(1), int64] = memory.alloc_tensor(%storage_0971, 0 /* ty=int64 */, meta[relay.Constant][796] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][984]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0168: Tensor[(1), int64] = %tensor_0810;
  %3855 = fn (%p0808: Tensor[(?), int64], %p1354: Tensor[(?), int64], Primitive=1) -> Tensor[(?), int64] {
    %3854 = (%p0808, %p1354);
    adv_index(%3854) /* ty=Tensor[(?), int64] */
  };
  %3856 = (%in_shape_0154, %in_shape_197);
  %3857 = (%shape_func_out_0168,);
  let %shape_func168: () = vm.shape_func(%3855, %3856, %3857, meta[relay.attrs.ShapeFuncAttrs][168]) /* ty=() */;
  let %storage_0972: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][985]) /* ty=Storage[] */;
  let %tensor_0811: int64 = memory.alloc_tensor(%storage_0972, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][985]) /* ty=int64 */;
  %3858 = fn (%p0809: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0809) /* ty=int64 */
  };
  %3859 = (%shape_func_out_0168,);
  %3860 = (%tensor_0811,);
  let %v803: () = vm.invoke_tvm_op(%3858, %3859, %3860) /* ty=() */;
  let %storage_0973: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][986]) /* ty=Storage[] */;
  let %tensor_0812: int64 = memory.alloc_tensor(%storage_0973, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][986]) /* ty=int64 */;
  %3861 = fn (%p0810: int64, Primitive=1) -> int64 {
    multiply(%p0810, 8 /* ty=int64 */) /* ty=int64 */
  };
  %3862 = (%tensor_0811,);
  %3863 = (%tensor_0812,);
  let %v804: () = vm.invoke_tvm_op(%3861, %3862, %3863) /* ty=() */;
  let %storage_0974: Storage[] = memory.alloc_storage(%tensor_0812, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][987]) /* ty=Storage[] */;
  let %out_0161: Tensor[(?), int64] = memory.alloc_tensor(%storage_0974, 0 /* ty=int64 */, %shape_func_out_0168, meta[relay.attrs.AllocTensorAttrs][987]) /* ty=Tensor[(?), int64] */;
  %3864 = (%x517, %x523);
  %3865 = (%out_0161,);
  let %v805: () = vm.invoke_tvm_op(%3855, %3864, %3865) /* ty=() */;
  let %x600: Tensor[(?), int64] = %out_0161;
  let %in_shape_0155: Tensor[(4), int64] = vm.shape_of(%x596, meta[relay.attrs.ShapeOfAttrs][166]) /* ty=Tensor[(4), int64] */;
  let %in_shape_198: Tensor[(1), int64] = vm.shape_of(%x599, meta[relay.attrs.ShapeOfAttrs][167]) /* ty=Tensor[(1), int64] */;
  let %in_shape_267: Tensor[(1), int64] = vm.shape_of(%x600, meta[relay.attrs.ShapeOfAttrs][168]) /* ty=Tensor[(1), int64] */;
  let %storage_0975: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][988]) /* ty=Storage[] */;
  let %tensor_0813: Tensor[(3), int64] = memory.alloc_tensor(%storage_0975, 0 /* ty=int64 */, meta[relay.Constant][797] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][988]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_0169: Tensor[(3), int64] = %tensor_0813;
  %3870 = fn (%p0811: Tensor[(?, 91, 28, 28), float32], %p1355: Tensor[(?), int64], %p2208: Tensor[(?), int64], Primitive=1) -> Tensor[(?, 28, 28), float32] {
    %3866 = sigmoid(%p0811) /* ty=Tensor[(?, 91, 28, 28), float32] */;
    %3867 = (%p2208,);
    %3868 = concatenate(%3867) /* ty=Tensor[(?), int64] */;
    %3869 = (%3866, %p1355, %3868);
    adv_index(%3869) /* ty=Tensor[(?, 28, 28), float32] */
  };
  %3871 = (%in_shape_0155, %in_shape_198, %in_shape_267);
  %3872 = (%shape_func_out_0169,);
  let %shape_func169: () = vm.shape_func(%3870, %3871, %3872, meta[relay.attrs.ShapeFuncAttrs][169]) /* ty=() */;
  let %storage_0976: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][989]) /* ty=Storage[] */;
  let %tensor_0814: int64 = memory.alloc_tensor(%storage_0976, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][989]) /* ty=int64 */;
  %3873 = fn (%p0812: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0812) /* ty=int64 */
  };
  %3874 = (%shape_func_out_0169,);
  %3875 = (%tensor_0814,);
  let %v806: () = vm.invoke_tvm_op(%3873, %3874, %3875) /* ty=() */;
  let %storage_0977: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][990]) /* ty=Storage[] */;
  let %tensor_0815: int64 = memory.alloc_tensor(%storage_0977, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][990]) /* ty=int64 */;
  %3876 = fn (%p0813: int64, Primitive=1) -> int64 {
    multiply(%p0813, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3877 = (%tensor_0814,);
  %3878 = (%tensor_0815,);
  let %v807: () = vm.invoke_tvm_op(%3876, %3877, %3878) /* ty=() */;
  let %storage_0978: Storage[] = memory.alloc_storage(%tensor_0815, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][991]) /* ty=Storage[] */;
  let %out_0162: Tensor[(?, 28, 28), float32] = memory.alloc_tensor(%storage_0978, 0 /* ty=int64 */, %shape_func_out_0169, meta[relay.attrs.AllocTensorAttrs][991]) /* ty=Tensor[(?, 28, 28), float32] */;
  %3879 = (%x596, %x599, %x600);
  %3880 = (%out_0162,);
  let %v808: () = vm.invoke_tvm_op(%3870, %3879, %3880) /* ty=() */;
  let %x601: Tensor[(?, 28, 28), float32] = %out_0162;
  let %storage_0979: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][992]) /* ty=Storage[] */;
  let %tensor_0816: Tensor[(3), int32] = memory.alloc_tensor(%storage_0979, 0 /* ty=int64 */, meta[relay.Constant][798] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][992]) /* ty=Tensor[(3), int32] */;
  %3881 = fn (%p0814: Tensor[(?, 28, 28), float32], Primitive=1) -> Tensor[(3), int32] {
    shape_of(%p0814, dtype="int32") /* ty=Tensor[(3), int32] */
  };
  %3882 = (%x601,);
  %3883 = (%tensor_0816,);
  let %v809: () = vm.invoke_tvm_op(%3881, %3882, %3883) /* ty=() */;
  let %x602: Tensor[(3), int32] = %tensor_0816;
  let %storage_0980: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][993]) /* ty=Storage[] */;
  let %tensor_0817: Tensor[(3), int32] = memory.alloc_tensor(%storage_0980, 0 /* ty=int64 */, meta[relay.Constant][799] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][993]) /* ty=Tensor[(3), int32] */;
  %3886 = fn (%p0815: Tensor[(3), bool], %p1356: Tensor[(3), int32], %p2209: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int32] {
    %3884 = cast_like(%p2209, %p1356) /* ty=Tensor[(3), int32] */;
    %3885 = add(%p1356, %3884) /* ty=Tensor[(3), int32] */;
    where(%p0815, %3885, %p1356) /* ty=Tensor[(3), int32] */
  };
  %3887 = (meta[relay.Constant][800] /* ty=Tensor[(3), bool] */, meta[relay.Constant][801] /* ty=Tensor[(3), int32] */, %x602);
  %3888 = (%tensor_0817,);
  let %v810: () = vm.invoke_tvm_op(%3886, %3887, %3888) /* ty=() */;
  let %x603: Tensor[(3), int32] = %tensor_0817;
  let %storage_0981: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][994]) /* ty=Storage[] */;
  let %tensor_0818: Tensor[(3), int64] = memory.alloc_tensor(%storage_0981, 0 /* ty=int64 */, meta[relay.Constant][802] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][994]) /* ty=Tensor[(3), int64] */;
  %3889 = fn (%p0816: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int64] {
    cast(%p0816, dtype="int64") /* ty=Tensor[(3), int64] */
  };
  %3890 = (%x602,);
  %3891 = (%tensor_0818,);
  let %v811: () = vm.invoke_tvm_op(%3889, %3890, %3891) /* ty=() */;
  let %x604: Tensor[(3), int64] = %tensor_0818;
  let %in_shape_0156: Tensor[(?, 28, 28), float32] = device_copy(%x601, meta[relay.attrs.DeviceCopyAttrs][214]) /* ty=Tensor[(?, 28, 28), float32] */;
  let %in_shape_199: Tensor[(3), int32] = device_copy(%x603, meta[relay.attrs.DeviceCopyAttrs][215]) /* ty=Tensor[(3), int32] */;
  let %in_shape_268: Tensor[(3), int64] = device_copy(%x604, meta[relay.attrs.DeviceCopyAttrs][216]) /* ty=Tensor[(3), int64] */;
  let %in_shape_352: Tensor[(3), int32] = device_copy(meta[relay.Constant][803] /* ty=Tensor[(3), int32] */, meta[relay.attrs.DeviceCopyAttrs][217]) /* ty=Tensor[(3), int32] */;
  let %storage_0982: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][995]) /* ty=Storage[] */;
  let %tensor_0819: Tensor[(3), int64] = memory.alloc_tensor(%storage_0982, 0 /* ty=int64 */, meta[relay.Constant][804] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][995]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_0170: Tensor[(3), int64] = %tensor_0819;
  %3892 = fn (%p0817: Tensor[(?, 28, 28), float32], %p1357: Tensor[(3), int32], %p2210: Tensor[(3), int64], %p3114: Tensor[(3), int32], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.strided_slice(%p0817, %p1357, %p2210, %p3114, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %3893 = (%in_shape_0156, %in_shape_199, %in_shape_268, %in_shape_352);
  %3894 = (%shape_func_out_0170,);
  let %shape_func170: () = vm.shape_func(%3892, %3893, %3894, meta[relay.attrs.ShapeFuncAttrs][170]) /* ty=() */;
  let %storage_0983: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][996]) /* ty=Storage[] */;
  let %tensor_0820: int64 = memory.alloc_tensor(%storage_0983, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][996]) /* ty=int64 */;
  %3895 = fn (%p0818: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0818) /* ty=int64 */
  };
  %3896 = (%shape_func_out_0170,);
  %3897 = (%tensor_0820,);
  let %v812: () = vm.invoke_tvm_op(%3895, %3896, %3897) /* ty=() */;
  let %storage_0984: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][997]) /* ty=Storage[] */;
  let %tensor_0821: int64 = memory.alloc_tensor(%storage_0984, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][997]) /* ty=int64 */;
  %3898 = fn (%p0819: int64, Primitive=1) -> int64 {
    multiply(%p0819, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3899 = (%tensor_0820,);
  %3900 = (%tensor_0821,);
  let %v813: () = vm.invoke_tvm_op(%3898, %3899, %3900) /* ty=() */;
  let %storage_0985: Storage[] = memory.alloc_storage(%tensor_0821, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][998]) /* ty=Storage[] */;
  let %out_0163: Tensor[(?, ?, ?), float32] = memory.alloc_tensor(%storage_0985, 0 /* ty=int64 */, %shape_func_out_0170, meta[relay.attrs.AllocTensorAttrs][998]) /* ty=Tensor[(?, ?, ?), float32] */;
  %3901 = (%x601, %x603, %x604, meta[relay.Constant][803] /* ty=Tensor[(3), int32] */);
  %3902 = (%out_0163,);
  let %v814: () = vm.invoke_tvm_op(%3892, %3901, %3902) /* ty=() */;
  let %x605: Tensor[(?, ?, ?), float32] = %out_0163;
  let %in_shape_0157: Tensor[(3), int64] = vm.shape_of(%x605, meta[relay.attrs.ShapeOfAttrs][169]) /* ty=Tensor[(3), int64] */;
  let %storage_0986: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][999]) /* ty=Storage[] */;
  let %tensor_0822: Tensor[(4), int64] = memory.alloc_tensor(%storage_0986, 0 /* ty=int64 */, meta[relay.Constant][805] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][999]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0171: Tensor[(4), int64] = %tensor_0822;
  %3903 = fn (%p0820: Tensor[(?, ?, ?), float32], Primitive=1) -> Tensor[(?, 1, ?, ?), float32] {
    expand_dims(%p0820, axis=1) /* ty=Tensor[(?, 1, ?, ?), float32] */
  };
  %3904 = (%in_shape_0157,);
  %3905 = (%shape_func_out_0171,);
  let %shape_func171: () = vm.shape_func(%3903, %3904, %3905, meta[relay.attrs.ShapeFuncAttrs][171]) /* ty=() */;
  let %storage_0987: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1000]) /* ty=Storage[] */;
  let %tensor_0823: int64 = memory.alloc_tensor(%storage_0987, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1000]) /* ty=int64 */;
  %3906 = fn (%p0821: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0821) /* ty=int64 */
  };
  %3907 = (%shape_func_out_0171,);
  %3908 = (%tensor_0823,);
  let %v815: () = vm.invoke_tvm_op(%3906, %3907, %3908) /* ty=() */;
  let %storage_0988: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1001]) /* ty=Storage[] */;
  let %tensor_0824: int64 = memory.alloc_tensor(%storage_0988, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1001]) /* ty=int64 */;
  %3909 = fn (%p0822: int64, Primitive=1) -> int64 {
    multiply(%p0822, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3910 = (%tensor_0823,);
  %3911 = (%tensor_0824,);
  let %v816: () = vm.invoke_tvm_op(%3909, %3910, %3911) /* ty=() */;
  let %storage_0989: Storage[] = memory.alloc_storage(%tensor_0824, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1002]) /* ty=Storage[] */;
  let %out_0164: Tensor[(?, 1, ?, ?), float32] = memory.alloc_tensor(%storage_0989, 0 /* ty=int64 */, %shape_func_out_0171, meta[relay.attrs.AllocTensorAttrs][1002]) /* ty=Tensor[(?, 1, ?, ?), float32] */;
  %3912 = (%x605,);
  %3913 = (%out_0164,);
  let %v817: () = vm.invoke_tvm_op(%3903, %3912, %3913) /* ty=() */;
  let %x606: Tensor[(?, 1, ?, ?), float32] = %out_0164;
  let %in_shape_0158: Tensor[(4), int64] = vm.shape_of(%x606, meta[relay.attrs.ShapeOfAttrs][170]) /* ty=Tensor[(4), int64] */;
  let %storage_0990: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1003]) /* ty=Storage[] */;
  let %tensor_0825: Tensor[(4), int64] = memory.alloc_tensor(%storage_0990, 0 /* ty=int64 */, meta[relay.Constant][806] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1003]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0172: Tensor[(4), int64] = %tensor_0825;
  %3914 = fn (%p0823: Tensor[(?, 1, ?, ?), float32], Primitive=1) -> Tensor[(?, 1, ?, ?), float32] {
    nn.pad(%p0823, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(?, 1, ?, ?), float32] */
  };
  %3915 = (%in_shape_0158,);
  %3916 = (%shape_func_out_0172,);
  let %shape_func172: () = vm.shape_func(%3914, %3915, %3916, meta[relay.attrs.ShapeFuncAttrs][172]) /* ty=() */;
  let %storage_0991: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1004]) /* ty=Storage[] */;
  let %tensor_0826: int64 = memory.alloc_tensor(%storage_0991, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1004]) /* ty=int64 */;
  %3917 = fn (%p0824: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0824) /* ty=int64 */
  };
  %3918 = (%shape_func_out_0172,);
  %3919 = (%tensor_0826,);
  let %v818: () = vm.invoke_tvm_op(%3917, %3918, %3919) /* ty=() */;
  let %storage_0992: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1005]) /* ty=Storage[] */;
  let %tensor_0827: int64 = memory.alloc_tensor(%storage_0992, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1005]) /* ty=int64 */;
  %3920 = fn (%p0825: int64, Primitive=1) -> int64 {
    multiply(%p0825, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3921 = (%tensor_0826,);
  %3922 = (%tensor_0827,);
  let %v819: () = vm.invoke_tvm_op(%3920, %3921, %3922) /* ty=() */;
  let %storage_0993: Storage[] = memory.alloc_storage(%tensor_0827, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1006]) /* ty=Storage[] */;
  let %out_0165: Tensor[(?, 1, ?, ?), float32] = memory.alloc_tensor(%storage_0993, 0 /* ty=int64 */, %shape_func_out_0172, meta[relay.attrs.AllocTensorAttrs][1006]) /* ty=Tensor[(?, 1, ?, ?), float32] */;
  %3923 = (%x606,);
  %3924 = (%out_0165,);
  let %v820: () = vm.invoke_tvm_op(%3914, %3923, %3924) /* ty=() */;
  let %x607: Tensor[(?, 1, ?, ?), float32] = %out_0165;
  let %in_shape_0159: Tensor[(2), int64] = vm.shape_of(%x539, meta[relay.attrs.ShapeOfAttrs][171]) /* ty=Tensor[(2), int64] */;
  let %storage_0994: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1007]) /* ty=Storage[] */;
  let %tensor_0828: Tensor[(2), int64] = memory.alloc_tensor(%storage_0994, 0 /* ty=int64 */, meta[relay.Constant][807] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1007]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0173: Tensor[(2), int64] = %tensor_0828;
  %3939 = fn (%p0826: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(?, 4), float32] {
    %3925 = split(%p0826, indices_or_sections=4, axis=1) /* ty=(Tensor[(?, 1), float32], Tensor[(?, 1), float32], Tensor[(?, 1), float32], Tensor[(?, 1), float32]) */;
    %3926 = %3925.0;
    %3927 = squeeze(%3926, axis=[1]) /* ty=Tensor[(?), float32] */;
    %3928 = multiply(%3927, 0.375f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %3929 = %3925.1;
    %3930 = squeeze(%3929, axis=[1]) /* ty=Tensor[(?), float32] */;
    %3931 = multiply(%3930, 0.375f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %3932 = %3925.2;
    %3933 = squeeze(%3932, axis=[1]) /* ty=Tensor[(?), float32] */;
    %3934 = multiply(%3933, 0.375f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %3935 = %3925.3;
    %3936 = squeeze(%3935, axis=[1]) /* ty=Tensor[(?), float32] */;
    %3937 = multiply(%3936, 0.375f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %3938 = (%3928, %3931, %3934, %3937);
    stack(%3938, axis=1) /* ty=Tensor[(?, 4), float32] */
  };
  %3940 = (%in_shape_0159,);
  %3941 = (%shape_func_out_0173,);
  let %shape_func173: () = vm.shape_func(%3939, %3940, %3941, meta[relay.attrs.ShapeFuncAttrs][173]) /* ty=() */;
  let %storage_0995: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1008]) /* ty=Storage[] */;
  let %tensor_0829: int64 = memory.alloc_tensor(%storage_0995, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1008]) /* ty=int64 */;
  %3942 = fn (%p0827: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0827) /* ty=int64 */
  };
  %3943 = (%shape_func_out_0173,);
  %3944 = (%tensor_0829,);
  let %v821: () = vm.invoke_tvm_op(%3942, %3943, %3944) /* ty=() */;
  let %storage_0996: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1009]) /* ty=Storage[] */;
  let %tensor_0830: int64 = memory.alloc_tensor(%storage_0996, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1009]) /* ty=int64 */;
  %3945 = fn (%p0828: int64, Primitive=1) -> int64 {
    multiply(%p0828, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3946 = (%tensor_0829,);
  %3947 = (%tensor_0830,);
  let %v822: () = vm.invoke_tvm_op(%3945, %3946, %3947) /* ty=() */;
  let %storage_0997: Storage[] = memory.alloc_storage(%tensor_0830, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1010]) /* ty=Storage[] */;
  let %out_0166: Tensor[(?, 4), float32] = memory.alloc_tensor(%storage_0997, 0 /* ty=int64 */, %shape_func_out_0173, meta[relay.attrs.AllocTensorAttrs][1010]) /* ty=Tensor[(?, 4), float32] */;
  %3948 = (%x539,);
  %3949 = (%out_0166,);
  let %v823: () = vm.invoke_tvm_op(%3939, %3948, %3949) /* ty=() */;
  let %x608: Tensor[(?, 4), float32] = %out_0166;
  let %in_shape_0160: Tensor[(1), int64] = vm.shape_of(%x519, meta[relay.attrs.ShapeOfAttrs][172]) /* ty=Tensor[(1), int64] */;
  let %in_shape_1100: Tensor[(1), int64] = vm.shape_of(%x523, meta[relay.attrs.ShapeOfAttrs][173]) /* ty=Tensor[(1), int64] */;
  let %storage_0998: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1011]) /* ty=Storage[] */;
  let %tensor_0831: Tensor[(1), int64] = memory.alloc_tensor(%storage_0998, 0 /* ty=int64 */, meta[relay.Constant][808] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1011]) /* ty=Tensor[(1), int64] */;
  let %shape_func_out_0174: Tensor[(1), int64] = %tensor_0831;
  %3951 = fn (%p0829: Tensor[(?), float32], %p1358: Tensor[(?), int64], Primitive=1) -> Tensor[(?), float32] {
    %3950 = (%p0829, %p1358);
    adv_index(%3950) /* ty=Tensor[(?), float32] */
  };
  %3952 = (%in_shape_0160, %in_shape_1100);
  %3953 = (%shape_func_out_0174,);
  let %shape_func174: () = vm.shape_func(%3951, %3952, %3953, meta[relay.attrs.ShapeFuncAttrs][174]) /* ty=() */;
  let %storage_0999: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1012]) /* ty=Storage[] */;
  let %tensor_0832: int64 = memory.alloc_tensor(%storage_0999, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1012]) /* ty=int64 */;
  %3954 = fn (%p0830: Tensor[(1), int64], Primitive=1) -> int64 {
    prod(%p0830) /* ty=int64 */
  };
  %3955 = (%shape_func_out_0174,);
  %3956 = (%tensor_0832,);
  let %v824: () = vm.invoke_tvm_op(%3954, %3955, %3956) /* ty=() */;
  let %storage_01000: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1013]) /* ty=Storage[] */;
  let %tensor_0833: int64 = memory.alloc_tensor(%storage_01000, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1013]) /* ty=int64 */;
  %3957 = fn (%p0831: int64, Primitive=1) -> int64 {
    multiply(%p0831, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3958 = (%tensor_0832,);
  %3959 = (%tensor_0833,);
  let %v825: () = vm.invoke_tvm_op(%3957, %3958, %3959) /* ty=() */;
  let %storage_01001: Storage[] = memory.alloc_storage(%tensor_0833, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1014]) /* ty=Storage[] */;
  let %out_0167: Tensor[(?), float32] = memory.alloc_tensor(%storage_01001, 0 /* ty=int64 */, %shape_func_out_0174, meta[relay.attrs.AllocTensorAttrs][1014]) /* ty=Tensor[(?), float32] */;
  %3960 = (%x519, %x523);
  %3961 = (%out_0167,);
  let %v826: () = vm.invoke_tvm_op(%3951, %3960, %3961) /* ty=() */;
  let %x609: Tensor[(?), float32] = %out_0167;
  let %storage_01002: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1015]) /* ty=Storage[] */;
  let %tensor_0834: Tensor[(3), int64] = memory.alloc_tensor(%storage_01002, 0 /* ty=int64 */, meta[relay.Constant][809] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1015]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_0175: Tensor[(3), int64] = %tensor_0834;
  %3962 = fn (Primitive=1) -> Tensor[(?, ?, ?), float32] {
    full(0 /* ty=int32 */, shape=[0, 300, 300], dtype="float32") /* ty=Tensor[(?, ?, ?), float32] */
  };
  %3963 = ();
  %3964 = (%shape_func_out_0175,);
  let %shape_func175: () = vm.shape_func(%3962, %3963, %3964, meta[relay.attrs.ShapeFuncAttrs][175]) /* ty=() */;
  let %storage_01003: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1016]) /* ty=Storage[] */;
  let %tensor_0835: int64 = memory.alloc_tensor(%storage_01003, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1016]) /* ty=int64 */;
  %3965 = fn (%p0832: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0832) /* ty=int64 */
  };
  %3966 = (%shape_func_out_0175,);
  %3967 = (%tensor_0835,);
  let %v827: () = vm.invoke_tvm_op(%3965, %3966, %3967) /* ty=() */;
  let %storage_01004: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1017]) /* ty=Storage[] */;
  let %tensor_0836: int64 = memory.alloc_tensor(%storage_01004, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1017]) /* ty=int64 */;
  %3968 = fn (%p0833: int64, Primitive=1) -> int64 {
    multiply(%p0833, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3969 = (%tensor_0835,);
  %3970 = (%tensor_0836,);
  let %v828: () = vm.invoke_tvm_op(%3968, %3969, %3970) /* ty=() */;
  let %storage_01005: Storage[] = memory.alloc_storage(%tensor_0836, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1018]) /* ty=Storage[] */;
  let %out_0168: Tensor[(?, ?, ?), float32] = memory.alloc_tensor(%storage_01005, 0 /* ty=int64 */, %shape_func_out_0175, meta[relay.attrs.AllocTensorAttrs][1018]) /* ty=Tensor[(?, ?, ?), float32] */;
  %3971 = ();
  %3972 = (%out_0168,);
  let %v829: () = vm.invoke_tvm_op(%3962, %3971, %3972) /* ty=() */;
  let %x610: Tensor[(?, ?, ?), float32] = %out_0168;
  let %storage_01006: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1019]) /* ty=Storage[] */;
  let %tensor_0837: Tensor[(2), int32] = memory.alloc_tensor(%storage_01006, 0 /* ty=int64 */, meta[relay.Constant][810] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1019]) /* ty=Tensor[(2), int32] */;
  %3973 = fn (%p0834: Tensor[(?, 4), float32], Primitive=1) -> Tensor[(2), int32] {
    shape_of(%p0834, dtype="int32") /* ty=Tensor[(2), int32] */
  };
  %3974 = (%x608,);
  %3975 = (%tensor_0837,);
  let %v830: () = vm.invoke_tvm_op(%3973, %3974, %3975) /* ty=() */;
  let %x611: Tensor[(2), int32] = %tensor_0837;
  let %storage_01007: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1020]) /* ty=Storage[] */;
  let %tensor_0838: Tensor[(2), int32] = memory.alloc_tensor(%storage_01007, 0 /* ty=int64 */, meta[relay.Constant][811] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1020]) /* ty=Tensor[(2), int32] */;
  %3978 = fn (%p0835: Tensor[(2), bool], %p1359: Tensor[(2), int32], %p2211: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3976 = cast_like(%p2211, %p1359) /* ty=Tensor[(2), int32] */;
    %3977 = add(%p1359, %3976) /* ty=Tensor[(2), int32] */;
    where(%p0835, %3977, %p1359) /* ty=Tensor[(2), int32] */
  };
  %3979 = (meta[relay.Constant][812] /* ty=Tensor[(2), bool] */, meta[relay.Constant][813] /* ty=Tensor[(2), int32] */, %x611);
  %3980 = (%tensor_0838,);
  let %v831: () = vm.invoke_tvm_op(%3978, %3979, %3980) /* ty=() */;
  let %x612: Tensor[(2), int32] = %tensor_0838;
  let %storage_01008: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1021]) /* ty=Storage[] */;
  let %tensor_0839: Tensor[(2), int64] = memory.alloc_tensor(%storage_01008, 0 /* ty=int64 */, meta[relay.Constant][814] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1021]) /* ty=Tensor[(2), int64] */;
  %3981 = fn (%p0836: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
    cast(%p0836, dtype="int64") /* ty=Tensor[(2), int64] */
  };
  %3982 = (%x611,);
  %3983 = (%tensor_0839,);
  let %v832: () = vm.invoke_tvm_op(%3981, %3982, %3983) /* ty=() */;
  let %x613: Tensor[(2), int64] = %tensor_0839;
  let %in_shape_0161: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][218]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1101: Tensor[(2), int32] = device_copy(%x612, meta[relay.attrs.DeviceCopyAttrs][219]) /* ty=Tensor[(2), int32] */;
  let %in_shape_269: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][220]) /* ty=Tensor[(2), int64] */;
  let %in_shape_353: Tensor[(2), int32] = device_copy(meta[relay.Constant][815] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][221]) /* ty=Tensor[(2), int32] */;
  let %storage_01009: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1022]) /* ty=Storage[] */;
  let %tensor_0840: Tensor[(2), int64] = memory.alloc_tensor(%storage_01009, 0 /* ty=int64 */, meta[relay.Constant][816] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1022]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0176: Tensor[(2), int64] = %tensor_0840;
  %3984 = fn (%p0837: Tensor[(?, 4), float32], %p1360: Tensor[(2), int32], %p2212: Tensor[(2), int64], %p3115: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0837, %p1360, %p2212, %p3115, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %3985 = (%in_shape_0161, %in_shape_1101, %in_shape_269, %in_shape_353);
  %3986 = (%shape_func_out_0176,);
  let %shape_func176: () = vm.shape_func(%3984, %3985, %3986, meta[relay.attrs.ShapeFuncAttrs][176]) /* ty=() */;
  let %storage_01010: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1023]) /* ty=Storage[] */;
  let %tensor_0841: int64 = memory.alloc_tensor(%storage_01010, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1023]) /* ty=int64 */;
  %3987 = fn (%p0838: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0838) /* ty=int64 */
  };
  %3988 = (%shape_func_out_0176,);
  %3989 = (%tensor_0841,);
  let %v833: () = vm.invoke_tvm_op(%3987, %3988, %3989) /* ty=() */;
  let %storage_01011: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1024]) /* ty=Storage[] */;
  let %tensor_0842: int64 = memory.alloc_tensor(%storage_01011, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1024]) /* ty=int64 */;
  %3990 = fn (%p0839: int64, Primitive=1) -> int64 {
    multiply(%p0839, 4 /* ty=int64 */) /* ty=int64 */
  };
  %3991 = (%tensor_0841,);
  %3992 = (%tensor_0842,);
  let %v834: () = vm.invoke_tvm_op(%3990, %3991, %3992) /* ty=() */;
  let %storage_01012: Storage[] = memory.alloc_storage(%tensor_0842, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1025]) /* ty=Storage[] */;
  let %out_0169: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01012, 0 /* ty=int64 */, %shape_func_out_0176, meta[relay.attrs.AllocTensorAttrs][1025]) /* ty=Tensor[(?, ?), float32] */;
  %3993 = (%x608, %x612, %x613, meta[relay.Constant][815] /* ty=Tensor[(2), int32] */);
  %3994 = (%out_0169,);
  let %v835: () = vm.invoke_tvm_op(%3984, %3993, %3994) /* ty=() */;
  let %x614: Tensor[(?, ?), float32] = %out_0169;
  let %storage_01013: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1026]) /* ty=Storage[] */;
  let %tensor_0843: Tensor[(2), int32] = memory.alloc_tensor(%storage_01013, 0 /* ty=int64 */, meta[relay.Constant][817] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1026]) /* ty=Tensor[(2), int32] */;
  %3997 = fn (%p0840: Tensor[(2), bool], %p1361: Tensor[(2), int32], %p2213: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %3995 = cast_like(%p2213, %p1361) /* ty=Tensor[(2), int32] */;
    %3996 = add(%p1361, %3995) /* ty=Tensor[(2), int32] */;
    where(%p0840, %3996, %p1361) /* ty=Tensor[(2), int32] */
  };
  %3998 = (meta[relay.Constant][818] /* ty=Tensor[(2), bool] */, meta[relay.Constant][819] /* ty=Tensor[(2), int32] */, %x611);
  %3999 = (%tensor_0843,);
  let %v836: () = vm.invoke_tvm_op(%3997, %3998, %3999) /* ty=() */;
  let %x615: Tensor[(2), int32] = %tensor_0843;
  let %in_shape_0162: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][222]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1102: Tensor[(2), int32] = device_copy(%x615, meta[relay.attrs.DeviceCopyAttrs][223]) /* ty=Tensor[(2), int32] */;
  let %in_shape_270: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][224]) /* ty=Tensor[(2), int64] */;
  let %in_shape_354: Tensor[(2), int32] = device_copy(meta[relay.Constant][820] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][225]) /* ty=Tensor[(2), int32] */;
  let %storage_01014: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1027]) /* ty=Storage[] */;
  let %tensor_0844: Tensor[(2), int64] = memory.alloc_tensor(%storage_01014, 0 /* ty=int64 */, meta[relay.Constant][821] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1027]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0177: Tensor[(2), int64] = %tensor_0844;
  %4000 = fn (%p0841: Tensor[(?, 4), float32], %p1362: Tensor[(2), int32], %p2214: Tensor[(2), int64], %p3116: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0841, %p1362, %p2214, %p3116, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %4001 = (%in_shape_0162, %in_shape_1102, %in_shape_270, %in_shape_354);
  %4002 = (%shape_func_out_0177,);
  let %shape_func177: () = vm.shape_func(%4000, %4001, %4002, meta[relay.attrs.ShapeFuncAttrs][177]) /* ty=() */;
  let %storage_01015: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1028]) /* ty=Storage[] */;
  let %tensor_0845: int64 = memory.alloc_tensor(%storage_01015, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1028]) /* ty=int64 */;
  %4003 = fn (%p0842: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0842) /* ty=int64 */
  };
  %4004 = (%shape_func_out_0177,);
  %4005 = (%tensor_0845,);
  let %v837: () = vm.invoke_tvm_op(%4003, %4004, %4005) /* ty=() */;
  let %storage_01016: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1029]) /* ty=Storage[] */;
  let %tensor_0846: int64 = memory.alloc_tensor(%storage_01016, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1029]) /* ty=int64 */;
  %4006 = fn (%p0843: int64, Primitive=1) -> int64 {
    multiply(%p0843, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4007 = (%tensor_0845,);
  %4008 = (%tensor_0846,);
  let %v838: () = vm.invoke_tvm_op(%4006, %4007, %4008) /* ty=() */;
  let %storage_01017: Storage[] = memory.alloc_storage(%tensor_0846, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1030]) /* ty=Storage[] */;
  let %out_0170: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01017, 0 /* ty=int64 */, %shape_func_out_0177, meta[relay.attrs.AllocTensorAttrs][1030]) /* ty=Tensor[(?, ?), float32] */;
  %4009 = (%x608, %x615, %x613, meta[relay.Constant][820] /* ty=Tensor[(2), int32] */);
  %4010 = (%out_0170,);
  let %v839: () = vm.invoke_tvm_op(%4000, %4009, %4010) /* ty=() */;
  let %x616: Tensor[(?, ?), float32] = %out_0170;
  let %storage_01018: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1031]) /* ty=Storage[] */;
  let %tensor_0847: Tensor[(2), int32] = memory.alloc_tensor(%storage_01018, 0 /* ty=int64 */, meta[relay.Constant][822] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1031]) /* ty=Tensor[(2), int32] */;
  %4013 = fn (%p0844: Tensor[(2), bool], %p1363: Tensor[(2), int32], %p2215: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %4011 = cast_like(%p2215, %p1363) /* ty=Tensor[(2), int32] */;
    %4012 = add(%p1363, %4011) /* ty=Tensor[(2), int32] */;
    where(%p0844, %4012, %p1363) /* ty=Tensor[(2), int32] */
  };
  %4014 = (meta[relay.Constant][823] /* ty=Tensor[(2), bool] */, meta[relay.Constant][824] /* ty=Tensor[(2), int32] */, %x611);
  %4015 = (%tensor_0847,);
  let %v840: () = vm.invoke_tvm_op(%4013, %4014, %4015) /* ty=() */;
  let %x617: Tensor[(2), int32] = %tensor_0847;
  let %in_shape_0163: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][226]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1103: Tensor[(2), int32] = device_copy(%x617, meta[relay.attrs.DeviceCopyAttrs][227]) /* ty=Tensor[(2), int32] */;
  let %in_shape_271: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][228]) /* ty=Tensor[(2), int64] */;
  let %in_shape_355: Tensor[(2), int32] = device_copy(meta[relay.Constant][825] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][229]) /* ty=Tensor[(2), int32] */;
  let %storage_01019: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1032]) /* ty=Storage[] */;
  let %tensor_0848: Tensor[(2), int64] = memory.alloc_tensor(%storage_01019, 0 /* ty=int64 */, meta[relay.Constant][826] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1032]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0178: Tensor[(2), int64] = %tensor_0848;
  %4016 = fn (%p0845: Tensor[(?, 4), float32], %p1364: Tensor[(2), int32], %p2216: Tensor[(2), int64], %p3117: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0845, %p1364, %p2216, %p3117, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %4017 = (%in_shape_0163, %in_shape_1103, %in_shape_271, %in_shape_355);
  %4018 = (%shape_func_out_0178,);
  let %shape_func178: () = vm.shape_func(%4016, %4017, %4018, meta[relay.attrs.ShapeFuncAttrs][178]) /* ty=() */;
  let %storage_01020: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1033]) /* ty=Storage[] */;
  let %tensor_0849: int64 = memory.alloc_tensor(%storage_01020, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1033]) /* ty=int64 */;
  %4019 = fn (%p0846: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0846) /* ty=int64 */
  };
  %4020 = (%shape_func_out_0178,);
  %4021 = (%tensor_0849,);
  let %v841: () = vm.invoke_tvm_op(%4019, %4020, %4021) /* ty=() */;
  let %storage_01021: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1034]) /* ty=Storage[] */;
  let %tensor_0850: int64 = memory.alloc_tensor(%storage_01021, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1034]) /* ty=int64 */;
  %4022 = fn (%p0847: int64, Primitive=1) -> int64 {
    multiply(%p0847, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4023 = (%tensor_0849,);
  %4024 = (%tensor_0850,);
  let %v842: () = vm.invoke_tvm_op(%4022, %4023, %4024) /* ty=() */;
  let %storage_01022: Storage[] = memory.alloc_storage(%tensor_0850, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1035]) /* ty=Storage[] */;
  let %out_0171: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01022, 0 /* ty=int64 */, %shape_func_out_0178, meta[relay.attrs.AllocTensorAttrs][1035]) /* ty=Tensor[(?, ?), float32] */;
  %4025 = (%x608, %x617, %x613, meta[relay.Constant][825] /* ty=Tensor[(2), int32] */);
  %4026 = (%out_0171,);
  let %v843: () = vm.invoke_tvm_op(%4016, %4025, %4026) /* ty=() */;
  let %x618: Tensor[(?, ?), float32] = %out_0171;
  let %storage_01023: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1036]) /* ty=Storage[] */;
  let %tensor_0851: Tensor[(2), int32] = memory.alloc_tensor(%storage_01023, 0 /* ty=int64 */, meta[relay.Constant][827] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1036]) /* ty=Tensor[(2), int32] */;
  %4029 = fn (%p0848: Tensor[(2), bool], %p1365: Tensor[(2), int32], %p2217: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %4027 = cast_like(%p2217, %p1365) /* ty=Tensor[(2), int32] */;
    %4028 = add(%p1365, %4027) /* ty=Tensor[(2), int32] */;
    where(%p0848, %4028, %p1365) /* ty=Tensor[(2), int32] */
  };
  %4030 = (meta[relay.Constant][828] /* ty=Tensor[(2), bool] */, meta[relay.Constant][829] /* ty=Tensor[(2), int32] */, %x611);
  %4031 = (%tensor_0851,);
  let %v844: () = vm.invoke_tvm_op(%4029, %4030, %4031) /* ty=() */;
  let %x619: Tensor[(2), int32] = %tensor_0851;
  let %in_shape_0164: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][230]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1104: Tensor[(2), int32] = device_copy(%x619, meta[relay.attrs.DeviceCopyAttrs][231]) /* ty=Tensor[(2), int32] */;
  let %in_shape_272: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][232]) /* ty=Tensor[(2), int64] */;
  let %in_shape_356: Tensor[(2), int32] = device_copy(meta[relay.Constant][830] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][233]) /* ty=Tensor[(2), int32] */;
  let %storage_01024: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1037]) /* ty=Storage[] */;
  let %tensor_0852: Tensor[(2), int64] = memory.alloc_tensor(%storage_01024, 0 /* ty=int64 */, meta[relay.Constant][831] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1037]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0179: Tensor[(2), int64] = %tensor_0852;
  %4032 = fn (%p0849: Tensor[(?, 4), float32], %p1366: Tensor[(2), int32], %p2218: Tensor[(2), int64], %p3118: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0849, %p1366, %p2218, %p3118, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %4033 = (%in_shape_0164, %in_shape_1104, %in_shape_272, %in_shape_356);
  %4034 = (%shape_func_out_0179,);
  let %shape_func179: () = vm.shape_func(%4032, %4033, %4034, meta[relay.attrs.ShapeFuncAttrs][179]) /* ty=() */;
  let %storage_01025: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1038]) /* ty=Storage[] */;
  let %tensor_0853: int64 = memory.alloc_tensor(%storage_01025, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1038]) /* ty=int64 */;
  %4035 = fn (%p0850: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0850) /* ty=int64 */
  };
  %4036 = (%shape_func_out_0179,);
  %4037 = (%tensor_0853,);
  let %v845: () = vm.invoke_tvm_op(%4035, %4036, %4037) /* ty=() */;
  let %storage_01026: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1039]) /* ty=Storage[] */;
  let %tensor_0854: int64 = memory.alloc_tensor(%storage_01026, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1039]) /* ty=int64 */;
  %4038 = fn (%p0851: int64, Primitive=1) -> int64 {
    multiply(%p0851, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4039 = (%tensor_0853,);
  %4040 = (%tensor_0854,);
  let %v846: () = vm.invoke_tvm_op(%4038, %4039, %4040) /* ty=() */;
  let %storage_01027: Storage[] = memory.alloc_storage(%tensor_0854, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1040]) /* ty=Storage[] */;
  let %out_0172: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01027, 0 /* ty=int64 */, %shape_func_out_0179, meta[relay.attrs.AllocTensorAttrs][1040]) /* ty=Tensor[(?, ?), float32] */;
  %4041 = (%x608, %x619, %x613, meta[relay.Constant][830] /* ty=Tensor[(2), int32] */);
  %4042 = (%out_0172,);
  let %v847: () = vm.invoke_tvm_op(%4032, %4041, %4042) /* ty=() */;
  let %x620: Tensor[(?, ?), float32] = %out_0172;
  let %storage_01028: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1041]) /* ty=Storage[] */;
  let %tensor_0855: Tensor[(4), int32] = memory.alloc_tensor(%storage_01028, 0 /* ty=int64 */, meta[relay.Constant][832] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1041]) /* ty=Tensor[(4), int32] */;
  %4043 = fn (%p0852: Tensor[(?, 1, ?, ?), float32], Primitive=1) -> Tensor[(4), int32] {
    shape_of(%p0852, dtype="int32") /* ty=Tensor[(4), int32] */
  };
  %4044 = (%x606,);
  %4045 = (%tensor_0855,);
  let %v848: () = vm.invoke_tvm_op(%4043, %4044, %4045) /* ty=() */;
  let %x621: Tensor[(4), int32] = %tensor_0855;
  let %storage_01029: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1042]) /* ty=Storage[] */;
  let %tensor_0856: Tensor[(2), int32] = memory.alloc_tensor(%storage_01029, 0 /* ty=int64 */, meta[relay.Constant][833] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1042]) /* ty=Tensor[(2), int32] */;
  %4048 = fn (%p0853: Tensor[(2), bool], %p1367: Tensor[(2), int32], %p2219: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %4046 = cast_like(%p2219, %p1367) /* ty=Tensor[(2), int32] */;
    %4047 = add(%p1367, %4046) /* ty=Tensor[(2), int32] */;
    where(%p0853, %4047, %p1367) /* ty=Tensor[(2), int32] */
  };
  %4049 = (meta[relay.Constant][834] /* ty=Tensor[(2), bool] */, meta[relay.Constant][835] /* ty=Tensor[(2), int32] */, %x611);
  %4050 = (%tensor_0856,);
  let %v849: () = vm.invoke_tvm_op(%4048, %4049, %4050) /* ty=() */;
  let %x622: Tensor[(2), int32] = %tensor_0856;
  let %in_shape_0165: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][234]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1105: Tensor[(2), int32] = device_copy(%x622, meta[relay.attrs.DeviceCopyAttrs][235]) /* ty=Tensor[(2), int32] */;
  let %in_shape_273: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][236]) /* ty=Tensor[(2), int64] */;
  let %in_shape_357: Tensor[(2), int32] = device_copy(meta[relay.Constant][836] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][237]) /* ty=Tensor[(2), int32] */;
  let %storage_01030: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1043]) /* ty=Storage[] */;
  let %tensor_0857: Tensor[(2), int64] = memory.alloc_tensor(%storage_01030, 0 /* ty=int64 */, meta[relay.Constant][837] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1043]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0180: Tensor[(2), int64] = %tensor_0857;
  %4051 = fn (%p0854: Tensor[(?, 4), float32], %p1368: Tensor[(2), int32], %p2220: Tensor[(2), int64], %p3119: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0854, %p1368, %p2220, %p3119, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %4052 = (%in_shape_0165, %in_shape_1105, %in_shape_273, %in_shape_357);
  %4053 = (%shape_func_out_0180,);
  let %shape_func180: () = vm.shape_func(%4051, %4052, %4053, meta[relay.attrs.ShapeFuncAttrs][180]) /* ty=() */;
  let %storage_01031: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1044]) /* ty=Storage[] */;
  let %tensor_0858: int64 = memory.alloc_tensor(%storage_01031, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1044]) /* ty=int64 */;
  %4054 = fn (%p0855: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0855) /* ty=int64 */
  };
  %4055 = (%shape_func_out_0180,);
  %4056 = (%tensor_0858,);
  let %v850: () = vm.invoke_tvm_op(%4054, %4055, %4056) /* ty=() */;
  let %storage_01032: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1045]) /* ty=Storage[] */;
  let %tensor_0859: int64 = memory.alloc_tensor(%storage_01032, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1045]) /* ty=int64 */;
  %4057 = fn (%p0856: int64, Primitive=1) -> int64 {
    multiply(%p0856, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4058 = (%tensor_0858,);
  %4059 = (%tensor_0859,);
  let %v851: () = vm.invoke_tvm_op(%4057, %4058, %4059) /* ty=() */;
  let %storage_01033: Storage[] = memory.alloc_storage(%tensor_0859, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1046]) /* ty=Storage[] */;
  let %out_0173: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01033, 0 /* ty=int64 */, %shape_func_out_0180, meta[relay.attrs.AllocTensorAttrs][1046]) /* ty=Tensor[(?, ?), float32] */;
  %4060 = (%x608, %x622, %x613, meta[relay.Constant][836] /* ty=Tensor[(2), int32] */);
  %4061 = (%out_0173,);
  let %v852: () = vm.invoke_tvm_op(%4051, %4060, %4061) /* ty=() */;
  let %x623: Tensor[(?, ?), float32] = %out_0173;
  let %storage_01034: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1047]) /* ty=Storage[] */;
  let %tensor_0860: Tensor[(2), int32] = memory.alloc_tensor(%storage_01034, 0 /* ty=int64 */, meta[relay.Constant][838] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1047]) /* ty=Tensor[(2), int32] */;
  %4064 = fn (%p0857: Tensor[(2), bool], %p1369: Tensor[(2), int32], %p2221: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %4062 = cast_like(%p2221, %p1369) /* ty=Tensor[(2), int32] */;
    %4063 = add(%p1369, %4062) /* ty=Tensor[(2), int32] */;
    where(%p0857, %4063, %p1369) /* ty=Tensor[(2), int32] */
  };
  %4065 = (meta[relay.Constant][839] /* ty=Tensor[(2), bool] */, meta[relay.Constant][840] /* ty=Tensor[(2), int32] */, %x611);
  %4066 = (%tensor_0860,);
  let %v853: () = vm.invoke_tvm_op(%4064, %4065, %4066) /* ty=() */;
  let %x624: Tensor[(2), int32] = %tensor_0860;
  let %in_shape_0166: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][238]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1106: Tensor[(2), int32] = device_copy(%x624, meta[relay.attrs.DeviceCopyAttrs][239]) /* ty=Tensor[(2), int32] */;
  let %in_shape_274: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][240]) /* ty=Tensor[(2), int64] */;
  let %in_shape_358: Tensor[(2), int32] = device_copy(meta[relay.Constant][841] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][241]) /* ty=Tensor[(2), int32] */;
  let %storage_01035: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1048]) /* ty=Storage[] */;
  let %tensor_0861: Tensor[(2), int64] = memory.alloc_tensor(%storage_01035, 0 /* ty=int64 */, meta[relay.Constant][842] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1048]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0181: Tensor[(2), int64] = %tensor_0861;
  %4067 = fn (%p0858: Tensor[(?, 4), float32], %p1370: Tensor[(2), int32], %p2222: Tensor[(2), int64], %p3120: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0858, %p1370, %p2222, %p3120, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %4068 = (%in_shape_0166, %in_shape_1106, %in_shape_274, %in_shape_358);
  %4069 = (%shape_func_out_0181,);
  let %shape_func181: () = vm.shape_func(%4067, %4068, %4069, meta[relay.attrs.ShapeFuncAttrs][181]) /* ty=() */;
  let %storage_01036: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1049]) /* ty=Storage[] */;
  let %tensor_0862: int64 = memory.alloc_tensor(%storage_01036, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1049]) /* ty=int64 */;
  %4070 = fn (%p0859: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0859) /* ty=int64 */
  };
  %4071 = (%shape_func_out_0181,);
  %4072 = (%tensor_0862,);
  let %v854: () = vm.invoke_tvm_op(%4070, %4071, %4072) /* ty=() */;
  let %storage_01037: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1050]) /* ty=Storage[] */;
  let %tensor_0863: int64 = memory.alloc_tensor(%storage_01037, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1050]) /* ty=int64 */;
  %4073 = fn (%p0860: int64, Primitive=1) -> int64 {
    multiply(%p0860, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4074 = (%tensor_0862,);
  %4075 = (%tensor_0863,);
  let %v855: () = vm.invoke_tvm_op(%4073, %4074, %4075) /* ty=() */;
  let %storage_01038: Storage[] = memory.alloc_storage(%tensor_0863, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1051]) /* ty=Storage[] */;
  let %out_0174: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01038, 0 /* ty=int64 */, %shape_func_out_0181, meta[relay.attrs.AllocTensorAttrs][1051]) /* ty=Tensor[(?, ?), float32] */;
  %4076 = (%x608, %x624, %x613, meta[relay.Constant][841] /* ty=Tensor[(2), int32] */);
  %4077 = (%out_0174,);
  let %v856: () = vm.invoke_tvm_op(%4067, %4076, %4077) /* ty=() */;
  let %x625: Tensor[(?, ?), float32] = %out_0174;
  let %storage_01039: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1052]) /* ty=Storage[] */;
  let %tensor_0864: Tensor[(2), int32] = memory.alloc_tensor(%storage_01039, 0 /* ty=int64 */, meta[relay.Constant][843] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1052]) /* ty=Tensor[(2), int32] */;
  %4080 = fn (%p0861: Tensor[(2), bool], %p1371: Tensor[(2), int32], %p2223: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %4078 = cast_like(%p2223, %p1371) /* ty=Tensor[(2), int32] */;
    %4079 = add(%p1371, %4078) /* ty=Tensor[(2), int32] */;
    where(%p0861, %4079, %p1371) /* ty=Tensor[(2), int32] */
  };
  %4081 = (meta[relay.Constant][844] /* ty=Tensor[(2), bool] */, meta[relay.Constant][845] /* ty=Tensor[(2), int32] */, %x611);
  %4082 = (%tensor_0864,);
  let %v857: () = vm.invoke_tvm_op(%4080, %4081, %4082) /* ty=() */;
  let %x626: Tensor[(2), int32] = %tensor_0864;
  let %in_shape_0167: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][242]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1107: Tensor[(2), int32] = device_copy(%x626, meta[relay.attrs.DeviceCopyAttrs][243]) /* ty=Tensor[(2), int32] */;
  let %in_shape_275: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][244]) /* ty=Tensor[(2), int64] */;
  let %in_shape_359: Tensor[(2), int32] = device_copy(meta[relay.Constant][846] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][245]) /* ty=Tensor[(2), int32] */;
  let %storage_01040: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1053]) /* ty=Storage[] */;
  let %tensor_0865: Tensor[(2), int64] = memory.alloc_tensor(%storage_01040, 0 /* ty=int64 */, meta[relay.Constant][847] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1053]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0182: Tensor[(2), int64] = %tensor_0865;
  %4083 = fn (%p0862: Tensor[(?, 4), float32], %p1372: Tensor[(2), int32], %p2224: Tensor[(2), int64], %p3121: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0862, %p1372, %p2224, %p3121, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %4084 = (%in_shape_0167, %in_shape_1107, %in_shape_275, %in_shape_359);
  %4085 = (%shape_func_out_0182,);
  let %shape_func182: () = vm.shape_func(%4083, %4084, %4085, meta[relay.attrs.ShapeFuncAttrs][182]) /* ty=() */;
  let %storage_01041: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1054]) /* ty=Storage[] */;
  let %tensor_0866: int64 = memory.alloc_tensor(%storage_01041, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1054]) /* ty=int64 */;
  %4086 = fn (%p0863: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0863) /* ty=int64 */
  };
  %4087 = (%shape_func_out_0182,);
  %4088 = (%tensor_0866,);
  let %v858: () = vm.invoke_tvm_op(%4086, %4087, %4088) /* ty=() */;
  let %storage_01042: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1055]) /* ty=Storage[] */;
  let %tensor_0867: int64 = memory.alloc_tensor(%storage_01042, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1055]) /* ty=int64 */;
  %4089 = fn (%p0864: int64, Primitive=1) -> int64 {
    multiply(%p0864, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4090 = (%tensor_0866,);
  %4091 = (%tensor_0867,);
  let %v859: () = vm.invoke_tvm_op(%4089, %4090, %4091) /* ty=() */;
  let %storage_01043: Storage[] = memory.alloc_storage(%tensor_0867, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1056]) /* ty=Storage[] */;
  let %out_0175: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01043, 0 /* ty=int64 */, %shape_func_out_0182, meta[relay.attrs.AllocTensorAttrs][1056]) /* ty=Tensor[(?, ?), float32] */;
  %4092 = (%x608, %x626, %x613, meta[relay.Constant][846] /* ty=Tensor[(2), int32] */);
  %4093 = (%out_0175,);
  let %v860: () = vm.invoke_tvm_op(%4083, %4092, %4093) /* ty=() */;
  let %x627: Tensor[(?, ?), float32] = %out_0175;
  let %storage_01044: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1057]) /* ty=Storage[] */;
  let %tensor_0868: Tensor[(2), int32] = memory.alloc_tensor(%storage_01044, 0 /* ty=int64 */, meta[relay.Constant][848] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1057]) /* ty=Tensor[(2), int32] */;
  %4096 = fn (%p0865: Tensor[(2), bool], %p1373: Tensor[(2), int32], %p2225: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
    %4094 = cast_like(%p2225, %p1373) /* ty=Tensor[(2), int32] */;
    %4095 = add(%p1373, %4094) /* ty=Tensor[(2), int32] */;
    where(%p0865, %4095, %p1373) /* ty=Tensor[(2), int32] */
  };
  %4097 = (meta[relay.Constant][849] /* ty=Tensor[(2), bool] */, meta[relay.Constant][850] /* ty=Tensor[(2), int32] */, %x611);
  %4098 = (%tensor_0868,);
  let %v861: () = vm.invoke_tvm_op(%4096, %4097, %4098) /* ty=() */;
  let %x628: Tensor[(2), int32] = %tensor_0868;
  let %in_shape_0168: Tensor[(?, 4), float32] = device_copy(%x608, meta[relay.attrs.DeviceCopyAttrs][246]) /* ty=Tensor[(?, 4), float32] */;
  let %in_shape_1108: Tensor[(2), int32] = device_copy(%x628, meta[relay.attrs.DeviceCopyAttrs][247]) /* ty=Tensor[(2), int32] */;
  let %in_shape_276: Tensor[(2), int64] = device_copy(%x613, meta[relay.attrs.DeviceCopyAttrs][248]) /* ty=Tensor[(2), int64] */;
  let %in_shape_360: Tensor[(2), int32] = device_copy(meta[relay.Constant][851] /* ty=Tensor[(2), int32] */, meta[relay.attrs.DeviceCopyAttrs][249]) /* ty=Tensor[(2), int32] */;
  let %storage_01045: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1058]) /* ty=Storage[] */;
  let %tensor_0869: Tensor[(2), int64] = memory.alloc_tensor(%storage_01045, 0 /* ty=int64 */, meta[relay.Constant][852] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1058]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0183: Tensor[(2), int64] = %tensor_0869;
  %4099 = fn (%p0866: Tensor[(?, 4), float32], %p1374: Tensor[(2), int32], %p2226: Tensor[(2), int64], %p3122: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
    dyn.strided_slice(%p0866, %p1374, %p2226, %p3122, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
  };
  %4100 = (%in_shape_0168, %in_shape_1108, %in_shape_276, %in_shape_360);
  %4101 = (%shape_func_out_0183,);
  let %shape_func183: () = vm.shape_func(%4099, %4100, %4101, meta[relay.attrs.ShapeFuncAttrs][183]) /* ty=() */;
  let %storage_01046: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1059]) /* ty=Storage[] */;
  let %tensor_0870: int64 = memory.alloc_tensor(%storage_01046, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1059]) /* ty=int64 */;
  %4102 = fn (%p0867: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0867) /* ty=int64 */
  };
  %4103 = (%shape_func_out_0183,);
  %4104 = (%tensor_0870,);
  let %v862: () = vm.invoke_tvm_op(%4102, %4103, %4104) /* ty=() */;
  let %storage_01047: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1060]) /* ty=Storage[] */;
  let %tensor_0871: int64 = memory.alloc_tensor(%storage_01047, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1060]) /* ty=int64 */;
  %4105 = fn (%p0868: int64, Primitive=1) -> int64 {
    multiply(%p0868, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4106 = (%tensor_0870,);
  %4107 = (%tensor_0871,);
  let %v863: () = vm.invoke_tvm_op(%4105, %4106, %4107) /* ty=() */;
  let %storage_01048: Storage[] = memory.alloc_storage(%tensor_0871, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1061]) /* ty=Storage[] */;
  let %out_0176: Tensor[(?, ?), float32] = memory.alloc_tensor(%storage_01048, 0 /* ty=int64 */, %shape_func_out_0183, meta[relay.attrs.AllocTensorAttrs][1061]) /* ty=Tensor[(?, ?), float32] */;
  %4108 = (%x608, %x628, %x613, meta[relay.Constant][851] /* ty=Tensor[(2), int32] */);
  %4109 = (%out_0176,);
  let %v864: () = vm.invoke_tvm_op(%4099, %4108, %4109) /* ty=() */;
  let %x629: Tensor[(?, ?), float32] = %out_0176;
  let %in_shape_0169: Tensor[(2), int64] = vm.shape_of(%x614, meta[relay.attrs.ShapeOfAttrs][174]) /* ty=Tensor[(2), int64] */;
  let %in_shape_1109: Tensor[(2), int64] = vm.shape_of(%x616, meta[relay.attrs.ShapeOfAttrs][175]) /* ty=Tensor[(2), int64] */;
  let %in_shape_277: Tensor[(2), int64] = vm.shape_of(%x618, meta[relay.attrs.ShapeOfAttrs][176]) /* ty=Tensor[(2), int64] */;
  let %in_shape_361: Tensor[(2), int64] = vm.shape_of(%x620, meta[relay.attrs.ShapeOfAttrs][177]) /* ty=Tensor[(2), int64] */;
  let %in_shape_52: Tensor[(2), int64] = vm.shape_of(%x623, meta[relay.attrs.ShapeOfAttrs][178]) /* ty=Tensor[(2), int64] */;
  let %in_shape_61: Tensor[(2), int64] = vm.shape_of(%x625, meta[relay.attrs.ShapeOfAttrs][179]) /* ty=Tensor[(2), int64] */;
  let %in_shape_71: Tensor[(2), int64] = vm.shape_of(%x627, meta[relay.attrs.ShapeOfAttrs][180]) /* ty=Tensor[(2), int64] */;
  let %in_shape_81: Tensor[(2), int64] = vm.shape_of(%x629, meta[relay.attrs.ShapeOfAttrs][181]) /* ty=Tensor[(2), int64] */;
  let %storage_01049: Storage[] = memory.alloc_storage(16 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1062]) /* ty=Storage[] */;
  let %tensor_0872: Tensor[(2), int64] = memory.alloc_tensor(%storage_01049, 0 /* ty=int64 */, meta[relay.Constant][853] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1062]) /* ty=Tensor[(2), int64] */;
  let %shape_func_out_0184: Tensor[(2), int64] = %tensor_0872;
  %4141 = fn (%p0869: Tensor[(?, ?), float32], %p1375: Tensor[(?, ?), float32], %p2227: Tensor[(?, ?), float32], %p3123: Tensor[(?, ?), float32], %p460: Tensor[(4), int32], %p520: Tensor[(?, ?), float32], %p63: Tensor[(?, ?), float32], %p73: Tensor[(?, ?), float32], %p83: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, 4), int64] {
    %4110 = take(%p0869, 2 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4111 = take(%p1375, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4112 = add(%4110, %4111) /* ty=Tensor[(?), float32] */;
    %4113 = multiply(%4112, 0.5f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %4114 = take(%p2227, 2 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4115 = take(%p3123, 0 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4116 = subtract(%4114, %4115) /* ty=Tensor[(?), float32] */;
    %4117 = multiply(%4116, 0.5f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %4118 = take(%p460, 3 /* ty=int32 */, axis=0) /* ty=int32 */;
    %4119 = add(%4118, 2 /* ty=int32 */) /* ty=int32 */;
    %4120 = cast(%4119, dtype="int64") /* ty=int64 */;
    %4121 = cast(%4120, dtype="float32") /* ty=float32 */;
    %4122 = cast(%4118, dtype="int64") /* ty=int64 */;
    %4123 = cast(%4122, dtype="float32") /* ty=float32 */;
    %4124 = divide(%4121, %4123) /* ty=float32 */;
    %4125 = multiply(%4117, %4124) /* ty=Tensor[(?), float32] */;
    %4126 = subtract(%4113, %4125) /* ty=Tensor[(?), float32] */;
    %4127 = take(%p520, 3 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4128 = take(%p63, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4129 = add(%4127, %4128) /* ty=Tensor[(?), float32] */;
    %4130 = multiply(%4129, 0.5f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %4131 = take(%p73, 3 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4132 = take(%p83, 1 /* ty=int32 */, axis=1) /* ty=Tensor[(?), float32] */;
    %4133 = subtract(%4131, %4132) /* ty=Tensor[(?), float32] */;
    %4134 = multiply(%4133, 0.5f /* ty=float32 */) /* ty=Tensor[(?), float32] */;
    %4135 = multiply(%4134, %4124) /* ty=Tensor[(?), float32] */;
    %4136 = subtract(%4130, %4135) /* ty=Tensor[(?), float32] */;
    %4137 = add(%4113, %4125) /* ty=Tensor[(?), float32] */;
    %4138 = add(%4130, %4135) /* ty=Tensor[(?), float32] */;
    %4139 = (%4126, %4136, %4137, %4138);
    %4140 = stack(%4139, axis=1) /* ty=Tensor[(?, 4), float32] */;
    cast(%4140, dtype="int64") /* ty=Tensor[(?, 4), int64] */
  };
  %4142 = (%in_shape_0169, %in_shape_1109, %in_shape_277, %in_shape_361, meta[relay.Constant][854] /* ty=Tensor[(1), int64] */, %in_shape_52, %in_shape_61, %in_shape_71, %in_shape_81);
  %4143 = (%shape_func_out_0184,);
  let %shape_func184: () = vm.shape_func(%4141, %4142, %4143, meta[relay.attrs.ShapeFuncAttrs][184]) /* ty=() */;
  let %storage_01050: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1063]) /* ty=Storage[] */;
  let %tensor_0873: int64 = memory.alloc_tensor(%storage_01050, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1063]) /* ty=int64 */;
  %4144 = fn (%p0870: Tensor[(2), int64], Primitive=1) -> int64 {
    prod(%p0870) /* ty=int64 */
  };
  %4145 = (%shape_func_out_0184,);
  %4146 = (%tensor_0873,);
  let %v865: () = vm.invoke_tvm_op(%4144, %4145, %4146) /* ty=() */;
  let %storage_01051: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1064]) /* ty=Storage[] */;
  let %tensor_0874: int64 = memory.alloc_tensor(%storage_01051, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1064]) /* ty=int64 */;
  %4147 = fn (%p0871: int64, Primitive=1) -> int64 {
    multiply(%p0871, 8 /* ty=int64 */) /* ty=int64 */
  };
  %4148 = (%tensor_0873,);
  %4149 = (%tensor_0874,);
  let %v866: () = vm.invoke_tvm_op(%4147, %4148, %4149) /* ty=() */;
  let %storage_01052: Storage[] = memory.alloc_storage(%tensor_0874, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1065]) /* ty=Storage[] */;
  let %out_0177: Tensor[(?, 4), int64] = memory.alloc_tensor(%storage_01052, 0 /* ty=int64 */, %shape_func_out_0184, meta[relay.attrs.AllocTensorAttrs][1065]) /* ty=Tensor[(?, 4), int64] */;
  %4150 = (%x614, %x616, %x618, %x620, %x621, %x623, %x625, %x627, %x629);
  %4151 = (%out_0177,);
  let %v867: () = vm.invoke_tvm_op(%4141, %4150, %4151) /* ty=() */;
  let %x630: Tensor[(?, 4), int64] = %out_0177;
  let %x631: fn (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) -> (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) = let %while_loop: fn (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) -> (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) = @lifted_name2452113581219567712(%x607, meta[relay.Constant][400] /* ty=Tensor[(1), int32] */) /* ty=fn (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) -> (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) */;
  %while_loop;
  let %x632: (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) = %x631(0 /* ty=int32 */, %x610, %x630, %x607) /* ty=(int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) */;
  let %x633: Tensor[(?, ?, ?), float32] = %x632.1;
  let %storage_01053: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1066]) /* ty=Storage[] */;
  let %tensor_0875: Tensor[(3), int32] = memory.alloc_tensor(%storage_01053, 0 /* ty=int64 */, meta[relay.Constant][855] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1066]) /* ty=Tensor[(3), int32] */;
  %4152 = fn (%p0872: Tensor[(?, ?, ?), float32], Primitive=1) -> Tensor[(3), int32] {
    shape_of(%p0872, dtype="int32") /* ty=Tensor[(3), int32] */
  };
  %4153 = (%x633,);
  %4154 = (%tensor_0875,);
  let %v868: () = vm.invoke_tvm_op(%4152, %4153, %4154) /* ty=() */;
  let %x634: Tensor[(3), int32] = %tensor_0875;
  let %storage_01054: Storage[] = memory.alloc_storage(12 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1067]) /* ty=Storage[] */;
  let %tensor_0876: Tensor[(3), int32] = memory.alloc_tensor(%storage_01054, 0 /* ty=int64 */, meta[relay.Constant][856] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1067]) /* ty=Tensor[(3), int32] */;
  %4157 = fn (%p0873: Tensor[(3), bool], %p1376: Tensor[(3), int32], %p2228: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int32] {
    %4155 = cast_like(%p2228, %p1376) /* ty=Tensor[(3), int32] */;
    %4156 = add(%p1376, %4155) /* ty=Tensor[(3), int32] */;
    where(%p0873, %4156, %p1376) /* ty=Tensor[(3), int32] */
  };
  %4158 = (meta[relay.Constant][857] /* ty=Tensor[(3), bool] */, meta[relay.Constant][858] /* ty=Tensor[(3), int32] */, %x634);
  %4159 = (%tensor_0876,);
  let %v869: () = vm.invoke_tvm_op(%4157, %4158, %4159) /* ty=() */;
  let %x635: Tensor[(3), int32] = %tensor_0876;
  let %storage_01055: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1068]) /* ty=Storage[] */;
  let %tensor_0877: Tensor[(3), int64] = memory.alloc_tensor(%storage_01055, 0 /* ty=int64 */, meta[relay.Constant][859] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1068]) /* ty=Tensor[(3), int64] */;
  %4160 = fn (%p0874: Tensor[(3), int32], Primitive=1) -> Tensor[(3), int64] {
    cast(%p0874, dtype="int64") /* ty=Tensor[(3), int64] */
  };
  %4161 = (%x634,);
  %4162 = (%tensor_0877,);
  let %v870: () = vm.invoke_tvm_op(%4160, %4161, %4162) /* ty=() */;
  let %x636: Tensor[(3), int64] = %tensor_0877;
  let %in_shape_0170: Tensor[(?, ?, ?), float32] = device_copy(%x633, meta[relay.attrs.DeviceCopyAttrs][250]) /* ty=Tensor[(?, ?, ?), float32] */;
  let %in_shape_1110: Tensor[(3), int32] = device_copy(%x635, meta[relay.attrs.DeviceCopyAttrs][251]) /* ty=Tensor[(3), int32] */;
  let %in_shape_278: Tensor[(3), int64] = device_copy(%x636, meta[relay.attrs.DeviceCopyAttrs][252]) /* ty=Tensor[(3), int64] */;
  let %in_shape_362: Tensor[(3), int32] = device_copy(meta[relay.Constant][860] /* ty=Tensor[(3), int32] */, meta[relay.attrs.DeviceCopyAttrs][253]) /* ty=Tensor[(3), int32] */;
  let %storage_01056: Storage[] = memory.alloc_storage(24 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1069]) /* ty=Storage[] */;
  let %tensor_0878: Tensor[(3), int64] = memory.alloc_tensor(%storage_01056, 0 /* ty=int64 */, meta[relay.Constant][861] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1069]) /* ty=Tensor[(3), int64] */;
  let %shape_func_out_0185: Tensor[(3), int64] = %tensor_0878;
  %4163 = fn (%p0875: Tensor[(?, ?, ?), float32], %p1377: Tensor[(3), int32], %p2229: Tensor[(3), int64], %p3124: Tensor[(3), int32], Primitive=1) -> Tensor[(?, ?, ?), float32] {
    dyn.strided_slice(%p0875, %p1377, %p2229, %p3124, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?, ?), float32] */
  };
  %4164 = (%in_shape_0170, %in_shape_1110, %in_shape_278, %in_shape_362);
  %4165 = (%shape_func_out_0185,);
  let %shape_func185: () = vm.shape_func(%4163, %4164, %4165, meta[relay.attrs.ShapeFuncAttrs][185]) /* ty=() */;
  let %storage_01057: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1070]) /* ty=Storage[] */;
  let %tensor_0879: int64 = memory.alloc_tensor(%storage_01057, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1070]) /* ty=int64 */;
  %4166 = fn (%p0876: Tensor[(3), int64], Primitive=1) -> int64 {
    prod(%p0876) /* ty=int64 */
  };
  %4167 = (%shape_func_out_0185,);
  %4168 = (%tensor_0879,);
  let %v871: () = vm.invoke_tvm_op(%4166, %4167, %4168) /* ty=() */;
  let %storage_01058: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1071]) /* ty=Storage[] */;
  let %tensor_0880: int64 = memory.alloc_tensor(%storage_01058, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1071]) /* ty=int64 */;
  %4169 = fn (%p0877: int64, Primitive=1) -> int64 {
    multiply(%p0877, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4170 = (%tensor_0879,);
  %4171 = (%tensor_0880,);
  let %v872: () = vm.invoke_tvm_op(%4169, %4170, %4171) /* ty=() */;
  let %storage_01059: Storage[] = memory.alloc_storage(%tensor_0880, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1072]) /* ty=Storage[] */;
  let %out_0178: Tensor[(?, ?, ?), float32] = memory.alloc_tensor(%storage_01059, 0 /* ty=int64 */, %shape_func_out_0185, meta[relay.attrs.AllocTensorAttrs][1072]) /* ty=Tensor[(?, ?, ?), float32] */;
  %4172 = (%x633, %x635, %x636, meta[relay.Constant][860] /* ty=Tensor[(3), int32] */);
  %4173 = (%out_0178,);
  let %v873: () = vm.invoke_tvm_op(%4163, %4172, %4173) /* ty=() */;
  let %x637: Tensor[(?, ?, ?), float32] = %out_0178;
  let %in_shape_0171: Tensor[(3), int64] = vm.shape_of(%x637, meta[relay.attrs.ShapeOfAttrs][182]) /* ty=Tensor[(3), int64] */;
  let %storage_01060: Storage[] = memory.alloc_storage(32 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1073]) /* ty=Storage[] */;
  let %tensor_0881: Tensor[(4), int64] = memory.alloc_tensor(%storage_01060, 0 /* ty=int64 */, meta[relay.Constant][862] /* ty=Tensor[(1), int64] */, meta[relay.attrs.AllocTensorAttrs][1073]) /* ty=Tensor[(4), int64] */;
  let %shape_func_out_0186: Tensor[(4), int64] = %tensor_0881;
  %4174 = fn (%p0878: Tensor[(?, ?, ?), float32], Primitive=1) -> Tensor[(?, 1, ?, ?), float32] {
    expand_dims(%p0878, axis=1) /* ty=Tensor[(?, 1, ?, ?), float32] */
  };
  %4175 = (%in_shape_0171,);
  %4176 = (%shape_func_out_0186,);
  let %shape_func186: () = vm.shape_func(%4174, %4175, %4176, meta[relay.attrs.ShapeFuncAttrs][186]) /* ty=() */;
  let %storage_01061: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1074]) /* ty=Storage[] */;
  let %tensor_0882: int64 = memory.alloc_tensor(%storage_01061, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1074]) /* ty=int64 */;
  %4177 = fn (%p0879: Tensor[(4), int64], Primitive=1) -> int64 {
    prod(%p0879) /* ty=int64 */
  };
  %4178 = (%shape_func_out_0186,);
  %4179 = (%tensor_0882,);
  let %v874: () = vm.invoke_tvm_op(%4177, %4178, %4179) /* ty=() */;
  let %storage_01062: Storage[] = memory.alloc_storage(8 /* ty=int64 */, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1075]) /* ty=Storage[] */;
  let %tensor_0883: int64 = memory.alloc_tensor(%storage_01062, 0 /* ty=int64 */, 0 /* ty=int64 */, meta[relay.attrs.AllocTensorAttrs][1075]) /* ty=int64 */;
  %4180 = fn (%p0880: int64, Primitive=1) -> int64 {
    multiply(%p0880, 4 /* ty=int64 */) /* ty=int64 */
  };
  %4181 = (%tensor_0882,);
  %4182 = (%tensor_0883,);
  let %v875: () = vm.invoke_tvm_op(%4180, %4181, %4182) /* ty=() */;
  let %storage_01063: Storage[] = memory.alloc_storage(%tensor_0883, 64 /* ty=int64 */, meta[relay.attrs.AllocStorageAttrs][1076]) /* ty=Storage[] */;
  let %out_0179: Tensor[(?, 1, ?, ?), float32] = memory.alloc_tensor(%storage_01063, 0 /* ty=int64 */, %shape_func_out_0186, meta[relay.attrs.AllocTensorAttrs][1076]) /* ty=Tensor[(?, 1, ?, ?), float32] */;
  %4183 = (%x637,);
  %4184 = (%out_0179,);
  let %v876: () = vm.invoke_tvm_op(%4174, %4183, %4184) /* ty=() */;
  let %x638: Tensor[(?, 1, ?, ?), float32] = %out_0179;
  let %x639: (Tensor[(?, 4), float32], Tensor[(?), float32], Tensor[(?), int64], Tensor[(?, 1, ?, ?), float32]) = (%x608, %x609, %x600, %x638);
  %x639;
  %x520;
  %x518;
  %x
}
#[version = "0.0.5"]
fn (%x: Tensor[(?, 1, ?, ?), float32], %x1: Tensor[(1), int32], Closure=1) -> fn (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) -> (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) {
  fn (%i.1: int32, %res_append.6: Tensor[(?, ?, ?), float32], %v7394: Tensor[(?, 4), int64], %v7286: Tensor[(?, 1, ?, ?), float32]) -> (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) {
    let %x2: fn (Tensor[(?, 1, ?, ?), float32]) -> Tensor[(4), int32] = fn (%p0: Tensor[(?, 1, ?, ?), float32], Primitive=1) -> Tensor[(4), int32] {
      shape_of(%p0, dtype="int32") /* ty=Tensor[(4), int32] */
    };
    let %x3: Tensor[(4), int32] = %x2(%x);
    let %x4: fn (int32, Tensor[(4), int32]) -> bool = fn (%p01: int32, %p1: Tensor[(4), int32], Primitive=1) -> bool {
      %0 = take(%p1, 0 /* ty=int32 */, axis=0) /* ty=int32 */;
      less(%p01, %0) /* ty=bool */
    };
    let %x5: bool = %x4(%i.1, %x3) /* ty=bool */;
    let %x6: (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) = if (%x5) {
      let %x7: fn (int32) -> int32 = fn (%p02: int32, Primitive=1) -> int32 {
        add(%p02, 1 /* ty=int32 */) /* ty=int32 */
      };
      let %x8: int32 = %x7(%i.1) /* ty=int32 */;
      let %x9: int32 = 0 /* ty=int32 */;
      let %x10: int32 = 0 /* ty=int32 */;
      let %x11: fn (Tensor[(?, 4), int64], int32) -> Tensor[(4), int64] = fn (%p03: Tensor[(?, 4), int64], %p11: int32, Primitive=1) -> Tensor[(4), int64] {
        take(%p03, %p11, axis=0) /* ty=Tensor[(4), int64] */
      };
      let %x12: Tensor[(4), int64] = %x11(%v7394, %i.1) /* ty=Tensor[(4), int64] */;
      let %x13: fn (Tensor[(4), int64]) -> int64 = fn (%p04: Tensor[(4), int64], Primitive=1) -> int64 {
        take(%p04, 1 /* ty=int32 */, axis=0) /* ty=int64 */
      };
      let %x14: int64 = %x13(%x12) /* ty=int64 */;
      let %x15: fn () -> Tensor[(1), int64] = fn (Primitive=1) -> Tensor[(1), int64] {
        full(0 /* ty=int32 */, shape=[1], dtype="int64") /* ty=Tensor[(1), int64] */
      };
      let %x16: Tensor[(1), int64] = %x15() /* ty=Tensor[(1), int64] */;
      let %x17: fn (int64, Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p05: int64, %p12: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %1 = expand_dims(%p05, axis=0) /* ty=Tensor[(1), int64] */;
        %2 = (%1, %p12);
        concatenate(%2) /* ty=Tensor[(2), int64] */
      };
      let %x18: Tensor[(2), int64] = %x17(%x14, %x16) /* ty=Tensor[(2), int64] */;
      let %x19: fn (Tensor[(2), int64]) -> int64 = fn (%p06: Tensor[(2), int64], Primitive=1) -> int64 {
        max(%p06) /* ty=int64 */
      };
      let %x20: int64 = %x19(%x18) /* ty=int64 */;
      let %x21: fn (Tensor[(?, 1, ?, ?), float32], int32) -> Tensor[(1, ?, ?), float32] = fn (%p07: Tensor[(?, 1, ?, ?), float32], %p13: int32, Primitive=1) -> Tensor[(1, ?, ?), float32] {
        take(%p07, %p13, axis=0) /* ty=Tensor[(1, ?, ?), float32] */
      };
      let %x22: Tensor[(1, ?, ?), float32] = %x21(%v7286, %i.1) /* ty=Tensor[(1, ?, ?), float32] */;
      let %x23: fn (Tensor[(1, ?, ?), float32]) -> Tensor[(1, 1, ?, ?), float32] = fn (%p08: Tensor[(1, ?, ?), float32], Primitive=1) -> Tensor[(1, 1, ?, ?), float32] {
        %3 = take(%p08, 0 /* ty=int32 */, axis=0) /* ty=Tensor[(?, ?), float32] */;
        %4 = expand_dims(%3, axis=0, num_newaxis=2) /* ty=Tensor[(1, 1, ?, ?), float32] */;
        %5 = repeat(%4, repeats=1, axis=0) /* ty=Tensor[(1, 1, ?, ?), float32] */;
        repeat(%5, repeats=1, axis=1) /* ty=Tensor[(1, 1, ?, ?), float32] */
      };
      let %x24: Tensor[(1, 1, ?, ?), float32] = %x23(%x22) /* ty=Tensor[(1, 1, ?, ?), float32] */;
      let %x25: fn (Tensor[(4), int64]) -> int64 = fn (%p09: Tensor[(4), int64], Primitive=1) -> int64 {
        take(%p09, 3 /* ty=int32 */, axis=0) /* ty=int64 */
      };
      let %x26: int64 = %x25(%x12) /* ty=int64 */;
      let %x27: fn () -> Tensor[(1), int64] = fn (Primitive=1) -> Tensor[(1), int64] {
        full(1 /* ty=int32 */, shape=[1], dtype="int64") /* ty=Tensor[(1), int64] */
      };
      let %x28: Tensor[(1), int64] = %x27() /* ty=Tensor[(1), int64] */;
      let %x29: fn (int64, int64, Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p010: int64, %p14: int64, %p2: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %6 = subtract(%p010, %p14) /* ty=int64 */;
        %7 = add(%6, %p2) /* ty=Tensor[(1), int64] */;
        %8 = (%7, %p2);
        concatenate(%8) /* ty=Tensor[(2), int64] */
      };
      let %x30: Tensor[(2), int64] = %x29(%x26, %x14, %x28) /* ty=Tensor[(2), int64] */;
      let %x31: fn (Tensor[(2), int64]) -> int64 = fn (%p011: Tensor[(2), int64], Primitive=1) -> int64 {
        max(%p011) /* ty=int64 */
      };
      let %x32: int64 = %x31(%x30) /* ty=int64 */;
      let %x33: fn (Tensor[(4), int64]) -> int64 = fn (%p012: Tensor[(4), int64], Primitive=1) -> int64 {
        take(%p012, 2 /* ty=int32 */, axis=0) /* ty=int64 */
      };
      let %x34: int64 = %x33(%x12) /* ty=int64 */;
      let %x35: fn (Tensor[(4), int64]) -> int64 = fn (%p013: Tensor[(4), int64], Primitive=1) -> int64 {
        take(%p013, 0 /* ty=int32 */, axis=0) /* ty=int64 */
      };
      let %x36: int64 = %x35(%x12) /* ty=int64 */;
      let %x37: fn (int64, int64, Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p014: int64, %p15: int64, %p21: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %9 = subtract(%p014, %p15) /* ty=int64 */;
        %10 = add(%9, %p21) /* ty=Tensor[(1), int64] */;
        %11 = (%10, %p21);
        concatenate(%11) /* ty=Tensor[(2), int64] */
      };
      let %x38: Tensor[(2), int64] = %x37(%x34, %x36, %x28) /* ty=Tensor[(2), int64] */;
      let %x39: fn (Tensor[(2), int64]) -> int64 = fn (%p015: Tensor[(2), int64], Primitive=1) -> int64 {
        max(%p015) /* ty=int64 */
      };
      let %x40: int64 = %x39(%x38) /* ty=int64 */;
      let %x41: fn (int64, int64) -> Tensor[(2), int64] = fn (%p016: int64, %p16: int64, Primitive=1) -> Tensor[(2), int64] {
        %12 = expand_dims(%p016, axis=0) /* ty=Tensor[(1), int64] */;
        %13 = expand_dims(%p16, axis=0) /* ty=Tensor[(1), int64] */;
        %14 = (%12, %13);
        concatenate(%14) /* ty=Tensor[(2), int64] */
      };
      let %x42: Tensor[(2), int64] = %x41(%x32, %x40) /* ty=Tensor[(2), int64] */;
      let %x43: fn (Tensor[(1, 1, ?, ?), float32], Tensor[(2), int64]) -> Tensor[(1, 1, ?, ?), float32] = fn (%p017: Tensor[(1, 1, ?, ?), float32], %p17: Tensor[(2), int64], Primitive=1) -> Tensor[(1, 1, ?, ?), float32] {
        dyn.image.resize(%p017, %p17, size=[]) /* ty=Tensor[(1, 1, ?, ?), float32] */
      };
      let %x44: Tensor[(1, 1, ?, ?), float32] = %x43(%x24, %x42) /* ty=Tensor[(1, 1, ?, ?), float32] */;
      let %x45: fn (Tensor[(1, 1, ?, ?), float32]) -> Tensor[(1, ?, ?), float32] = fn (%p018: Tensor[(1, 1, ?, ?), float32], Primitive=1) -> Tensor[(1, ?, ?), float32] {
        take(%p018, 0 /* ty=int32 */, axis=0) /* ty=Tensor[(1, ?, ?), float32] */
      };
      let %x46: Tensor[(1, ?, ?), float32] = %x45(%x44) /* ty=Tensor[(1, ?, ?), float32] */;
      let %x47: fn (Tensor[(1, ?, ?), float32]) -> Tensor[(?, ?), float32] = fn (%p019: Tensor[(1, ?, ?), float32], Primitive=1) -> Tensor[(?, ?), float32] {
        take(%p019, 0 /* ty=int32 */, axis=0) /* ty=Tensor[(?, ?), float32] */
      };
      let %x48: Tensor[(?, ?), float32] = %x47(%x46) /* ty=Tensor[(?, ?), float32] */;
      let %x49: Tensor[(1), int64] = meta[relay.Constant][0] /* ty=Tensor[(1), int64] */;
      let %x50: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p020: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p020, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x51: Tensor[(2), int32] = %x50(%x48) /* ty=Tensor[(2), int32] */;
      let %x52: fn (int64, int64, Tensor[(1), int64], Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p021: int64, %p18: int64, %p22: Tensor[(1), int64], %p3: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        %15 = subtract(%p021, %p18) /* ty=int64 */;
        %16 = expand_dims(%15, axis=0) /* ty=Tensor[(1), int64] */;
        %17 = cast(%16, dtype="int64") /* ty=Tensor[(1), int64] */;
        %18 = (%17, %p22);
        %19 = concatenate(%18) /* ty=Tensor[(2), int64] */;
        %20 = cast_like(0 /* ty=int32 */, %19) /* ty=int64 */;
        %21 = less(%19, %20) /* ty=Tensor[(2), bool] */;
        %22 = cast_like(%p3, %19) /* ty=Tensor[(2), int64] */;
        %23 = add(%19, %22) /* ty=Tensor[(2), int64] */;
        where(%21, %23, %19) /* ty=Tensor[(2), int64] */
      };
      let %x53: Tensor[(2), int64] = %x52(%x20, %x14, %x49, %x51) /* ty=Tensor[(2), int64] */;
      let %x54: fn (Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p022: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        cast(%p022, dtype="int64") /* ty=Tensor[(2), int64] */
      };
      let %x55: Tensor[(2), int64] = %x54(%x51) /* ty=Tensor[(2), int64] */;
      let %x56: Tensor[(1), int32] = meta[relay.Constant][1] /* ty=Tensor[(1), int32] */;
      let %x57: Tensor[(1), int64] = meta[relay.Constant][2] /* ty=Tensor[(1), int64] */;
      let %x58: fn (int64, Tensor[(1), int64], Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p023: int64, %p19: Tensor[(1), int64], %p23: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %24 = expand_dims(%p023, axis=0) /* ty=Tensor[(1), int64] */;
        %25 = add(%24, %p19) /* ty=Tensor[(1), int64] */;
        %26 = (%25, %p23);
        concatenate(%26) /* ty=Tensor[(2), int64] */
      };
      let %x59: Tensor[(2), int64] = %x58(%x26, %x28, %x57) /* ty=Tensor[(2), int64] */;
      let %x60: fn (Tensor[(2), int64]) -> int64 = fn (%p024: Tensor[(2), int64], Primitive=1) -> int64 {
        min(%p024) /* ty=int64 */
      };
      let %x61: int64 = %x60(%x59) /* ty=int64 */;
      let %x62: fn (int64, int64) -> Tensor[(1), int64] = fn (%p025: int64, %p110: int64, Primitive=1) -> Tensor[(1), int64] {
        %27 = subtract(%p025, %p110) /* ty=int64 */;
        expand_dims(%27, axis=0) /* ty=Tensor[(1), int64] */
      };
      let %x63: Tensor[(1), int64] = %x62(%x61, %x14) /* ty=Tensor[(1), int64] */;
      let %x64: fn (Tensor[(2), int64], Tensor[(1), int32], Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p026: Tensor[(2), int64], %p111: Tensor[(1), int32], %p24: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        scatter(%p026, %p111, %p24, meta[relay.attrs.ScatterAttrs][0]) /* ty=Tensor[(2), int64] */
      };
      let %x65: Tensor[(2), int64] = %x64(%x55, %x56, %x63) /* ty=Tensor[(2), int64] */;
      let %x66: Tensor[(2), int32] = meta[relay.Constant][3] /* ty=Tensor[(2), int32] */;
      let %x67: fn (Tensor[(?, ?), float32], Tensor[(2), int64], Tensor[(2), int64], Tensor[(2), int32]) -> Tensor[(?, ?), float32] = fn (%p027: Tensor[(?, ?), float32], %p112: Tensor[(2), int64], %p25: Tensor[(2), int64], %p31: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.strided_slice(%p027, %p112, %p25, %p31, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
      };
      let %x68: Tensor[(?, ?), float32] = %x67(%x48, %x53, %x65, %x66) /* ty=Tensor[(?, ?), float32] */;
      let %x69: fn (int64, Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p028: int64, %p113: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %28 = expand_dims(%p028, axis=0) /* ty=Tensor[(1), int64] */;
        %29 = (%28, %p113);
        concatenate(%29) /* ty=Tensor[(2), int64] */
      };
      let %x70: Tensor[(2), int64] = %x69(%x36, %x16) /* ty=Tensor[(2), int64] */;
      let %x71: fn (Tensor[(2), int64]) -> int64 = fn (%p029: Tensor[(2), int64], Primitive=1) -> int64 {
        max(%p029) /* ty=int64 */
      };
      let %x72: int64 = %x71(%x70) /* ty=int64 */;
      let %x73: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p030: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p030, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x74: Tensor[(2), int32] = %x73(%x68) /* ty=Tensor[(2), int32] */;
      let %x75: fn (Tensor[(1), int64], int64, int64, Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p031: Tensor[(1), int64], %p114: int64, %p26: int64, %p32: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        %30 = subtract(%p114, %p26) /* ty=int64 */;
        %31 = expand_dims(%30, axis=0) /* ty=Tensor[(1), int64] */;
        %32 = cast(%31, dtype="int64") /* ty=Tensor[(1), int64] */;
        %33 = (%p031, %32);
        %34 = concatenate(%33) /* ty=Tensor[(2), int64] */;
        %35 = cast_like(0 /* ty=int32 */, %34) /* ty=int64 */;
        %36 = less(%34, %35) /* ty=Tensor[(2), bool] */;
        %37 = cast_like(%p32, %34) /* ty=Tensor[(2), int64] */;
        %38 = add(%34, %37) /* ty=Tensor[(2), int64] */;
        where(%36, %38, %34) /* ty=Tensor[(2), int64] */
      };
      let %x76: Tensor[(2), int64] = %x75(%x49, %x72, %x36, %x74) /* ty=Tensor[(2), int64] */;
      let %x77: fn (Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p032: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        cast(%p032, dtype="int64") /* ty=Tensor[(2), int64] */
      };
      let %x78: Tensor[(2), int64] = %x77(%x74) /* ty=Tensor[(2), int64] */;
      let %x79: fn (int64, Tensor[(1), int64], Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p033: int64, %p115: Tensor[(1), int64], %p27: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %39 = expand_dims(%p033, axis=0) /* ty=Tensor[(1), int64] */;
        %40 = add(%39, %p115) /* ty=Tensor[(1), int64] */;
        %41 = (%40, %p27);
        concatenate(%41) /* ty=Tensor[(2), int64] */
      };
      let %x80: Tensor[(2), int64] = %x79(%x34, %x28, %x57) /* ty=Tensor[(2), int64] */;
      let %x81: fn (Tensor[(2), int64]) -> int64 = fn (%p034: Tensor[(2), int64], Primitive=1) -> int64 {
        min(%p034) /* ty=int64 */
      };
      let %x82: int64 = %x81(%x80) /* ty=int64 */;
      let %x83: fn (int64, int64) -> Tensor[(1), int64] = fn (%p035: int64, %p116: int64, Primitive=1) -> Tensor[(1), int64] {
        %42 = subtract(%p035, %p116) /* ty=int64 */;
        expand_dims(%42, axis=0) /* ty=Tensor[(1), int64] */
      };
      let %x84: Tensor[(1), int64] = %x83(%x82, %x36) /* ty=Tensor[(1), int64] */;
      let %x85: fn (Tensor[(2), int64], Tensor[(1), int32], Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p036: Tensor[(2), int64], %p117: Tensor[(1), int32], %p28: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        scatter(%p036, %p117, %p28, meta[relay.attrs.ScatterAttrs][1]) /* ty=Tensor[(2), int64] */
      };
      let %x86: Tensor[(2), int64] = %x85(%x78, %x1, %x84);
      let %x87: Tensor[(2), int32] = meta[relay.Constant][4] /* ty=Tensor[(2), int32] */;
      let %x88: fn (Tensor[(?, ?), float32], Tensor[(2), int64], Tensor[(2), int64], Tensor[(2), int32]) -> Tensor[(?, ?), float32] = fn (%p037: Tensor[(?, ?), float32], %p118: Tensor[(2), int64], %p29: Tensor[(2), int64], %p33: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.strided_slice(%p037, %p118, %p29, %p33, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
      };
      let %x89: Tensor[(?, ?), float32] = %x88(%x68, %x76, %x86, %x87) /* ty=Tensor[(?, ?), float32] */;
      let %x90: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p038: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p038, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x91: Tensor[(2), int32] = %x90(%x89) /* ty=Tensor[(2), int32] */;
      let %x92: fn (Tensor[(2), int32]) -> Tensor[(1), int64] = fn (%p039: Tensor[(2), int32], Primitive=1) -> Tensor[(1), int64] {
        %43 = take(%p039, 1 /* ty=int32 */, axis=0) /* ty=int32 */;
        %44 = expand_dims(%43, axis=0) /* ty=Tensor[(1), int32] */;
        cast(%44, dtype="int64") /* ty=Tensor[(1), int64] */
      };
      let %x93: Tensor[(1), int64] = %x92(%x91) /* ty=Tensor[(1), int64] */;
      let %x94: fn (int64, Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p040: int64, %p119: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %45 = expand_dims(%p040, axis=0) /* ty=Tensor[(1), int64] */;
        %46 = cast(%45, dtype="int64") /* ty=Tensor[(1), int64] */;
        %47 = (%46, %p119);
        concatenate(%47) /* ty=Tensor[(2), int64] */
      };
      let %x95: Tensor[(2), int64] = %x94(%x20, %x93) /* ty=Tensor[(2), int64] */;
      let %x96: fn (int32, Tensor[(2), int64]) -> Tensor[(?, ?), float32] = fn (%p041: int32, %p120: Tensor[(2), int64], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.full(%p041, %p120, shape=None, dtype="float32") /* ty=Tensor[(?, ?), float32] */
      };
      let %x97: Tensor[(?, ?), float32] = %x96(%x10, %x95) /* ty=Tensor[(?, ?), float32] */;
      let %x98: int32 = 0 /* ty=int32 */;
      let %x99: fn (int64, Tensor[(1), int64]) -> Tensor[(2), int64] = fn (%p042: int64, %p121: Tensor[(1), int64], Primitive=1) -> Tensor[(2), int64] {
        %48 = subtract(300 /* ty=int64 */, %p042) /* ty=int64 */;
        %49 = expand_dims(%48, axis=0) /* ty=Tensor[(1), int64] */;
        %50 = cast(%49, dtype="int64") /* ty=Tensor[(1), int64] */;
        %51 = (%50, %p121);
        concatenate(%51) /* ty=Tensor[(2), int64] */
      };
      let %x100: Tensor[(2), int64] = %x99(%x61, %x93) /* ty=Tensor[(2), int64] */;
      let %x101: fn (int32, Tensor[(2), int64]) -> Tensor[(?, ?), float32] = fn (%p043: int32, %p122: Tensor[(2), int64], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.full(%p043, %p122, shape=None, dtype="float32") /* ty=Tensor[(?, ?), float32] */
      };
      let %x102: Tensor[(?, ?), float32] = %x101(%x98, %x100) /* ty=Tensor[(?, ?), float32] */;
      let %x103: fn (Tensor[(?, ?), float32], Tensor[(?, ?), float32], Tensor[(?, ?), float32]) -> Tensor[(?, ?), float32] = fn (%p044: Tensor[(?, ?), float32], %p123: Tensor[(?, ?), float32], %p210: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, ?), float32] {
        %52 = reshape(%p044, newshape=[0, 0]) /* ty=Tensor[(?, ?), float32] */;
        %53 = reshape(%p210, newshape=[0, 0]) /* ty=Tensor[(?, ?), float32] */;
        %54 = (%52, %p123, %53);
        concatenate(%54) /* ty=Tensor[(?, ?), float32] */
      };
      let %x104: Tensor[(?, ?), float32] = %x103(%x97, %x89, %x102) /* ty=Tensor[(?, ?), float32] */;
      let %x105: Tensor[(2), bool] = meta[relay.Constant][5] /* ty=Tensor[(2), bool] */;
      let %x106: Tensor[(2), int32] = meta[relay.Constant][6] /* ty=Tensor[(2), int32] */;
      let %x107: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p045: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p045, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x108: Tensor[(2), int32] = %x107(%x104) /* ty=Tensor[(2), int32] */;
      let %x109: fn (Tensor[(2), bool], Tensor[(2), int32], Tensor[(2), int32]) -> Tensor[(2), int32] = fn (%p046: Tensor[(2), bool], %p124: Tensor[(2), int32], %p211: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
        %55 = cast_like(%p211, %p124) /* ty=Tensor[(2), int32] */;
        %56 = add(%p124, %55) /* ty=Tensor[(2), int32] */;
        where(%p046, %56, %p124) /* ty=Tensor[(2), int32] */
      };
      let %x110: Tensor[(2), int32] = %x109(%x105, %x106, %x108) /* ty=Tensor[(2), int32] */;
      let %x111: Tensor[(1), int32] = meta[relay.Constant][7] /* ty=Tensor[(1), int32] */;
      let %x112: fn (Tensor[(2), int32], Tensor[(1), int32], Tensor[(1), int32]) -> Tensor[(2), int32] = fn (%p047: Tensor[(2), int32], %p125: Tensor[(1), int32], %p212: Tensor[(1), int32], Primitive=1) -> Tensor[(2), int32] {
        scatter(%p047, %p125, %p212, meta[relay.attrs.ScatterAttrs][2]) /* ty=Tensor[(2), int32] */
      };
      let %x113: Tensor[(2), int32] = %x112(%x108, %x56, %x111) /* ty=Tensor[(2), int32] */;
      let %x114: fn (Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p048: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        cast(%p048, dtype="int64") /* ty=Tensor[(2), int64] */
      };
      let %x115: Tensor[(2), int64] = %x114(%x113) /* ty=Tensor[(2), int64] */;
      let %x116: Tensor[(2), int32] = meta[relay.Constant][8] /* ty=Tensor[(2), int32] */;
      let %x117: fn (Tensor[(?, ?), float32], Tensor[(2), int32], Tensor[(2), int64], Tensor[(2), int32]) -> Tensor[(?, ?), float32] = fn (%p049: Tensor[(?, ?), float32], %p126: Tensor[(2), int32], %p213: Tensor[(2), int64], %p34: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.strided_slice(%p049, %p126, %p213, %p34, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
      };
      let %x118: Tensor[(?, ?), float32] = %x117(%x104, %x110, %x115, %x116) /* ty=Tensor[(?, ?), float32] */;
      let %x119: Tensor[(2), bool] = meta[relay.Constant][9] /* ty=Tensor[(2), bool] */;
      let %x120: Tensor[(2), int32] = meta[relay.Constant][10] /* ty=Tensor[(2), int32] */;
      let %x121: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p050: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p050, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x122: Tensor[(2), int32] = %x121(%x118) /* ty=Tensor[(2), int32] */;
      let %x123: fn (Tensor[(2), bool], Tensor[(2), int32], Tensor[(2), int32]) -> Tensor[(2), int32] = fn (%p051: Tensor[(2), bool], %p127: Tensor[(2), int32], %p214: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
        %57 = cast_like(%p214, %p127) /* ty=Tensor[(2), int32] */;
        %58 = add(%p127, %57) /* ty=Tensor[(2), int32] */;
        where(%p051, %58, %p127) /* ty=Tensor[(2), int32] */
      };
      let %x124: Tensor[(2), int32] = %x123(%x119, %x120, %x122) /* ty=Tensor[(2), int32] */;
      let %x125: fn (Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p052: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        cast(%p052, dtype="int64") /* ty=Tensor[(2), int64] */
      };
      let %x126: Tensor[(2), int64] = %x125(%x122) /* ty=Tensor[(2), int64] */;
      let %x127: Tensor[(2), int32] = meta[relay.Constant][11] /* ty=Tensor[(2), int32] */;
      let %x128: fn (Tensor[(?, ?), float32], Tensor[(2), int32], Tensor[(2), int64], Tensor[(2), int32]) -> Tensor[(?, ?), float32] = fn (%p053: Tensor[(?, ?), float32], %p128: Tensor[(2), int32], %p215: Tensor[(2), int64], %p35: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.strided_slice(%p053, %p128, %p215, %p35, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
      };
      let %x129: Tensor[(?, ?), float32] = %x128(%x118, %x124, %x126, %x127) /* ty=Tensor[(?, ?), float32] */;
      let %x130: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p054: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p054, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x131: Tensor[(2), int32] = %x130(%x129) /* ty=Tensor[(2), int32] */;
      let %x132: fn (Tensor[(2), int32]) -> Tensor[(1), int64] = fn (%p055: Tensor[(2), int32], Primitive=1) -> Tensor[(1), int64] {
        %59 = take(%p055, 0 /* ty=int32 */, axis=0) /* ty=int32 */;
        %60 = expand_dims(%59, axis=0) /* ty=Tensor[(1), int32] */;
        cast(%60, dtype="int64") /* ty=Tensor[(1), int64] */
      };
      let %x133: Tensor[(1), int64] = %x132(%x131) /* ty=Tensor[(1), int64] */;
      let %x134: fn (Tensor[(1), int64], int64) -> Tensor[(2), int64] = fn (%p056: Tensor[(1), int64], %p129: int64, Primitive=1) -> Tensor[(2), int64] {
        %61 = expand_dims(%p129, axis=0) /* ty=Tensor[(1), int64] */;
        %62 = cast(%61, dtype="int64") /* ty=Tensor[(1), int64] */;
        %63 = (%p056, %62);
        concatenate(%63) /* ty=Tensor[(2), int64] */
      };
      let %x135: Tensor[(2), int64] = %x134(%x133, %x72) /* ty=Tensor[(2), int64] */;
      let %x136: fn (int32, Tensor[(2), int64]) -> Tensor[(?, ?), float32] = fn (%p057: int32, %p130: Tensor[(2), int64], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.full(%p057, %p130, shape=None, dtype="float32") /* ty=Tensor[(?, ?), float32] */
      };
      let %x137: Tensor[(?, ?), float32] = %x136(%x9, %x135) /* ty=Tensor[(?, ?), float32] */;
      let %x138: int32 = 0 /* ty=int32 */;
      let %x139: fn (Tensor[(1), int64], int64) -> Tensor[(2), int64] = fn (%p058: Tensor[(1), int64], %p131: int64, Primitive=1) -> Tensor[(2), int64] {
        %64 = subtract(300 /* ty=int64 */, %p131) /* ty=int64 */;
        %65 = expand_dims(%64, axis=0) /* ty=Tensor[(1), int64] */;
        %66 = cast(%65, dtype="int64") /* ty=Tensor[(1), int64] */;
        %67 = (%p058, %66);
        concatenate(%67) /* ty=Tensor[(2), int64] */
      };
      let %x140: Tensor[(2), int64] = %x139(%x133, %x82) /* ty=Tensor[(2), int64] */;
      let %x141: fn (int32, Tensor[(2), int64]) -> Tensor[(?, ?), float32] = fn (%p059: int32, %p132: Tensor[(2), int64], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.full(%p059, %p132, shape=None, dtype="float32") /* ty=Tensor[(?, ?), float32] */
      };
      let %x142: Tensor[(?, ?), float32] = %x141(%x138, %x140) /* ty=Tensor[(?, ?), float32] */;
      let %x143: fn (Tensor[(?, ?), float32], Tensor[(?, ?), float32], Tensor[(?, ?), float32]) -> Tensor[(?, ?), float32] = fn (%p060: Tensor[(?, ?), float32], %p133: Tensor[(?, ?), float32], %p216: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, ?), float32] {
        %68 = reshape(%p060, newshape=[0, 0]) /* ty=Tensor[(?, ?), float32] */;
        %69 = reshape(%p216, newshape=[0, 0]) /* ty=Tensor[(?, ?), float32] */;
        %70 = (%68, %p133, %69);
        concatenate(%70, axis=1) /* ty=Tensor[(?, ?), float32] */
      };
      let %x144: Tensor[(?, ?), float32] = %x143(%x137, %x129, %x142) /* ty=Tensor[(?, ?), float32] */;
      let %x145: Tensor[(2), bool] = meta[relay.Constant][12] /* ty=Tensor[(2), bool] */;
      let %x146: Tensor[(2), int32] = meta[relay.Constant][13] /* ty=Tensor[(2), int32] */;
      let %x147: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p061: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p061, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x148: Tensor[(2), int32] = %x147(%x144) /* ty=Tensor[(2), int32] */;
      let %x149: fn (Tensor[(2), bool], Tensor[(2), int32], Tensor[(2), int32]) -> Tensor[(2), int32] = fn (%p062: Tensor[(2), bool], %p134: Tensor[(2), int32], %p217: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
        %71 = cast_like(%p217, %p134) /* ty=Tensor[(2), int32] */;
        %72 = add(%p134, %71) /* ty=Tensor[(2), int32] */;
        where(%p062, %72, %p134) /* ty=Tensor[(2), int32] */
      };
      let %x150: Tensor[(2), int32] = %x149(%x145, %x146, %x148) /* ty=Tensor[(2), int32] */;
      let %x151: fn (Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p063: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        cast(%p063, dtype="int64") /* ty=Tensor[(2), int64] */
      };
      let %x152: Tensor[(2), int64] = %x151(%x148) /* ty=Tensor[(2), int64] */;
      let %x153: Tensor[(2), int32] = meta[relay.Constant][14] /* ty=Tensor[(2), int32] */;
      let %x154: fn (Tensor[(?, ?), float32], Tensor[(2), int32], Tensor[(2), int64], Tensor[(2), int32]) -> Tensor[(?, ?), float32] = fn (%p064: Tensor[(?, ?), float32], %p135: Tensor[(2), int32], %p218: Tensor[(2), int64], %p36: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.strided_slice(%p064, %p135, %p218, %p36, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
      };
      let %x155: Tensor[(?, ?), float32] = %x154(%x144, %x150, %x152, %x153) /* ty=Tensor[(?, ?), float32] */;
      let %x156: Tensor[(2), bool] = meta[relay.Constant][15] /* ty=Tensor[(2), bool] */;
      let %x157: Tensor[(2), int32] = meta[relay.Constant][16] /* ty=Tensor[(2), int32] */;
      let %x158: fn (Tensor[(?, ?), float32]) -> Tensor[(2), int32] = fn (%p065: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(2), int32] {
        shape_of(%p065, dtype="int32") /* ty=Tensor[(2), int32] */
      };
      let %x159: Tensor[(2), int32] = %x158(%x155) /* ty=Tensor[(2), int32] */;
      let %x160: fn (Tensor[(2), bool], Tensor[(2), int32], Tensor[(2), int32]) -> Tensor[(2), int32] = fn (%p066: Tensor[(2), bool], %p136: Tensor[(2), int32], %p219: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int32] {
        %73 = cast_like(%p219, %p136) /* ty=Tensor[(2), int32] */;
        %74 = add(%p136, %73) /* ty=Tensor[(2), int32] */;
        where(%p066, %74, %p136) /* ty=Tensor[(2), int32] */
      };
      let %x161: Tensor[(2), int32] = %x160(%x156, %x157, %x159) /* ty=Tensor[(2), int32] */;
      let %x162: fn (Tensor[(2), int32], Tensor[(1), int32], Tensor[(1), int32]) -> Tensor[(2), int32] = fn (%p067: Tensor[(2), int32], %p137: Tensor[(1), int32], %p220: Tensor[(1), int32], Primitive=1) -> Tensor[(2), int32] {
        scatter(%p067, %p137, %p220, meta[relay.attrs.ScatterAttrs][3]) /* ty=Tensor[(2), int32] */
      };
      let %x163: Tensor[(2), int32] = %x162(%x159, %x1, %x111);
      let %x164: fn (Tensor[(2), int32]) -> Tensor[(2), int64] = fn (%p068: Tensor[(2), int32], Primitive=1) -> Tensor[(2), int64] {
        cast(%p068, dtype="int64") /* ty=Tensor[(2), int64] */
      };
      let %x165: Tensor[(2), int64] = %x164(%x163) /* ty=Tensor[(2), int64] */;
      let %x166: Tensor[(2), int32] = meta[relay.Constant][17] /* ty=Tensor[(2), int32] */;
      let %x167: fn (Tensor[(?, ?), float32], Tensor[(2), int32], Tensor[(2), int64], Tensor[(2), int32]) -> Tensor[(?, ?), float32] = fn (%p069: Tensor[(?, ?), float32], %p138: Tensor[(2), int32], %p221: Tensor[(2), int64], %p37: Tensor[(2), int32], Primitive=1) -> Tensor[(?, ?), float32] {
        dyn.strided_slice(%p069, %p138, %p221, %p37, begin=None, end=None, strides=None) /* ty=Tensor[(?, ?), float32] */
      };
      let %x168: Tensor[(?, ?), float32] = %x167(%x155, %x161, %x165, %x166) /* ty=Tensor[(?, ?), float32] */;
      let %x169: fn (Tensor[(?, ?, ?), float32], Tensor[(?, ?), float32]) -> Tensor[(?, ?, ?), float32] = fn (%p070: Tensor[(?, ?, ?), float32], %p139: Tensor[(?, ?), float32], Primitive=1) -> Tensor[(?, ?, ?), float32] {
        %75 = expand_dims(%p139, axis=0) /* ty=Tensor[(1, ?, ?), float32] */;
        %76 = (%p070, %75);
        concatenate(%76) /* ty=Tensor[(?, ?, ?), float32] */
      };
      let %x170: Tensor[(?, ?, ?), float32] = %x169(%res_append.6, %x168) /* ty=Tensor[(?, ?, ?), float32] */;
      %77 = @lifted_name12992284627567120431(%x, %x1);
      let %x171: (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) = %77(%x8, %x170, %v7394, %v7286);
      %x171
    } else {
      let %x172: (int32, Tensor[(?, ?, ?), float32], Tensor[(?, 4), int64], Tensor[(?, 1, ?, ?), float32]) = (%i.1, %res_append.6, %v7394, %v7286);
      %x172
    };
    %x6
  }
}
